{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import _pickle as pickle\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "import cv2\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "import keras\n",
    "import tensorflow\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.applications import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Conv2D, Lambda,Activation,ZeroPadding2D, Conv2DTranspose, Add, Dense,MaxPool2D,Concatenate,Reshape,Embedding, LeakyReLU,Flatten,MaxPooling2D,Dropout, BatchNormalization,UpSampling2D,GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "# from tensorflow.keras.engine.input_layer import Input\n",
    "from keras.layers import merge\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.regularizers import l2\n",
    "import numpy.random as rng\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file,name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'wb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'wb')\n",
    "    pickle.dump(file, outfile)\n",
    "    outfile.close\n",
    "    \n",
    "def load(name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'rb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'rb')\n",
    "    file = pickle.load(outfile)\n",
    "    outfile.close\n",
    "    return file\n",
    "\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "SIZE = 84\n",
    "def bbox(img):\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "    return rmin, rmax, cmin, cmax\n",
    "\n",
    "def crop_resize(img0, size=SIZE, pad=16):\n",
    "    #crop a box around pixels large than the threshold \n",
    "    #some images contain line at the sides\n",
    "    ymin,ymax,xmin,xmax = bbox(img0[5:-5,5:-5] > 80)\n",
    "    #cropping may cut too much, so we need to add it back\n",
    "    xmin = xmin - 13 if (xmin > 13) else 0\n",
    "    ymin = ymin - 10 if (ymin > 10) else 0\n",
    "    xmax = xmax + 13 if (xmax < WIDTH - 13) else WIDTH\n",
    "    ymax = ymax + 10 if (ymax < HEIGHT - 10) else HEIGHT\n",
    "    img = img0[ymin:ymax,xmin:xmax]\n",
    "    #remove lo intensity pixels as noise\n",
    "    img[img < 28] = 0\n",
    "    lx, ly = xmax-xmin,ymax-ymin\n",
    "    l = max(lx,ly) + pad\n",
    "    #make sure that the aspect ratio is kept in rescaling\n",
    "    img = np.pad(img, [((l-ly)//2,), ((l-lx)//2,)], mode='constant')\n",
    "    return cv2.resize(img,(size,size)) /255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [\n",
    "    'train_image_data_0.parquet',\n",
    "    'train_image_data_1.parquet',\n",
    "    'train_image_data_2.parquet',\n",
    "    'train_image_data_3.parquet'\n",
    "]\n",
    "\n",
    "test = [\n",
    "    'test_image_data_0.parquet',\n",
    "    'test_image_data_1.parquet',\n",
    "    'test_image_data_2.parquet',\n",
    "    'test_image_data_3.parquet'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing and cropping the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "\n",
    "im = 255 - imageio.imread('./gr/0.png')[:,:,0]\n",
    "print(im.shape)\n",
    "\n",
    "HEIGHT = im.shape[0]\n",
    "WIDTH = im.shape[1]\n",
    "\n",
    "# plt.imshow(im, cmap = 'gray')\n",
    "plt.imshow(crop_resize(im), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_gr = {}\n",
    "for i in range(168):\n",
    "#     print(i)\n",
    "    im = 255 - imageio.imread('./gr/'+str(i)+'.png')[:,:,0]\n",
    "    HEIGHT = im.shape[0]\n",
    "    WIDTH = im.shape[1]\n",
    "    im = crop_resize(im)\n",
    "    dico_gr[i] = im\n",
    "    \n",
    "dico_cd = {}\n",
    "dico_cd[0] = np.zeros((84,84,))\n",
    "for i in range(1,7):\n",
    "#     print(i)\n",
    "    im = 255 - imageio.imread('./cd/'+str(i)+'.png')[:,:,0]\n",
    "    HEIGHT = im.shape[0]\n",
    "    WIDTH = im.shape[1]\n",
    "    im = crop_resize(im)\n",
    "    dico_cd[i] = im\n",
    "\n",
    "dico_vd = {}\n",
    "dico_vd[0] = np.zeros((84,84,))\n",
    "for i in range(1, 11):\n",
    "#     print(i)\n",
    "    im = 255 - imageio.imread('./vd/'+str(i)+'.png')[:,:,0]\n",
    "    HEIGHT = im.shape[0]\n",
    "    WIDTH = im.shape[1]\n",
    "    im = crop_resize(im)\n",
    "    dico_vd[i] = im\n",
    "    \n",
    "save((dico_gr, dico_cd, dico_vd), 'dico base images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "#     if i != 0:\n",
    "    df = pd.read_parquet(train[i])\n",
    "    \n",
    "    dataset = list(np.zeros(df.shape[0]))\n",
    "    ids = df['image_id'].values\n",
    "    \n",
    "    for j in tqdm(range(df.shape[0])):\n",
    "        img = 255 - df.iloc[j].values[1:].astype(np.uint8).reshape((137, 236))\n",
    "        img = crop_resize(img)\n",
    "        dataset[j] = img\n",
    "    \n",
    "    dataset = np.array(dataset)\n",
    "    \n",
    "    save((dataset, ids), 'train_set_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    df = pd.read_parquet(test[i])\n",
    "    \n",
    "    dataset = list(np.zeros(df.shape[0]))\n",
    "    ids = df['image_id'].values\n",
    "    \n",
    "    for j in tqdm(range(df.shape[0])):\n",
    "        img = 255 - df.iloc[j].values[1:].astype(np.uint8).reshape((137, 236))\n",
    "        img = crop_resize(img)\n",
    "        dataset[j] = img\n",
    "    \n",
    "    dataset = np.array(dataset)\n",
    "    \n",
    "    save((dataset, ids), 'test_set_'+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the preprocessed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, ids = load('train_set_0')\n",
    "\n",
    "for i in range(1,4):\n",
    "    dataset1, ids1 = load('train_set_'+str(i))\n",
    "    \n",
    "    dataset = np.concatenate([dataset, dataset1], axis = 0)\n",
    "    ids = np.concatenate([ids, ids1], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, ids = load('train_set_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset  = dataset.reshape((dataset.shape[0],84,84,1))\n",
    "# dataset = dataset[:200]\n",
    "\n",
    "labels = pd.read_csv('train.csv')\n",
    "\n",
    "labels.index = labels['image_id'].values\n",
    "\n",
    "GR = labels.loc[ids]['grapheme_root'].values\n",
    "VD = labels.loc[ids]['vowel_diacritic'].values\n",
    "CD = labels.loc[ids]['consonant_diacritic'].values\n",
    "\n",
    "gr = np_utils.to_categorical(GR)\n",
    "vd = np_utils.to_categorical(VD)\n",
    "cd = np_utils.to_categorical(CD)\n",
    "\n",
    "\n",
    "# (dico_gr, dico_cd, dico_vd) = load('dico base images')\n",
    "\n",
    "# def build_image(X, dico_X):\n",
    "#     Y = list(np.zeros(X.shape[0]))\n",
    "    \n",
    "#     for elt in range(len(X)):\n",
    "#         Y[elt] = dico_X[X[elt]]\n",
    "    \n",
    "#     Y = np.array(Y)\n",
    "#     return Y\n",
    "\n",
    "# GR1 = build_image(GR, dico_gr).reshape((dataset.shape[0],84,84,1))\n",
    "# VD1 = build_image(VD, dico_gr).reshape((dataset.shape[0],84,84,1))\n",
    "# CD1 = build_image(CD, dico_gr).reshape((dataset.shape[0],84,84,1))\n",
    "\n",
    "y = np.concatenate([gr, vd, cd], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    " \n",
    "class print_score(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.aucs = []\n",
    "        self.losses = []\n",
    " \n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    " \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        \n",
    "        y_pred = self.model.predict(X_test)\n",
    "        pred_gr = y_pred[:,:168]\n",
    "        pred_vd = y_pred[:,168:179]\n",
    "        pred_cd = y_pred[:, 179:]\n",
    "        \n",
    "        y_gr = y_test[:,:168]\n",
    "        y_vd = y_test[:,168:179]\n",
    "        y_cd = y_test[:, 179:]\n",
    "        \n",
    "        pred_gr = np.argmax(pred_gr, axis = 1)\n",
    "        pred_vd = np.argmax(pred_vd, axis = 1)\n",
    "        pred_cd = np.argmax(pred_cd, axis = 1)\n",
    "        \n",
    "        y_gr = np.argmax(y_gr, axis = 1)\n",
    "        y_vd = np.argmax(y_vd, axis = 1)\n",
    "        y_cd = np.argmax(y_cd, axis = 1)\n",
    "        \n",
    "        p_gr = recall_score(y_gr, pred_gr, average='macro')\n",
    "        p_vd = recall_score(y_vd, pred_vd, average='macro')\n",
    "        p_cd = recall_score(y_cd, pred_cd, average='macro')\n",
    "        \n",
    "        score = 0.5*p_gr + 0.25*p_vd + 0.25*p_cd\n",
    "\n",
    "        a_gr = accuracy_score(y_gr, pred_gr)\n",
    "        a_vd = accuracy_score(y_vd, pred_vd)\n",
    "        a_cd = accuracy_score(y_cd, pred_cd)\n",
    "    \n",
    "        print('recall scores : gr = '+str(p_gr)+' vd = '+str(p_vd)+' cd = '+str(p_cd))\n",
    "        print('global score is : '+str(score))\n",
    "        print('accuracy scores : gr = '+str(a_gr)+' vd = '+str(a_vd)+' cd = '+str(a_cd))        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.aucs.append(score)\n",
    "        print(score)\n",
    "        return\n",
    " \n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    " \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x226cf873f48>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0].reshape(84,84))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160672, 186)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gabri\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\gabri\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\gabri\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\gabri\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\gabri\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\gabri\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\gabri\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\gabri\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import resnet\n",
    "build = resnet.ResnetBuilder()\n",
    "model = build.build_resnet_18((1,84,84),186)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import densenet\n",
    "model_transfert = densenet.DenseNet121(include_top=False,input_shape=(84,84,1), weights = None  )\n",
    "\n",
    "inputs = model_transfert.input\n",
    "outputs = model_transfert.output\n",
    "outputs = GlobalAveragePooling2D(name='avg_pool')(outputs)\n",
    "outputs = Dense(186, activation='softmax', name='fc64')(outputs)\n",
    "model = Model(inputs=inputs,   outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import inception_v3\n",
    "\n",
    "model_transfert = inception_v3.InceptionV3(include_top=False,input_shape=(84,84,1), weights = None  )\n",
    "\n",
    "inputs = model_transfert.input\n",
    "outputs = model_transfert.output\n",
    "outputs = GlobalAveragePooling2D(name='avg_pool')(outputs)\n",
    "outputs = Dense(186, activation='softmax', name='fc64')(outputs)\n",
    "model = Model(inputs=inputs,   outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 84, 84, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 84, 84, 64)   640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 84, 84, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 84, 84, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 84, 84, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 84, 84, 64)   36928       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 84, 84, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 84, 84, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 84, 84, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 84, 84, 64)   0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 84, 84, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 84, 84, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 84, 84, 64)   36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 84, 84, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 84, 84, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 84, 84, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 84, 84, 64)   0           add_1[0][0]                      \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 84, 84, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 84, 84, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 42, 42, 128)  73856       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 42, 42, 128)  512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 42, 42, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 42, 42, 128)  8320        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 42, 42, 128)  147584      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 42, 42, 128)  0           conv2d_8[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 42, 42, 128)  512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 42, 42, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 42, 42, 128)  147584      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 42, 42, 128)  512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 42, 42, 128)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 42, 42, 128)  147584      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 42, 42, 128)  0           add_3[0][0]                      \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 42, 42, 128)  512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 42, 42, 128)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 21, 21, 256)  295168      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 21, 21, 256)  1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 21, 21, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 21, 21, 256)  33024       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 21, 21, 256)  590080      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 21, 21, 256)  0           conv2d_13[0][0]                  \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 21, 21, 256)  1024        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 21, 21, 256)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 21, 21, 256)  590080      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 21, 21, 256)  1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 21, 21, 256)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 21, 21, 256)  590080      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 21, 21, 256)  0           add_5[0][0]                      \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 21, 21, 256)  1024        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 21, 21, 256)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 11, 11, 512)  1180160     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 11, 11, 512)  2048        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 11, 11, 512)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 11, 11, 512)  131584      add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 11, 11, 512)  2359808     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 11, 11, 512)  0           conv2d_18[0][0]                  \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 11, 11, 512)  2048        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 11, 11, 512)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 11, 11, 512)  2359808     activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 11, 11, 512)  2048        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 11, 11, 512)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 11, 11, 512)  2359808     activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 11, 11, 512)  0           add_7[0][0]                      \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 11, 11, 512)  2048        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 11, 11, 512)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 512)    0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 186)          95418       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 11,273,914\n",
      "Trainable params: 11,266,106\n",
      "Non-trainable params: 7,808\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load('densenet121 - to train', 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gabri\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\gabri\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/30\n",
      "5021/5021 [==============================] - 851s 170ms/step - loss: 8.2011 - val_loss: 6.4082\n",
      "recall scores : gr = 0.6228256095866458 vd = 0.8308114785405714 cd = 0.8886957025026614\n",
      "global score is : 0.7412896000541311\n",
      "accuracy scores : gr = 0.7535102569209321 vd = 0.8479884485162318 cd = 0.9151563433578969\n",
      "0.7412896000541311\n",
      "Epoch 2/30\n",
      "5021/5021 [==============================] - 845s 168ms/step - loss: 5.3839 - val_loss: 5.1869\n",
      "recall scores : gr = 0.7562946432712098 vd = 0.9484870769300194 cd = 0.8896983402835988\n",
      "global score is : 0.8376936759390095\n",
      "accuracy scores : gr = 0.8274497112129058 vd = 0.9573541127265485 cd = 0.9610635331607249\n",
      "0.8376936759390095\n",
      "Epoch 3/30\n",
      "5021/5021 [==============================] - 845s 168ms/step - loss: 4.8625 - val_loss: 4.8373\n",
      "recall scores : gr = 0.8552683801313615 vd = 0.9521061895161204 cd = 0.913239754334149\n",
      "global score is : 0.8939706760282481\n",
      "accuracy scores : gr = 0.8873232423819957 vd = 0.9698267277434774 cd = 0.9577773351921928\n",
      "0.8939706760282481\n",
      "Epoch 4/30\n",
      "5021/5021 [==============================] - 842s 168ms/step - loss: 4.6053 - val_loss: 4.5911\n",
      "recall scores : gr = 0.8760470154324229 vd = 0.9663501922733605 cd = 0.9631179754546374\n",
      "global score is : 0.920390549648211\n",
      "accuracy scores : gr = 0.8996215893248357 vd = 0.9754779924317865 cd = 0.9747062338179645\n",
      "0.920390549648211\n",
      "Epoch 5/30\n",
      "5021/5021 [==============================] - 842s 168ms/step - loss: 4.4420 - val_loss: 4.4589\n",
      "recall scores : gr = 0.9171700366694262 vd = 0.9682557944943212 cd = 0.9592242252557569\n",
      "global score is : 0.9404550232722326\n",
      "accuracy scores : gr = 0.9274546903007369 vd = 0.9765236008763195 cd = 0.9759759012148974\n",
      "0.9404550232722326\n",
      "Epoch 6/30\n",
      "5021/5021 [==============================] - 841s 167ms/step - loss: 4.3211 - val_loss: 4.2556\n",
      "recall scores : gr = 0.916604825504467 vd = 0.9736511314088051 cd = 0.9616382935644067\n",
      "global score is : 0.9421247689955364\n",
      "accuracy scores : gr = 0.9340519816769568 vd = 0.9806064528978291 cd = 0.9805068711412069\n",
      "0.9421247689955364\n",
      "Epoch 7/30\n",
      "5021/5021 [==============================] - 842s 168ms/step - loss: 4.2240 - val_loss: 4.1637\n",
      "recall scores : gr = 0.9235484533226542 vd = 0.9716924938129403 cd = 0.9714071009421154\n",
      "global score is : 0.947549125350091\n",
      "accuracy scores : gr = 0.9420434176458873 vd = 0.9801832304321848 cd = 0.9820254929296953\n",
      "0.947549125350091\n",
      "Epoch 8/30\n",
      "5021/5021 [==============================] - 843s 168ms/step - loss: 4.1525 - val_loss: 4.1795\n",
      "recall scores : gr = 0.9271964435950505 vd = 0.9759597379544193 cd = 0.9703030684199986\n",
      "global score is : 0.9501639233911297\n",
      "accuracy scores : gr = 0.9409978092013543 vd = 0.9822495518820952 cd = 0.9813533160724955\n",
      "0.9501639233911297\n",
      "Epoch 9/30\n",
      "5021/5021 [==============================] - 843s 168ms/step - loss: 4.0947 - val_loss: 4.1737\n",
      "recall scores : gr = 0.9148024502293789 vd = 0.9725456956170241 cd = 0.9597198639231111\n",
      "global score is : 0.9404676149997232\n",
      "accuracy scores : gr = 0.9313632742481578 vd = 0.9771957777335192 cd = 0.9753286197968533\n",
      "0.9404676149997232\n",
      "Epoch 10/30\n",
      "5021/5021 [==============================] - 842s 168ms/step - loss: 4.0440 - val_loss: 4.1061\n",
      "recall scores : gr = 0.9229718347121489 vd = 0.9685723954137693 cd = 0.9541192796652932\n",
      "global score is : 0.9421588361258401\n",
      "accuracy scores : gr = 0.9361183031268672 vd = 0.9742083250348537 cd = 0.977320254929297\n",
      "0.9421588361258401\n",
      "Epoch 11/30\n",
      "5021/5021 [==============================] - 841s 168ms/step - loss: 4.0068 - val_loss: 4.0279\n",
      "recall scores : gr = 0.9338859507756477 vd = 0.9770804739218213 cd = 0.9736632108920649\n",
      "global score is : 0.9546288965912955\n",
      "accuracy scores : gr = 0.9441097390957977 vd = 0.9836188010356502 cd = 0.9821250746863175\n",
      "0.9546288965912955\n",
      "Epoch 12/30\n",
      " 101/5021 [..............................] - ETA: 12:50 - loss: 3.9524"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b2f6ce39609b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m history = model.fit_generator(aug.flow(X_train, y_train, batch_size=batch_size),\n\u001b[0;32m     38\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     epochs=epochs,verbose=1, callbacks = callbacks)\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# aug = ImageDataGenerator(rotation_range=10, zoom_range=0.15,\n",
    "#                          width_shift_range=0.1, height_shift_range=0.1, shear_range=0.1,\n",
    "#                          horizontal_flip=False, fill_mode=\"nearest\")\n",
    "\n",
    "# from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "aug = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=8,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            zoom_range = 0.15, # Randomly zoom image \n",
    "            width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=False,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "optimizer=SGD(lr=0.1)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=optimizer,#keras.optimizers.Adadelta(),\n",
    "#               metrics=['accuracy'])\n",
    "             )\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=0.001, verbose = 1),\n",
    "    EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=5, verbose=1, mode='auto', restore_best_weights = True),\n",
    "    print_score()\n",
    "]\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "\n",
    "history = model.fit_generator(aug.flow(X_train, y_train, batch_size=batch_size),\n",
    "    validation_data=(X_test, y_test), steps_per_epoch=len(X_train) // batch_size,\n",
    "    epochs=epochs,verbose=1, callbacks = callbacks)\n",
    "\n",
    "\n",
    "# history = model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, validation_data=(X_test, y_test),verbose=0, callbacks=[TQDMNotebookCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(model, 'resnet18 - altered - to_train', 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1415/5021 [=======>......................] - ETA: 9:34 - loss: 3.8598 - acc: 0.3721"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-5985a43ead48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m history = model.fit_generator(aug.flow(X_train, y_train, batch_size=batch_size),\n\u001b[0;32m     11\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     epochs=epochs,verbose=1, callbacks = callbacks)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer=SGD(lr=0.01)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=optimizer,#keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "history = model.fit_generator(aug.flow(X_train, y_train, batch_size=batch_size),\n",
    "    validation_data=(X_test, y_test), steps_per_epoch=len(X_train) // batch_size,\n",
    "    epochs=epochs,verbose=1, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=SGD(lr=0.001)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=optimizer,#keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "history = model.fit_generator(aug.flow(X_train, y_train, batch_size=batch_size),\n",
    "    validation_data=(X_test, y_test), steps_per_epoch=len(X_train) // batch_size,\n",
    "    epochs=epochs,verbose=1, callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred, axis = 1)\n",
    "\n",
    "Y_true = np.argmax(y_test, axis = 1)\n",
    "\n",
    "print(recall_score(Y_true, pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(X_test, y_test, model):\n",
    "    \n",
    "    from sklearn.metrics import recall_score\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    y_pred = model.predict(X_test)\n",
    "    pred_gr = y_pred[:,:168]\n",
    "    pred_vd = y_pred[:,168:179]\n",
    "    pred_cd = y_pred[:, 179:]\n",
    "        \n",
    "    y_gr = y_test[:,:168]\n",
    "    y_vd = y_test[:,168:179]\n",
    "    y_cd = y_test[:, 179:]\n",
    "        \n",
    "    pred_gr = np.argmax(pred_gr, axis = 1)\n",
    "    pred_vd = np.argmax(pred_vd, axis = 1)\n",
    "    pred_cd = np.argmax(pred_cd, axis = 1)\n",
    "        \n",
    "    y_gr = np.argmax(y_gr, axis = 1)\n",
    "    y_vd = np.argmax(y_vd, axis = 1)\n",
    "    y_cd = np.argmax(y_cd, axis = 1)\n",
    "        \n",
    "    p_gr = recall_score(y_gr, pred_gr, average='macro')\n",
    "    p_vd = recall_score(y_vd, pred_vd, average='macro')\n",
    "    p_cd = recall_score(y_cd, pred_cd, average='macro')\n",
    "    \n",
    "    a_gr = accuracy_score(y_gr, pred_gr)\n",
    "    a_vd = accuracy_score(y_vd, pred_vd)\n",
    "    a_cd = accuracy_score(y_cd, pred_cd)\n",
    "        \n",
    "    score = 0.5*p_gr + 0.25*p_vd + 0.25*p_cd\n",
    "    \n",
    "    print('recall scores : gr = '+str(p_gr)+' vd = '+str(p_vd)+' cd = '+str(p_cd))\n",
    "    print('global score is : '+str(score))\n",
    "    \n",
    "    print('accuracy scores : gr = '+str(a_gr)+' vd = '+str(a_vd)+' cd = '+str(a_cd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_score(X_test, y_test, models, weights):\n",
    "    \n",
    "    from sklearn.metrics import recall_score\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    preds = [[] for i in range(len(models))]\n",
    "    for j in range(len(models)):\n",
    "        print(' model '+str(j))\n",
    "        model = load(models[j], 'models')\n",
    "            \n",
    "        pred = model.predict(X_test)\n",
    "        print(pred.shape)\n",
    "#       print(pred)\n",
    "        preds[j] = pred\n",
    "        \n",
    "    preds = np.array(preds)\n",
    "    \n",
    "    print(preds.shape)\n",
    "    \n",
    "    pred = weights[0] * preds[0]\n",
    "    for i in range(1,len(models)):\n",
    "        pred += preds[i] * weights[i]\n",
    "    \n",
    "    y_pred = pred\n",
    "#     y_pred = model.predict(X_test)\n",
    "    pred_gr = y_pred[:,:168]\n",
    "    pred_vd = y_pred[:,168:179]\n",
    "    pred_cd = y_pred[:, 179:]\n",
    "        \n",
    "    y_gr = y_test[:,:168]\n",
    "    y_vd = y_test[:,168:179]\n",
    "    y_cd = y_test[:, 179:]\n",
    "        \n",
    "    pred_gr = np.argmax(pred_gr, axis = 1)\n",
    "    pred_vd = np.argmax(pred_vd, axis = 1)\n",
    "    pred_cd = np.argmax(pred_cd, axis = 1)\n",
    "        \n",
    "    y_gr = np.argmax(y_gr, axis = 1)\n",
    "    y_vd = np.argmax(y_vd, axis = 1)\n",
    "    y_cd = np.argmax(y_cd, axis = 1)\n",
    "        \n",
    "    p_gr = recall_score(y_gr, pred_gr, average='macro')\n",
    "    p_vd = recall_score(y_vd, pred_vd, average='macro')\n",
    "    p_cd = recall_score(y_cd, pred_cd, average='macro')\n",
    "    \n",
    "    a_gr = accuracy_score(y_gr, pred_gr)\n",
    "    a_vd = accuracy_score(y_vd, pred_vd)\n",
    "    a_cd = accuracy_score(y_cd, pred_cd)\n",
    "        \n",
    "    score = 0.5*p_gr + 0.25*p_vd + 0.25*p_cd\n",
    "    \n",
    "    print('recall scores : gr = '+str(p_gr)+' vd = '+str(p_vd)+' cd = '+str(p_cd))\n",
    "    print('global score is : '+str(score))\n",
    "    \n",
    "    print('accuracy scores : gr = '+str(a_gr)+' vd = '+str(a_vd)+' cd = '+str(a_cd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'resnet18',\n",
    "    'densenet121'\n",
    "]\n",
    "\n",
    "weights = [\n",
    "    0.5,\n",
    "    0.5\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_score(X_test, y_test, models, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load('resnet18', 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall scores : gr = 0.9482916049245819 vd = 0.9829679880214762 cd = 0.9808181731698694\n",
      "global score is : 0.9650923427601273\n",
      "accuracy scores : gr = 0.9591216889065923 vd = 0.9879257120095598 cd = 0.987427803226449\n"
     ]
    }
   ],
   "source": [
    "score(X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
