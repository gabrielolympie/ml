{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "potential-visibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-birthday",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.saved_model.load('./1611385245')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-aberdeen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-romantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(onnx.load_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx_tf.backend import prepare\n",
    "\n",
    "onnx_model = onnx.load_model(\"./1611385245/saved_model.pb\")  # load onnx model\n",
    "# output = prepare(onnx_model).run(input)  # run the loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-learning",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(onnx.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dominican-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflowjs as tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vocal-induction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module tensorflowjs.read_weights in tensorflowjs:\n",
      "\n",
      "NAME\n",
      "    tensorflowjs.read_weights - Read weights stored in TensorFlow.js-format binary files.\n",
      "\n",
      "FUNCTIONS\n",
      "    decode_weights(weights_manifest, data_buffers, flatten=False)\n",
      "        Load weight values from buffer(s) according to a weights manifest.\n",
      "        \n",
      "        Args:\n",
      "          weights_manifest: A TensorFlow.js-format weights manifest (a JSON array).\n",
      "          data_buffers: A buffer or a `list` of buffers containing the weights values\n",
      "            in binary format, concatenated in the order specified in\n",
      "            `weights_manifest`. If a `list` of buffers, the length of the `list`\n",
      "            must match the length of `weights_manifest`. A single buffer is\n",
      "            interpreted as a `list` of one buffer and is valid only if the length of\n",
      "            `weights_manifest` is `1`.\n",
      "          flatten: Whether all the weight groups in the return value are to be\n",
      "            flattened as a single weight groups. Default: `False`.\n",
      "        \n",
      "        Returns:\n",
      "          If `flatten` is `False`, a `list` of weight groups. Each group is an array\n",
      "          of weight entries. Each entry is a dict that maps a unique name to a numpy\n",
      "          array, for example:\n",
      "              entry = {\n",
      "                'name': 'weight1',\n",
      "                'data': np.array([1, 2, 3], 'float32')\n",
      "              }\n",
      "        \n",
      "              Weights groups would then look like:\n",
      "              weight_groups = [\n",
      "                [group_0_entry1, group_0_entry2],\n",
      "                [group_1_entry1, group_1_entry2],\n",
      "              ]\n",
      "          If `flatten` is `True`, returns a single weight group.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: if the lengths of `weights_manifest` and `data_buffers` do not\n",
      "            match.\n",
      "    \n",
      "    read_weights(weights_manifest, base_path, flatten=False)\n",
      "        Load weight values according to a TensorFlow.js weights manifest.\n",
      "        \n",
      "        Args:\n",
      "          weights_manifest: A TensorFlow.js-format weights manifest (a JSON array).\n",
      "          base_path: Base path prefix for the weights files.\n",
      "          flatten: Whether all the weight groups in the return value are to be\n",
      "            flattened as a single weights group. Default: `False`.\n",
      "        \n",
      "        Returns:\n",
      "          If `flatten` is `False`, a `list` of weight groups. Each group is an array\n",
      "          of weight entries. Each entry is a dict that maps a unique name to a numpy\n",
      "          array, for example:\n",
      "              entry = {\n",
      "                'name': 'weight1',\n",
      "                'data': np.array([1, 2, 3], 'float32')\n",
      "              }\n",
      "        \n",
      "              Weights groups would then look like:\n",
      "              weight_groups = [\n",
      "                [group_0_entry1, group_0_entry2],\n",
      "                [group_1_entry1, group_1_entry2],\n",
      "              ]\n",
      "          If `flatten` is `True`, returns a single weight group.\n",
      "\n",
      "DATA\n",
      "    STRING_LENGTH_DTYPE = dtype('<u4')\n",
      "    STRING_LENGTH_NUM_BYTES = 4\n",
      "    absolute_import = _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0...\n",
      "    division = _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192...\n",
      "    print_function = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0)...\n",
      "\n",
      "FILE\n",
      "    c:\\users\\gabri\\appdata\\roaming\\python\\python37\\site-packages\\tensorflowjs\\read_weights.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tfjs.read_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "southwest-friend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module tensorflowjs.converters.tf_saved_model_conversion_v2 in tensorflowjs.converters:\n",
      "\n",
      "NAME\n",
      "    tensorflowjs.converters.tf_saved_model_conversion_v2 - Convert Tensorflow SavedModel to TensorFlow.js web format.\n",
      "\n",
      "FUNCTIONS\n",
      "    convert_tf_frozen_model(frozen_model_path, output_node_names, output_dir, quantization_dtype_map=None, skip_op_check=False, strip_debug_ops=False, weight_shard_size_bytes=4194304, experiments=False, metadata=None)\n",
      "        Convert frozen model and check the model compatibility with Tensorflow.js.\n",
      "        Optimize and convert the model to Tensorflow.js format, when the model passes\n",
      "        the compatiblity check.\n",
      "        Args:\n",
      "          frozen_model_path: string The path to frozen model.\n",
      "          output_node_names: string The names of the output nodes, comma separated.\n",
      "          output_dir: string The name of the output directory. The directory\n",
      "            will consist of\n",
      "            - a file named 'model.json'\n",
      "            - possibly sharded binary weight files.\n",
      "          quantization_dtype_map: A mapping from dtype\n",
      "            (`uint8`, `uint16`, `float16`) to weights names. The weight mapping\n",
      "            supports wildcard substitution.\n",
      "          skip_op_check: Bool whether to skip the op check.\n",
      "          strip_debug_ops: Bool whether to strip debug ops.\n",
      "          weight_shard_size_bytes: Shard size (in bytes) of the weight files.\n",
      "            The size of each weight file will be <= this value.\n",
      "          experiments: Bool enable experimental features.\n",
      "          metadata: User defined metadata map.\n",
      "    \n",
      "    convert_tf_hub_module(module_handle, output_dir, signature='default', saved_model_tags='serve', quantization_dtype_map=None, skip_op_check=False, strip_debug_ops=False, weight_shard_size_bytes=4194304, control_flow_v2=False, experiments=False, metadata=None)\n",
      "        Conversion for TF Hub modules V1 and V2.\n",
      "        \n",
      "        See convert_tf_hub_module and convert_tf_saved_model.\n",
      "        \n",
      "        Args:\n",
      "          module_path: string Path to the module.\n",
      "          output_dir: string The name of the output directory. The directory\n",
      "            will consist of\n",
      "            - a file named 'model.json'\n",
      "            - possibly sharded binary weight files.\n",
      "          signature: string Signature to load.\n",
      "          saved_model_tags: tags of the GraphDef to load. Defaults to ''.\n",
      "          quantization_dtype_map: A mapping from dtype\n",
      "            (`uint8`, `uint16`, `float16`) to weights names. The weight mapping\n",
      "            supports wildcard substitution.\n",
      "          skip_op_check: Bool whether to skip the op check.\n",
      "          strip_debug_ops: Bool whether to strip debug ops.\n",
      "          weight_shard_size_bytes: Shard size (in bytes) of the weight files.\n",
      "            The size of each weight file will be <= this value.\n",
      "          control_flow_v2: Bool whether to enable control flow v2 ops.\n",
      "          experiments: Bool enable experimental features.\n",
      "          metadata: User defined metadata map.\n",
      "    \n",
      "    convert_tf_hub_module_v1(module_path, output_dir, signature='default', quantization_dtype_map=None, skip_op_check=False, strip_debug_ops=False, weight_shard_size_bytes=4194304, experiments=False, metadata=None)\n",
      "        Freeze the TF-Hub module and check compatibility with Tensorflow.js.\n",
      "        \n",
      "        Optimize and convert the TF-Hub module to Tensorflow.js format, if it passes\n",
      "        the compatiblity check.\n",
      "        \n",
      "        Args:\n",
      "          module_path: string Path to the module.\n",
      "          output_dir: string The name of the output directory. The directory\n",
      "            will consist of\n",
      "            - a file named 'model.json'\n",
      "            - possibly sharded binary weight files.\n",
      "          signature: string Signature to load.\n",
      "          quantization_dtype_map: A mapping from dtype\n",
      "            (`uint8`, `uint16`, `float16`) to weights names. The weight mapping\n",
      "            supports wildcard substitution.\n",
      "          skip_op_check: Bool whether to skip the op check.\n",
      "          strip_debug_ops: Bool whether to strip debug ops.\n",
      "          weight_shard_size_bytes: Shard size (in bytes) of the weight files.\n",
      "            The size of each weight file will be <= this value.\n",
      "          experiments: Bool enable experimental features.\n",
      "          metadata: User defined metadata map.\n",
      "    \n",
      "    convert_tf_saved_model(saved_model_dir, output_dir, signature_def='serving_default', saved_model_tags='serve', quantization_dtype_map=None, skip_op_check=False, strip_debug_ops=False, weight_shard_size_bytes=4194304, control_flow_v2=False, experiments=False, metadata=None)\n",
      "        Freeze the SavedModel and check the model compatibility with Tensorflow.js.\n",
      "        \n",
      "        Optimize and convert the model to Tensorflow.js format, when the model passes\n",
      "        the compatiblity check.\n",
      "        \n",
      "        Args:\n",
      "          saved_model_dir: string The saved model directory.\n",
      "          : string The names of the output nodes, comma separated.\n",
      "          output_dir: string The name of the output directory. The directory\n",
      "            will consist of\n",
      "            - a file named 'model.json'\n",
      "            - possibly sharded binary weight files.\n",
      "          signature_def: string Tagset of the SignatureDef to load. Defaults to\n",
      "            'serving_default'.\n",
      "          saved_model_tags: tags of the GraphDef to load. Defaults to 'serve'.\n",
      "          quantization_dtype_map: A mapping from dtype\n",
      "            (`uint8`, `uint16`, `float16`) to weights names. The weight mapping\n",
      "            supports wildcard substitution.\n",
      "          skip_op_check: Bool whether to skip the op check.\n",
      "          strip_debug_ops: Bool whether to strip debug ops.\n",
      "          weight_shard_size_bytes: Shard size (in bytes) of the weight files.\n",
      "            The size of each weight file will be <= this value.\n",
      "          control_flow_v2: Bool whether to enable control flow v2 ops.\n",
      "          experiments: Bool enable experimental features.\n",
      "          metadata: User defined metadata map.\n",
      "    \n",
      "    extract_const_nodes(nodes)\n",
      "        Takes a list of nodes and extract the weights. Return weight manifest\n",
      "        object.\n",
      "        \n",
      "        Args:\n",
      "          nodes: list of tf.NodeDef TensorFlow NodeDef proto object.\n",
      "    \n",
      "    extract_weights(graph_def, output_graph, tf_version, signature_def, quantization_dtype_map=None, weight_shard_size_bytes=4194304, initializer_graph_def=None, metadata=None)\n",
      "        Takes a Python GraphDef object and extract the weights.\n",
      "        \n",
      "        Args:\n",
      "          graph_def: tf.GraphDef TensorFlow GraphDef proto object, which represents\n",
      "            the model topology.\n",
      "          tf_version: Tensorflow version of the input graph.\n",
      "          signature_def: the SignatureDef of the inference graph.\n",
      "          quantization_dtype_map: A mapping from dtype\n",
      "            (`uint8`, `uint16`, `float16`) to weights names. The weight mapping\n",
      "            compression. Only np.uint8 and np.uint16 are supported.\n",
      "            supports wildcard substitution.\n",
      "          weight_shard_size_bytes: Shard size (in bytes) of the weight files.\n",
      "            The size of each weight file will be <= this value.\n",
      "          initializer_graph_def: tf.GraphDef proto object for initializer graph.\n",
      "          metadata: User defined metadata map.\n",
      "    \n",
      "    get_cluster()\n",
      "        Grappler optimization configuration for GPU.\n",
      "    \n",
      "    load_and_initialize_hub_module(module_path, signature='default')\n",
      "        Loads graph of a TF-Hub module and initializes it into a session.\n",
      "        \n",
      "        Args:\n",
      "          module_path: string Path to TF-Hub module.\n",
      "          signature: string Signature to use when creating the apply graph.\n",
      "        \n",
      "        Return:\n",
      "          graph: tf.Graph Graph of the module.\n",
      "          session: tf.Session Session with initialized variables and tables.\n",
      "          inputs: dict Dictionary of input tensors.\n",
      "          outputs: dict Dictionary of output tensors.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If signature contains a SparseTensor on input or output.\n",
      "    \n",
      "    load_graph(graph_filename)\n",
      "        Loads GraphDef. Returns Python Graph object.\n",
      "        \n",
      "        Args:\n",
      "          graph_filename: string File name for the frozen graph.\n",
      "    \n",
      "    optimize_graph(graph, signature_def, output_graph, tf_version, quantization_dtype_map=None, skip_op_check=False, strip_debug_ops=False, weight_shard_size_bytes=4194304, experiments=False, initializer_graph=None, metadata=None)\n",
      "        Takes a Python Graph object and optimizes the graph.\n",
      "        \n",
      "        Args:\n",
      "          graph: The frozen graph to optimize.\n",
      "          signature_def: the SignatureDef of the inference graph.\n",
      "          output_graph: The location of the output graph.\n",
      "          tf_version: Tensorflow version of the input graph.\n",
      "          quantization_dtype_map: A mapping from dtype\n",
      "            (`uint8`, `uint16`, `float16`) to weights names. The weight mapping\n",
      "            supports wildcard substitution.\n",
      "          skip_op_check: Bool whether to skip the op check.\n",
      "          strip_debug_ops: Bool whether to strip debug ops.\n",
      "          weight_shard_size_bytes: Shard size (in bytes) of the weight files.\n",
      "            The size of each weight file will be <= this value.\n",
      "          initializer_graph: The frozen graph for initializers.\n",
      "          metadata: User defined metadata map.\n",
      "    \n",
      "    validate(nodes, skip_op_check, strip_debug_ops)\n",
      "        Validate if the node's op is compatible with TensorFlow.js.\n",
      "        \n",
      "        Args:\n",
      "          nodes: tf.NodeDef TensorFlow NodeDef objects from GraphDef.\n",
      "          skip_op_check: Bool whether to skip the op check.\n",
      "          strip_debug_ops: Bool whether to allow unsupported debug ops.\n",
      "    \n",
      "    write_artifacts(topology, weights, output_graph, tf_version, signature_def, quantization_dtype_map=None, weight_shard_size_bytes=4194304, initializer_graph_def=None, metadata=None)\n",
      "        Writes weights and topology to the output_dir.\n",
      "        \n",
      "        If `topology` is Falsy (e.g., `None`), only emit weights to output_dir.\n",
      "        \n",
      "        Args:\n",
      "          topology: tf.GraphDef TensorFlow GraphDef proto object, which represents\n",
      "            the model topology.\n",
      "          weights: an array of weight groups (as defined in tfjs write_weights).\n",
      "          output_graph: the output file name to hold all the contents.\n",
      "          tf_version: Tensorflow version of the input graph.\n",
      "          signature_def: the SignatureDef of the inference graph.\n",
      "          quantization_dtype_map: A mapping from dtype\n",
      "            (`uint8`, `uint16`, `float16`) to weights names. The weight mapping\n",
      "            supports wildcard substitution.\n",
      "          weight_shard_size_bytes: Shard size (in bytes) of the weight files.\n",
      "            The size of each weight file will be <= this value.\n",
      "          initializer_graph_def: tf.GraphDef proto object for initializer graph.\n",
      "          metadata: User defined metadata map.\n",
      "\n",
      "DATA\n",
      "    CLEARED_TENSOR_FIELDS = ('tensor_content', 'half_val', 'float_val', 'd...\n",
      "    absolute_import = _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0...\n",
      "    division = _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192...\n",
      "    print_function = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0)...\n",
      "\n",
      "FILE\n",
      "    c:\\users\\gabri\\appdata\\roaming\\python\\python37\\site-packages\\tensorflowjs\\converters\\tf_saved_model_conversion_v2.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tfjs.converters.tf_saved_model_conversion_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "powerful-emphasis",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Converting GraphDef to Graph has failed. The binary trying to import the GraphDef was built when GraphDef version was 440. The GraphDef was produced by a binary built when GraphDef version was 642. The difference between these versions is larger than TensorFlow's forward compatibility guarantee. The following error might be due to the binary trying to import the GraphDef being too old: Op type not registered 'DecisionTreeEnsembleResourceHandleOp' in binary running on DESKTOP-S7BFJ3A. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-93196b6cabe9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtfjs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_saved_model_conversion_v2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_tf_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./1611385245'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./output'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflowjs\\converters\\tf_saved_model_conversion_v2.py\u001b[0m in \u001b[0;36mconvert_tf_saved_model\u001b[1;34m(saved_model_dir, output_dir, signature_def, saved_model_tags, quantization_dtype_map, skip_op_check, strip_debug_ops, weight_shard_size_bytes, control_flow_v2, experiments, metadata)\u001b[0m\n\u001b[0;32m    558\u001b[0m     \u001b[0msaved_model_tags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaved_model_tags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m   \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaved_model_tags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m   \u001b[0m_check_signature_in_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature_def\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflowjs\\converters\\tf_saved_model_conversion_v2.py\u001b[0m in \u001b[0;36m_load_model\u001b[1;34m(saved_model_dir, saved_model_tags)\u001b[0m\n\u001b[0;32m    506\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msaved_model_tags\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m       \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaved_model_tags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m       \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaved_model_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m   \"\"\"\n\u001b[1;32m--> 603\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload_internal\u001b[1;34m(export_dir, tags, options, loader_cls)\u001b[0m\n\u001b[0;32m    647\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m       \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_v1_in_v2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m       \u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_debug_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdebug_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\load_v1_in_v2.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(export_dir, tags)\u001b[0m\n\u001b[0;32m    261\u001b[0m   \u001b[1;34m\"\"\"Load a v1-style SavedModel as an object.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m   \u001b[0mloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_EagerSavedModelLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\load_v1_in_v2.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, tags)\u001b[0m\n\u001b[0;32m    207\u001b[0m     wrapped = wrap_function.wrap_function(\n\u001b[0;32m    208\u001b[0m         \u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_graph_returns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         signature=[])\n\u001b[0m\u001b[0;32m    210\u001b[0m     \u001b[0msaver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_graph_returns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[0mrestore_from_saver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extract_saver_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\wrap_function.py\u001b[0m in \u001b[0;36mwrap_function\u001b[1;34m(fn, signature, name)\u001b[0m\n\u001b[0;32m    626\u001b[0m           \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m           \u001b[0madd_control_dependencies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m           collections={}),\n\u001b[0m\u001b[0;32m    629\u001b[0m       \u001b[0mvariable_holder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mholder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m       signature=signature)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\wrap_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_with_variable_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_variable_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\wrap_function.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mvariable_scope\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_creator_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\load_v1_in_v2.py\u001b[0m in \u001b[0;36mload_graph\u001b[1;34m(self, returns, meta_graph_def)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     saver, _ = tf_saver._import_meta_graph_with_return_elements(\n\u001b[1;32m---> 90\u001b[1;33m         meta_graph_def)\n\u001b[0m\u001b[0;32m     91\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[0mreturns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36m_import_meta_graph_with_return_elements\u001b[1;34m(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m           \u001b[0mimport_scope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1485\u001b[0m           \u001b[0mreturn_elements\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_elements\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1486\u001b[1;33m           **kwargs))\n\u001b[0m\u001b[0;32m   1487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1488\u001b[0m   saver = _create_saver_from_imported_meta_graph(meta_graph_def, import_scope,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\u001b[0m in \u001b[0;36mimport_scoped_meta_graph_with_return_elements\u001b[1;34m(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements)\u001b[0m\n\u001b[0;32m    797\u001b[0m         \u001b[0minput_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m         \u001b[0mproducer_op_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproducer_op_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 799\u001b[1;33m         return_elements=return_elements)\n\u001b[0m\u001b[0;32m    800\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m     \u001b[1;31m# TensorFlow versions before 1.9 (not inclusive) exported SavedModels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 instructions)\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\u001b[0m in \u001b[0;36mimport_graph_def\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    403\u001b[0m       \u001b[0mreturn_elements\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_elements\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m       producer_op_list=producer_op_list)\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\u001b[0m in \u001b[0;36m_import_graph_def_internal\u001b[1;34m(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list)\u001b[0m\n\u001b[0;32m    495\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         results = c_api.TF_GraphImportGraphDefWithResults(\n\u001b[1;32m--> 497\u001b[1;33m             graph._c_graph, serialized, options)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    498\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mScopedTFImportGraphDefResults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Converting GraphDef to Graph has failed. The binary trying to import the GraphDef was built when GraphDef version was 440. The GraphDef was produced by a binary built when GraphDef version was 642. The difference between these versions is larger than TensorFlow's forward compatibility guarantee. The following error might be due to the binary trying to import the GraphDef being too old: Op type not registered 'DecisionTreeEnsembleResourceHandleOp' in binary running on DESKTOP-S7BFJ3A. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed."
     ]
    }
   ],
   "source": [
    "tfjs.converters.tf_saved_model_conversion_v2.convert_tf_saved_model('./1611385245', './output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-bargain",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
