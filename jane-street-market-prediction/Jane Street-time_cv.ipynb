{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: GeForce RTX 2070, compute capability 7.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import _pickle as pickle\n",
    "import gc\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import optuna\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from hyperopt import fmin, tpe, hp\n",
    "\n",
    "# import tensorflow as tf\n",
    "def save(file,name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'wb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'wb')\n",
    "    pickle.dump(file, outfile, protocol=4)\n",
    "    outfile.close\n",
    "    \n",
    "def load(name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'rb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'rb')\n",
    "    file = pickle.load(outfile)\n",
    "    outfile.close\n",
    "    return file\n",
    "\n",
    "pd.set_option('display.max_columns', 150)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)]\n",
    "            )\n",
    "logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "# policy = mixed_precision.Policy('float32')\n",
    "mixed_precision.set_policy(policy)\n",
    "\n",
    "def utility_metric(date,weights, resp, action):\n",
    "    import numpy as np\n",
    "    p = []\n",
    "    for i in np.unique(date):\n",
    "        wi = weights[date == i]\n",
    "        ri = resp[date == i]\n",
    "        ai = action[date == i]\n",
    "        pi = np.sum(wi * ri * ai)\n",
    "        p.append(pi)\n",
    "    p = np.array(p)\n",
    "    \n",
    "    nt = np.unique(date).shape[0]\n",
    "#     print(nt)\n",
    "    sp = np.sum(p)\n",
    "    normp = np.sqrt(np.sum(np.square(p)))\n",
    "    t = (sp / normp) * np.sqrt(250/nt)\n",
    "    u = min(max(t,0), 6) * sp\n",
    "    return u\n",
    "    \n",
    "\n",
    "def build_model(parameters):\n",
    "    inputs = tf.keras.Input(shape = (131,))\n",
    "    if parameters['norm']:\n",
    "        x = tf.keras.layers.experimental.preprocessing.Normalization()(inputs)\n",
    "    else:\n",
    "        x = inputs\n",
    "        \n",
    "    for block in range(parameters['n_blocks']):\n",
    "        for n in range(parameters['n_dense_per_block']):\n",
    "            x = tf.keras.layers.Dense(parameters['dense_shape'][block], name = 'block_'+str(block)+'_dense_'+str(n))(x)\n",
    "        if parameters['normalization'][block]:\n",
    "            x = tf.keras.layers.BatchNormalization(name =  'block_'+str(block)+'_batch_norm')(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        tf.keras.layers.Dropout(parameters['dropouts'][block], name =  'block_'+str(block)+'_dropout')(x)\n",
    "    x = tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'classification_head')(x)\n",
    "    model = tf.keras.Model(inputs, x)\n",
    "    model.compile(  loss = 'binary_crossentropy',\n",
    "                    optimizer = tf.keras.optimizers.Adam(parameters['lr']),\n",
    "                    metrics = ['accuracy', 'AUC'])\n",
    "    return model\n",
    "\n",
    "def get_fold(fold_number, X_train, y_train, date_train, weights_train):\n",
    "    filters = (date_train >= 44*fold_number)&(date_train < 44*(fold_number+1))\n",
    "    filters = np.invert(filters)\n",
    "    Xt, Xv, Yt, Yv = X_train[filters], X_train[np.invert(filters)], y_train[filters], y_train[np.invert(filters)]\n",
    "    datet, datev, weightst, weightsv = date_train[filters], date_train[np.invert(filters)], weights_train[filters], weights_train[np.invert(filters)]\n",
    "    sw = abs((Yt * weightst)) + 1\n",
    "    yt, yv = (Yt > 0)*1, (Yv > 0)*1\n",
    "    return Xt, Xv, yt, yv, Yt, Yv, datet, datev, weightst, weightsv, sw\n",
    "\n",
    "def train(model, parameters, Xt, Xv, yt, yv, sw):\n",
    "    sample_weight = sw if parameters['use_sample_weights'] else None\n",
    "    \n",
    "    epochs = 2\n",
    "    early = EarlyStopping(monitor='val_auc', min_delta=0.0001, patience=8, verbose=1, \n",
    "                                                mode='max', restore_best_weights=True)\n",
    "\n",
    "    reduce = ReduceLROnPlateau(monitor='val_auc', factor=0.1, patience=3, verbose=1, \n",
    "                               mode='max', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "    callbacks =[early, reduce]\n",
    "    \n",
    "    history = model.fit(Xt, yt, validation_data = (Xv, yv), \n",
    "                  batch_size=parameters['batch_size'], epochs=epochs, callbacks = callbacks,\n",
    "                           sample_weight = sample_weight, verbose = 2)\n",
    "    sc = np.max(history.history['val_auc'])\n",
    "    return model, sc\n",
    "\n",
    "def make_experiment(fold_number, n_trials = 100):\n",
    "    try:\n",
    "        os.mkdir('./time_cv_ensembling/'+str(fold_number))\n",
    "    except:\n",
    "        1\n",
    "    \n",
    "    print(\"Loading Data\")\n",
    "    (X_train, X_test, y_train, y_test, date_train, date_test, weights_train, weights_test) = load('splitted_dataset')\n",
    "    \n",
    "    X_train = X_train.values\n",
    "    X_test = X_test.values\n",
    "    y_test_cat = (y_test > 0)*1\n",
    "    \n",
    "    print(\"Loading Fold\")\n",
    "    Xt, Xv, yt, yv, Yt, Yv, datet, datev, weightst, weightsv, sw = get_fold(fold_number, X_train, y_train, date_train, weights_train)\n",
    "    del X_train\n",
    "    del y_train\n",
    "    gc.collect()\n",
    "    \n",
    "    print(Xt.shape, yt.shape, Yt.shape,datet.shape, weightst.shape, sw.shape)\n",
    "    print(Xv.shape, yv.shape, Yv.shape,datev.shape, weightsv.shape)\n",
    "    print(X_test.shape, y_test_cat.shape, y_test.shape,date_test.shape, weights_test.shape)\n",
    "    \n",
    "    print(\"Launching study\")\n",
    "    study = optuna.create_study(direction = 'maximize')\n",
    "    study.optimize(get_objective((Xt, Xv, yt, yv, Yt, Yv, datet, datev, weightst, weightsv, sw, X_test, y_test, y_test_cat,date_test, weights_test, fold_number)), n_trials= n_trials)\n",
    "    print(\"Study ended\")\n",
    "\n",
    "def get_objective(data):\n",
    "    def objective(trial, data = data):\n",
    "        assert data is not None , \"Please inject some datas in the objective function\"\n",
    "        Xt, Xv, yt, yv, Yt, Yv, datet, datev, weightst, weightsv, sw, X_test, y_test, y_test_cat,date_test, weights_test, fold_number = data\n",
    "        name = trial.suggest_int('name', 100000, 999999)\n",
    "        ## Parameters\n",
    "        n_blocks = trial.suggest_int('n_block', 2, 3)\n",
    "        n_dense_per_block = trial.suggest_int('n_dense_per_block', 1, 2)\n",
    "\n",
    "        dense_shape = []\n",
    "        dropouts = []\n",
    "        normalization = []\n",
    "\n",
    "        for i in range(n_blocks):\n",
    "            dense_shape.append(trial.suggest_categorical('dense_block_'+str(i), [64,128,256, 512, 1024]))\n",
    "            dropouts.append(trial.suggest_uniform('dropout_block_'+str(i),0,0.4))\n",
    "            normalization.append(trial.suggest_categorical('norm_block_'+str(i), [True, False])) \n",
    "        batch_size = trial.suggest_categorical(\"batch_size\", [128, 256,512, 1024, 2048])\n",
    "        lr = trial.suggest_categorical(\"lr\", [0.01,0.001, 0.0001])\n",
    "        norm = trial.suggest_categorical(\"norm\", [True, False])\n",
    "        use_sample_weights = trial.suggest_categorical(\"sample_weights\", [True, False])\n",
    "\n",
    "        parameters = {\n",
    "            \"name\" : name,\n",
    "            \"n_blocks\" : n_blocks,\n",
    "            \"n_dense_per_block\" : n_dense_per_block,\n",
    "            \"dense_shape\" : dense_shape,\n",
    "            \"dropouts\" : dropouts,\n",
    "            \"normalization\" : normalization,\n",
    "            \"batch_size\" : batch_size,  \n",
    "            'lr' : lr,\n",
    "            \"use_sample_weights\" : use_sample_weights,\n",
    "            \"norm\" : norm, \n",
    "        }\n",
    "\n",
    "        ## Model building and training\n",
    "        print('Model training, go grab a coffee')\n",
    "        print(parameters)\n",
    "        model = build_model(parameters)\n",
    "        model, val_auc = train(model, parameters, Xt, Xv, yt, yv, sw)\n",
    "\n",
    "        print(\"Model trained\")\n",
    "        ## Evaluation on val set\n",
    "        print(\"Evaluation\")\n",
    "        parameters['val_auc'] = val_auc\n",
    "        print(\"Val auc : \" + str(val_auc))\n",
    "        pred = model.predict(Xv, batch_size = parameters['batch_size'])[:,0]\n",
    "        \n",
    "        space = hp.normal('x', 0.5, 0.02)\n",
    "        def f(x):\n",
    "            action = (pred>x)*1\n",
    "            utility = utility_metric(datev,weightsv, Yv, action)\n",
    "            return -utility\n",
    "        \n",
    "        best = fmin(\n",
    "            fn=f,  # \"Loss\" function to minimize\n",
    "            space=space,  # Hyperparameter space\n",
    "            algo=tpe.suggest,  # Tree-structured Parzen Estimator (TPE)\n",
    "            max_evals=100  # Perform 1000 trials\n",
    "        )\n",
    "\n",
    "        parameters['val_treshold'] = best['x']\n",
    "        action = (pred >= best['x'])*1\n",
    "        val_utility = utility_metric(datev , weightsv , Yv , action)\n",
    "        parameters['val_utility'] = val_utility\n",
    "        print(\"Val_utility : \" + str(val_utility))\n",
    "\n",
    "        ## Evaluation on test set\n",
    "        pred = model.predict(X_test, batch_size = parameters['batch_size'])[:,0]\n",
    "        test_auc = roc_auc_score(y_test_cat, pred)\n",
    "        print(\"Test Auc : \" + str(test_auc))\n",
    "        parameters['test_auc'] = test_auc\n",
    "                \n",
    "        space = hp.normal('x', 0.5, 0.02)\n",
    "        def f(x):\n",
    "            action = (pred>x)*1\n",
    "            utility = utility_metric(date_test,weights_test, y_test, action)\n",
    "            return -utility\n",
    "        best = fmin(\n",
    "                fn=f,  # \"Loss\" function to minimize\n",
    "                space=space,  # Hyperparameter space\n",
    "                algo=tpe.suggest,  # Tree-structured Parzen Estimator (TPE)\n",
    "                max_evals=100  # Perform 1000 trials\n",
    "            )\n",
    "#         action = (pred >= study_test.best_params['x'])*1\n",
    "        action = (pred >= best['x'])*1\n",
    "        parameters['test_treshold'] = best['x']\n",
    "        test_utility = utility_metric(date_test , weights_test , y_test , action)\n",
    "        parameters['test_utility'] = test_utility\n",
    "        print('Test utility : '+ str(test_utility))\n",
    "        ## Parameters and model savings\n",
    "        print(\"Saving\")\n",
    "        try:\n",
    "            os.mkdir('./time_cv_ensembling/'+str(fold_number)+'/trial_'+str(name))\n",
    "        except:\n",
    "            1\n",
    "\n",
    "        save(parameters, './time_cv_ensembling/'+str(fold_number)+'/trial_'+str(name)+'/parameters')\n",
    "        model.save('./time_cv_ensembling/'+str(fold_number)+'/trial_'+str(name)+'/model')\n",
    "\n",
    "        print(\"Next model\")\n",
    "        print('\\n')\n",
    "        return val_utility\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n",
      "Loading Fold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-02 21:54:25,399]\u001b[0m A new study created in memory with name: no-name-9b1d5c2b-1c2b-4bf9-a138-f45f27d43430\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1488461, 131) (1488461,) (1488461,) (1488461,) (1488461,) (1488461,)\n",
      "(218063, 131) (218063,) (218063,) (218063,) (218063,)\n",
      "(274763, 131) (274763,) (274763,) (274763,) (274763,)\n",
      "Launching study\n",
      "Model training, go grab a coffee\n",
      "{'name': 829175, 'n_blocks': 2, 'n_dense_per_block': 1, 'dense_shape': [128, 128], 'dropouts': [0.2160870270089681, 0.1331418695761676], 'normalization': [True, False], 'batch_size': 512, 'lr': 0.01, 'use_sample_weights': True, 'norm': False}\n",
      "Epoch 1/2\n",
      "2908/2908 - 22s - loss: 0.7187 - accuracy: 0.5125 - auc: 0.5195 - val_loss: 0.6914 - val_accuracy: 0.5224 - val_auc: 0.5328\n",
      "Epoch 2/2\n",
      "2908/2908 - 21s - loss: 0.7175 - accuracy: 0.5154 - auc: 0.5243 - val_loss: 0.6927 - val_accuracy: 0.5239 - val_auc: 0.5296\n",
      "Model trained\n",
      "Evaluation\n",
      "Val auc : 0.5328340530395508\n",
      "100%|███████████████████████████████| 100/100 [00:05<00:00, 17.10trial/s, best loss: -801.788367707175]\n",
      "Val_utility : 767.3170587096529\n",
      "Test Auc : 0.5261204477437575\n",
      "100%|██████████████████████████████| 100/100 [00:08<00:00, 11.46trial/s, best loss: -2039.918863302082]\n",
      "Test utility : 1992.2456307642296\n",
      "Saving\n",
      "WARNING:tensorflow:From C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./time_cv_ensembling/0/trial_829175/model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-02 21:57:56,315]\u001b[0m Trial 0 finished with value: 767.3170587096529 and parameters: {'name': 829175, 'n_block': 2, 'n_dense_per_block': 1, 'dense_block_0': 128, 'dropout_block_0': 0.2160870270089681, 'norm_block_0': True, 'dense_block_1': 128, 'dropout_block_1': 0.1331418695761676, 'norm_block_1': False, 'batch_size': 512, 'lr': 0.01, 'norm': False, 'sample_weights': True}. Best is trial 0 with value: 767.3170587096529.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next model\n",
      "\n",
      "\n",
      "Model training, go grab a coffee\n",
      "{'name': 773753, 'n_blocks': 3, 'n_dense_per_block': 2, 'dense_shape': [1024, 256, 256], 'dropouts': [0.30735211349911373, 0.013826860957623976, 0.35590931235393386], 'normalization': [True, True, False], 'batch_size': 512, 'lr': 0.01, 'use_sample_weights': False, 'norm': False}\n",
      "Epoch 1/2\n",
      "2908/2908 - 30s - loss: 0.6953 - accuracy: 0.5049 - auc: 0.5060 - val_loss: 0.6922 - val_accuracy: 0.5171 - val_auc: 0.5221\n",
      "Epoch 2/2\n",
      "2908/2908 - 29s - loss: 0.6932 - accuracy: 0.5024 - auc: 0.5002 - val_loss: 0.6930 - val_accuracy: 0.5127 - val_auc: 0.5000\n",
      "Model trained\n",
      "Evaluation\n",
      "Val auc : 0.5221238732337952\n",
      "  4%|█▎                               | 4/100 [00:00<00:06, 15.72trial/s, best loss: -8.59453524085071]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:66: RuntimeWarning: invalid value encountered in double_scalars\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 100/100 [00:06<00:00, 16.45trial/s, best loss: -8.59453524085071]\n",
      "Val_utility : 8.59453524085071\n",
      "Test Auc : 0.5\n",
      "  9%|████▏                                          | 9/100 [00:00<00:08, 10.84trial/s, best loss: 0.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:66: RuntimeWarning: invalid value encountered in double_scalars\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 83%|██████████████████████████████████████▏       | 83/100 [00:07<00:01, 11.03trial/s, best loss: 0.0]"
     ]
    }
   ],
   "source": [
    "make_experiment(0, n_trials = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
