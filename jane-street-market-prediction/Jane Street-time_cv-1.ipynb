{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import _pickle as pickle\n",
    "import gc\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import optuna\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from hyperopt import fmin, tpe, hp\n",
    "\n",
    "# import tensorflow as tf\n",
    "def save(file,name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'wb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'wb')\n",
    "    pickle.dump(file, outfile, protocol=4)\n",
    "    outfile.close\n",
    "    \n",
    "def load(name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'rb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'rb')\n",
    "    file = pickle.load(outfile)\n",
    "    outfile.close\n",
    "    return file\n",
    "\n",
    "pd.set_option('display.max_columns', 150)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1500)]\n",
    "            )\n",
    "logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "# policy = mixed_precision.Policy('float32')\n",
    "mixed_precision.set_policy(policy)\n",
    "\n",
    "def utility_metric(date,weights, resp, action):\n",
    "    import numpy as np\n",
    "    p = []\n",
    "    for i in np.unique(date):\n",
    "        wi = weights[date == i]\n",
    "        ri = resp[date == i]\n",
    "        ai = action[date == i]\n",
    "        pi = np.sum(wi * ri * ai)\n",
    "        p.append(pi)\n",
    "    p = np.array(p)\n",
    "    \n",
    "    nt = np.unique(date).shape[0]\n",
    "#     print(nt)\n",
    "    sp = np.sum(p)\n",
    "    normp = np.sqrt(np.sum(np.square(p)))\n",
    "    t = (sp / normp) * np.sqrt(250/nt)\n",
    "    u = min(max(t,0), 6) * sp\n",
    "    return u\n",
    "    \n",
    "\n",
    "def build_model(parameters):\n",
    "    inputs = tf.keras.Input(shape = (131,))\n",
    "    if parameters['norm']:\n",
    "        x = tf.keras.layers.experimental.preprocessing.Normalization()(inputs)\n",
    "    else:\n",
    "        x = inputs\n",
    "        \n",
    "    for block in range(parameters['n_blocks']):\n",
    "        for n in range(parameters['n_dense_per_block']):\n",
    "            x = tf.keras.layers.Dense(parameters['dense_shape'][block], name = 'block_'+str(block)+'_dense_'+str(n))(x)\n",
    "        if parameters['normalization'][block]:\n",
    "            x = tf.keras.layers.BatchNormalization(name =  'block_'+str(block)+'_batch_norm')(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        tf.keras.layers.Dropout(parameters['dropouts'][block], name =  'block_'+str(block)+'_dropout')(x)\n",
    "    x = tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'classification_head')(x)\n",
    "    model = tf.keras.Model(inputs, x)\n",
    "    model.compile(  loss = 'binary_crossentropy',\n",
    "                    optimizer = tf.keras.optimizers.Adam(parameters['lr']),\n",
    "                    metrics = ['accuracy', 'AUC'])\n",
    "    return model\n",
    "\n",
    "def get_fold(fold_number, X_train, y_train, date_train, weights_train):\n",
    "    filters = (date_train >= 44*fold_number)&(date_train < 44*(fold_number+1))\n",
    "    filters = np.invert(filters)\n",
    "    Xt, Xv, Yt, Yv = X_train[filters], X_train[np.invert(filters)], y_train[filters], y_train[np.invert(filters)]\n",
    "    datet, datev, weightst, weightsv = date_train[filters], date_train[np.invert(filters)], weights_train[filters], weights_train[np.invert(filters)]\n",
    "    sw = abs((Yt * weightst)) + 1\n",
    "    yt, yv = (Yt > 0)*1, (Yv > 0)*1\n",
    "    return Xt, Xv, yt, yv, Yt, Yv, datet, datev, weightst, weightsv, sw\n",
    "\n",
    "class Utility_Callback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, Xv, Yv,yv, datev, weightsv, bs):\n",
    "        self.Xv = Xv\n",
    "        self.Yv = Yv\n",
    "        self.yv = yv\n",
    "        self.datev = datev\n",
    "        self.weightsv = weightsv\n",
    "        self.bs = bs\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        ## Prediction\n",
    "        pred = self.model.predict(self.Xv, batch_size = self.bs)[:,0]\n",
    "        pred[pred<0] = 0\n",
    "        pred[pred>1] = 1\n",
    "        \n",
    "        auc = roc_auc_score(self.yv, pred)\n",
    "#         print(\"val_auc is \"+str(auc))\n",
    "        \n",
    "        ## Optimization\n",
    "        space = hp.normal('x', 0.5, 0.02)\n",
    "        def f(x):\n",
    "            action = (pred>x)*1\n",
    "            utility = utility_metric(self.datev,self.weightsv, self.Yv, action)\n",
    "            return -utility\n",
    "        \n",
    "        best = fmin(\n",
    "            fn=f,  # \"Loss\" function to minimize\n",
    "            space=space,  # Hyperparameter space\n",
    "            algo=tpe.suggest,  # Tree-structured Parzen Estimator (TPE)\n",
    "            max_evals=100  # Perform 1000 trials\n",
    "        )\n",
    "        action = (pred >= best['x'])*1\n",
    "        val_utility = utility_metric(self.datev,self.weightsv, self.Yv, action)\n",
    "        bench_utility = utility_metric(self.datev,self.weightsv, self.Yv, self.yv)\n",
    "        logs.update({'val_utility' : val_utility})\n",
    "        print(\"Val_utility is : \"+str(val_utility) + ' best possible would be : '+str(bench_utility))\n",
    "        \n",
    "        \n",
    "def train(model, parameters, Xt, Xv, yt, yv, sw, Yv, datev, weightsv):\n",
    "    sample_weight = sw if parameters['use_sample_weights'] else None\n",
    "    epochs = 100\n",
    "    utility_call = Utility_Callback(Xv, Yv,yv, datev, weightsv, bs = parameters['batch_size'])\n",
    "    \n",
    "    early = EarlyStopping(monitor='val_utility', min_delta=0.0001, patience=8, verbose=1, \n",
    "                                                mode='max', restore_best_weights=True)\n",
    "\n",
    "    reduce = ReduceLROnPlateau(monitor='val_utility', factor=0.1, patience=3, verbose=1, \n",
    "                               mode='max', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "    callbacks =[utility_call, early, reduce]\n",
    "    \n",
    "    history = model.fit(Xt, yt, validation_data = (Xv, yv), \n",
    "                  batch_size=parameters['batch_size'], epochs=epochs, callbacks = callbacks,\n",
    "                           sample_weight = None, verbose = 2)\n",
    "    sc = np.max(history.history['val_auc'])\n",
    "    return model, sc\n",
    "\n",
    "def make_experiment(fold_number, n_trials = 100):\n",
    "    try:\n",
    "        os.mkdir('./time_cv_ensembling/'+str(fold_number))\n",
    "    except:\n",
    "        1\n",
    "    \n",
    "    print(\"Loading Data\")\n",
    "    (X_train, X_test, y_train, y_test, date_train, date_test, weights_train, weights_test) = load('splitted_dataset')\n",
    "    \n",
    "    X_train = X_train.values\n",
    "    X_test = X_test.values\n",
    "    y_test_cat = (y_test > 0)*1\n",
    "    \n",
    "    print(\"Loading Fold\")\n",
    "    Xt, Xv, yt, yv, Yt, Yv, datet, datev, weightst, weightsv, sw = get_fold(fold_number, X_train, y_train, date_train, weights_train)\n",
    "    del X_train\n",
    "    del y_train\n",
    "    gc.collect()\n",
    "    \n",
    "    print(Xt.shape, yt.shape, Yt.shape,datet.shape, weightst.shape, sw.shape)\n",
    "    print(Xv.shape, yv.shape, Yv.shape,datev.shape, weightsv.shape)\n",
    "    print(X_test.shape, y_test_cat.shape, y_test.shape,date_test.shape, weights_test.shape)\n",
    "    \n",
    "    print(\"Launching study\")\n",
    "    study = optuna.create_study(direction = 'maximize')\n",
    "    study.optimize(get_objective((Xt, Xv, yt, yv, Yt, Yv, datet, datev, weightst, weightsv, sw, X_test, y_test, y_test_cat,date_test, weights_test, fold_number)), n_trials= n_trials)\n",
    "    print(\"Study ended\")\n",
    "\n",
    "def get_objective(data):\n",
    "    def objective(trial, data = data):\n",
    "        assert data is not None , \"Please inject some datas in the objective function\"\n",
    "        Xt, Xv, yt, yv, Yt, Yv, datet, datev, weightst, weightsv, sw, X_test, y_test, y_test_cat,date_test, weights_test, fold_number = data\n",
    "        name = trial.suggest_int('name', 100000, 999999)\n",
    "        ## Parameters\n",
    "        n_blocks = 2 #trial.suggest_int('n_block', 2, 2)\n",
    "        n_dense_per_block = trial.suggest_int('n_dense_per_block', 1, 2)\n",
    "\n",
    "        dense_shape = []\n",
    "        dropouts = []\n",
    "        normalization = []\n",
    "\n",
    "        for i in range(n_blocks):\n",
    "            dense_shape.append(trial.suggest_categorical('dense_block_'+str(i), [64,128,256, 512, 1024]))\n",
    "            dropouts.append(trial.suggest_uniform('dropout_block_'+str(i),0,0.4))\n",
    "            normalization.append(trial.suggest_categorical('norm_block_'+str(i), [True])) \n",
    "        batch_size = trial.suggest_categorical(\"batch_size\", [512, 1024, 2048])\n",
    "        lr = trial.suggest_categorical(\"lr\", [0.01,0.001, 0.0001])\n",
    "        norm = trial.suggest_categorical(\"norm\", [True])\n",
    "        use_sample_weights = trial.suggest_categorical(\"sample_weights\", [True, False])\n",
    "\n",
    "        parameters = {\n",
    "            \"name\" : name,\n",
    "            \"n_blocks\" : n_blocks,\n",
    "            \"n_dense_per_block\" : n_dense_per_block,\n",
    "            \"dense_shape\" : dense_shape,\n",
    "            \"dropouts\" : dropouts,\n",
    "            \"normalization\" : normalization,\n",
    "            \"batch_size\" : batch_size,  \n",
    "            'lr' : lr,\n",
    "            \"use_sample_weights\" : use_sample_weights,\n",
    "            \"norm\" : norm, \n",
    "        }\n",
    "\n",
    "        ## Model building and training\n",
    "        print('Model training, go grab a coffee')\n",
    "        print(parameters)\n",
    "        model = build_model(parameters)\n",
    "        \n",
    "        model, val_auc = train(model, parameters, Xt, Xv, yt, yv, sw, Yv, datev, weightsv)\n",
    "\n",
    "        print(\"Model trained\")\n",
    "        ## Evaluation on val set\n",
    "        print(\"Evaluation\")\n",
    "        parameters['val_auc'] = val_auc\n",
    "        print(\"Val auc : \" + str(val_auc))\n",
    "        pred = model.predict(Xv, batch_size = parameters['batch_size'])[:,0]\n",
    "        pred[pred<0] = 0\n",
    "        pred[pred>1] = 1\n",
    "        \n",
    "        space = hp.normal('x', 0.5, 0.02)\n",
    "        def f(x):\n",
    "            action = (pred>x)*1\n",
    "            utility = utility_metric(datev,weightsv, Yv, action)\n",
    "            return -utility\n",
    "        \n",
    "        best = fmin(\n",
    "            fn=f,  # \"Loss\" function to minimize\n",
    "            space=space,  # Hyperparameter space\n",
    "            algo=tpe.suggest,  # Tree-structured Parzen Estimator (TPE)\n",
    "            max_evals=100  # Perform 1000 trials\n",
    "        )\n",
    "\n",
    "        parameters['val_treshold'] = best['x']\n",
    "        action = (pred >= best['x'])*1\n",
    "        val_utility = utility_metric(datev , weightsv , Yv , action)\n",
    "        parameters['val_utility'] = val_utility\n",
    "        print(\"Val_utility : \" + str(val_utility))\n",
    "\n",
    "        ## Evaluation on test set\n",
    "        pred = model.predict(X_test, batch_size = parameters['batch_size'])[:,0]\n",
    "        test_auc = roc_auc_score(y_test_cat, pred)\n",
    "        print(\"Test Auc : \" + str(test_auc))\n",
    "        parameters['test_auc'] = test_auc\n",
    "                \n",
    "        space = hp.normal('x', 0.5, 0.02)\n",
    "        def f(x):\n",
    "            action = (pred>x)*1\n",
    "            utility = utility_metric(date_test,weights_test, y_test, action)\n",
    "            return -utility\n",
    "        best = fmin(\n",
    "                fn=f,  # \"Loss\" function to minimize\n",
    "                space=space,  # Hyperparameter space\n",
    "                algo=tpe.suggest,  # Tree-structured Parzen Estimator (TPE)\n",
    "                max_evals=100  # Perform 1000 trials\n",
    "            )\n",
    "#         action = (pred >= study_test.best_params['x'])*1\n",
    "        action = (pred >= best['x'])*1\n",
    "        parameters['test_treshold'] = best['x']\n",
    "        test_utility = utility_metric(date_test , weights_test , y_test , action)\n",
    "        parameters['test_utility'] = test_utility\n",
    "        print('Test utility : '+ str(test_utility))\n",
    "        ## Parameters and model savings\n",
    "        print(\"Saving\")\n",
    "        try:\n",
    "            os.mkdir('./time_cv_ensembling/'+str(fold_number)+'/trial_'+str(name))\n",
    "        except:\n",
    "            1\n",
    "\n",
    "        save(parameters, './time_cv_ensembling/'+str(fold_number)+'/trial_'+str(name)+'/parameters')\n",
    "        model.save('./time_cv_ensembling/'+str(fold_number)+'/trial_'+str(name)+'/model')\n",
    "\n",
    "        print(\"Next model\")\n",
    "        print('\\n')\n",
    "        return val_utility\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "make_experiment(3, n_trials = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = None\n",
    "for elt in os.listdir(\"./time_cv_ensembling/0\"):\n",
    "    params = load('./time_cv_ensembling/0/'+elt+'/parameters')\n",
    "    if dico is None:\n",
    "        dico = {}\n",
    "        for elt in params:\n",
    "            dico[elt] = [params[elt]]\n",
    "    else:\n",
    "        for elt in params:\n",
    "            dico[elt].append(params[elt])\n",
    "            \n",
    "df = pd.DataFrame(dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by = 'test_utility', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 250\n",
    "# def get_fold(fold_number, X_train, y_train, date_train, weights_train):\n",
    "#     filters = (date_train >= int(440/n_fold)*fold_number)&(date_train < int(440/n_fold)*(fold_number+1))\n",
    "#     filters = np.invert(filters)\n",
    "#     Xt, Xv, Yt, Yv = X_train[filters], X_train[np.invert(filters)], y_train[filters], y_train[np.invert(filters)]\n",
    "#     datet, datev, weightst, weightsv = date_train[filters], date_train[np.invert(filters)], weights_train[filters], weights_train[np.invert(filters)]\n",
    "#     sw = abs((Yt * weightst)) + 1\n",
    "#     yt, yv = (Yt > 0)*1, (Yv > 0)*1\n",
    "#     return Xt, Xv, yt, yv, Yt, Yv, datet, datev, weightst, weightsv, sw\n",
    "\n",
    "def get_fold(fold_number, X_train, y_train, date_train, weights_train):\n",
    "    val = np.random.choice(list(range(440)), size = 146)\n",
    "    def check(x, val = val):\n",
    "        if x in val:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    filters = list(map(check, date_train))\n",
    "    filters = np.invert(filters)\n",
    "    Xt, Xv, Yt, Yv = X_train[filters], X_train[np.invert(filters)], y_train[filters], y_train[np.invert(filters)]\n",
    "    datet, datev, weightst, weightsv = date_train[filters], date_train[np.invert(filters)], weights_train[filters], weights_train[np.invert(filters)]\n",
    "    sw = abs((Yt * weightst)) + 1\n",
    "    sw_eval = abs((Yv * weightsv)) + 1\n",
    "    yt, yv = (Yt > 0)*1, (Yv > 0)*1\n",
    "    return Xt, Xv, yt, yv, Yt, Yv, datet, datev, weightst, weightsv, sw, sw_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(pred_train, pred_test, ratio) = load(\"lgbm_prediction_train_test\")\n",
    "\n",
    "start = 250\n",
    "for fold_number in tqdm(range(start, start + n_fold)):\n",
    "    print(\"Loading Data\")\n",
    "    (X_train, X_test, y_train, y_test, date_train, date_test, weights_train, weights_test) = load('splitted_dataset')\n",
    "    \n",
    "    X_train = X_train.values\n",
    "    X_test = X_test.values\n",
    "    y_test_cat = (y_test > 0)*1\n",
    "    \n",
    "    X_train = np.concatenate([X_train, (date_train%7)[:,None], (date_train%5)[:,None], (date_train%365)[:,None]], axis = -1)\n",
    "    X_test = np.concatenate([X_test, (date_test%7)[:,None], (date_test%5)[:,None], (date_test%365)[:,None]], axis = -1)\n",
    "    \n",
    "    print(\"Loading Fold\")\n",
    "    Xt, Xv, yt, yv, Yt, Yv, datet, datev, weightst, weightsv, sw, sw_eval = get_fold(fold_number, X_train, y_train, date_train, weights_train)\n",
    "    del X_train\n",
    "    del y_train\n",
    "    gc.collect()\n",
    "    \n",
    "    import lightgbm as lgb\n",
    "    clf = lgb.LGBMClassifier(max_depth = -1, n_estimators = 20000, n_jobs = 6, early_stopping_rounds = 20,  first_metric_only = True)\n",
    "    print(1)\n",
    "    clf.fit(Xt, yt, eval_set =(Xv, yv), eval_metric = 'auc', sample_weight=sw,verbose = True, eval_sample_weight = [sw_eval])\n",
    "    p = clf.predict(Xv)\n",
    "    th_util = utility_metric(datev , weightsv , Yv , yv)\n",
    "    re_util = utility_metric(datev , weightsv , Yv , p)\n",
    "    ratio.append(re_util/th_util)\n",
    "    save(clf, './lgb_fold/lgb_'+str(fold_number))\n",
    "    print(\"real utility is \"+str(re_util)+\" theoric util is \"+str(th_util))\n",
    "    print(re_util/th_util)\n",
    "    print(np.mean(ratio))\n",
    "    print(len(ratio))\n",
    "    print('\\n')\n",
    "    \n",
    "save(ratio, 'lgbm_success_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Benchmark\n",
    "import lightgbm as lgb\n",
    "\n",
    "(X_train, X_test, y_train, y_test, date_train, date_test, weights_train, weights_test) = load('splitted_dataset')\n",
    "SAMPLE_WEIGHTS = abs((y_train * weights_train)) + 1\n",
    "SAMPLE_WEIGHTS_EVAL = abs((y_test * weights_test)) + 1\n",
    "X_train = np.concatenate([X_train, (date_train%7)[:,None], (date_train%5)[:,None], (date_train%365)[:,None]], axis = -1)\n",
    "X_test = np.concatenate([X_test, (date_test%7)[:,None], (date_test%5)[:,None], (date_test%365)[:,None]], axis = -1)\n",
    "\n",
    "clf = lgb.LGBMClassifier(max_depth = -1, n_estimators = 20000, n_jobs = 12, silent = False, early_stopping_rounds = 20,  first_metric_only = True)\n",
    "clf.fit(X_train, (y_train>0)*1, eval_set =(X_test, (y_test>0)*1), eval_metric = 'auc', sample_weight=SAMPLE_WEIGHTS, eval_sample_weight = [SAMPLE_WEIGHTS_EVAL])\n",
    "p = clf.predict(X_test)\n",
    "utility_metric(date_test , weights_test , y_test , p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2527"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test, date_train, date_test, weights_train, weights_test) = load('splitted_dataset')\n",
    "ratio = load('lgbm_success_ratio')\n",
    "X_train = np.concatenate([X_train, (date_train%7)[:,None], (date_train%5)[:,None], (date_train%365)[:,None]], axis = -1)\n",
    "X_test = np.concatenate([X_test, (date_test%7)[:,None], (date_test%5)[:,None], (date_test%365)[:,None]], axis = -1)\n",
    "\n",
    "pred_train = []\n",
    "pred_test = []\n",
    "n_fold = 500\n",
    "utilities = []\n",
    "for fold_number in tqdm(range(n_fold)):\n",
    "    print(fold_number)\n",
    "    print(ratio[fold_number])\n",
    "    clf = load('./lgb_fold/lgb_'+str(fold_number))\n",
    "    \n",
    "    p = clf.predict(X_test)\n",
    "    ut = utility_metric(date_test , weights_test , y_test , p)\n",
    "    utilities.append(ut)\n",
    "    print('utility is : '+str(ut))\n",
    "    \n",
    "    pred_train.append(clf.predict_proba(X_train)[:,1])\n",
    "    pred_test.append(clf.predict_proba(X_test)[:,1])\n",
    "\n",
    "plt.scatter(ratio, utilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1 = (y_train > 0)*1\n",
    "y_test1 = (y_test > 0)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = np.array(pred_train).T\n",
    "pred_test = np.array(pred_test).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save((pred_train, pred_test, ratio), \"lgbm_prediction_train_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pred_train, pred_test, ratio) = load(\"lgbm_prediction_train_test\")\n",
    "\n",
    "n = 500\n",
    "ratio = np.array(ratio)\n",
    "s = np.argsort(ratio)[-n:]\n",
    "\n",
    "pred_train = pred_train[:, s]\n",
    "pred_test = pred_test[:, s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test, date_train, date_test, weights_train, weights_test) = load('splitted_dataset')\n",
    "\n",
    "SAMPLE_WEIGHTS = abs((y_train * weights_train)) + 1\n",
    "y_train1 = (y_train > 0)*1\n",
    "y_test1 = (y_test > 0)*1\n",
    "\n",
    "# import lightgbm as lgb\n",
    "# clf = lgb.LGBMClassifier(max_depth = -1, n_estimators = 1500, n_jobs = 12, silent = False, early_stopping_rounds = 50,  first_metric_only = True)\n",
    "# clf.fit(pred_train, y_train1, eval_set =(pred_test, y_test1), eval_metric = 'auc', sample_weight=SAMPLE_WEIGHTS)\n",
    "# clf.fit(pred_train, y_train1, sample_weight=SAMPLE_WEIGHTS)\n",
    "# import sklearn\n",
    "# clf = sklearn.linear_model.LogisticRegression(n_jobs = 6)\n",
    "# clf.fit(pred_train, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = clf.predict(pred_test)\n",
    "pred = clf.predict_proba(pred_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.mean(pred_test , axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_soft = clf.predict_proba(pred_train)[:,1]\n",
    "# y_test_soft = clf.predict_proba(pred_test)[:,1]\n",
    "\n",
    "y_train_soft = np.mean(pred_train , axis = -1)\n",
    "y_test_soft = np.mean(pred_test , axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save((y_train_soft, y_test_soft), 'soft_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir(lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_train_soft, y_test_soft) = load('soft_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_train_soft*fact, bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_test_soft*fact, bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test, date_train, date_test, weights_train, weights_test) = load('splitted_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test, date_train, date_test, weights_train, weights_test) = load('splitted_dataset')\n",
    "ratio = load('lgbm_success_ratio')\n",
    "X_train = np.concatenate([X_train, (date_train%7)[:,None], (date_train%5)[:,None], (date_train%365)[:,None]], axis = -1)\n",
    "X_test = np.concatenate([X_test, (date_test%7)[:,None], (date_test%5)[:,None], (date_test%365)[:,None]], axis = -1)\n",
    "SAMPLE_WEIGHTS = abs((y_train * weights_train)) + 1\n",
    "(y_train_soft, y_test_soft) = load('soft_labels')\n",
    "\n",
    "y_train_soft *= 100\n",
    "y_test_soft *= 100\n",
    "\n",
    "import lightgbm as lgb\n",
    "clf = lgb.LGBMRegressor(max_depth = -1, n_estimators = 20000, n_jobs = 12, silent = False, early_stopping_rounds = 50,  first_metric_only = True)\n",
    "clf.fit(X_train, y_train_soft, eval_set =(X_test, y_test_soft), sample_weight=SAMPLE_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(500)):\n",
    "    a = clf.predict(X_test[i:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(pred, bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "def objective(trial):\n",
    "#     x = trial.suggest_uniform('x', 0.45, 0.55)\n",
    "    x = trial.suggest_uniform('x', 45, 55)\n",
    "    action = (pred>x)*1\n",
    "    utility = utility_metric(date_test,weights_test, y_test, action)\n",
    "    print(utility)\n",
    "    return -utility\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = (pred >= study.best_params['x'])*1\n",
    "# action = (pred >= 50)*1\n",
    "# action = pred\n",
    "utility_metric(date_test,weights_test, y_test, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(clf, 'distil_lgb_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2848"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_artificial_dataset(X, n_sample, batch_size, shuffle_ratio):\n",
    "    n_batch = int(n_sample/batch_size)\n",
    "    X_aug = [0 for i in range(n_batch+1)]\n",
    "    X_aug[0] = deepcopy(X)\n",
    "    for i in tqdm(range(n_batch)):\n",
    "        indices = np.random.randint(0, X.shape[0], size = batch_size)\n",
    "        X_temp = X[ind]\n",
    "        \n",
    "        for col in range(X_temp.shape[0]):\n",
    "            r = np.random.uniform(0,1)\n",
    "            if r < shuffle_ratio:\n",
    "                X_temp[:,col] = np.random.shuffle(X_temp[:,col])\n",
    "        X_aug[i+1] = deepcopy(X_temp)\n",
    "    X_aug = np.concatenate(X_aug, axis = 0)\n",
    "    \n",
    "    ## Shuffle\n",
    "    shuffle_id = np.random.shuffle(list(range(X_aug.shape[0])))\n",
    "    \n",
    "    X_aug = X_aug[shuffle_id]\n",
    "    return X_aug\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
