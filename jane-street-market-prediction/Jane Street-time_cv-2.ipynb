{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import _pickle as pickle\n",
    "import gc\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import optuna\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from hyperopt import fmin, tpe, hp\n",
    "\n",
    "# import tensorflow as tf\n",
    "def save(file,name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'wb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'wb')\n",
    "    pickle.dump(file, outfile, protocol=4)\n",
    "    outfile.close\n",
    "    \n",
    "def load(name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'rb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'rb')\n",
    "    file = pickle.load(outfile)\n",
    "    outfile.close\n",
    "    return file\n",
    "\n",
    "pd.set_option('display.max_columns', 150)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1500)]\n",
    "            )\n",
    "logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "# policy = mixed_precision.Policy('float32')\n",
    "mixed_precision.set_policy(policy)\n",
    "\n",
    "def utility_metric(date,weights, resp, action):\n",
    "    import numpy as np\n",
    "    p = []\n",
    "    for i in np.unique(date):\n",
    "        wi = weights[date == i]\n",
    "        ri = resp[date == i]\n",
    "        ai = action[date == i]\n",
    "        pi = np.sum(wi * ri * ai)\n",
    "        p.append(pi)\n",
    "    p = np.array(p)\n",
    "    \n",
    "    nt = np.unique(date).shape[0]\n",
    "#     print(nt)\n",
    "    sp = np.sum(p)\n",
    "    normp = np.sqrt(np.sum(np.square(p)))\n",
    "    t = (sp / normp) * np.sqrt(250/nt)\n",
    "    u = min(max(t,0), 6) * sp\n",
    "    return u\n",
    "    \n",
    "\n",
    "def build_model(parameters):\n",
    "    inputs = tf.keras.Input(shape = (131,))\n",
    "    if parameters['norm']:\n",
    "        x = tf.keras.layers.experimental.preprocessing.Normalization()(inputs)\n",
    "    else:\n",
    "        x = inputs\n",
    "        \n",
    "    for block in range(parameters['n_blocks']):\n",
    "        for n in range(parameters['n_dense_per_block']):\n",
    "            x = tf.keras.layers.Dense(parameters['dense_shape'][block], name = 'block_'+str(block)+'_dense_'+str(n))(x)\n",
    "        if parameters['normalization'][block]:\n",
    "            x = tf.keras.layers.BatchNormalization(name =  'block_'+str(block)+'_batch_norm')(x)\n",
    "        x = tf.keras.activations.relu(x)\n",
    "        tf.keras.layers.Dropout(parameters['dropouts'][block], name =  'block_'+str(block)+'_dropout')(x)\n",
    "    x = tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'classification_head')(x)\n",
    "    model = tf.keras.Model(inputs, x)\n",
    "    model.compile(  loss = 'binary_crossentropy',\n",
    "                    optimizer = tf.keras.optimizers.Adam(parameters['lr']),\n",
    "                    metrics = ['accuracy', 'AUC'])\n",
    "    return model\n",
    "\n",
    "def get_fold(fold_number, X_train, y_train, date_train, weights_train):\n",
    "    filters = (date_train >= 44*fold_number)&(date_train < 44*(fold_number+1))\n",
    "    filters = np.invert(filters)\n",
    "    Xt, Xv, Yt, Yv = X_train[filters], X_train[np.invert(filters)], y_train[filters], y_train[np.invert(filters)]\n",
    "    datet, datev, weightst, weightsv = date_train[filters], date_train[np.invert(filters)], weights_train[filters], weights_train[np.invert(filters)]\n",
    "    sw = abs((Yt * weightst)) + 1\n",
    "    yt, yv = (Yt > 0)*1, (Yv > 0)*1\n",
    "    return Xt, Xv, yt, yv, Yt, Yv, datet, datev, weightst, weightsv, sw\n",
    "\n",
    "class Utility_Callback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, Xv, Yv,yv, datev, weightsv, bs):\n",
    "        self.Xv = Xv\n",
    "        self.Yv = Yv\n",
    "        self.yv = yv\n",
    "        self.datev = datev\n",
    "        self.weightsv = weightsv\n",
    "        self.bs = bs\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        ## Prediction\n",
    "        pred = self.model.predict(self.Xv, batch_size = self.bs)[:,0]\n",
    "        pred[pred<0] = 0\n",
    "        pred[pred>1] = 1\n",
    "        \n",
    "        auc = roc_auc_score(self.yv, pred)\n",
    "#         print(\"val_auc is \"+str(auc))\n",
    "        \n",
    "        ## Optimization\n",
    "        space = hp.normal('x', 0.5, 0.02)\n",
    "        def f(x):\n",
    "            action = (pred>x)*1\n",
    "            utility = utility_metric(self.datev,self.weightsv, self.Yv, action)\n",
    "            return -utility\n",
    "        \n",
    "        best = fmin(\n",
    "            fn=f,  # \"Loss\" function to minimize\n",
    "            space=space,  # Hyperparameter space\n",
    "            algo=tpe.suggest,  # Tree-structured Parzen Estimator (TPE)\n",
    "            max_evals=100  # Perform 1000 trials\n",
    "        )\n",
    "        action = (pred >= best['x'])*1\n",
    "        val_utility = utility_metric(self.datev,self.weightsv, self.Yv, action)\n",
    "        bench_utility = utility_metric(self.datev,self.weightsv, self.Yv, self.yv)\n",
    "        logs.update({'val_utility' : val_utility})\n",
    "        print(\"Val_utility is : \"+str(val_utility) + ' best possible would be : '+str(bench_utility))\n",
    "        \n",
    "        \n",
    "def train(model, parameters, Xt, Xv, yt, yv, sw, Yv, datev, weightsv):\n",
    "    sample_weight = sw if parameters['use_sample_weights'] else None\n",
    "    epochs = 100\n",
    "    utility_call = Utility_Callback(Xv, Yv,yv, datev, weightsv, bs = parameters['batch_size'])\n",
    "    \n",
    "    early = EarlyStopping(monitor='val_utility', min_delta=0.0001, patience=8, verbose=1, \n",
    "                                                mode='max', restore_best_weights=True)\n",
    "\n",
    "    reduce = ReduceLROnPlateau(monitor='val_utility', factor=0.1, patience=3, verbose=1, \n",
    "                               mode='max', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "    callbacks =[utility_call, early, reduce]\n",
    "    \n",
    "    history = model.fit(Xt, yt, validation_data = (Xv, yv), \n",
    "                  batch_size=parameters['batch_size'], epochs=epochs, callbacks = callbacks,\n",
    "                           sample_weight = None, verbose = 2)\n",
    "    sc = np.max(history.history['val_auc'])\n",
    "    return model, sc\n",
    "\n",
    "def make_experiment(fold_number, n_trials = 100):\n",
    "    try:\n",
    "        os.mkdir('./time_cv_ensembling/'+str(fold_number))\n",
    "    except:\n",
    "        1\n",
    "    \n",
    "    print(\"Loading Data\")\n",
    "    (X_train, X_test, y_train, y_test, date_train, date_test, weights_train, weights_test) = load('splitted_dataset')\n",
    "    \n",
    "    X_train = X_train.values\n",
    "    X_test = X_test.values\n",
    "    y_test_cat = (y_test > 0)*1\n",
    "    \n",
    "    print(\"Loading Fold\")\n",
    "    Xt, Xv, yt, yv, Yt, Yv, datet, datev, weightst, weightsv, sw = get_fold(fold_number, X_train, y_train, date_train, weights_train)\n",
    "    del X_train\n",
    "    del y_train\n",
    "    gc.collect()\n",
    "    \n",
    "    print(Xt.shape, yt.shape, Yt.shape,datet.shape, weightst.shape, sw.shape)\n",
    "    print(Xv.shape, yv.shape, Yv.shape,datev.shape, weightsv.shape)\n",
    "    print(X_test.shape, y_test_cat.shape, y_test.shape,date_test.shape, weights_test.shape)\n",
    "    \n",
    "    print(\"Launching study\")\n",
    "    study = optuna.create_study(direction = 'maximize')\n",
    "    study.optimize(get_objective((Xt, Xv, yt, yv, Yt, Yv, datet, datev, weightst, weightsv, sw, X_test, y_test, y_test_cat,date_test, weights_test, fold_number)), n_trials= n_trials)\n",
    "    print(\"Study ended\")\n",
    "\n",
    "def get_objective(data):\n",
    "    def objective(trial, data = data):\n",
    "        assert data is not None , \"Please inject some datas in the objective function\"\n",
    "        Xt, Xv, yt, yv, Yt, Yv, datet, datev, weightst, weightsv, sw, X_test, y_test, y_test_cat,date_test, weights_test, fold_number = data\n",
    "        name = trial.suggest_int('name', 100000, 999999)\n",
    "        ## Parameters\n",
    "        n_blocks = 2 #trial.suggest_int('n_block', 2, 2)\n",
    "        n_dense_per_block = trial.suggest_int('n_dense_per_block', 1, 2)\n",
    "\n",
    "        dense_shape = []\n",
    "        dropouts = []\n",
    "        normalization = []\n",
    "\n",
    "        for i in range(n_blocks):\n",
    "            dense_shape.append(trial.suggest_categorical('dense_block_'+str(i), [64,128,256, 512, 1024]))\n",
    "            dropouts.append(trial.suggest_uniform('dropout_block_'+str(i),0,0.4))\n",
    "            normalization.append(trial.suggest_categorical('norm_block_'+str(i), [True])) \n",
    "        batch_size = trial.suggest_categorical(\"batch_size\", [512, 1024, 2048])\n",
    "        lr = trial.suggest_categorical(\"lr\", [0.01,0.001, 0.0001])\n",
    "        norm = trial.suggest_categorical(\"norm\", [True])\n",
    "        use_sample_weights = trial.suggest_categorical(\"sample_weights\", [True, False])\n",
    "\n",
    "        parameters = {\n",
    "            \"name\" : name,\n",
    "            \"n_blocks\" : n_blocks,\n",
    "            \"n_dense_per_block\" : n_dense_per_block,\n",
    "            \"dense_shape\" : dense_shape,\n",
    "            \"dropouts\" : dropouts,\n",
    "            \"normalization\" : normalization,\n",
    "            \"batch_size\" : batch_size,  \n",
    "            'lr' : lr,\n",
    "            \"use_sample_weights\" : use_sample_weights,\n",
    "            \"norm\" : norm, \n",
    "        }\n",
    "\n",
    "        ## Model building and training\n",
    "        print('Model training, go grab a coffee')\n",
    "        print(parameters)\n",
    "        model = build_model(parameters)\n",
    "        \n",
    "        model, val_auc = train(model, parameters, Xt, Xv, yt, yv, sw, Yv, datev, weightsv)\n",
    "\n",
    "        print(\"Model trained\")\n",
    "        ## Evaluation on val set\n",
    "        print(\"Evaluation\")\n",
    "        parameters['val_auc'] = val_auc\n",
    "        print(\"Val auc : \" + str(val_auc))\n",
    "        pred = model.predict(Xv, batch_size = parameters['batch_size'])[:,0]\n",
    "        pred[pred<0] = 0\n",
    "        pred[pred>1] = 1\n",
    "        \n",
    "        space = hp.normal('x', 0.5, 0.02)\n",
    "        def f(x):\n",
    "            action = (pred>x)*1\n",
    "            utility = utility_metric(datev,weightsv, Yv, action)\n",
    "            return -utility\n",
    "        \n",
    "        best = fmin(\n",
    "            fn=f,  # \"Loss\" function to minimize\n",
    "            space=space,  # Hyperparameter space\n",
    "            algo=tpe.suggest,  # Tree-structured Parzen Estimator (TPE)\n",
    "            max_evals=100  # Perform 1000 trials\n",
    "        )\n",
    "\n",
    "        parameters['val_treshold'] = best['x']\n",
    "        action = (pred >= best['x'])*1\n",
    "        val_utility = utility_metric(datev , weightsv , Yv , action)\n",
    "        parameters['val_utility'] = val_utility\n",
    "        print(\"Val_utility : \" + str(val_utility))\n",
    "\n",
    "        ## Evaluation on test set\n",
    "        pred = model.predict(X_test, batch_size = parameters['batch_size'])[:,0]\n",
    "        test_auc = roc_auc_score(y_test_cat, pred)\n",
    "        print(\"Test Auc : \" + str(test_auc))\n",
    "        parameters['test_auc'] = test_auc\n",
    "                \n",
    "        space = hp.normal('x', 0.5, 0.02)\n",
    "        def f(x):\n",
    "            action = (pred>x)*1\n",
    "            utility = utility_metric(date_test,weights_test, y_test, action)\n",
    "            return -utility\n",
    "        best = fmin(\n",
    "                fn=f,  # \"Loss\" function to minimize\n",
    "                space=space,  # Hyperparameter space\n",
    "                algo=tpe.suggest,  # Tree-structured Parzen Estimator (TPE)\n",
    "                max_evals=100  # Perform 1000 trials\n",
    "            )\n",
    "#         action = (pred >= study_test.best_params['x'])*1\n",
    "        action = (pred >= best['x'])*1\n",
    "        parameters['test_treshold'] = best['x']\n",
    "        test_utility = utility_metric(date_test , weights_test , y_test , action)\n",
    "        parameters['test_utility'] = test_utility\n",
    "        print('Test utility : '+ str(test_utility))\n",
    "        ## Parameters and model savings\n",
    "        print(\"Saving\")\n",
    "        try:\n",
    "            os.mkdir('./time_cv_ensembling/'+str(fold_number)+'/trial_'+str(name))\n",
    "        except:\n",
    "            1\n",
    "\n",
    "        save(parameters, './time_cv_ensembling/'+str(fold_number)+'/trial_'+str(name)+'/parameters')\n",
    "        model.save('./time_cv_ensembling/'+str(fold_number)+'/trial_'+str(name)+'/model')\n",
    "\n",
    "        print(\"Next model\")\n",
    "        print('\\n')\n",
    "        return val_utility\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "make_experiment(2, n_trials = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
