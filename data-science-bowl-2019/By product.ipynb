{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## General librairies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import _pickle as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "import dateutil.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = 'specs.csv'\n",
    "test = 'test.csv'\n",
    "train = 'train.csv'\n",
    "train_labels = 'train_labels.csv'\n",
    "subs = 'sample_submission_exemple.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file,name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'wb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'wb')\n",
    "    pickle.dump(file, outfile)\n",
    "    outfile.close\n",
    "    \n",
    "def load(name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'rb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'rb')\n",
    "    file = pickle.load(outfile)\n",
    "    outfile.close\n",
    "    return file\n",
    "\n",
    "def relative_time(x):\n",
    "    x1 = []\n",
    "    for elt in x:\n",
    "        x1.append((elt-x[0]).item()/1000000000)\n",
    "    return x1\n",
    "\n",
    "def categorise(x):\n",
    "    dico = {}\n",
    "    count = 0\n",
    "    for elt in x:\n",
    "        if not(elt in dico):\n",
    "            dico[elt] = count\n",
    "            count += 1\n",
    "    return dico\n",
    "\n",
    "def padding( dataset, n):\n",
    "    d = list(np.zeros(len(dataset)))\n",
    "    c = 0\n",
    "    count = 0\n",
    "    for elt in dataset:\n",
    "        \n",
    "        if count % 100 == 0:\n",
    "            print(count)\n",
    "        u = elt.shape[0]\n",
    "        \n",
    "        if u<200:\n",
    "            c += 1\n",
    "        \n",
    "        if u > n:\n",
    "            d[count] = elt[-n:]\n",
    "        else:\n",
    "            a = np.zeros(((n-u), elt.shape[1])) -1\n",
    "            elt = np.concatenate([a, elt], axis = 0)\n",
    "            d[count] = elt\n",
    "        count += 1\n",
    "    return d\n",
    "\n",
    "def build_line(df, installation_id, game_session):\n",
    "    \n",
    "    df1 = df[(df['installation_id']==installation_id)&(df['date']<=df[(df['installation_id']==installation_id)&(df['game_session']==game_session)]['date'].iloc[0])]\n",
    "    dico = categorise(df1['game_session'].unique())\n",
    "    df1 = df1.replace({'game_session' : dico})\n",
    "    x = relative_time(df1['date'].values)\n",
    "    \n",
    "    df1['time_delta'] = x\n",
    "    \n",
    "#     df1 = df1.drop_duplicates(subset = ['event_id'])\n",
    "    \n",
    "    cats_to_keep = ['game_session','time_delta','title','type', 'world',  'event_count', 'game_time', 'event_code']\n",
    "    df1 = df1[cats_to_keep]\n",
    "    return df1\n",
    "\n",
    "def format_input(X):\n",
    "    return [X[:,:,4:24], X[:,:,0].reshape((X.shape[0], X.shape[1],1)), \n",
    "            X[:,:,1].reshape((X.shape[0], X.shape[1],1)), \n",
    "            X[:,:,2].reshape((X.shape[0], X.shape[1],1)),\n",
    "            X[:,:,3].reshape((X.shape[0], X.shape[1],1)),\n",
    "            X[:,:,24].reshape((X.shape[0], X.shape[1],1))]\n",
    "\n",
    "def build_feature(i,session):\n",
    "    vect = []\n",
    "    \n",
    "    title = session.iloc[0]['title']\n",
    "    typ = session.iloc[0]['type']\n",
    "    \n",
    "    vect.append(session.iloc[0]['game_session'])    ##game_session\n",
    "    vect.append(session.iloc[0]['installation_id'])   ##installation_id\n",
    "    vect.append(session.iloc[0]['title'])  ##title\n",
    "    vect.append(session.iloc[0]['type'])  ##type\n",
    "    vect.append(session.iloc[0]['world'])  ##world\n",
    "    vect.append(session.iloc[0]['timestamp'])  ##timestamp\n",
    "    \n",
    "    \n",
    "    ## adding validation data if game or assessment\n",
    "    if typ == 'Game' or typ == 'Assessment':\n",
    "        pos = 0\n",
    "        neg = 0\n",
    "        for elt in session[session['event_code']==4100]['event_data']:\n",
    "            a = json.loads(elt)['correct']\n",
    "#             print(a)\n",
    "            if a:\n",
    "                pos+=1\n",
    "            else:\n",
    "                neg+=1\n",
    "            \n",
    "        if pos+neg ==0:\n",
    "            acc = -1\n",
    "        else:\n",
    "            acc = pos/(pos+neg)\n",
    "        \n",
    "#         print(acc)\n",
    "        if acc == 1:\n",
    "            acc_class = 3\n",
    "        elif acc == 0.5:\n",
    "            acc_class = 2\n",
    "        elif acc <=0:\n",
    "            acc_class = 0\n",
    "        else:\n",
    "            acc_class = 1\n",
    "#         print(acc_class)\n",
    "        vect.append(acc_class)   ## accuracy_group\n",
    "        vect.append(acc)       ## accuracy\n",
    "        vect.append(pos)       ## n_positive\n",
    "        vect.append(neg)       ## n_negative\n",
    "            \n",
    "            \n",
    "    else: \n",
    "        vect.append(-1)  ##accuracy_group\n",
    "        vect.append(-1) ## accuracy_group\n",
    "        vect.append(-1)  ## n_positive\n",
    "        vect.append(-1)  ## n_negative\n",
    "    \n",
    "    ## Adding features relative to Game, Assessment and activity\n",
    "    if typ != 'Clip':\n",
    "        ## Avg time per instruction\n",
    "        \n",
    "        st = session['game_time'][session['event_code'] == 3010]\n",
    "        en = session['game_time'][session['event_code'] == 3110]\n",
    "        \n",
    "        s = min(st.shape[0], en.shape[0])\n",
    "        if s!=0:\n",
    "            vect.append((en[:s].sum()-st[:s].sum())/s)  ## time per instruction\n",
    "        else:\n",
    "            vect.append(-1)  ##time per instruction\n",
    "        \n",
    "        ##total_time\n",
    "        total_time = session['game_time'].max()/1000\n",
    "        vect.append(total_time)\n",
    "        \n",
    "        ##number of actions\n",
    "        n_action = session[(session['event_code']>=4020)&(session['event_code']<=4080)].shape[0]\n",
    "        vect.append(n_action)\n",
    "        \n",
    "        ## rounds\n",
    "        n_rounds_st = session[session['event_code']==2020].shape[0]\n",
    "        n_rounds_en = session[session['event_code']==2030].shape[0]\n",
    "        \n",
    "        vect.append(n_rounds_st)\n",
    "        vect.append(n_rounds_st)\n",
    "        \n",
    "        if n_rounds_st != 0:\n",
    "            vect.append(n_action/n_rounds_st)\n",
    "            vect.append(total_time/n_rounds_st)\n",
    "        else:\n",
    "            vect.append(-1)\n",
    "            vect.append(-1)\n",
    "        ## hints\n",
    "        vect.append(session[session['event_code']==4090].shape[0])\n",
    "        \n",
    "    else:\n",
    "        vect.append(-1)  ## time per instruction\n",
    "        vect.append(-1)  ##  total time\n",
    "        vect.append(-1)  ## n_actions\n",
    "        vect.append(-1)  ## n_rounds_start\n",
    "        vect.append(-1)  ## n_round end\n",
    "        vect.append(-1)  ## action per round\n",
    "        vect.append(-1)  ## time per round\n",
    "        vect.append(-1)  ## N_hints\n",
    "    \n",
    "    if typ == 'Game' or typ == 'Assessment':\n",
    "        ## feed backs\n",
    "        \n",
    "        n_correct_f = session[session['event_code'] == 3021].shape[0]\n",
    "        n_incorrect_f = session[session['event_code'] == 3020].shape[0]\n",
    "        \n",
    "        vect.append(n_correct_f)\n",
    "        vect.append(n_incorrect_f)\n",
    "        \n",
    "        if n_incorrect_f + n_correct_f != 0:\n",
    "            vect.append(n_correct_f/(n_correct_f+n_incorrect_f))\n",
    "        else:\n",
    "            vect.append(0)\n",
    "        \n",
    "        if n_correct_f !=0:\n",
    "            vect.append((session['game_time'][session['event_code'] == 3121].sum()-session['game_time'][session['event_code'] == 3021].sum())/n_correct_f)\n",
    "        else:\n",
    "            vect.append(-1)\n",
    "        \n",
    "        if n_incorrect_f !=0:\n",
    "            vect.append((session['game_time'][session['event_code'] == 3120].sum()-session['game_time'][session['event_code'] == 3020].sum())/n_incorrect_f)\n",
    "        else:\n",
    "            vect.append(-1)\n",
    "    else:\n",
    "        vect.append(-1)  ## correct_feed\n",
    "        vect.append(-1)  ## incorrect_feed\n",
    "        vect.append(-1)  ## acc_feed\n",
    "        vect.append(-1)  ## time correct feedback\n",
    "        vect.append(-1)  ## time incorrect feedback\n",
    "    \n",
    "    if typ == 'Game':\n",
    "        vect.append(session[session['event_code'] == 2080].shape[0])\n",
    "        vect.append(session[session['event_code'] == 2081].shape[0])\n",
    "        vect.append(session[session['event_code'] == 2060].shape[0])\n",
    "        vect.append(session[session['event_code'] == 2075].shape[0])\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        vect.append(-1)  ## n movie\n",
    "        vect.append(-1)  ## n_skipp movie\n",
    "        vect.append(-1)  ## tutorial\n",
    "        vect.append(-1)  ## skipped tutorial\n",
    "        \n",
    "    \n",
    "    \n",
    "    return vect\n",
    "\n",
    "titles = df['title'].unique()\n",
    "def build_set(df, installation_id, game_session):\n",
    "    df1 = df[df['installation_id']==installation_id]\n",
    "    \n",
    "    df1 = df1.sort_values(by = ['date'], ascending = True)\n",
    "    date = df1[df1['game_session']==game_session].iloc[0]['date']\n",
    "    pred_title = df1[df1['game_session']==game_session].iloc[0]['title']\n",
    "    \n",
    "    df1['pred_title'] = pred_title\n",
    "    df1 = df1[df1['date'] < date]\n",
    "    \n",
    "    \n",
    "    vect = []\n",
    "    \n",
    "    vect.append(pred_title)\n",
    "    \n",
    "    ## Clip\n",
    "    df2 = df1[df1['type']=='Clip']\n",
    "    vect.append(df2.shape[0])\n",
    "    \n",
    "    ## Activity\n",
    "    df2 = df1[df1['type']=='Activity']\n",
    "    \n",
    "    #n_activity\n",
    "    vect.append(df2.shape[0])\n",
    "    # instruction\n",
    "    vect.append(df2[df2['time_instruction']!=-1]['time_instruction'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['total_time']!=-1]['total_time'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['actions']!=-1]['actions'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['start_rounds']!=-1]['start_rounds'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['end_rounds']!=-1]['end_rounds'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['action_rounds']!=-1]['action_rounds'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['time_rounds']!=-1]['time_rounds'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['hints']!=-1]['hints'].values.astype('float32').mean())\n",
    "    \n",
    "    ## Assessment\n",
    "    df2 = df1[df1['type']=='Assessment']\n",
    "    if pred_title in df2['title'].values:\n",
    "        vect.append(1)\n",
    "    else:\n",
    "        vect.append(0)\n",
    "    vect.append(df2.shape[0])\n",
    "    vect.append(df2[df2['accuracy_group']!=-1]['accuracy_group'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['time_instruction']!=-1]['time_instruction'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['total_time']!=-1]['total_time'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['actions']!=-1]['actions'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['start_rounds']!=-1]['start_rounds'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['end_rounds']!=-1]['end_rounds'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['action_rounds']!=-1]['action_rounds'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['time_rounds']!=-1]['time_rounds'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['hints']!=-1]['hints'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['correct_feed']!=-1]['correct_feed'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['incorrect_feed']!=-1]['incorrect_feed'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['time_corr_feed']!=-1]['time_corr_feed'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['time_inc_feed']!=-1]['time_inc_feed'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['acc_feed']!=-1]['acc_feed'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['accuracy']!=-1]['accuracy'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['n_positive']!=-1]['n_positive'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['n_negative']!=-1]['n_negative'].values.astype('float32').mean())\n",
    "    \n",
    "    ## Games\n",
    "    df2 = df1[df1['type']=='Game']\n",
    "    vect.append(df2.shape[0])\n",
    "    vect.append(df2[df2['accuracy_group']!=-1]['accuracy_group'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['time_instruction']!=-1]['time_instruction'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['total_time']!=-1]['total_time'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['actions']!=-1]['actions'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['start_rounds']!=-1]['start_rounds'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['end_rounds']!=-1]['end_rounds'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['action_rounds']!=-1]['action_rounds'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['time_rounds']!=-1]['time_rounds'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['hints']!=-1]['hints'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['correct_feed']!=-1]['correct_feed'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['incorrect_feed']!=-1]['incorrect_feed'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['time_corr_feed']!=-1]['time_corr_feed'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['time_inc_feed']!=-1]['time_inc_feed'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['acc_feed']!=-1]['acc_feed'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['accuracy']!=-1]['accuracy'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['n_positive']!=-1]['n_positive'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['n_negative']!=-1]['n_negative'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['movies']!=-1]['movies'].values.astype('float32').sum())\n",
    "    vect.append(df2[df2['skipped_movie']!=-1]['skipped_movie'].values.astype('float32').sum())\n",
    "    vect.append(df2[df2['tuto']!=-1]['tuto'].values.astype('float32').sum())\n",
    "    vect.append(df2[df2['skipped_tuto']!=-1]['skipped_tuto'].values.astype('float32').mean())\n",
    "    \n",
    "    ## Activity done\n",
    "    for x in titles:\n",
    "        vect.append( df1[df1['title']==x].shape[0])\n",
    "    \n",
    "    \n",
    "    return vect\n",
    "\n",
    "columns = [\n",
    "    'game_session',\n",
    "'installation_id',\n",
    "'title',\n",
    "'type',\n",
    "'world',\n",
    "'timestamp',\n",
    "'accuracy_group',\n",
    "'accuracy',\n",
    "'n_positive',\n",
    "'n_negative',\n",
    "'time_instruction',\n",
    "'actions',\n",
    "'total_time',\n",
    "'start_rounds',\n",
    "'end_rounds',\n",
    "'action_rounds',\n",
    "'time_rounds',\n",
    "'hints',\n",
    "'correct_feed',\n",
    "'incorrect_feed',\n",
    "'acc_feed',\n",
    "'time_corr_feed',\n",
    "'time_inc_feed',\n",
    "'movies',\n",
    "'skipped_movie',\n",
    "'tuto',\n",
    "'skipped_tuto'\n",
    "]\n",
    "\n",
    "cols = [\n",
    "    'pred_title',\n",
    "'n_clip',\n",
    "'n_activity',\n",
    "'Activity_time_instruction',\n",
    "'Activity_total_time',\n",
    "'Activity_actions',\n",
    "'Activity_start_rounds',\n",
    "'Activity_end_rounds',\n",
    "'Activity_action_rounds',\n",
    "'Activity_time_rounds',\n",
    "'Activity_hints',\n",
    "'same_title',\n",
    "'n_assessment',\n",
    "'Assessment_accuracy_group',\n",
    "'Assessment_time_instruction',\n",
    "'Assessment_total_time',\n",
    "'Assessment_actions',\n",
    "'Assessment_start_rounds',\n",
    "'Assessment_end_rounds',\n",
    "'Assessment_action_rounds',\n",
    "'Assessment_time_rounds',\n",
    "'Assessment_hints',\n",
    "'Assessment_correct_feed',\n",
    "'Assessment_incorrect_feed',\n",
    "'Assessment_time_corr_feed',\n",
    "'Assessment_time_inc_feed',\n",
    "'Assessment_acc_feed',\n",
    "'Assessment_accuracy',\n",
    "'Assessment_n_positive',\n",
    "'Assessment_n_negative',\n",
    "'n_games',\n",
    "'Games_accuracy_group',\n",
    "'Games_time_instruction',\n",
    "'Games_total_time',\n",
    "'Games_actions',\n",
    "'Games_start_rounds',\n",
    "'Games_end_rounds',\n",
    "'Games_action_rounds',\n",
    "'Games_time_rounds',\n",
    "'Games_hints',\n",
    "'Games_correct_feed',\n",
    "'Games_incorrect_feed',\n",
    "'Games_time_corr_feed',\n",
    "'Games_time_inc_feed',\n",
    "'Games_acc_feed',\n",
    "'Games_accuracy',\n",
    "'Games_n_positive',\n",
    "'Games_n_negative',\n",
    "'Games_movies',\n",
    "'Games_skipped_movie',\n",
    "'Games_tuto',\n",
    "'Games_skipped_tuto',  \n",
    "]\n",
    "\n",
    "for elt in titles:\n",
    "    cols.append('actitivity_title_'+str(elt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data and grouping by game session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(train)\n",
    "# labels = pd.read_csv(train_labels)\n",
    "vect = df['event_code']\n",
    "vect[df['event_id'] == '17113b36'] = 4100\n",
    "df['event_code'] = vect\n",
    "\n",
    "dataset = list(np.zeros(df['game_session'].unique().shape[0]))\n",
    "\n",
    "print(df['game_session'].unique().shape[0])\n",
    "\n",
    "count = 0\n",
    "for i, session in df.groupby(['game_session']):\n",
    "#     if count >= 100:\n",
    "#         break\n",
    "    line =build_feature(i, session)\n",
    "#     dataset.append(line)\n",
    "    dataset[count] = line\n",
    "    if count % 1000 == 0:\n",
    "        print(count)\n",
    "    count += 1\n",
    "\n",
    "dataset = np.array(dataset)\n",
    "\n",
    "data = pd.DataFrame(dataset, columns = columns)\n",
    "\n",
    "save(data, 'data by session')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(test)\n",
    "vect = df['event_code']\n",
    "vect[df['event_id'] == '17113b36'] = 4100\n",
    "df['event_code'] = vect\n",
    "\n",
    "dataset = list(np.zeros(df['game_session'].unique().shape[0]))\n",
    "\n",
    "print(df['game_session'].unique().shape[0])\n",
    "\n",
    "count = 0\n",
    "for i, session in df.groupby(['game_session']):\n",
    "#     if count >= 100:\n",
    "#         break\n",
    "    line =build_feature(i, session)\n",
    "#     dataset.append(line)\n",
    "    dataset[count] = line\n",
    "    if count % 1000 == 0:\n",
    "        print(count)\n",
    "    count += 1\n",
    "\n",
    "dataset = np.array(dataset)\n",
    "\n",
    "data = pd.DataFrame(dataset, columns = columns)\n",
    "\n",
    "save(data, 'data test by session')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load('data by session')\n",
    "labels = pd.read_csv(train_labels)\n",
    "\n",
    "ids = df[df['type']=='Assessment']['installation_id'].unique()\n",
    "df = df[df.installation_id.isin(ids)]\n",
    "df = df[df.installation_id.isin(labels.installation_id.unique())]\n",
    "\n",
    "# dtitle = categorise(df['title'])\n",
    "\n",
    "# df = df.replace({'title' : dtitle})\n",
    "\n",
    "# save(dtitle, 'dico_title')\n",
    "\n",
    "df['date'] = df['timestamp'].apply(dateutil.parser.parse)\n",
    "\n",
    "df = df.sort_values(by = ['date'], ascending =True)\n",
    "\n",
    "save(df, 'data by session')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load('data test by session')\n",
    "\n",
    "ids = df[df['type']=='Assessment']['installation_id'].unique()\n",
    "\n",
    "# dtitle =load('dico_title')\n",
    "\n",
    "# df = df.replace({'title' : dtitle})\n",
    "\n",
    "df['date'] = df['timestamp'].apply(dateutil.parser.parse)\n",
    "\n",
    "df = df.sort_values(by = ['date'], ascending =True)\n",
    "\n",
    "game_inst = []\n",
    "for elt in ids:\n",
    "    df1 = df[df['installation_id']==elt]\n",
    "    df1 = df1.sort_values(by = ['date'], ascending = True)\n",
    "    game_inst.append(df1.iloc[-1]['game_session'])\n",
    "    \n",
    "save((ids, game_inst), 'test_labels')\n",
    "save(df, 'data test by session')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding test session into train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(test)\n",
    "\n",
    "test_train = []\n",
    "\n",
    "df_labels = df[(df['type'] == 'Assessment')&(df['event_code'] == 4100)][['installation_id', 'game_session']].drop_duplicates(subset = ['installation_id', 'game_session'])\n",
    "\n",
    "df = load('data test by session')\n",
    "\n",
    "vect = []\n",
    "\n",
    "for i in range(df_labels.shape[0]):\n",
    "    vect.append(df[(df['installation_id'] == df_labels.iloc[i]['installation_id'])&(df['game_session'] == df_labels.iloc[i]['game_session'])]['accuracy_group'].values[0])\n",
    "\n",
    "df_labels['accuracy_group'] = vect\n",
    "\n",
    "save(df_labels, 'test labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building train dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load('data by session')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df['title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'pred_title',\n",
    "'n_clip',\n",
    "'n_activity',\n",
    "'Activity_time_instruction',\n",
    "'Activity_total_time',\n",
    "'Activity_actions',\n",
    "'Activity_start_rounds',\n",
    "'Activity_end_rounds',\n",
    "'Activity_action_rounds',\n",
    "'Activity_time_rounds',\n",
    "'Activity_hints',\n",
    "'same_title',\n",
    "'n_assessment',\n",
    "'Assessment_accuracy_group',\n",
    "'Assessment_time_instruction',\n",
    "'Assessment_total_time',\n",
    "'Assessment_actions',\n",
    "'Assessment_start_rounds',\n",
    "'Assessment_end_rounds',\n",
    "'Assessment_action_rounds',\n",
    "'Assessment_time_rounds',\n",
    "'Assessment_hints',\n",
    "'Assessment_correct_feed',\n",
    "'Assessment_incorrect_feed',\n",
    "'Assessment_time_corr_feed',\n",
    "'Assessment_time_inc_feed',\n",
    "'Assessment_acc_feed',\n",
    "'Assessment_accuracy',\n",
    "'Assessment_n_positive',\n",
    "'Assessment_n_negative',\n",
    "'n_games',\n",
    "'Games_accuracy_group',\n",
    "'Games_time_instruction',\n",
    "'Games_total_time',\n",
    "'Games_actions',\n",
    "'Games_start_rounds',\n",
    "'Games_end_rounds',\n",
    "'Games_action_rounds',\n",
    "'Games_time_rounds',\n",
    "'Games_hints',\n",
    "'Games_correct_feed',\n",
    "'Games_incorrect_feed',\n",
    "'Games_time_corr_feed',\n",
    "'Games_time_inc_feed',\n",
    "'Games_acc_feed',\n",
    "'Games_accuracy',\n",
    "'Games_n_positive',\n",
    "'Games_n_negative',\n",
    "'Games_movies',\n",
    "'Games_skipped_movie',\n",
    "'Games_tuto',\n",
    "'Games_skipped_tuto',  \n",
    "]\n",
    "\n",
    "for elt in titles:\n",
    "    cols.append('actitivity_title_'+str(elt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "labels = pd.read_csv(train_labels)\n",
    "labels_test = load('test labels')\n",
    "\n",
    "dataset = list(range(labels.shape[0]))\n",
    "\n",
    "df = load('data by session')\n",
    "for i in range(labels.shape[0]):\n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "    installation_id = labels.iloc[i]['installation_id']\n",
    "    game_session = labels.iloc[i]['game_session']\n",
    "    dataset[i] = build_set(df, installation_id, game_session)\n",
    "\n",
    "    \n",
    "df = load('data test by session')\n",
    "for i in range(labels_test.shape[0]):\n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "    installation_id = labels_test.iloc[i]['installation_id']\n",
    "    game_session = labels_test.iloc[i]['game_session']\n",
    "    dataset.append(build_set(df, installation_id, game_session))\n",
    "    \n",
    "df_data = pd.DataFrame(dataset, columns = cols)\n",
    "\n",
    "save(df_data, 'train dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, game_inst = load('test_labels')\n",
    "\n",
    "dataset = list(range(ids.shape[0]))\n",
    "\n",
    "for i in range(ids.shape[0]):\n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "    installation_id = ids[i]\n",
    "    game_session = game_inst[i]\n",
    "    dataset[i] = build_set(df, installation_id, game_session)\n",
    "\n",
    "df_data = pd.DataFrame(dataset, columns = cols)\n",
    "save(df_data, 'dataset test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.describe().loc['mean'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load('train dataset')\n",
    "\n",
    "X = dataset\n",
    "labels = pd.read_csv(train_labels)\n",
    "test_labels = load('test labels')\n",
    "Y = np.concatenate([labels['accuracy_group'].values.astype('float64'), test_labels['accuracy_group'].values.astype('float64')], axis = 0)\n",
    "# y = np_utils.to_categorical(Y)\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(Y),Y)\n",
    "\n",
    "dtitle = load('dico_title')\n",
    "X = X.replace({'pred_title': dtitle})\n",
    "X = X.fillna(-1)\n",
    "# X = dataset.iloc[17690:]\n",
    "# Y = Y[17690:]\n",
    "# X = X.astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=43)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "df.profile_report(style={'full_width':True}, pool_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y = Y[X['pred_title']==28]\n",
    "# X = X[X['pred_title']==28]\n",
    "\n",
    "# class_weights = class_weight.compute_class_weight('balanced',\n",
    "#                                                  np.unique(Y),Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier, Pool, CatBoostRegressor\n",
    "\n",
    "# clf = RandomForestClassifier(n_estimators=500,n_jobs = 8, random_state=0)\n",
    "\n",
    "# clf = CatBoostClassifier(\n",
    "#                                loss_function='MultiClass',\n",
    "#                                 eval_metric=\"WKappa\",\n",
    "#                                task_type=\"GPU\",\n",
    "#                                learning_rate=0.01,\n",
    "#                                iterations=10000,\n",
    "#                                od_type=\"Iter\",\n",
    "# #                                 depth=4,\n",
    "#                                early_stopping_rounds=2000,\n",
    "# #                                 l2_leaf_reg=10,\n",
    "# #                                 border_count=254,\n",
    "#                                random_seed=42,\n",
    "#                                 #use_best_model=use_best_model,\n",
    "#                                 class_weights=class_weights\n",
    "#                               )\n",
    "\n",
    "clf = CatBoostRegressor(loss_function='RMSE', \n",
    "                        iterations=1000,\n",
    "                          learning_rate=0.01,\n",
    "                        task_type=\"GPU\",\n",
    "#                         early_stopping_rounds=500,\n",
    "                          depth=8, )\n",
    "\n",
    "clf.fit(X_train, y_train,cat_features = [0], eval_set = (X_test, y_test))\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "# print(accuracy_score(y_test, pred))\n",
    "# print(cohen_kappa_score(y_test, pred, weights = 'quadratic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators':5000,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            'subsample': 0.75,\n",
    "            'subsample_freq': 1,\n",
    "            'learning_rate': 0.005,\n",
    "            'feature_fraction': 0.9,\n",
    "         'max_depth': 15,\n",
    "            'lambda_l1': 1,  \n",
    "            'lambda_l2': 1,\n",
    "            'verbose': 100,\n",
    "            'early_stopping_rounds': 100, 'eval_metric': 'cappa'\n",
    "            }\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "clf = LGBMRegressor(**params)\n",
    "clf.fit(X_train, y_train,categorical_feature =[0], eval_set = (X_test, y_test), eval_metric='cappa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "def tres(pred, t):\n",
    "    pred1 = deepcopy(pred)\n",
    "    pred1[pred1 < t[0]] = 0\n",
    "    pred1[(pred1>= t[0])&(pred1 < t[1])] = 1\n",
    "    pred1[(pred1>= t[1])&(pred1 < t[2])] = 2\n",
    "    pred1[pred1 >= t[2]] = 3\n",
    "    \n",
    "    return pred1\n",
    "\n",
    "def objective(trial, pred = clf.predict(X_train), y_test = y_train):\n",
    "# def objective(trial, pred = clf.predict(X_test), y_test = y_test):\n",
    "# def objective(trial, pred = clf.predict(X_val), y_test = y_val):\n",
    "    x0 = trial.suggest_uniform('x0', pred.min(), pred.max())\n",
    "    x1 = trial.suggest_uniform('x1', x0,  pred.max())\n",
    "    x2 = trial.suggest_uniform('x2', x1,  pred.max())\n",
    "\n",
    "    t = [x0, x1, x2]\n",
    "    pred1 = tres(pred, t)\n",
    "    a = cohen_kappa_score(y_test, pred1, weights = 'quadratic')\n",
    "    print(a)\n",
    "    return 1-a\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = list(study.best_params.values())\n",
    "\n",
    "pred = clf.predict(X_val)\n",
    "pred1 = tres(pred, t)\n",
    "\n",
    "print(cohen_kappa_score(y_val, pred1, weights = 'quadratic'))\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "pred1 = tres(pred, t)\n",
    "\n",
    "print(cohen_kappa_score(y_test, pred1, weights = 'quadratic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind0 = 90\n",
    "ind1 = 110\n",
    "plt.plot(X.columns[ind0:ind1], clf.feature_importances_[ind0:ind1])\n",
    "plt.xticks(X.columns[ind0:ind1], X.columns[ind0:ind1], rotation = 'vertical')\n",
    "plt.savefig('features.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in range(len(X.columns)):\n",
    "    l.append([clf.feature_importances_[i], X.columns[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.sort(reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l[:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_to_keep = l[:30,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, game_inst = load('test_labels')\n",
    "df_data = load('dataset test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data.replace({'pred_title': dtitle})\n",
    "df_data =df_data.fillna(-1)\n",
    "\n",
    "pred = clf.predict(df_data)\n",
    "# pred = pred.reshape((pred.shape[0])).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tres(pred, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in range(len(pred)):\n",
    "    X.append([ids[i], pred[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(X, columns = ['installation_id','accuracy_group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.index = pred['installation_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub = pd.read_csv(subs)\n",
    "sample_sub['accuracy_group'] = pred.loc[sample_sub['installation_id'].values]['accuracy_group'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
