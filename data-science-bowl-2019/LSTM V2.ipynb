{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## General librairies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import _pickle as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "import dateutil.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = 'specs.csv'\n",
    "test = 'test.csv'\n",
    "train = 'train.csv'\n",
    "train_labels = 'train_labels.csv'\n",
    "subs = 'sample_submission_exemple.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file,name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'wb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'wb')\n",
    "    pickle.dump(file, outfile)\n",
    "    outfile.close\n",
    "    \n",
    "def load(name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'rb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'rb')\n",
    "    file = pickle.load(outfile)\n",
    "    outfile.close\n",
    "    return file\n",
    "\n",
    "def relative_time(x):\n",
    "    x1 = []\n",
    "    for elt in x:\n",
    "        x1.append((elt-x[0]).item()/1000000000)\n",
    "    return x1\n",
    "\n",
    "def categorise(x):\n",
    "    dico = {}\n",
    "    count = 0\n",
    "    for elt in x:\n",
    "        if not(elt in dico):\n",
    "            dico[elt] = count\n",
    "            count += 1\n",
    "    return dico\n",
    "\n",
    "def padding( dataset, n):\n",
    "    d = list(np.zeros(len(dataset)))\n",
    "    c = 0\n",
    "    count = 0\n",
    "    for elt in dataset:\n",
    "        elt = elt.values.astype('float32')\n",
    "        if count % 100 == 0:\n",
    "            print(count)\n",
    "        u = elt.shape[0]\n",
    "        \n",
    "        if u<200:\n",
    "            c += 1\n",
    "        \n",
    "        if u > n:\n",
    "            d[count] = elt[-n:]\n",
    "        else:\n",
    "            a = np.zeros(((n-u), elt.shape[1])) -1\n",
    "            elt = np.concatenate([a, elt], axis = 0)\n",
    "            d[count] = elt\n",
    "        count += 1\n",
    "    return d\n",
    "\n",
    "def build_line(df, installation_id, game_session):\n",
    "    \n",
    "    df1 = df[(df['installation_id']==installation_id)&(df['date']<=df[(df['installation_id']==installation_id)&(df['game_session']==game_session)]['date'].iloc[0])]\n",
    "    dico = categorise(df1['game_session'].unique())\n",
    "    df1 = df1.replace({'game_session' : dico})\n",
    "    x = relative_time(df1['date'].values)\n",
    "    \n",
    "    df1['time_delta'] = x\n",
    "    \n",
    "#     df1 = df1.drop_duplicates(subset = ['event_id'])\n",
    "    \n",
    "    cats_to_keep = ['game_session','time_delta','title','type', 'world',  'event_count', 'game_time', 'event_code']\n",
    "    df1 = df1[cats_to_keep]\n",
    "    return df1\n",
    "\n",
    "def format_input(X):\n",
    "    return [X[:,:,4:24], X[:,:,0].reshape((X.shape[0], X.shape[1],1)), \n",
    "            X[:,:,1].reshape((X.shape[0], X.shape[1],1)), \n",
    "            X[:,:,2].reshape((X.shape[0], X.shape[1],1)),\n",
    "            X[:,:,3].reshape((X.shape[0], X.shape[1],1)),\n",
    "            X[:,:,24].reshape((X.shape[0], X.shape[1],1))]\n",
    "\n",
    "def build_feature(i,session):\n",
    "    vect = []\n",
    "    \n",
    "    title = session.iloc[0]['title']\n",
    "    typ = session.iloc[0]['type']\n",
    "    \n",
    "    vect.append(session.iloc[0]['game_session'])    ##game_session\n",
    "    vect.append(session.iloc[0]['installation_id'])   ##installation_id\n",
    "    vect.append(session.iloc[0]['title'])  ##title\n",
    "    vect.append(session.iloc[0]['type'])  ##type\n",
    "    vect.append(session.iloc[0]['world'])  ##world\n",
    "    vect.append(session.iloc[0]['timestamp'])  ##timestamp\n",
    "    \n",
    "    \n",
    "    ## adding validation data if game or assessment\n",
    "    if typ == 'Game' or typ == 'Assessment':\n",
    "        pos = 0\n",
    "        neg = 0\n",
    "        for elt in session[session['event_code']==4100]['event_data']:\n",
    "            a = json.loads(elt)['correct']\n",
    "#             print(a)\n",
    "            if a:\n",
    "                pos+=1\n",
    "            else:\n",
    "                neg+=1\n",
    "            \n",
    "        if pos+neg ==0:\n",
    "            acc = -1\n",
    "        else:\n",
    "            acc = pos/(pos+neg)\n",
    "        \n",
    "#         print(acc)\n",
    "        if acc == 1:\n",
    "            acc_class = 3\n",
    "        elif acc == 0.5:\n",
    "            acc_class = 2\n",
    "        elif acc <=0:\n",
    "            acc_class = 0\n",
    "        else:\n",
    "            acc_class = 1\n",
    "#         print(acc_class)\n",
    "        vect.append(acc_class)   ## accuracy_group\n",
    "        vect.append(acc)       ## accuracy\n",
    "        vect.append(pos)       ## n_positive\n",
    "        vect.append(neg)       ## n_negative\n",
    "            \n",
    "            \n",
    "    else: \n",
    "        vect.append(-1)  ##accuracy_group\n",
    "        vect.append(-1) ## accuracy_group\n",
    "        vect.append(-1)  ## n_positive\n",
    "        vect.append(-1)  ## n_negative\n",
    "    \n",
    "    ## Adding features relative to Game, Assessment and activity\n",
    "    if typ != 'Clip':\n",
    "        ## Avg time per instruction\n",
    "        \n",
    "        st = session['game_time'][session['event_code'] == 3010]\n",
    "        en = session['game_time'][session['event_code'] == 3110]\n",
    "        \n",
    "        s = min(st.shape[0], en.shape[0])\n",
    "        if s!=0:\n",
    "            vect.append((en[:s].sum()-st[:s].sum())/s)  ## time per instruction\n",
    "        else:\n",
    "            vect.append(-1)  ##time per instruction\n",
    "        \n",
    "        ##total_time\n",
    "        total_time = session['game_time'].max()/1000\n",
    "        vect.append(total_time)\n",
    "        \n",
    "        ##number of actions\n",
    "        n_action = session[(session['event_code']>=4020)&(session['event_code']<=4080)].shape[0]\n",
    "        vect.append(n_action)\n",
    "        \n",
    "        ## rounds\n",
    "        n_rounds_st = session[session['event_code']==2020].shape[0]\n",
    "        n_rounds_en = session[session['event_code']==2030].shape[0]\n",
    "        \n",
    "        vect.append(n_rounds_st)\n",
    "        vect.append(n_rounds_st)\n",
    "        \n",
    "        if n_rounds_st != 0:\n",
    "            vect.append(n_action/n_rounds_st)\n",
    "            vect.append(total_time/n_rounds_st)\n",
    "        else:\n",
    "            vect.append(-1)\n",
    "            vect.append(-1)\n",
    "        ## hints\n",
    "        vect.append(session[session['event_code']==4090].shape[0])\n",
    "        \n",
    "    else:\n",
    "        vect.append(-1)  ## time per instruction\n",
    "        vect.append(-1)  ##  total time\n",
    "        vect.append(-1)  ## n_actions\n",
    "        vect.append(-1)  ## n_rounds_start\n",
    "        vect.append(-1)  ## n_round end\n",
    "        vect.append(-1)  ## action per round\n",
    "        vect.append(-1)  ## time per round\n",
    "        vect.append(-1)  ## N_hints\n",
    "    \n",
    "    if typ == 'Game' or typ == 'Assessment':\n",
    "        ## feed backs\n",
    "        \n",
    "        n_correct_f = session[session['event_id'] == 3121].shape[0]\n",
    "        n_incorrect_f = session[session['event_id'] == 3120].shape[0]\n",
    "        \n",
    "        vect.append(n_correct_f)\n",
    "        vect.append(n_incorrect_f)\n",
    "        \n",
    "        if n_incorrect_f + n_correct_f != 0:\n",
    "            vect.append(n_correct_f/(n_correct_f+n_incorrect_f))\n",
    "        else:\n",
    "            vect.append(0)\n",
    "        \n",
    "        if n_correct_f !=0:\n",
    "            vect.append((session['game_time'][session['event_code'] == 3121].sum()-session['game_time'][session['event_code'] == 3021].sum())/n_correct_f)\n",
    "        else:\n",
    "            vect.append(-1)\n",
    "        \n",
    "        if n_incorrect_f !=0:\n",
    "            vect.append((session['game_time'][session['event_code'] == 3120].sum()-session['game_time'][session['event_code'] == 3020].sum())/n_correct_f)\n",
    "        else:\n",
    "            vect.append(-1)\n",
    "    else:\n",
    "        vect.append(-1)  ## correct_feed\n",
    "        vect.append(-1)  ## incorrect_feed\n",
    "        vect.append(-1)  ## acc_feed\n",
    "        vect.append(-1)  ## time correct feedback\n",
    "        vect.append(-1)  ## time incorrect feedback\n",
    "    \n",
    "    if typ == 'Game':\n",
    "        vect.append(session[session['event_code'] == 2080].shape[0])\n",
    "        vect.append(session[session['event_code'] == 2081].shape[0])\n",
    "        vect.append(session[session['event_code'] == 2060].shape[0])\n",
    "        vect.append(session[session['event_code'] == 2075].shape[0])\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        vect.append(-1)  ## n movie\n",
    "        vect.append(-1)  ## n_skipp movie\n",
    "        vect.append(-1)  ## tutorial\n",
    "        vect.append(-1)  ## skipped tutorial\n",
    "        \n",
    "    \n",
    "    \n",
    "    return vect\n",
    "\n",
    "titles = df['title'].unique()\n",
    "def build_set(df, installation_id, game_session):\n",
    "    df1 = df[df['installation_id']==installation_id]\n",
    "    \n",
    "    df1 = df1.sort_values(by = ['date'], ascending = True)\n",
    "    date = df1[df1['game_session']==game_session].iloc[0]['date']\n",
    "    pred_title = df1[df1['game_session']==game_session].iloc[0]['title']\n",
    "    \n",
    "    df1['pred_title'] = pred_title\n",
    "    df1 = df1[df1['date'] < date]\n",
    "    \n",
    "    \n",
    "    vect = []\n",
    "    \n",
    "    vect.append(pred_title)\n",
    "    \n",
    "    ## Clip\n",
    "    df2 = df1[df1['type']=='Clip']\n",
    "    vect.append(df2.shape[0])\n",
    "    \n",
    "    ## Activity\n",
    "    df2 = df1[df1['type']=='Activity']\n",
    "    \n",
    "    #n_activity\n",
    "    vect.append(df2.shape[0])\n",
    "    # instruction\n",
    "    vect.append(df2[df2['time_instruction']!=-1]['time_instruction'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['total_time']!=-1]['total_time'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['actions']!=-1]['actions'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['start_rounds']!=-1]['start_rounds'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['end_rounds']!=-1]['end_rounds'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['action_rounds']!=-1]['action_rounds'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['time_rounds']!=-1]['time_rounds'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['hints']!=-1]['hints'].values.astype('float32').mean())\n",
    "    \n",
    "    ## Assessment\n",
    "    df2 = df1[df1['type']=='Assessment']\n",
    "    if pred_title in df2['title'].values:\n",
    "        vect.append(1)\n",
    "    else:\n",
    "        vect.append(0)\n",
    "    vect.append(df2.shape[0])\n",
    "    vect.append(df2[df2['accuracy_group']!=-1]['accuracy_group'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['time_instruction']!=-1]['time_instruction'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['total_time']!=-1]['total_time'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['actions']!=-1]['actions'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['start_rounds']!=-1]['start_rounds'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['end_rounds']!=-1]['end_rounds'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['action_rounds']!=-1]['action_rounds'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['time_rounds']!=-1]['time_rounds'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['hints']!=-1]['hints'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['correct_feed']!=-1]['correct_feed'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['incorrect_feed']!=-1]['incorrect_feed'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['time_corr_feed']!=-1]['time_corr_feed'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['time_inc_feed']!=-1]['time_inc_feed'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['acc_feed']!=-1]['acc_feed'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['accuracy']!=-1]['accuracy'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['n_positive']!=-1]['n_positive'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['n_negative']!=-1]['n_negative'].values.astype('float32').mean())\n",
    "    \n",
    "    ## Games\n",
    "    df2 = df1[df1['type']=='Game']\n",
    "    vect.append(df2.shape[0])\n",
    "    vect.append(df2[df2['accuracy_group']!=-1]['accuracy_group'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['time_instruction']!=-1]['time_instruction'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['total_time']!=-1]['total_time'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['actions']!=-1]['actions'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['start_rounds']!=-1]['start_rounds'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['end_rounds']!=-1]['end_rounds'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['action_rounds']!=-1]['action_rounds'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['time_rounds']!=-1]['time_rounds'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['hints']!=-1]['hints'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['correct_feed']!=-1]['correct_feed'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['incorrect_feed']!=-1]['incorrect_feed'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['time_corr_feed']!=-1]['time_corr_feed'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['time_inc_feed']!=-1]['time_inc_feed'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['acc_feed']!=-1]['acc_feed'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['accuracy']!=-1]['accuracy'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['n_positive']!=-1]['n_positive'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['n_negative']!=-1]['n_negative'].values.astype('float32').mean())\n",
    "    vect.append(df2[df2['movies']!=-1]['movies'].values.astype('float32').sum())\n",
    "    vect.append(df2[df2['skipped_movie']!=-1]['skipped_movie'].values.astype('float32').sum())\n",
    "    vect.append(df2[df2['tuto']!=-1]['tuto'].values.astype('float32').sum())\n",
    "    vect.append(df2[df2['skipped_tuto']!=-1]['skipped_tuto'].values.astype('float32').mean())\n",
    "    \n",
    "    ## Activity done\n",
    "    for x in titles:\n",
    "        vect.append( df1[df1['title']==x].shape[0])\n",
    "    \n",
    "    \n",
    "    return vect\n",
    "\n",
    "columns = [\n",
    "    'game_session',\n",
    "'installation_id',\n",
    "'title',\n",
    "'type',\n",
    "'world',\n",
    "'timestamp',\n",
    "'accuracy_group',\n",
    "'accuracy',\n",
    "'n_positive',\n",
    "'n_negative',\n",
    "'time_instruction',\n",
    "'actions',\n",
    "'total_time',\n",
    "'start_rounds',\n",
    "'end_rounds',\n",
    "'action_rounds',\n",
    "'time_rounds',\n",
    "'hints',\n",
    "'correct_feed',\n",
    "'incorrect_feed',\n",
    "'acc_feed',\n",
    "'time_corr_feed',\n",
    "'time_inc_feed',\n",
    "'movies',\n",
    "'skipped_movie',\n",
    "'tuto',\n",
    "'skipped_tuto'\n",
    "]\n",
    "\n",
    "cols = [\n",
    "    'pred_title',\n",
    "'n_clip',\n",
    "'n_activity',\n",
    "'Activity_time_instruction',\n",
    "'Activity_total_time',\n",
    "'Activity_actions',\n",
    "'Activity_start_rounds',\n",
    "'Activity_end_rounds',\n",
    "'Activity_action_rounds',\n",
    "'Activity_time_rounds',\n",
    "'Activity_hints',\n",
    "'same_title',\n",
    "'n_assessment',\n",
    "'Assessment_accuracy_group',\n",
    "'Assessment_time_instruction',\n",
    "'Assessment_total_time',\n",
    "'Assessment_actions',\n",
    "'Assessment_start_rounds',\n",
    "'Assessment_end_rounds',\n",
    "'Assessment_action_rounds',\n",
    "'Assessment_time_rounds',\n",
    "'Assessment_hints',\n",
    "'Assessment_correct_feed',\n",
    "'Assessment_incorrect_feed',\n",
    "'Assessment_time_corr_feed',\n",
    "'Assessment_time_inc_feed',\n",
    "'Assessment_acc_feed',\n",
    "'Assessment_accuracy',\n",
    "'Assessment_n_positive',\n",
    "'Assessment_n_negative',\n",
    "'n_games',\n",
    "'Games_accuracy_group',\n",
    "'Games_time_instruction',\n",
    "'Games_total_time',\n",
    "'Games_actions',\n",
    "'Games_start_rounds',\n",
    "'Games_end_rounds',\n",
    "'Games_action_rounds',\n",
    "'Games_time_rounds',\n",
    "'Games_hints',\n",
    "'Games_correct_feed',\n",
    "'Games_incorrect_feed',\n",
    "'Games_time_corr_feed',\n",
    "'Games_time_inc_feed',\n",
    "'Games_acc_feed',\n",
    "'Games_accuracy',\n",
    "'Games_n_positive',\n",
    "'Games_n_negative',\n",
    "'Games_movies',\n",
    "'Games_skipped_movie',\n",
    "'Games_tuto',\n",
    "'Games_skipped_tuto',  \n",
    "]\n",
    "\n",
    "for elt in titles:\n",
    "    cols.append('actitivity_title_'+str(elt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load('data by session')\n",
    "labels = pd.read_csv(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['type'] == 'Assessment']['title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtitle = categorise(data['title'])\n",
    "# dtype = categorise(data['type'])\n",
    "# dworld = categorise(data['world'])\n",
    "\n",
    "# # data = data.replace({'title' : dtitle})\n",
    "# data = data.replace({'type' : dtype})\n",
    "# data = data.replace({'world' : dworld})\n",
    "\n",
    "data['date'] = data['timestamp'].apply(dateutil.parser.parse)\n",
    "\n",
    "\n",
    "data = pd.concat([data,pd.get_dummies(data['type'],prefix=['type'])], axis = 1)\n",
    "data = pd.concat([data,pd.get_dummies(data['title'],prefix=['title'])], axis = 1)\n",
    "data = pd.concat([data,pd.get_dummies(data['world'],prefix=['world'])], axis = 1)\n",
    "data = pd.concat([data,pd.get_dummies(data['accuracy_group'],prefix=['accuracy_group'])], axis = 1)\n",
    "\n",
    "\n",
    "save((dtitle, dtype, dworld), 'dicos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns1 = [\n",
    " 'accuracy_group',\n",
    " 'accuracy',\n",
    " 'n_positive',\n",
    " 'n_negative',\n",
    " 'time_instruction',\n",
    " 'actions',\n",
    " 'total_time',\n",
    " 'start_rounds',\n",
    " 'end_rounds',\n",
    " 'action_rounds',\n",
    " 'time_rounds',\n",
    " 'hints',\n",
    " 'correct_feed',\n",
    " 'incorrect_feed',\n",
    " 'acc_feed',\n",
    " 'time_corr_feed',\n",
    " 'time_inc_feed',\n",
    " 'movies',\n",
    " 'skipped_movie',\n",
    " 'tuto',\n",
    " 'skipped_tuto',\n",
    " \"['type']_Activity\",\n",
    " \"['type']_Assessment\",\n",
    " \"['type']_Clip\",\n",
    " \"['type']_Game\",\n",
    " \"['title']_0\",\n",
    " \"['title']_1\",\n",
    " \"['title']_2\",\n",
    " \"['title']_3\",\n",
    " \"['title']_4\",\n",
    " \"['title']_5\",\n",
    " \"['title']_6\",\n",
    " \"['title']_7\",\n",
    " \"['title']_8\",\n",
    " \"['title']_9\",\n",
    " \"['title']_10\",\n",
    " \"['title']_11\",\n",
    " \"['title']_12\",\n",
    " \"['title']_13\",\n",
    " \"['title']_14\",\n",
    " \"['title']_15\",\n",
    " \"['title']_16\",\n",
    " \"['title']_17\",\n",
    " \"['title']_18\",\n",
    " \"['title']_19\",\n",
    " \"['title']_20\",\n",
    " \"['title']_21\",\n",
    " \"['title']_22\",\n",
    " \"['title']_23\",\n",
    " \"['title']_24\",\n",
    " \"['title']_25\",\n",
    " \"['title']_26\",\n",
    " \"['title']_27\",\n",
    " \"['title']_28\",\n",
    " \"['title']_29\",\n",
    " \"['title']_30\",\n",
    " \"['title']_31\",\n",
    " \"['title']_32\",\n",
    " \"['title']_33\",\n",
    " \"['title']_34\",\n",
    " \"['title']_35\",\n",
    " \"['title']_36\",\n",
    " \"['title']_37\",\n",
    " \"['title']_38\",\n",
    " \"['title']_39\",\n",
    " \"['title']_40\",\n",
    " \"['title']_41\",\n",
    " \"['title']_42\",\n",
    " \"['title']_43\",\n",
    " \"['world']_CRYSTALCAVES\",\n",
    " \"['world']_MAGMAPEAK\",\n",
    " \"['world']_NONE\",\n",
    " \"['world']_TREETOPCITY\",\n",
    " \"['accuracy_group']_-1\",\n",
    " \"['accuracy_group']_0\",\n",
    " \"['accuracy_group']_1\",\n",
    " \"['accuracy_group']_2\",\n",
    " \"['accuracy_group']_3\"]\n",
    "dataset = list(np.zeros(labels.shape[0]))\n",
    "\n",
    "for i in range(labels.shape[0]):\n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "    installation_id = labels.iloc[i]['installation_id']\n",
    "    game_session = labels.iloc[i]['game_session']\n",
    "    time = data[(data['installation_id'] == installation_id)&(data['game_session']==game_session)].iloc[0]['date']\n",
    "    ass_title = data[(data['installation_id'] == installation_id)&(data['game_session']==game_session)].iloc[0]['title']\n",
    "    \n",
    "    df1 = data[(data['installation_id']==installation_id)&(data['date']<time)]\n",
    "    df1 = df1.sort_values(by = ['date'])\n",
    "    \n",
    "    \n",
    "    if ass_title == 28:\n",
    "        df1['title_28'] = 1\n",
    "        df1['title_24'] = 0\n",
    "        df1['title_36'] = 0\n",
    "        df1['title_14'] = 0\n",
    "        df1['title_27'] = 0\n",
    "    elif ass_title == 24:\n",
    "        df1['title_28'] = 0\n",
    "        df1['title_24'] = 1\n",
    "        df1['title_36'] = 0\n",
    "        df1['title_14'] = 0\n",
    "        df1['title_27'] = 0\n",
    "    elif ass_title == 36:\n",
    "        df1['title_28'] = 0\n",
    "        df1['title_24'] = 0\n",
    "        df1['title_36'] = 1\n",
    "        df1['title_14'] = 0\n",
    "        df1['title_27'] = 0\n",
    "    elif ass_title == 14:\n",
    "        df1['title_28'] = 0\n",
    "        df1['title_24'] = 0\n",
    "        df1['title_36'] = 0\n",
    "        df1['title_14'] = 1\n",
    "        df1['title_27'] = 0\n",
    "    else:\n",
    "        df1['title_28'] = 0\n",
    "        df1['title_24'] = 0\n",
    "        df1['title_36'] = 0\n",
    "        df1['title_14'] = 0\n",
    "        df1['title_27'] = 1\n",
    "    df1['pred_type'] = ass_type\n",
    "    \n",
    "    dataset[i] = df1[columns1]\n",
    "\n",
    "save(dataset, 'data for lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 0\n",
    "s = 0\n",
    "for i in dataset:\n",
    "    s+=i.shape[0]\n",
    "    if i.shape[0] > M:\n",
    "        M = i.shape[0]\n",
    "s = s/17600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0].values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n"
     ]
    }
   ],
   "source": [
    "dataset = load('data for lstm')\n",
    "\n",
    "pad = 150\n",
    "\n",
    "dataset = padding(dataset,pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(train_labels)\n",
    "X = np.array(dataset)\n",
    "Y = labels['accuracy_group'].values\n",
    "y = np_utils.to_categorical(Y)\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(Y),\n",
    "                                               Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dropout, Dense,CuDNNLSTM, Flatten, Embedding, TimeDistributed, Concatenate, LSTM, BatchNormalization, Lambda, Reshape\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(CuDNNLSTM(64, return_sequences = False, input_shape = (pad, 78)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation = 'relu',  kernel_initializer='normal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(4,  kernel_initializer='normal', activation = 'sigmoid' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def kappa_loss(y_pred, y_true, y_pow=2, eps=1e-10, N=4, bsize=256, name='kappa'):\n",
    "    \"\"\"A continuous differentiable approximation of discrete kappa loss.\n",
    "        Args:\n",
    "            y_pred: 2D tensor or array, [batch_size, num_classes]\n",
    "            y_true: 2D tensor or array,[batch_size, num_classes]\n",
    "            y_pow: int,  e.g. y_pow=2\n",
    "            N: typically num_classes of the model\n",
    "            bsize: batch_size of the training or validation ops\n",
    "            eps: a float, prevents divide by zero\n",
    "            name: Optional scope/name for op_scope.\n",
    "        Returns:\n",
    "            A tensor with the kappa loss.\"\"\"\n",
    "\n",
    "    with tf.name_scope(name):\n",
    "        y_true = tf.to_float(y_true)\n",
    "        repeat_op = tf.to_float(tf.tile(tf.reshape(tf.range(0, N), [N, 1]), [1, N]))\n",
    "        repeat_op_sq = tf.square((repeat_op - tf.transpose(repeat_op)))\n",
    "        weights = repeat_op_sq / tf.to_float((N - 1) ** 2)\n",
    "    \n",
    "        pred_ = y_pred ** y_pow\n",
    "        try:\n",
    "            pred_norm = pred_ / (eps + tf.reshape(tf.reduce_sum(pred_, 1), [-1, 1]))\n",
    "        except Exception:\n",
    "            pred_norm = pred_ / (eps + tf.reshape(tf.reduce_sum(pred_, 1), [bsize, 1]))\n",
    "    \n",
    "        hist_rater_a = tf.reduce_sum(pred_norm, 0)\n",
    "        hist_rater_b = tf.reduce_sum(y_true, 0)\n",
    "    \n",
    "        conf_mat = tf.matmul(tf.transpose(pred_norm), y_true)\n",
    "    \n",
    "        nom = tf.reduce_sum(weights * conf_mat)\n",
    "        denom = tf.reduce_sum(weights * tf.matmul(\n",
    "            tf.reshape(hist_rater_a, [N, 1]), tf.reshape(hist_rater_b, [1, N])) /\n",
    "                              tf.to_float(bsize))\n",
    "    \n",
    "        return nom / (denom + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14152 samples, validate on 3538 samples\n",
      "Epoch 1/15\n",
      "14152/14152 [==============================] - ETA: 14:33 - loss: 21.350 - ETA: 2:37 - loss: 21.339 - ETA: 1:40 - loss: 21.33 - ETA: 1:11 - loss: 21.34 - ETA: 59s - loss: 21.3401 - ETA: 49s - loss: 21.338 - ETA: 42s - loss: 21.333 - ETA: 38s - loss: 21.331 - ETA: 35s - loss: 21.329 - ETA: 32s - loss: 21.326 - ETA: 30s - loss: 21.324 - ETA: 29s - loss: 21.327 - ETA: 27s - loss: 21.331 - ETA: 26s - loss: 21.337 - ETA: 25s - loss: 21.338 - ETA: 24s - loss: 21.338 - ETA: 23s - loss: 21.337 - ETA: 22s - loss: 21.337 - ETA: 22s - loss: 21.336 - ETA: 21s - loss: 21.333 - ETA: 21s - loss: 21.332 - ETA: 20s - loss: 21.333 - ETA: 20s - loss: 21.332 - ETA: 19s - loss: 21.332 - ETA: 19s - loss: 21.333 - ETA: 19s - loss: 21.334 - ETA: 18s - loss: 21.334 - ETA: 18s - loss: 21.334 - ETA: 18s - loss: 21.333 - ETA: 17s - loss: 21.332 - ETA: 17s - loss: 21.330 - ETA: 17s - loss: 21.330 - ETA: 17s - loss: 21.332 - ETA: 16s - loss: 21.332 - ETA: 16s - loss: 21.333 - ETA: 16s - loss: 21.333 - ETA: 16s - loss: 21.333 - ETA: 15s - loss: 21.333 - ETA: 15s - loss: 21.330 - ETA: 15s - loss: 21.329 - ETA: 15s - loss: 21.331 - ETA: 15s - loss: 21.333 - ETA: 15s - loss: 21.335 - ETA: 14s - loss: 21.336 - ETA: 14s - loss: 21.334 - ETA: 14s - loss: 21.333 - ETA: 14s - loss: 21.333 - ETA: 14s - loss: 21.331 - ETA: 14s - loss: 21.330 - ETA: 13s - loss: 21.329 - ETA: 13s - loss: 21.328 - ETA: 13s - loss: 21.326 - ETA: 13s - loss: 21.325 - ETA: 13s - loss: 21.324 - ETA: 13s - loss: 21.324 - ETA: 13s - loss: 21.322 - ETA: 13s - loss: 21.321 - ETA: 12s - loss: 21.319 - ETA: 12s - loss: 21.312 - ETA: 12s - loss: 21.309 - ETA: 12s - loss: 21.305 - ETA: 12s - loss: 21.300 - ETA: 12s - loss: 21.296 - ETA: 12s - loss: 21.289 - ETA: 12s - loss: 21.279 - ETA: 12s - loss: 21.284 - ETA: 12s - loss: 21.287 - ETA: 11s - loss: 21.280 - ETA: 11s - loss: 21.284 - ETA: 11s - loss: 21.286 - ETA: 11s - loss: 21.282 - ETA: 11s - loss: 21.271 - ETA: 11s - loss: 21.262 - ETA: 11s - loss: 21.254 - ETA: 11s - loss: 21.250 - ETA: 11s - loss: 21.238 - ETA: 11s - loss: 21.228 - ETA: 11s - loss: 21.222 - ETA: 11s - loss: 21.203 - ETA: 10s - loss: 21.193 - ETA: 10s - loss: 21.203 - ETA: 10s - loss: 21.185 - ETA: 10s - loss: 21.169 - ETA: 10s - loss: 21.141 - ETA: 10s - loss: 21.129 - ETA: 10s - loss: 21.101 - ETA: 10s - loss: 21.094 - ETA: 10s - loss: 21.107 - ETA: 10s - loss: 21.098 - ETA: 10s - loss: 21.098 - ETA: 10s - loss: 21.098 - ETA: 10s - loss: 21.085 - ETA: 9s - loss: 21.081 - ETA: 9s - loss: 21.07 - ETA: 9s - loss: 21.04 - ETA: 9s - loss: 21.01 - ETA: 9s - loss: 20.99 - ETA: 9s - loss: 20.98 - ETA: 9s - loss: 20.97 - ETA: 9s - loss: 20.93 - ETA: 9s - loss: 20.92 - ETA: 9s - loss: 20.88 - ETA: 9s - loss: 20.85 - ETA: 9s - loss: 20.82 - ETA: 9s - loss: 20.79 - ETA: 9s - loss: 20.79 - ETA: 8s - loss: 20.75 - ETA: 8s - loss: 20.77 - ETA: 8s - loss: 20.77 - ETA: 8s - loss: 20.79 - ETA: 8s - loss: 20.79 - ETA: 8s - loss: 20.77 - ETA: 8s - loss: 20.78 - ETA: 8s - loss: 20.75 - ETA: 8s - loss: 20.73 - ETA: 8s - loss: 20.70 - ETA: 8s - loss: 20.65 - ETA: 8s - loss: 20.65 - ETA: 8s - loss: 20.63 - ETA: 8s - loss: 20.60 - ETA: 7s - loss: 20.59 - ETA: 7s - loss: 20.59 - ETA: 7s - loss: 20.57 - ETA: 7s - loss: 20.58 - ETA: 7s - loss: 20.56 - ETA: 7s - loss: 20.54 - ETA: 7s - loss: 20.50 - ETA: 7s - loss: 20.47 - ETA: 7s - loss: 20.44 - ETA: 7s - loss: 20.41 - ETA: 7s - loss: 20.40 - ETA: 7s - loss: 20.40 - ETA: 7s - loss: 20.39 - ETA: 7s - loss: 20.36 - ETA: 7s - loss: 20.34 - ETA: 7s - loss: 20.32 - ETA: 6s - loss: 20.27 - ETA: 6s - loss: 20.23 - ETA: 6s - loss: 20.17 - ETA: 6s - loss: 20.18 - ETA: 6s - loss: 20.16 - ETA: 6s - loss: 20.12 - ETA: 6s - loss: 20.08 - ETA: 6s - loss: 20.06 - ETA: 6s - loss: 20.05 - ETA: 6s - loss: 19.98 - ETA: 6s - loss: 19.92 - ETA: 6s - loss: 19.89 - ETA: 6s - loss: 19.86 - ETA: 6s - loss: 19.85 - ETA: 6s - loss: 19.80 - ETA: 6s - loss: 19.75 - ETA: 5s - loss: 19.72 - ETA: 5s - loss: 19.67 - ETA: 5s - loss: 19.63 - ETA: 5s - loss: 19.60 - ETA: 5s - loss: 19.58 - ETA: 5s - loss: 19.56 - ETA: 5s - loss: 19.52 - ETA: 5s - loss: 19.52 - ETA: 5s - loss: 19.50 - ETA: 5s - loss: 19.47 - ETA: 5s - loss: 19.46 - ETA: 5s - loss: 19.40 - ETA: 5s - loss: 19.39 - ETA: 5s - loss: 19.41 - ETA: 5s - loss: 19.38 - ETA: 4s - loss: 19.36 - ETA: 4s - loss: 19.34 - ETA: 4s - loss: 19.34 - ETA: 4s - loss: 19.31 - ETA: 4s - loss: 19.27 - ETA: 4s - loss: 19.21 - ETA: 4s - loss: 19.21 - ETA: 4s - loss: 19.16 - ETA: 4s - loss: 19.13 - ETA: 4s - loss: 19.07 - ETA: 4s - loss: 19.01 - ETA: 4s - loss: 18.97 - ETA: 4s - loss: 18.92 - ETA: 4s - loss: 18.86 - ETA: 4s - loss: 18.80 - ETA: 4s - loss: 18.75 - ETA: 4s - loss: 18.67 - ETA: 3s - loss: 18.60 - ETA: 3s - loss: 18.60 - ETA: 3s - loss: 18.59 - ETA: 3s - loss: 18.57 - ETA: 3s - loss: 18.54 - ETA: 3s - loss: 18.48 - ETA: 3s - loss: 18.43 - ETA: 3s - loss: 18.41 - ETA: 3s - loss: 18.39 - ETA: 3s - loss: 18.36 - ETA: 3s - loss: 18.28 - ETA: 3s - loss: 18.23 - ETA: 3s - loss: 18.20 - ETA: 3s - loss: 18.15 - ETA: 3s - loss: 18.16 - ETA: 2s - loss: 18.13 - ETA: 2s - loss: 18.09 - ETA: 2s - loss: 18.05 - ETA: 2s - loss: 17.99 - ETA: 2s - loss: 17.97 - ETA: 2s - loss: 17.94 - ETA: 2s - loss: 17.95 - ETA: 2s - loss: 17.92 - ETA: 2s - loss: 17.88 - ETA: 2s - loss: 17.87 - ETA: 2s - loss: 17.85 - ETA: 2s - loss: 17.82 - ETA: 2s - loss: 17.78 - ETA: 2s - loss: 17.82 - ETA: 2s - loss: 17.85 - ETA: 2s - loss: 17.82 - ETA: 2s - loss: 17.83 - ETA: 1s - loss: 17.82 - ETA: 1s - loss: 17.82 - ETA: 1s - loss: 17.85 - ETA: 1s - loss: 17.80 - ETA: 1s - loss: 17.80 - ETA: 1s - loss: 17.75 - ETA: 1s - loss: 17.73 - ETA: 1s - loss: 17.73 - ETA: 1s - loss: 17.70 - ETA: 1s - loss: 17.67 - ETA: 1s - loss: 17.64 - ETA: 1s - loss: 17.63 - ETA: 1s - loss: 17.62 - ETA: 1s - loss: 17.60 - ETA: 1s - loss: 17.59 - ETA: 1s - loss: 17.58 - ETA: 1s - loss: 17.61 - ETA: 0s - loss: 17.57 - ETA: 0s - loss: 17.55 - ETA: 0s - loss: 17.54 - ETA: 0s - loss: 17.53 - ETA: 0s - loss: 17.53 - ETA: 0s - loss: 17.49 - ETA: 0s - loss: 17.46 - ETA: 0s - loss: 17.47 - ETA: 0s - loss: 17.48 - ETA: 0s - loss: 17.46 - ETA: 0s - loss: 17.43 - ETA: 0s - loss: 17.39 - ETA: 0s - loss: 17.38 - ETA: 0s - loss: 17.36 - ETA: 0s - loss: 17.35 - ETA: 0s - loss: 17.35 - ETA: 0s - loss: 17.34 - ETA: 0s - loss: 17.33 - 17s 1ms/step - loss: 17.2975 - val_loss: 12.3612\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14152/14152 [==============================] - ETA: 15s - loss: 15.966 - ETA: 13s - loss: 9.620 - ETA: 13s - loss: 14.728 - ETA: 13s - loss: 13.767 - ETA: 12s - loss: 14.480 - ETA: 12s - loss: 13.936 - ETA: 12s - loss: 12.856 - ETA: 12s - loss: 12.734 - ETA: 12s - loss: 12.394 - ETA: 12s - loss: 12.393 - ETA: 12s - loss: 12.848 - ETA: 12s - loss: 13.042 - ETA: 12s - loss: 12.806 - ETA: 12s - loss: 12.629 - ETA: 12s - loss: 12.584 - ETA: 12s - loss: 12.335 - ETA: 12s - loss: 12.182 - ETA: 12s - loss: 11.954 - ETA: 12s - loss: 12.056 - ETA: 12s - loss: 11.835 - ETA: 12s - loss: 11.741 - ETA: 12s - loss: 11.971 - ETA: 11s - loss: 12.281 - ETA: 11s - loss: 12.276 - ETA: 11s - loss: 12.327 - ETA: 11s - loss: 12.321 - ETA: 11s - loss: 12.432 - ETA: 11s - loss: 12.387 - ETA: 11s - loss: 12.702 - ETA: 11s - loss: 12.925 - ETA: 11s - loss: 12.928 - ETA: 11s - loss: 12.626 - ETA: 11s - loss: 12.960 - ETA: 11s - loss: 12.761 - ETA: 11s - loss: 12.656 - ETA: 11s - loss: 12.730 - ETA: 11s - loss: 12.526 - ETA: 11s - loss: 12.735 - ETA: 10s - loss: 13.050 - ETA: 10s - loss: 12.900 - ETA: 10s - loss: 12.914 - ETA: 10s - loss: 12.845 - ETA: 10s - loss: 12.902 - ETA: 10s - loss: 12.905 - ETA: 10s - loss: 13.048 - ETA: 10s - loss: 13.593 - ETA: 10s - loss: 13.557 - ETA: 10s - loss: 13.520 - ETA: 10s - loss: 13.533 - ETA: 10s - loss: 13.480 - ETA: 10s - loss: 13.366 - ETA: 10s - loss: 13.473 - ETA: 10s - loss: 13.501 - ETA: 10s - loss: 13.539 - ETA: 9s - loss: 13.347 - ETA: 9s - loss: 13.43 - ETA: 9s - loss: 13.25 - ETA: 9s - loss: 13.20 - ETA: 9s - loss: 13.18 - ETA: 9s - loss: 13.07 - ETA: 9s - loss: 13.02 - ETA: 9s - loss: 12.99 - ETA: 9s - loss: 13.06 - ETA: 9s - loss: 13.01 - ETA: 9s - loss: 12.93 - ETA: 9s - loss: 12.86 - ETA: 9s - loss: 12.84 - ETA: 9s - loss: 12.76 - ETA: 9s - loss: 12.74 - ETA: 9s - loss: 12.74 - ETA: 9s - loss: 12.76 - ETA: 9s - loss: 12.90 - ETA: 9s - loss: 12.98 - ETA: 9s - loss: 12.98 - ETA: 9s - loss: 12.95 - ETA: 8s - loss: 12.89 - ETA: 8s - loss: 12.90 - ETA: 8s - loss: 12.92 - ETA: 8s - loss: 13.00 - ETA: 8s - loss: 13.00 - ETA: 8s - loss: 13.02 - ETA: 8s - loss: 13.09 - ETA: 8s - loss: 13.03 - ETA: 8s - loss: 12.93 - ETA: 8s - loss: 12.90 - ETA: 8s - loss: 12.86 - ETA: 8s - loss: 12.89 - ETA: 8s - loss: 12.83 - ETA: 8s - loss: 12.88 - ETA: 8s - loss: 12.84 - ETA: 8s - loss: 12.72 - ETA: 8s - loss: 12.81 - ETA: 8s - loss: 12.84 - ETA: 7s - loss: 12.82 - ETA: 7s - loss: 12.76 - ETA: 7s - loss: 12.78 - ETA: 7s - loss: 12.73 - ETA: 7s - loss: 12.76 - ETA: 7s - loss: 12.85 - ETA: 7s - loss: 12.93 - ETA: 7s - loss: 12.93 - ETA: 7s - loss: 12.85 - ETA: 7s - loss: 12.88 - ETA: 7s - loss: 12.90 - ETA: 7s - loss: 12.93 - ETA: 7s - loss: 13.12 - ETA: 7s - loss: 13.03 - ETA: 7s - loss: 13.02 - ETA: 7s - loss: 13.03 - ETA: 7s - loss: 13.10 - ETA: 7s - loss: 13.11 - ETA: 6s - loss: 13.19 - ETA: 6s - loss: 13.17 - ETA: 6s - loss: 13.30 - ETA: 6s - loss: 13.32 - ETA: 6s - loss: 13.32 - ETA: 6s - loss: 13.29 - ETA: 6s - loss: 13.25 - ETA: 6s - loss: 13.16 - ETA: 6s - loss: 13.20 - ETA: 6s - loss: 13.14 - ETA: 6s - loss: 13.16 - ETA: 6s - loss: 13.13 - ETA: 6s - loss: 13.13 - ETA: 6s - loss: 13.18 - ETA: 6s - loss: 13.19 - ETA: 6s - loss: 13.11 - ETA: 6s - loss: 13.08 - ETA: 6s - loss: 13.07 - ETA: 6s - loss: 13.07 - ETA: 6s - loss: 13.06 - ETA: 5s - loss: 13.06 - ETA: 5s - loss: 13.05 - ETA: 5s - loss: 13.02 - ETA: 5s - loss: 13.06 - ETA: 5s - loss: 13.11 - ETA: 5s - loss: 13.06 - ETA: 5s - loss: 13.07 - ETA: 5s - loss: 13.06 - ETA: 5s - loss: 13.01 - ETA: 5s - loss: 13.00 - ETA: 5s - loss: 12.98 - ETA: 5s - loss: 13.03 - ETA: 5s - loss: 13.01 - ETA: 5s - loss: 13.01 - ETA: 5s - loss: 12.99 - ETA: 5s - loss: 12.94 - ETA: 5s - loss: 12.93 - ETA: 5s - loss: 12.88 - ETA: 5s - loss: 12.93 - ETA: 5s - loss: 12.87 - ETA: 5s - loss: 12.82 - ETA: 5s - loss: 12.82 - ETA: 5s - loss: 12.79 - ETA: 5s - loss: 12.73 - ETA: 5s - loss: 12.76 - ETA: 5s - loss: 12.73 - ETA: 4s - loss: 12.79 - ETA: 4s - loss: 12.76 - ETA: 4s - loss: 12.73 - ETA: 4s - loss: 12.72 - ETA: 4s - loss: 12.67 - ETA: 4s - loss: 12.69 - ETA: 4s - loss: 12.71 - ETA: 4s - loss: 12.74 - ETA: 4s - loss: 12.76 - ETA: 4s - loss: 12.74 - ETA: 4s - loss: 12.71 - ETA: 4s - loss: 12.72 - ETA: 4s - loss: 12.72 - ETA: 4s - loss: 12.66 - ETA: 4s - loss: 12.70 - ETA: 4s - loss: 12.71 - ETA: 4s - loss: 12.68 - ETA: 3s - loss: 12.67 - ETA: 3s - loss: 12.72 - ETA: 3s - loss: 12.76 - ETA: 3s - loss: 12.76 - ETA: 3s - loss: 12.83 - ETA: 3s - loss: 12.78 - ETA: 3s - loss: 12.81 - ETA: 3s - loss: 12.75 - ETA: 3s - loss: 12.74 - ETA: 3s - loss: 12.68 - ETA: 3s - loss: 12.65 - ETA: 3s - loss: 12.63 - ETA: 3s - loss: 12.69 - ETA: 3s - loss: 12.68 - ETA: 3s - loss: 12.68 - ETA: 3s - loss: 12.67 - ETA: 3s - loss: 12.66 - ETA: 2s - loss: 12.64 - ETA: 2s - loss: 12.63 - ETA: 2s - loss: 12.66 - ETA: 2s - loss: 12.66 - ETA: 2s - loss: 12.64 - ETA: 2s - loss: 12.60 - ETA: 2s - loss: 12.61 - ETA: 2s - loss: 12.60 - ETA: 2s - loss: 12.59 - ETA: 2s - loss: 12.57 - ETA: 2s - loss: 12.57 - ETA: 2s - loss: 12.59 - ETA: 2s - loss: 12.62 - ETA: 2s - loss: 12.58 - ETA: 2s - loss: 12.57 - ETA: 2s - loss: 12.58 - ETA: 2s - loss: 12.58 - ETA: 1s - loss: 12.60 - ETA: 1s - loss: 12.62 - ETA: 1s - loss: 12.61 - ETA: 1s - loss: 12.59 - ETA: 1s - loss: 12.57 - ETA: 1s - loss: 12.58 - ETA: 1s - loss: 12.59 - ETA: 1s - loss: 12.58 - ETA: 1s - loss: 12.60 - ETA: 1s - loss: 12.59 - ETA: 1s - loss: 12.57 - ETA: 1s - loss: 12.57 - ETA: 1s - loss: 12.55 - ETA: 1s - loss: 12.55 - ETA: 1s - loss: 12.55 - ETA: 1s - loss: 12.53 - ETA: 1s - loss: 12.58 - ETA: 0s - loss: 12.56 - ETA: 0s - loss: 12.63 - ETA: 0s - loss: 12.63 - ETA: 0s - loss: 12.62 - ETA: 0s - loss: 12.63 - ETA: 0s - loss: 12.62 - ETA: 0s - loss: 12.60 - ETA: 0s - loss: 12.68 - ETA: 0s - loss: 12.67 - ETA: 0s - loss: 12.66 - ETA: 0s - loss: 12.67 - ETA: 0s - loss: 12.63 - ETA: 0s - loss: 12.64 - ETA: 0s - loss: 12.67 - ETA: 0s - loss: 12.70 - ETA: 0s - loss: 12.68 - ETA: 0s - loss: 12.68 - ETA: 0s - loss: 12.65 - 15s 1ms/step - loss: 12.6718 - val_loss: 11.2942\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14152/14152 [==============================] - ETA: 15s - loss: 3.66 - ETA: 13s - loss: 11.984 - ETA: 13s - loss: 14.649 - ETA: 13s - loss: 15.570 - ETA: 13s - loss: 12.850 - ETA: 13s - loss: 13.239 - ETA: 13s - loss: 11.780 - ETA: 13s - loss: 11.870 - ETA: 13s - loss: 11.217 - ETA: 12s - loss: 11.428 - ETA: 12s - loss: 10.822 - ETA: 12s - loss: 11.296 - ETA: 12s - loss: 11.269 - ETA: 12s - loss: 11.480 - ETA: 12s - loss: 11.222 - ETA: 12s - loss: 10.756 - ETA: 12s - loss: 12.000 - ETA: 12s - loss: 12.495 - ETA: 12s - loss: 12.485 - ETA: 12s - loss: 12.692 - ETA: 11s - loss: 12.553 - ETA: 11s - loss: 13.565 - ETA: 11s - loss: 13.641 - ETA: 11s - loss: 13.523 - ETA: 11s - loss: 13.448 - ETA: 11s - loss: 14.318 - ETA: 11s - loss: 14.322 - ETA: 11s - loss: 14.284 - ETA: 11s - loss: 14.421 - ETA: 11s - loss: 14.132 - ETA: 11s - loss: 13.879 - ETA: 11s - loss: 14.367 - ETA: 11s - loss: 14.296 - ETA: 11s - loss: 14.288 - ETA: 11s - loss: 14.173 - ETA: 11s - loss: 14.052 - ETA: 11s - loss: 14.186 - ETA: 11s - loss: 14.535 - ETA: 11s - loss: 14.669 - ETA: 11s - loss: 14.528 - ETA: 11s - loss: 14.548 - ETA: 10s - loss: 14.239 - ETA: 10s - loss: 14.330 - ETA: 10s - loss: 14.211 - ETA: 10s - loss: 14.269 - ETA: 10s - loss: 14.150 - ETA: 10s - loss: 14.230 - ETA: 10s - loss: 14.088 - ETA: 10s - loss: 14.018 - ETA: 10s - loss: 14.136 - ETA: 10s - loss: 14.146 - ETA: 10s - loss: 14.019 - ETA: 10s - loss: 13.931 - ETA: 10s - loss: 13.773 - ETA: 10s - loss: 13.769 - ETA: 10s - loss: 13.656 - ETA: 10s - loss: 13.633 - ETA: 10s - loss: 13.494 - ETA: 10s - loss: 13.420 - ETA: 10s - loss: 13.285 - ETA: 9s - loss: 13.205 - ETA: 9s - loss: 13.19 - ETA: 9s - loss: 13.16 - ETA: 9s - loss: 13.07 - ETA: 9s - loss: 12.93 - ETA: 9s - loss: 12.90 - ETA: 9s - loss: 12.89 - ETA: 9s - loss: 12.92 - ETA: 9s - loss: 12.91 - ETA: 9s - loss: 13.06 - ETA: 9s - loss: 13.06 - ETA: 9s - loss: 13.05 - ETA: 9s - loss: 13.03 - ETA: 9s - loss: 13.02 - ETA: 9s - loss: 13.00 - ETA: 9s - loss: 12.96 - ETA: 9s - loss: 12.92 - ETA: 9s - loss: 12.97 - ETA: 9s - loss: 12.85 - ETA: 8s - loss: 12.93 - ETA: 8s - loss: 13.01 - ETA: 8s - loss: 12.93 - ETA: 8s - loss: 12.91 - ETA: 8s - loss: 12.92 - ETA: 8s - loss: 12.87 - ETA: 8s - loss: 12.94 - ETA: 8s - loss: 12.88 - ETA: 8s - loss: 12.92 - ETA: 8s - loss: 12.93 - ETA: 8s - loss: 13.06 - ETA: 8s - loss: 13.08 - ETA: 8s - loss: 13.01 - ETA: 8s - loss: 12.99 - ETA: 8s - loss: 12.96 - ETA: 8s - loss: 12.98 - ETA: 8s - loss: 12.95 - ETA: 8s - loss: 12.88 - ETA: 7s - loss: 12.84 - ETA: 7s - loss: 12.87 - ETA: 7s - loss: 12.79 - ETA: 7s - loss: 12.77 - ETA: 7s - loss: 12.78 - ETA: 7s - loss: 12.70 - ETA: 7s - loss: 12.67 - ETA: 7s - loss: 12.58 - ETA: 7s - loss: 12.54 - ETA: 7s - loss: 12.46 - ETA: 7s - loss: 12.50 - ETA: 7s - loss: 12.44 - ETA: 7s - loss: 12.45 - ETA: 7s - loss: 12.46 - ETA: 7s - loss: 12.42 - ETA: 7s - loss: 12.35 - ETA: 7s - loss: 12.35 - ETA: 7s - loss: 12.37 - ETA: 6s - loss: 12.39 - ETA: 6s - loss: 12.33 - ETA: 6s - loss: 12.39 - ETA: 6s - loss: 12.40 - ETA: 6s - loss: 12.35 - ETA: 6s - loss: 12.34 - ETA: 6s - loss: 12.29 - ETA: 6s - loss: 12.27 - ETA: 6s - loss: 12.23 - ETA: 6s - loss: 12.26 - ETA: 6s - loss: 12.22 - ETA: 6s - loss: 12.29 - ETA: 6s - loss: 12.29 - ETA: 6s - loss: 12.26 - ETA: 6s - loss: 12.19 - ETA: 6s - loss: 12.13 - ETA: 6s - loss: 12.09 - ETA: 6s - loss: 12.13 - ETA: 5s - loss: 12.15 - ETA: 5s - loss: 12.14 - ETA: 5s - loss: 12.14 - ETA: 5s - loss: 12.16 - ETA: 5s - loss: 12.17 - ETA: 5s - loss: 12.23 - ETA: 5s - loss: 12.21 - ETA: 5s - loss: 12.22 - ETA: 5s - loss: 12.31 - ETA: 5s - loss: 12.30 - ETA: 5s - loss: 12.35 - ETA: 5s - loss: 12.37 - ETA: 5s - loss: 12.37 - ETA: 5s - loss: 12.32 - ETA: 5s - loss: 12.28 - ETA: 5s - loss: 12.28 - ETA: 5s - loss: 12.32 - ETA: 5s - loss: 12.31 - ETA: 4s - loss: 12.30 - ETA: 4s - loss: 12.28 - ETA: 4s - loss: 12.30 - ETA: 4s - loss: 12.26 - ETA: 4s - loss: 12.34 - ETA: 4s - loss: 12.31 - ETA: 4s - loss: 12.29 - ETA: 4s - loss: 12.25 - ETA: 4s - loss: 12.24 - ETA: 4s - loss: 12.25 - ETA: 4s - loss: 12.23 - ETA: 4s - loss: 12.24 - ETA: 4s - loss: 12.23 - ETA: 4s - loss: 12.22 - ETA: 4s - loss: 12.30 - ETA: 4s - loss: 12.30 - ETA: 4s - loss: 12.26 - ETA: 4s - loss: 12.25 - ETA: 3s - loss: 12.22 - ETA: 3s - loss: 12.25 - ETA: 3s - loss: 12.21 - ETA: 3s - loss: 12.18 - ETA: 3s - loss: 12.21 - ETA: 3s - loss: 12.20 - ETA: 3s - loss: 12.21 - ETA: 3s - loss: 12.21 - ETA: 3s - loss: 12.17 - ETA: 3s - loss: 12.13 - ETA: 3s - loss: 12.16 - ETA: 3s - loss: 12.16 - ETA: 3s - loss: 12.12 - ETA: 3s - loss: 12.12 - ETA: 3s - loss: 12.09 - ETA: 3s - loss: 12.07 - ETA: 3s - loss: 12.04 - ETA: 3s - loss: 11.99 - ETA: 3s - loss: 11.96 - ETA: 2s - loss: 11.96 - ETA: 2s - loss: 11.99 - ETA: 2s - loss: 11.98 - ETA: 2s - loss: 11.98 - ETA: 2s - loss: 11.94 - ETA: 2s - loss: 11.90 - ETA: 2s - loss: 11.88 - ETA: 2s - loss: 11.87 - ETA: 2s - loss: 11.88 - ETA: 2s - loss: 11.87 - ETA: 2s - loss: 11.87 - ETA: 2s - loss: 11.89 - ETA: 2s - loss: 11.87 - ETA: 2s - loss: 11.87 - ETA: 2s - loss: 11.85 - ETA: 2s - loss: 11.83 - ETA: 2s - loss: 11.82 - ETA: 2s - loss: 11.80 - ETA: 1s - loss: 11.79 - ETA: 1s - loss: 11.78 - ETA: 1s - loss: 11.78 - ETA: 1s - loss: 11.80 - ETA: 1s - loss: 11.78 - ETA: 1s - loss: 11.79 - ETA: 1s - loss: 11.78 - ETA: 1s - loss: 11.78 - ETA: 1s - loss: 11.82 - ETA: 1s - loss: 11.83 - ETA: 1s - loss: 11.83 - ETA: 1s - loss: 11.82 - ETA: 1s - loss: 11.87 - ETA: 1s - loss: 11.87 - ETA: 1s - loss: 11.91 - ETA: 1s - loss: 11.93 - ETA: 1s - loss: 11.92 - ETA: 1s - loss: 11.91 - ETA: 1s - loss: 11.91 - ETA: 0s - loss: 11.88 - ETA: 0s - loss: 11.86 - ETA: 0s - loss: 11.86 - ETA: 0s - loss: 11.86 - ETA: 0s - loss: 11.91 - ETA: 0s - loss: 11.89 - ETA: 0s - loss: 11.94 - ETA: 0s - loss: 11.90 - ETA: 0s - loss: 11.89 - ETA: 0s - loss: 11.87 - ETA: 0s - loss: 11.85 - ETA: 0s - loss: 11.83 - ETA: 0s - loss: 11.82 - ETA: 0s - loss: 11.83 - ETA: 0s - loss: 11.81 - ETA: 0s - loss: 11.79 - ETA: 0s - loss: 11.78 - ETA: 0s - loss: 11.80 - 15s 1ms/step - loss: 11.8170 - val_loss: 10.6646\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14152/14152 [==============================] - ETA: 17s - loss: 24.559 - ETA: 14s - loss: 13.833 - ETA: 14s - loss: 12.551 - ETA: 14s - loss: 13.630 - ETA: 13s - loss: 13.093 - ETA: 13s - loss: 11.676 - ETA: 13s - loss: 11.574 - ETA: 13s - loss: 11.453 - ETA: 13s - loss: 10.344 - ETA: 13s - loss: 10.597 - ETA: 13s - loss: 10.442 - ETA: 13s - loss: 10.675 - ETA: 13s - loss: 11.562 - ETA: 12s - loss: 11.390 - ETA: 12s - loss: 12.056 - ETA: 12s - loss: 12.563 - ETA: 12s - loss: 12.529 - ETA: 12s - loss: 12.149 - ETA: 12s - loss: 12.108 - ETA: 12s - loss: 11.977 - ETA: 12s - loss: 12.182 - ETA: 12s - loss: 11.677 - ETA: 12s - loss: 11.811 - ETA: 12s - loss: 11.470 - ETA: 12s - loss: 11.263 - ETA: 12s - loss: 11.223 - ETA: 12s - loss: 11.382 - ETA: 12s - loss: 11.111 - ETA: 12s - loss: 10.895 - ETA: 12s - loss: 10.584 - ETA: 11s - loss: 10.919 - ETA: 11s - loss: 10.944 - ETA: 11s - loss: 10.985 - ETA: 11s - loss: 10.856 - ETA: 11s - loss: 10.867 - ETA: 11s - loss: 10.877 - ETA: 11s - loss: 10.857 - ETA: 11s - loss: 10.767 - ETA: 11s - loss: 10.996 - ETA: 11s - loss: 10.945 - ETA: 11s - loss: 10.954 - ETA: 11s - loss: 10.883 - ETA: 11s - loss: 10.912 - ETA: 11s - loss: 11.045 - ETA: 11s - loss: 11.070 - ETA: 10s - loss: 10.891 - ETA: 10s - loss: 11.087 - ETA: 10s - loss: 11.091 - ETA: 10s - loss: 10.941 - ETA: 10s - loss: 10.838 - ETA: 10s - loss: 10.800 - ETA: 10s - loss: 10.927 - ETA: 10s - loss: 10.949 - ETA: 10s - loss: 10.897 - ETA: 10s - loss: 10.888 - ETA: 10s - loss: 10.901 - ETA: 10s - loss: 11.009 - ETA: 10s - loss: 10.945 - ETA: 10s - loss: 10.958 - ETA: 10s - loss: 10.928 - ETA: 10s - loss: 10.945 - ETA: 10s - loss: 10.887 - ETA: 10s - loss: 10.778 - ETA: 10s - loss: 10.692 - ETA: 10s - loss: 10.781 - ETA: 10s - loss: 10.631 - ETA: 9s - loss: 10.511 - ETA: 9s - loss: 10.55 - ETA: 9s - loss: 10.47 - ETA: 9s - loss: 10.55 - ETA: 9s - loss: 10.51 - ETA: 9s - loss: 10.68 - ETA: 9s - loss: 10.71 - ETA: 9s - loss: 10.72 - ETA: 9s - loss: 10.69 - ETA: 9s - loss: 10.76 - ETA: 9s - loss: 10.87 - ETA: 9s - loss: 10.94 - ETA: 9s - loss: 10.84 - ETA: 9s - loss: 10.93 - ETA: 9s - loss: 10.93 - ETA: 9s - loss: 10.86 - ETA: 9s - loss: 10.92 - ETA: 9s - loss: 10.99 - ETA: 8s - loss: 11.02 - ETA: 8s - loss: 11.10 - ETA: 8s - loss: 11.04 - ETA: 8s - loss: 10.99 - ETA: 8s - loss: 11.04 - ETA: 8s - loss: 11.00 - ETA: 8s - loss: 10.98 - ETA: 8s - loss: 10.90 - ETA: 8s - loss: 10.95 - ETA: 8s - loss: 10.85 - ETA: 8s - loss: 10.89 - ETA: 8s - loss: 10.82 - ETA: 8s - loss: 10.80 - ETA: 8s - loss: 10.72 - ETA: 8s - loss: 10.69 - ETA: 8s - loss: 10.68 - ETA: 8s - loss: 10.76 - ETA: 7s - loss: 10.81 - ETA: 7s - loss: 10.80 - ETA: 7s - loss: 10.82 - ETA: 7s - loss: 10.78 - ETA: 7s - loss: 10.85 - ETA: 7s - loss: 10.86 - ETA: 7s - loss: 10.82 - ETA: 7s - loss: 10.86 - ETA: 7s - loss: 10.84 - ETA: 7s - loss: 10.92 - ETA: 7s - loss: 10.95 - ETA: 7s - loss: 10.86 - ETA: 7s - loss: 10.93 - ETA: 7s - loss: 11.01 - ETA: 7s - loss: 11.02 - ETA: 7s - loss: 11.15 - ETA: 7s - loss: 11.18 - ETA: 7s - loss: 11.19 - ETA: 7s - loss: 11.23 - ETA: 6s - loss: 11.29 - ETA: 6s - loss: 11.23 - ETA: 6s - loss: 11.21 - ETA: 6s - loss: 11.27 - ETA: 6s - loss: 11.27 - ETA: 6s - loss: 11.29 - ETA: 6s - loss: 11.32 - ETA: 6s - loss: 11.25 - ETA: 6s - loss: 11.32 - ETA: 6s - loss: 11.34 - ETA: 6s - loss: 11.32 - ETA: 6s - loss: 11.37 - ETA: 6s - loss: 11.36 - ETA: 6s - loss: 11.37 - ETA: 6s - loss: 11.39 - ETA: 6s - loss: 11.33 - ETA: 6s - loss: 11.34 - ETA: 6s - loss: 11.45 - ETA: 5s - loss: 11.44 - ETA: 5s - loss: 11.47 - ETA: 5s - loss: 11.48 - ETA: 5s - loss: 11.46 - ETA: 5s - loss: 11.44 - ETA: 5s - loss: 11.38 - ETA: 5s - loss: 11.38 - ETA: 5s - loss: 11.32 - ETA: 5s - loss: 11.29 - ETA: 5s - loss: 11.29 - ETA: 5s - loss: 11.28 - ETA: 5s - loss: 11.30 - ETA: 5s - loss: 11.31 - ETA: 5s - loss: 11.25 - ETA: 5s - loss: 11.20 - ETA: 5s - loss: 11.23 - ETA: 4s - loss: 11.18 - ETA: 4s - loss: 11.20 - ETA: 4s - loss: 11.20 - ETA: 4s - loss: 11.20 - ETA: 4s - loss: 11.22 - ETA: 4s - loss: 11.20 - ETA: 4s - loss: 11.21 - ETA: 4s - loss: 11.23 - ETA: 4s - loss: 11.23 - ETA: 4s - loss: 11.28 - ETA: 4s - loss: 11.26 - ETA: 4s - loss: 11.22 - ETA: 4s - loss: 11.17 - ETA: 4s - loss: 11.12 - ETA: 4s - loss: 11.09 - ETA: 4s - loss: 11.05 - ETA: 4s - loss: 11.05 - ETA: 4s - loss: 11.00 - ETA: 3s - loss: 11.04 - ETA: 3s - loss: 11.07 - ETA: 3s - loss: 11.09 - ETA: 3s - loss: 11.07 - ETA: 3s - loss: 11.11 - ETA: 3s - loss: 11.12 - ETA: 3s - loss: 11.17 - ETA: 3s - loss: 11.22 - ETA: 3s - loss: 11.26 - ETA: 3s - loss: 11.21 - ETA: 3s - loss: 11.20 - ETA: 3s - loss: 11.24 - ETA: 3s - loss: 11.22 - ETA: 3s - loss: 11.20 - ETA: 3s - loss: 11.18 - ETA: 3s - loss: 11.23 - ETA: 3s - loss: 11.21 - ETA: 3s - loss: 11.20 - ETA: 2s - loss: 11.24 - ETA: 2s - loss: 11.21 - ETA: 2s - loss: 11.25 - ETA: 2s - loss: 11.26 - ETA: 2s - loss: 11.28 - ETA: 2s - loss: 11.30 - ETA: 2s - loss: 11.31 - ETA: 2s - loss: 11.30 - ETA: 2s - loss: 11.28 - ETA: 2s - loss: 11.27 - ETA: 2s - loss: 11.31 - ETA: 2s - loss: 11.31 - ETA: 2s - loss: 11.31 - ETA: 2s - loss: 11.26 - ETA: 2s - loss: 11.31 - ETA: 2s - loss: 11.33 - ETA: 2s - loss: 11.33 - ETA: 2s - loss: 11.33 - ETA: 1s - loss: 11.40 - ETA: 1s - loss: 11.43 - ETA: 1s - loss: 11.46 - ETA: 1s - loss: 11.45 - ETA: 1s - loss: 11.52 - ETA: 1s - loss: 11.48 - ETA: 1s - loss: 11.50 - ETA: 1s - loss: 11.45 - ETA: 1s - loss: 11.46 - ETA: 1s - loss: 11.43 - ETA: 1s - loss: 11.44 - ETA: 1s - loss: 11.43 - ETA: 1s - loss: 11.42 - ETA: 1s - loss: 11.38 - ETA: 1s - loss: 11.36 - ETA: 1s - loss: 11.36 - ETA: 1s - loss: 11.36 - ETA: 1s - loss: 11.33 - ETA: 0s - loss: 11.48 - ETA: 0s - loss: 11.48 - ETA: 0s - loss: 11.44 - ETA: 0s - loss: 11.41 - ETA: 0s - loss: 11.38 - ETA: 0s - loss: 11.37 - ETA: 0s - loss: 11.33 - ETA: 0s - loss: 11.30 - ETA: 0s - loss: 11.26 - ETA: 0s - loss: 11.25 - ETA: 0s - loss: 11.26 - ETA: 0s - loss: 11.29 - ETA: 0s - loss: 11.29 - ETA: 0s - loss: 11.28 - ETA: 0s - loss: 11.27 - ETA: 0s - loss: 11.29 - ETA: 0s - loss: 11.26 - ETA: 0s - loss: 11.29 - 15s 1ms/step - loss: 11.3130 - val_loss: 13.3478\n",
      "Epoch 5/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14152/14152 [==============================] - ETA: 16s - loss: 9.96 - ETA: 13s - loss: 11.868 - ETA: 13s - loss: 11.776 - ETA: 13s - loss: 9.441 - ETA: 13s - loss: 8.91 - ETA: 13s - loss: 8.05 - ETA: 13s - loss: 9.23 - ETA: 12s - loss: 9.65 - ETA: 12s - loss: 9.61 - ETA: 12s - loss: 10.110 - ETA: 12s - loss: 10.434 - ETA: 12s - loss: 11.104 - ETA: 12s - loss: 11.783 - ETA: 12s - loss: 13.389 - ETA: 12s - loss: 12.531 - ETA: 12s - loss: 11.779 - ETA: 12s - loss: 11.857 - ETA: 12s - loss: 11.658 - ETA: 12s - loss: 11.115 - ETA: 12s - loss: 10.983 - ETA: 12s - loss: 10.815 - ETA: 12s - loss: 10.793 - ETA: 12s - loss: 10.547 - ETA: 11s - loss: 10.373 - ETA: 11s - loss: 10.581 - ETA: 11s - loss: 11.117 - ETA: 11s - loss: 10.939 - ETA: 11s - loss: 10.808 - ETA: 11s - loss: 10.959 - ETA: 11s - loss: 10.770 - ETA: 11s - loss: 10.707 - ETA: 11s - loss: 11.253 - ETA: 11s - loss: 11.674 - ETA: 11s - loss: 12.315 - ETA: 11s - loss: 12.186 - ETA: 11s - loss: 12.077 - ETA: 11s - loss: 12.056 - ETA: 11s - loss: 12.414 - ETA: 11s - loss: 12.241 - ETA: 11s - loss: 12.423 - ETA: 10s - loss: 12.340 - ETA: 10s - loss: 12.261 - ETA: 10s - loss: 12.301 - ETA: 10s - loss: 12.141 - ETA: 10s - loss: 12.104 - ETA: 10s - loss: 12.202 - ETA: 10s - loss: 12.043 - ETA: 10s - loss: 11.864 - ETA: 10s - loss: 11.795 - ETA: 10s - loss: 11.733 - ETA: 10s - loss: 11.843 - ETA: 10s - loss: 11.709 - ETA: 10s - loss: 11.770 - ETA: 10s - loss: 11.853 - ETA: 10s - loss: 11.902 - ETA: 10s - loss: 11.834 - ETA: 10s - loss: 11.817 - ETA: 9s - loss: 11.882 - ETA: 9s - loss: 11.77 - ETA: 9s - loss: 11.62 - ETA: 9s - loss: 11.49 - ETA: 9s - loss: 11.62 - ETA: 9s - loss: 11.58 - ETA: 9s - loss: 11.59 - ETA: 9s - loss: 11.63 - ETA: 9s - loss: 11.68 - ETA: 9s - loss: 11.62 - ETA: 9s - loss: 11.62 - ETA: 9s - loss: 11.50 - ETA: 9s - loss: 11.64 - ETA: 9s - loss: 11.65 - ETA: 9s - loss: 11.84 - ETA: 9s - loss: 11.73 - ETA: 9s - loss: 11.88 - ETA: 9s - loss: 11.78 - ETA: 9s - loss: 11.74 - ETA: 8s - loss: 11.75 - ETA: 8s - loss: 11.76 - ETA: 8s - loss: 11.74 - ETA: 8s - loss: 11.74 - ETA: 8s - loss: 11.70 - ETA: 8s - loss: 11.81 - ETA: 8s - loss: 11.91 - ETA: 8s - loss: 11.86 - ETA: 8s - loss: 11.91 - ETA: 8s - loss: 11.91 - ETA: 8s - loss: 11.85 - ETA: 8s - loss: 11.78 - ETA: 8s - loss: 11.76 - ETA: 8s - loss: 11.78 - ETA: 8s - loss: 11.73 - ETA: 8s - loss: 11.77 - ETA: 8s - loss: 11.74 - ETA: 8s - loss: 11.80 - ETA: 7s - loss: 11.72 - ETA: 7s - loss: 11.65 - ETA: 7s - loss: 11.59 - ETA: 7s - loss: 11.56 - ETA: 7s - loss: 11.57 - ETA: 7s - loss: 11.47 - ETA: 7s - loss: 11.48 - ETA: 7s - loss: 11.44 - ETA: 7s - loss: 11.44 - ETA: 7s - loss: 11.44 - ETA: 7s - loss: 11.42 - ETA: 7s - loss: 11.35 - ETA: 7s - loss: 11.40 - ETA: 7s - loss: 11.51 - ETA: 7s - loss: 11.45 - ETA: 7s - loss: 11.40 - ETA: 7s - loss: 11.46 - ETA: 7s - loss: 11.50 - ETA: 6s - loss: 11.69 - ETA: 6s - loss: 11.63 - ETA: 6s - loss: 11.59 - ETA: 6s - loss: 11.60 - ETA: 6s - loss: 11.76 - ETA: 6s - loss: 11.68 - ETA: 6s - loss: 11.63 - ETA: 6s - loss: 11.72 - ETA: 6s - loss: 11.67 - ETA: 6s - loss: 11.62 - ETA: 6s - loss: 11.63 - ETA: 6s - loss: 11.56 - ETA: 6s - loss: 11.49 - ETA: 6s - loss: 11.58 - ETA: 6s - loss: 11.64 - ETA: 6s - loss: 11.63 - ETA: 6s - loss: 11.61 - ETA: 6s - loss: 11.67 - ETA: 6s - loss: 11.67 - ETA: 5s - loss: 11.75 - ETA: 5s - loss: 11.69 - ETA: 5s - loss: 11.77 - ETA: 5s - loss: 11.75 - ETA: 5s - loss: 11.71 - ETA: 5s - loss: 11.75 - ETA: 5s - loss: 11.77 - ETA: 5s - loss: 11.80 - ETA: 5s - loss: 11.81 - ETA: 5s - loss: 11.78 - ETA: 5s - loss: 11.72 - ETA: 5s - loss: 11.76 - ETA: 5s - loss: 11.84 - ETA: 5s - loss: 11.83 - ETA: 5s - loss: 11.83 - ETA: 5s - loss: 11.81 - ETA: 5s - loss: 11.77 - ETA: 5s - loss: 11.85 - ETA: 4s - loss: 11.81 - ETA: 4s - loss: 11.77 - ETA: 4s - loss: 11.75 - ETA: 4s - loss: 11.72 - ETA: 4s - loss: 11.74 - ETA: 4s - loss: 11.77 - ETA: 4s - loss: 11.77 - ETA: 4s - loss: 11.78 - ETA: 4s - loss: 11.78 - ETA: 4s - loss: 11.78 - ETA: 4s - loss: 11.70 - ETA: 4s - loss: 11.69 - ETA: 4s - loss: 11.65 - ETA: 4s - loss: 11.64 - ETA: 4s - loss: 11.59 - ETA: 4s - loss: 11.56 - ETA: 4s - loss: 11.53 - ETA: 4s - loss: 11.51 - ETA: 3s - loss: 11.48 - ETA: 3s - loss: 11.50 - ETA: 3s - loss: 11.52 - ETA: 3s - loss: 11.50 - ETA: 3s - loss: 11.48 - ETA: 3s - loss: 11.46 - ETA: 3s - loss: 11.50 - ETA: 3s - loss: 11.53 - ETA: 3s - loss: 11.52 - ETA: 3s - loss: 11.52 - ETA: 3s - loss: 11.50 - ETA: 3s - loss: 11.47 - ETA: 3s - loss: 11.42 - ETA: 3s - loss: 11.49 - ETA: 3s - loss: 11.48 - ETA: 3s - loss: 11.45 - ETA: 3s - loss: 11.45 - ETA: 3s - loss: 11.43 - ETA: 3s - loss: 11.46 - ETA: 2s - loss: 11.46 - ETA: 2s - loss: 11.50 - ETA: 2s - loss: 11.52 - ETA: 2s - loss: 11.53 - ETA: 2s - loss: 11.49 - ETA: 2s - loss: 11.50 - ETA: 2s - loss: 11.48 - ETA: 2s - loss: 11.52 - ETA: 2s - loss: 11.52 - ETA: 2s - loss: 11.49 - ETA: 2s - loss: 11.45 - ETA: 2s - loss: 11.46 - ETA: 2s - loss: 11.44 - ETA: 2s - loss: 11.41 - ETA: 2s - loss: 11.39 - ETA: 2s - loss: 11.39 - ETA: 2s - loss: 11.39 - ETA: 2s - loss: 11.44 - ETA: 1s - loss: 11.46 - ETA: 1s - loss: 11.43 - ETA: 1s - loss: 11.41 - ETA: 1s - loss: 11.39 - ETA: 1s - loss: 11.41 - ETA: 1s - loss: 11.38 - ETA: 1s - loss: 11.40 - ETA: 1s - loss: 11.41 - ETA: 1s - loss: 11.38 - ETA: 1s - loss: 11.38 - ETA: 1s - loss: 11.35 - ETA: 1s - loss: 11.32 - ETA: 1s - loss: 11.28 - ETA: 1s - loss: 11.33 - ETA: 1s - loss: 11.37 - ETA: 1s - loss: 11.38 - ETA: 1s - loss: 11.35 - ETA: 1s - loss: 11.37 - ETA: 0s - loss: 11.41 - ETA: 0s - loss: 11.46 - ETA: 0s - loss: 11.46 - ETA: 0s - loss: 11.44 - ETA: 0s - loss: 11.42 - ETA: 0s - loss: 11.41 - ETA: 0s - loss: 11.38 - ETA: 0s - loss: 11.37 - ETA: 0s - loss: 11.34 - ETA: 0s - loss: 11.36 - ETA: 0s - loss: 11.37 - ETA: 0s - loss: 11.37 - ETA: 0s - loss: 11.41 - ETA: 0s - loss: 11.40 - ETA: 0s - loss: 11.46 - ETA: 0s - loss: 11.50 - ETA: 0s - loss: 11.51 - ETA: 0s - loss: 11.51 - 15s 1ms/step - loss: 11.5192 - val_loss: 11.1560\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14152/14152 [==============================] - ETA: 17s - loss: 4.49 - ETA: 13s - loss: 14.105 - ETA: 13s - loss: 12.230 - ETA: 13s - loss: 15.099 - ETA: 13s - loss: 12.801 - ETA: 13s - loss: 12.255 - ETA: 13s - loss: 11.574 - ETA: 13s - loss: 11.518 - ETA: 13s - loss: 10.852 - ETA: 13s - loss: 11.670 - ETA: 13s - loss: 11.273 - ETA: 13s - loss: 10.920 - ETA: 13s - loss: 10.486 - ETA: 13s - loss: 10.808 - ETA: 13s - loss: 10.271 - ETA: 13s - loss: 10.184 - ETA: 12s - loss: 11.154 - ETA: 12s - loss: 10.966 - ETA: 12s - loss: 11.366 - ETA: 12s - loss: 12.011 - ETA: 12s - loss: 11.834 - ETA: 12s - loss: 12.147 - ETA: 12s - loss: 11.702 - ETA: 12s - loss: 11.867 - ETA: 12s - loss: 12.017 - ETA: 12s - loss: 12.109 - ETA: 12s - loss: 11.774 - ETA: 12s - loss: 11.847 - ETA: 12s - loss: 11.968 - ETA: 12s - loss: 11.954 - ETA: 12s - loss: 12.016 - ETA: 12s - loss: 11.853 - ETA: 11s - loss: 11.779 - ETA: 11s - loss: 12.066 - ETA: 11s - loss: 12.168 - ETA: 11s - loss: 12.462 - ETA: 11s - loss: 12.277 - ETA: 11s - loss: 12.205 - ETA: 11s - loss: 12.160 - ETA: 11s - loss: 12.431 - ETA: 11s - loss: 12.337 - ETA: 11s - loss: 12.177 - ETA: 11s - loss: 12.270 - ETA: 11s - loss: 12.262 - ETA: 11s - loss: 12.259 - ETA: 11s - loss: 12.337 - ETA: 11s - loss: 12.447 - ETA: 11s - loss: 12.372 - ETA: 11s - loss: 12.597 - ETA: 11s - loss: 12.597 - ETA: 10s - loss: 12.636 - ETA: 10s - loss: 12.454 - ETA: 10s - loss: 12.327 - ETA: 10s - loss: 12.147 - ETA: 10s - loss: 12.154 - ETA: 10s - loss: 12.081 - ETA: 10s - loss: 12.031 - ETA: 10s - loss: 11.983 - ETA: 10s - loss: 12.102 - ETA: 10s - loss: 12.306 - ETA: 10s - loss: 12.417 - ETA: 10s - loss: 12.413 - ETA: 10s - loss: 12.328 - ETA: 10s - loss: 12.251 - ETA: 10s - loss: 12.135 - ETA: 10s - loss: 11.965 - ETA: 10s - loss: 12.047 - ETA: 10s - loss: 12.009 - ETA: 9s - loss: 11.981 - ETA: 9s - loss: 11.90 - ETA: 9s - loss: 12.04 - ETA: 9s - loss: 12.12 - ETA: 9s - loss: 12.17 - ETA: 9s - loss: 12.30 - ETA: 9s - loss: 12.37 - ETA: 9s - loss: 12.48 - ETA: 9s - loss: 12.54 - ETA: 9s - loss: 12.58 - ETA: 9s - loss: 12.70 - ETA: 9s - loss: 12.69 - ETA: 9s - loss: 12.69 - ETA: 9s - loss: 12.71 - ETA: 9s - loss: 12.62 - ETA: 9s - loss: 12.56 - ETA: 9s - loss: 12.58 - ETA: 9s - loss: 12.55 - ETA: 8s - loss: 12.55 - ETA: 8s - loss: 12.49 - ETA: 8s - loss: 12.43 - ETA: 8s - loss: 12.45 - ETA: 8s - loss: 12.45 - ETA: 8s - loss: 12.43 - ETA: 8s - loss: 12.39 - ETA: 8s - loss: 12.32 - ETA: 8s - loss: 12.20 - ETA: 8s - loss: 12.15 - ETA: 8s - loss: 12.22 - ETA: 8s - loss: 12.13 - ETA: 8s - loss: 12.10 - ETA: 8s - loss: 12.00 - ETA: 8s - loss: 11.97 - ETA: 8s - loss: 11.96 - ETA: 8s - loss: 11.89 - ETA: 7s - loss: 11.81 - ETA: 7s - loss: 11.74 - ETA: 7s - loss: 11.64 - ETA: 7s - loss: 11.59 - ETA: 7s - loss: 11.54 - ETA: 7s - loss: 11.47 - ETA: 7s - loss: 11.45 - ETA: 7s - loss: 11.41 - ETA: 7s - loss: 11.40 - ETA: 7s - loss: 11.36 - ETA: 7s - loss: 11.28 - ETA: 7s - loss: 11.26 - ETA: 7s - loss: 11.39 - ETA: 7s - loss: 11.41 - ETA: 7s - loss: 11.62 - ETA: 7s - loss: 11.64 - ETA: 7s - loss: 11.57 - ETA: 6s - loss: 11.66 - ETA: 6s - loss: 11.67 - ETA: 6s - loss: 11.66 - ETA: 6s - loss: 11.58 - ETA: 6s - loss: 11.59 - ETA: 6s - loss: 11.54 - ETA: 6s - loss: 11.53 - ETA: 6s - loss: 11.46 - ETA: 6s - loss: 11.44 - ETA: 6s - loss: 11.49 - ETA: 6s - loss: 11.56 - ETA: 6s - loss: 11.62 - ETA: 6s - loss: 11.62 - ETA: 6s - loss: 11.73 - ETA: 6s - loss: 11.71 - ETA: 6s - loss: 11.74 - ETA: 6s - loss: 11.66 - ETA: 6s - loss: 11.66 - ETA: 5s - loss: 11.66 - ETA: 5s - loss: 11.67 - ETA: 5s - loss: 11.65 - ETA: 5s - loss: 11.64 - ETA: 5s - loss: 11.58 - ETA: 5s - loss: 11.62 - ETA: 5s - loss: 11.55 - ETA: 5s - loss: 11.51 - ETA: 5s - loss: 11.56 - ETA: 5s - loss: 11.52 - ETA: 5s - loss: 11.49 - ETA: 5s - loss: 11.46 - ETA: 5s - loss: 11.49 - ETA: 5s - loss: 11.46 - ETA: 5s - loss: 11.47 - ETA: 5s - loss: 11.51 - ETA: 5s - loss: 11.45 - ETA: 4s - loss: 11.51 - ETA: 4s - loss: 11.54 - ETA: 4s - loss: 11.59 - ETA: 4s - loss: 11.62 - ETA: 4s - loss: 11.64 - ETA: 4s - loss: 11.70 - ETA: 4s - loss: 11.65 - ETA: 4s - loss: 11.58 - ETA: 4s - loss: 11.62 - ETA: 4s - loss: 11.61 - ETA: 4s - loss: 11.59 - ETA: 4s - loss: 11.57 - ETA: 4s - loss: 11.60 - ETA: 4s - loss: 11.56 - ETA: 4s - loss: 11.64 - ETA: 4s - loss: 11.59 - ETA: 4s - loss: 11.54 - ETA: 3s - loss: 11.55 - ETA: 3s - loss: 11.58 - ETA: 3s - loss: 11.69 - ETA: 3s - loss: 11.66 - ETA: 3s - loss: 11.62 - ETA: 3s - loss: 11.59 - ETA: 3s - loss: 11.55 - ETA: 3s - loss: 11.49 - ETA: 3s - loss: 11.62 - ETA: 3s - loss: 11.65 - ETA: 3s - loss: 11.66 - ETA: 3s - loss: 11.71 - ETA: 3s - loss: 11.72 - ETA: 3s - loss: 11.70 - ETA: 3s - loss: 11.72 - ETA: 3s - loss: 11.73 - ETA: 3s - loss: 11.72 - ETA: 3s - loss: 11.70 - ETA: 2s - loss: 11.69 - ETA: 2s - loss: 11.75 - ETA: 2s - loss: 11.78 - ETA: 2s - loss: 11.74 - ETA: 2s - loss: 11.70 - ETA: 2s - loss: 11.67 - ETA: 2s - loss: 11.67 - ETA: 2s - loss: 11.63 - ETA: 2s - loss: 11.61 - ETA: 2s - loss: 11.62 - ETA: 2s - loss: 11.60 - ETA: 2s - loss: 11.59 - ETA: 2s - loss: 11.54 - ETA: 2s - loss: 11.56 - ETA: 2s - loss: 11.56 - ETA: 2s - loss: 11.54 - ETA: 2s - loss: 11.54 - ETA: 2s - loss: 11.58 - ETA: 2s - loss: 11.56 - ETA: 2s - loss: 11.54 - ETA: 1s - loss: 11.51 - ETA: 1s - loss: 11.50 - ETA: 1s - loss: 11.47 - ETA: 1s - loss: 11.42 - ETA: 1s - loss: 11.41 - ETA: 1s - loss: 11.37 - ETA: 1s - loss: 11.33 - ETA: 1s - loss: 11.31 - ETA: 1s - loss: 11.35 - ETA: 1s - loss: 11.34 - ETA: 1s - loss: 11.36 - ETA: 1s - loss: 11.34 - ETA: 1s - loss: 11.36 - ETA: 1s - loss: 11.37 - ETA: 1s - loss: 11.42 - ETA: 1s - loss: 11.43 - ETA: 1s - loss: 11.49 - ETA: 1s - loss: 11.48 - ETA: 1s - loss: 11.45 - ETA: 1s - loss: 11.45 - ETA: 1s - loss: 11.45 - ETA: 1s - loss: 11.46 - ETA: 1s - loss: 11.48 - ETA: 0s - loss: 11.47 - ETA: 0s - loss: 11.47 - ETA: 0s - loss: 11.43 - ETA: 0s - loss: 11.42 - ETA: 0s - loss: 11.39 - ETA: 0s - loss: 11.37 - ETA: 0s - loss: 11.41 - ETA: 0s - loss: 11.37 - ETA: 0s - loss: 11.39 - ETA: 0s - loss: 11.38 - ETA: 0s - loss: 11.35 - ETA: 0s - loss: 11.33 - ETA: 0s - loss: 11.32 - ETA: 0s - loss: 11.28 - ETA: 0s - loss: 11.33 - ETA: 0s - loss: 11.31 - ETA: 0s - loss: 11.29 - ETA: 0s - loss: 11.27 - ETA: 0s - loss: 11.31 - ETA: 0s - loss: 11.30 - 16s 1ms/step - loss: 11.3140 - val_loss: 10.2255\n",
      "Epoch 7/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14152/14152 [==============================] - ETA: 15s - loss: 0.00 - ETA: 14s - loss: 10.163 - ETA: 14s - loss: 15.868 - ETA: 13s - loss: 11.960 - ETA: 13s - loss: 11.769 - ETA: 13s - loss: 10.419 - ETA: 13s - loss: 9.009 - ETA: 13s - loss: 8.85 - ETA: 13s - loss: 8.11 - ETA: 13s - loss: 7.82 - ETA: 13s - loss: 8.77 - ETA: 13s - loss: 8.67 - ETA: 13s - loss: 9.03 - ETA: 13s - loss: 9.22 - ETA: 13s - loss: 8.80 - ETA: 12s - loss: 8.94 - ETA: 12s - loss: 9.59 - ETA: 12s - loss: 9.63 - ETA: 12s - loss: 10.039 - ETA: 12s - loss: 10.338 - ETA: 12s - loss: 10.392 - ETA: 11s - loss: 10.176 - ETA: 11s - loss: 9.788 - ETA: 11s - loss: 9.55 - ETA: 11s - loss: 9.52 - ETA: 11s - loss: 9.68 - ETA: 11s - loss: 10.097 - ETA: 11s - loss: 10.160 - ETA: 11s - loss: 10.184 - ETA: 11s - loss: 10.394 - ETA: 11s - loss: 10.478 - ETA: 11s - loss: 10.179 - ETA: 11s - loss: 10.360 - ETA: 11s - loss: 10.282 - ETA: 11s - loss: 10.535 - ETA: 11s - loss: 10.276 - ETA: 11s - loss: 10.629 - ETA: 10s - loss: 10.716 - ETA: 10s - loss: 10.886 - ETA: 10s - loss: 10.722 - ETA: 10s - loss: 10.801 - ETA: 10s - loss: 10.651 - ETA: 10s - loss: 10.577 - ETA: 10s - loss: 10.661 - ETA: 10s - loss: 10.601 - ETA: 10s - loss: 10.476 - ETA: 10s - loss: 10.503 - ETA: 10s - loss: 10.604 - ETA: 10s - loss: 10.531 - ETA: 10s - loss: 10.437 - ETA: 10s - loss: 10.518 - ETA: 10s - loss: 10.577 - ETA: 10s - loss: 10.534 - ETA: 10s - loss: 10.597 - ETA: 10s - loss: 10.699 - ETA: 10s - loss: 10.746 - ETA: 10s - loss: 10.911 - ETA: 10s - loss: 10.893 - ETA: 10s - loss: 10.882 - ETA: 10s - loss: 10.843 - ETA: 9s - loss: 10.759 - ETA: 9s - loss: 11.01 - ETA: 9s - loss: 11.05 - ETA: 9s - loss: 11.21 - ETA: 9s - loss: 11.27 - ETA: 9s - loss: 11.34 - ETA: 9s - loss: 11.23 - ETA: 9s - loss: 11.23 - ETA: 9s - loss: 11.15 - ETA: 9s - loss: 11.28 - ETA: 9s - loss: 11.40 - ETA: 9s - loss: 11.34 - ETA: 9s - loss: 11.31 - ETA: 9s - loss: 11.25 - ETA: 9s - loss: 11.25 - ETA: 8s - loss: 11.14 - ETA: 8s - loss: 11.03 - ETA: 8s - loss: 10.94 - ETA: 8s - loss: 10.89 - ETA: 8s - loss: 10.83 - ETA: 8s - loss: 10.75 - ETA: 8s - loss: 10.76 - ETA: 8s - loss: 10.80 - ETA: 8s - loss: 10.78 - ETA: 8s - loss: 10.73 - ETA: 8s - loss: 10.83 - ETA: 8s - loss: 10.80 - ETA: 8s - loss: 10.80 - ETA: 8s - loss: 10.79 - ETA: 8s - loss: 10.86 - ETA: 8s - loss: 10.80 - ETA: 8s - loss: 10.86 - ETA: 8s - loss: 11.03 - ETA: 7s - loss: 10.99 - ETA: 7s - loss: 10.95 - ETA: 7s - loss: 10.93 - ETA: 7s - loss: 10.84 - ETA: 7s - loss: 10.85 - ETA: 7s - loss: 10.87 - ETA: 7s - loss: 10.82 - ETA: 7s - loss: 10.83 - ETA: 7s - loss: 10.83 - ETA: 7s - loss: 10.79 - ETA: 7s - loss: 10.79 - ETA: 7s - loss: 10.71 - ETA: 7s - loss: 10.73 - ETA: 7s - loss: 10.71 - ETA: 7s - loss: 10.65 - ETA: 7s - loss: 10.61 - ETA: 7s - loss: 10.62 - ETA: 6s - loss: 10.69 - ETA: 6s - loss: 10.57 - ETA: 6s - loss: 10.59 - ETA: 6s - loss: 10.62 - ETA: 6s - loss: 10.54 - ETA: 6s - loss: 10.47 - ETA: 6s - loss: 10.50 - ETA: 6s - loss: 10.55 - ETA: 6s - loss: 10.56 - ETA: 6s - loss: 10.53 - ETA: 6s - loss: 10.51 - ETA: 6s - loss: 10.44 - ETA: 6s - loss: 10.43 - ETA: 6s - loss: 10.38 - ETA: 6s - loss: 10.33 - ETA: 6s - loss: 10.32 - ETA: 6s - loss: 10.38 - ETA: 5s - loss: 10.50 - ETA: 5s - loss: 10.43 - ETA: 5s - loss: 10.40 - ETA: 5s - loss: 10.46 - ETA: 5s - loss: 10.44 - ETA: 5s - loss: 10.47 - ETA: 5s - loss: 10.45 - ETA: 5s - loss: 10.50 - ETA: 5s - loss: 10.46 - ETA: 5s - loss: 10.45 - ETA: 5s - loss: 10.48 - ETA: 5s - loss: 10.57 - ETA: 5s - loss: 10.59 - ETA: 5s - loss: 10.60 - ETA: 5s - loss: 10.55 - ETA: 5s - loss: 10.58 - ETA: 5s - loss: 10.60 - ETA: 5s - loss: 10.56 - ETA: 4s - loss: 10.69 - ETA: 4s - loss: 10.71 - ETA: 4s - loss: 10.66 - ETA: 4s - loss: 10.63 - ETA: 4s - loss: 10.65 - ETA: 4s - loss: 10.62 - ETA: 4s - loss: 10.59 - ETA: 4s - loss: 10.56 - ETA: 4s - loss: 10.51 - ETA: 4s - loss: 10.54 - ETA: 4s - loss: 10.53 - ETA: 4s - loss: 10.47 - ETA: 4s - loss: 10.45 - ETA: 4s - loss: 10.41 - ETA: 4s - loss: 10.39 - ETA: 4s - loss: 10.39 - ETA: 4s - loss: 10.36 - ETA: 4s - loss: 10.38 - ETA: 4s - loss: 10.34 - ETA: 4s - loss: 10.36 - ETA: 3s - loss: 10.37 - ETA: 3s - loss: 10.33 - ETA: 3s - loss: 10.39 - ETA: 3s - loss: 10.38 - ETA: 3s - loss: 10.38 - ETA: 3s - loss: 10.33 - ETA: 3s - loss: 10.28 - ETA: 3s - loss: 10.27 - ETA: 3s - loss: 10.23 - ETA: 3s - loss: 10.25 - ETA: 3s - loss: 10.20 - ETA: 3s - loss: 10.21 - ETA: 3s - loss: 10.21 - ETA: 3s - loss: 10.21 - ETA: 3s - loss: 10.26 - ETA: 3s - loss: 10.29 - ETA: 3s - loss: 10.26 - ETA: 3s - loss: 10.33 - ETA: 2s - loss: 10.32 - ETA: 2s - loss: 10.36 - ETA: 2s - loss: 10.32 - ETA: 2s - loss: 10.32 - ETA: 2s - loss: 10.36 - ETA: 2s - loss: 10.41 - ETA: 2s - loss: 10.44 - ETA: 2s - loss: 10.43 - ETA: 2s - loss: 10.42 - ETA: 2s - loss: 10.38 - ETA: 2s - loss: 10.36 - ETA: 2s - loss: 10.33 - ETA: 2s - loss: 10.30 - ETA: 2s - loss: 10.38 - ETA: 2s - loss: 10.36 - ETA: 2s - loss: 10.37 - ETA: 2s - loss: 10.33 - ETA: 2s - loss: 10.31 - ETA: 2s - loss: 10.33 - ETA: 2s - loss: 10.30 - ETA: 1s - loss: 10.29 - ETA: 1s - loss: 10.29 - ETA: 1s - loss: 10.30 - ETA: 1s - loss: 10.35 - ETA: 1s - loss: 10.33 - ETA: 1s - loss: 10.38 - ETA: 1s - loss: 10.36 - ETA: 1s - loss: 10.41 - ETA: 1s - loss: 10.41 - ETA: 1s - loss: 10.38 - ETA: 1s - loss: 10.38 - ETA: 1s - loss: 10.38 - ETA: 1s - loss: 10.41 - ETA: 1s - loss: 10.45 - ETA: 1s - loss: 10.42 - ETA: 1s - loss: 10.42 - ETA: 1s - loss: 10.47 - ETA: 1s - loss: 10.43 - ETA: 1s - loss: 10.44 - ETA: 1s - loss: 10.51 - ETA: 0s - loss: 10.55 - ETA: 0s - loss: 10.55 - ETA: 0s - loss: 10.52 - ETA: 0s - loss: 10.55 - ETA: 0s - loss: 10.56 - ETA: 0s - loss: 10.53 - ETA: 0s - loss: 10.53 - ETA: 0s - loss: 10.53 - ETA: 0s - loss: 10.52 - ETA: 0s - loss: 10.49 - ETA: 0s - loss: 10.49 - ETA: 0s - loss: 10.48 - ETA: 0s - loss: 10.50 - ETA: 0s - loss: 10.53 - ETA: 0s - loss: 10.53 - ETA: 0s - loss: 10.56 - ETA: 0s - loss: 10.58 - ETA: 0s - loss: 10.61 - ETA: 0s - loss: 10.60 - ETA: 0s - loss: 10.56 - 15s 1ms/step - loss: 10.5633 - val_loss: 10.7994\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14152/14152 [==============================] - ETA: 15s - loss: 1.02 - ETA: 13s - loss: 1.28 - ETA: 13s - loss: 3.47 - ETA: 13s - loss: 6.80 - ETA: 13s - loss: 6.39 - ETA: 13s - loss: 8.00 - ETA: 13s - loss: 7.26 - ETA: 13s - loss: 6.90 - ETA: 13s - loss: 7.96 - ETA: 13s - loss: 7.81 - ETA: 13s - loss: 8.03 - ETA: 12s - loss: 8.54 - ETA: 12s - loss: 7.96 - ETA: 12s - loss: 7.59 - ETA: 12s - loss: 7.87 - ETA: 12s - loss: 8.34 - ETA: 12s - loss: 9.06 - ETA: 12s - loss: 9.00 - ETA: 12s - loss: 8.84 - ETA: 12s - loss: 8.71 - ETA: 12s - loss: 9.06 - ETA: 12s - loss: 9.01 - ETA: 12s - loss: 8.89 - ETA: 12s - loss: 9.08 - ETA: 12s - loss: 8.94 - ETA: 12s - loss: 9.36 - ETA: 12s - loss: 9.46 - ETA: 12s - loss: 9.31 - ETA: 12s - loss: 9.68 - ETA: 12s - loss: 9.56 - ETA: 12s - loss: 9.63 - ETA: 12s - loss: 9.54 - ETA: 12s - loss: 9.31 - ETA: 12s - loss: 9.53 - ETA: 12s - loss: 9.36 - ETA: 11s - loss: 9.59 - ETA: 11s - loss: 9.39 - ETA: 11s - loss: 9.30 - ETA: 11s - loss: 9.44 - ETA: 11s - loss: 9.28 - ETA: 11s - loss: 9.45 - ETA: 11s - loss: 9.57 - ETA: 11s - loss: 9.66 - ETA: 11s - loss: 9.84 - ETA: 11s - loss: 10.148 - ETA: 11s - loss: 10.200 - ETA: 11s - loss: 10.199 - ETA: 11s - loss: 10.319 - ETA: 11s - loss: 10.393 - ETA: 11s - loss: 10.378 - ETA: 11s - loss: 10.442 - ETA: 11s - loss: 10.394 - ETA: 11s - loss: 10.248 - ETA: 10s - loss: 10.350 - ETA: 10s - loss: 10.565 - ETA: 10s - loss: 10.758 - ETA: 10s - loss: 10.659 - ETA: 10s - loss: 10.826 - ETA: 10s - loss: 10.998 - ETA: 10s - loss: 10.982 - ETA: 10s - loss: 11.116 - ETA: 10s - loss: 11.226 - ETA: 10s - loss: 11.159 - ETA: 10s - loss: 11.237 - ETA: 10s - loss: 11.251 - ETA: 10s - loss: 11.385 - ETA: 10s - loss: 11.444 - ETA: 10s - loss: 11.307 - ETA: 10s - loss: 11.372 - ETA: 10s - loss: 11.350 - ETA: 10s - loss: 11.378 - ETA: 9s - loss: 11.339 - ETA: 9s - loss: 11.31 - ETA: 9s - loss: 11.20 - ETA: 9s - loss: 11.24 - ETA: 9s - loss: 11.10 - ETA: 9s - loss: 11.06 - ETA: 9s - loss: 11.02 - ETA: 9s - loss: 11.17 - ETA: 9s - loss: 11.04 - ETA: 9s - loss: 10.96 - ETA: 9s - loss: 10.92 - ETA: 9s - loss: 10.91 - ETA: 9s - loss: 10.96 - ETA: 9s - loss: 11.03 - ETA: 9s - loss: 11.06 - ETA: 9s - loss: 11.14 - ETA: 9s - loss: 11.11 - ETA: 9s - loss: 11.07 - ETA: 9s - loss: 11.03 - ETA: 8s - loss: 10.92 - ETA: 8s - loss: 10.95 - ETA: 8s - loss: 11.01 - ETA: 8s - loss: 10.96 - ETA: 8s - loss: 11.03 - ETA: 8s - loss: 11.00 - ETA: 8s - loss: 10.96 - ETA: 8s - loss: 10.94 - ETA: 8s - loss: 10.89 - ETA: 8s - loss: 10.88 - ETA: 8s - loss: 10.83 - ETA: 8s - loss: 10.87 - ETA: 8s - loss: 10.89 - ETA: 8s - loss: 10.87 - ETA: 8s - loss: 10.82 - ETA: 8s - loss: 10.92 - ETA: 7s - loss: 10.97 - ETA: 7s - loss: 10.88 - ETA: 7s - loss: 11.07 - ETA: 7s - loss: 11.01 - ETA: 7s - loss: 11.15 - ETA: 7s - loss: 11.10 - ETA: 7s - loss: 11.06 - ETA: 7s - loss: 11.12 - ETA: 7s - loss: 11.13 - ETA: 7s - loss: 11.13 - ETA: 7s - loss: 11.14 - ETA: 7s - loss: 11.12 - ETA: 7s - loss: 11.16 - ETA: 7s - loss: 11.16 - ETA: 7s - loss: 11.18 - ETA: 7s - loss: 11.11 - ETA: 7s - loss: 11.07 - ETA: 6s - loss: 11.05 - ETA: 6s - loss: 11.06 - ETA: 6s - loss: 10.97 - ETA: 6s - loss: 11.13 - ETA: 6s - loss: 11.19 - ETA: 6s - loss: 11.11 - ETA: 6s - loss: 11.13 - ETA: 6s - loss: 11.11 - ETA: 6s - loss: 11.09 - ETA: 6s - loss: 11.09 - ETA: 6s - loss: 11.07 - ETA: 6s - loss: 11.02 - ETA: 6s - loss: 11.11 - ETA: 6s - loss: 11.13 - ETA: 6s - loss: 11.10 - ETA: 6s - loss: 11.07 - ETA: 6s - loss: 11.10 - ETA: 6s - loss: 11.11 - ETA: 5s - loss: 11.07 - ETA: 5s - loss: 11.03 - ETA: 5s - loss: 10.99 - ETA: 5s - loss: 11.09 - ETA: 5s - loss: 11.05 - ETA: 5s - loss: 11.08 - ETA: 5s - loss: 11.06 - ETA: 5s - loss: 11.17 - ETA: 5s - loss: 11.21 - ETA: 5s - loss: 11.23 - ETA: 5s - loss: 11.21 - ETA: 5s - loss: 11.27 - ETA: 5s - loss: 11.24 - ETA: 5s - loss: 11.24 - ETA: 5s - loss: 11.21 - ETA: 5s - loss: 11.21 - ETA: 5s - loss: 11.24 - ETA: 4s - loss: 11.20 - ETA: 4s - loss: 11.23 - ETA: 4s - loss: 11.21 - ETA: 4s - loss: 11.15 - ETA: 4s - loss: 11.11 - ETA: 4s - loss: 11.15 - ETA: 4s - loss: 11.09 - ETA: 4s - loss: 11.09 - ETA: 4s - loss: 11.11 - ETA: 4s - loss: 11.10 - ETA: 4s - loss: 11.06 - ETA: 4s - loss: 11.05 - ETA: 4s - loss: 11.05 - ETA: 4s - loss: 11.01 - ETA: 4s - loss: 11.03 - ETA: 4s - loss: 11.00 - ETA: 4s - loss: 10.95 - ETA: 3s - loss: 10.92 - ETA: 3s - loss: 10.92 - ETA: 3s - loss: 10.87 - ETA: 3s - loss: 10.83 - ETA: 3s - loss: 10.88 - ETA: 3s - loss: 10.86 - ETA: 3s - loss: 10.86 - ETA: 3s - loss: 10.91 - ETA: 3s - loss: 10.91 - ETA: 3s - loss: 10.89 - ETA: 3s - loss: 10.88 - ETA: 3s - loss: 10.85 - ETA: 3s - loss: 10.87 - ETA: 3s - loss: 10.86 - ETA: 3s - loss: 10.86 - ETA: 3s - loss: 10.84 - ETA: 3s - loss: 10.81 - ETA: 2s - loss: 10.83 - ETA: 2s - loss: 10.82 - ETA: 2s - loss: 10.83 - ETA: 2s - loss: 10.86 - ETA: 2s - loss: 10.86 - ETA: 2s - loss: 10.90 - ETA: 2s - loss: 10.90 - ETA: 2s - loss: 10.91 - ETA: 2s - loss: 10.93 - ETA: 2s - loss: 10.94 - ETA: 2s - loss: 10.98 - ETA: 2s - loss: 10.94 - ETA: 2s - loss: 10.97 - ETA: 2s - loss: 10.96 - ETA: 2s - loss: 10.92 - ETA: 2s - loss: 10.88 - ETA: 2s - loss: 10.87 - ETA: 1s - loss: 10.86 - ETA: 1s - loss: 10.84 - ETA: 1s - loss: 10.87 - ETA: 1s - loss: 10.83 - ETA: 1s - loss: 10.86 - ETA: 1s - loss: 10.88 - ETA: 1s - loss: 10.87 - ETA: 1s - loss: 10.83 - ETA: 1s - loss: 10.83 - ETA: 1s - loss: 10.79 - ETA: 1s - loss: 10.77 - ETA: 1s - loss: 10.75 - ETA: 1s - loss: 10.76 - ETA: 1s - loss: 10.76 - ETA: 1s - loss: 10.76 - ETA: 1s - loss: 10.75 - ETA: 1s - loss: 10.72 - ETA: 0s - loss: 10.72 - ETA: 0s - loss: 10.75 - ETA: 0s - loss: 10.74 - ETA: 0s - loss: 10.71 - ETA: 0s - loss: 10.69 - ETA: 0s - loss: 10.68 - ETA: 0s - loss: 10.71 - ETA: 0s - loss: 10.69 - ETA: 0s - loss: 10.71 - ETA: 0s - loss: 10.72 - ETA: 0s - loss: 10.71 - ETA: 0s - loss: 10.68 - ETA: 0s - loss: 10.67 - ETA: 0s - loss: 10.62 - ETA: 0s - loss: 10.70 - ETA: 0s - loss: 10.69 - ETA: 0s - loss: 10.66 - ETA: 0s - loss: 10.67 - 15s 1ms/step - loss: 10.6680 - val_loss: 9.7719\n",
      "Epoch 9/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14152/14152 [==============================] - ETA: 16s - loss: 2.53 - ETA: 13s - loss: 9.95 - ETA: 13s - loss: 10.030 - ETA: 13s - loss: 8.735 - ETA: 13s - loss: 8.44 - ETA: 13s - loss: 7.74 - ETA: 13s - loss: 9.16 - ETA: 13s - loss: 10.565 - ETA: 13s - loss: 10.005 - ETA: 13s - loss: 9.654 - ETA: 12s - loss: 9.84 - ETA: 12s - loss: 9.98 - ETA: 12s - loss: 10.382 - ETA: 12s - loss: 10.088 - ETA: 12s - loss: 9.559 - ETA: 12s - loss: 9.48 - ETA: 12s - loss: 9.31 - ETA: 12s - loss: 9.32 - ETA: 12s - loss: 9.59 - ETA: 11s - loss: 9.41 - ETA: 11s - loss: 9.02 - ETA: 11s - loss: 8.92 - ETA: 11s - loss: 8.67 - ETA: 11s - loss: 8.85 - ETA: 11s - loss: 8.83 - ETA: 11s - loss: 8.61 - ETA: 11s - loss: 8.45 - ETA: 11s - loss: 8.22 - ETA: 11s - loss: 8.07 - ETA: 11s - loss: 8.21 - ETA: 11s - loss: 8.25 - ETA: 10s - loss: 8.18 - ETA: 10s - loss: 8.33 - ETA: 10s - loss: 8.29 - ETA: 10s - loss: 8.44 - ETA: 10s - loss: 8.35 - ETA: 10s - loss: 8.33 - ETA: 10s - loss: 8.29 - ETA: 10s - loss: 8.24 - ETA: 10s - loss: 8.43 - ETA: 10s - loss: 8.50 - ETA: 10s - loss: 8.58 - ETA: 10s - loss: 8.44 - ETA: 10s - loss: 8.64 - ETA: 10s - loss: 8.47 - ETA: 10s - loss: 8.46 - ETA: 10s - loss: 8.58 - ETA: 10s - loss: 8.75 - ETA: 10s - loss: 8.70 - ETA: 10s - loss: 8.72 - ETA: 9s - loss: 8.7768 - ETA: 9s - loss: 8.978 - ETA: 9s - loss: 8.951 - ETA: 9s - loss: 8.945 - ETA: 9s - loss: 8.932 - ETA: 9s - loss: 8.857 - ETA: 9s - loss: 8.726 - ETA: 9s - loss: 8.756 - ETA: 9s - loss: 8.818 - ETA: 9s - loss: 8.838 - ETA: 9s - loss: 8.822 - ETA: 9s - loss: 8.946 - ETA: 9s - loss: 8.825 - ETA: 9s - loss: 8.708 - ETA: 9s - loss: 8.810 - ETA: 9s - loss: 8.806 - ETA: 9s - loss: 8.723 - ETA: 8s - loss: 8.660 - ETA: 8s - loss: 8.658 - ETA: 8s - loss: 8.682 - ETA: 8s - loss: 8.575 - ETA: 8s - loss: 8.725 - ETA: 8s - loss: 8.694 - ETA: 8s - loss: 8.646 - ETA: 8s - loss: 8.727 - ETA: 8s - loss: 8.918 - ETA: 8s - loss: 9.078 - ETA: 8s - loss: 9.018 - ETA: 8s - loss: 8.962 - ETA: 8s - loss: 8.956 - ETA: 8s - loss: 8.980 - ETA: 8s - loss: 9.058 - ETA: 8s - loss: 9.123 - ETA: 8s - loss: 9.080 - ETA: 7s - loss: 9.041 - ETA: 7s - loss: 8.995 - ETA: 7s - loss: 8.952 - ETA: 7s - loss: 8.872 - ETA: 7s - loss: 8.945 - ETA: 7s - loss: 8.927 - ETA: 7s - loss: 8.845 - ETA: 7s - loss: 8.773 - ETA: 7s - loss: 8.753 - ETA: 7s - loss: 8.791 - ETA: 7s - loss: 8.870 - ETA: 7s - loss: 9.013 - ETA: 7s - loss: 9.044 - ETA: 7s - loss: 9.143 - ETA: 7s - loss: 9.179 - ETA: 7s - loss: 9.115 - ETA: 7s - loss: 9.119 - ETA: 7s - loss: 9.084 - ETA: 7s - loss: 9.094 - ETA: 6s - loss: 9.066 - ETA: 6s - loss: 9.161 - ETA: 6s - loss: 9.084 - ETA: 6s - loss: 9.056 - ETA: 6s - loss: 8.993 - ETA: 6s - loss: 8.937 - ETA: 6s - loss: 8.975 - ETA: 6s - loss: 9.000 - ETA: 6s - loss: 8.931 - ETA: 6s - loss: 8.876 - ETA: 6s - loss: 8.831 - ETA: 6s - loss: 8.778 - ETA: 6s - loss: 8.745 - ETA: 6s - loss: 8.731 - ETA: 6s - loss: 8.750 - ETA: 6s - loss: 8.746 - ETA: 5s - loss: 8.743 - ETA: 5s - loss: 8.724 - ETA: 5s - loss: 8.802 - ETA: 5s - loss: 8.825 - ETA: 5s - loss: 8.881 - ETA: 5s - loss: 8.924 - ETA: 5s - loss: 8.952 - ETA: 5s - loss: 8.968 - ETA: 5s - loss: 8.992 - ETA: 5s - loss: 8.992 - ETA: 5s - loss: 8.992 - ETA: 5s - loss: 9.054 - ETA: 5s - loss: 9.065 - ETA: 5s - loss: 9.110 - ETA: 5s - loss: 9.131 - ETA: 5s - loss: 9.395 - ETA: 5s - loss: 9.411 - ETA: 5s - loss: 9.427 - ETA: 5s - loss: 9.444 - ETA: 4s - loss: 9.449 - ETA: 4s - loss: 9.484 - ETA: 4s - loss: 9.473 - ETA: 4s - loss: 9.449 - ETA: 4s - loss: 9.411 - ETA: 4s - loss: 9.381 - ETA: 4s - loss: 9.485 - ETA: 4s - loss: 9.478 - ETA: 4s - loss: 9.487 - ETA: 4s - loss: 9.439 - ETA: 4s - loss: 9.405 - ETA: 4s - loss: 9.371 - ETA: 4s - loss: 9.433 - ETA: 4s - loss: 9.401 - ETA: 4s - loss: 9.367 - ETA: 4s - loss: 9.347 - ETA: 4s - loss: 9.413 - ETA: 4s - loss: 9.500 - ETA: 3s - loss: 9.506 - ETA: 3s - loss: 9.468 - ETA: 3s - loss: 9.503 - ETA: 3s - loss: 9.491 - ETA: 3s - loss: 9.485 - ETA: 3s - loss: 9.451 - ETA: 3s - loss: 9.513 - ETA: 3s - loss: 9.470 - ETA: 3s - loss: 9.448 - ETA: 3s - loss: 9.447 - ETA: 3s - loss: 9.412 - ETA: 3s - loss: 9.425 - ETA: 3s - loss: 9.397 - ETA: 3s - loss: 9.406 - ETA: 3s - loss: 9.552 - ETA: 3s - loss: 9.526 - ETA: 3s - loss: 9.584 - ETA: 3s - loss: 9.615 - ETA: 2s - loss: 9.601 - ETA: 2s - loss: 9.577 - ETA: 2s - loss: 9.597 - ETA: 2s - loss: 9.615 - ETA: 2s - loss: 9.566 - ETA: 2s - loss: 9.591 - ETA: 2s - loss: 9.686 - ETA: 2s - loss: 9.637 - ETA: 2s - loss: 9.685 - ETA: 2s - loss: 9.731 - ETA: 2s - loss: 9.730 - ETA: 2s - loss: 9.760 - ETA: 2s - loss: 9.725 - ETA: 2s - loss: 9.743 - ETA: 2s - loss: 9.777 - ETA: 2s - loss: 9.827 - ETA: 2s - loss: 9.827 - ETA: 2s - loss: 9.901 - ETA: 1s - loss: 9.901 - ETA: 1s - loss: 9.900 - ETA: 1s - loss: 9.893 - ETA: 1s - loss: 9.912 - ETA: 1s - loss: 9.944 - ETA: 1s - loss: 9.925 - ETA: 1s - loss: 9.981 - ETA: 1s - loss: 9.940 - ETA: 1s - loss: 9.910 - ETA: 1s - loss: 9.922 - ETA: 1s - loss: 9.934 - ETA: 1s - loss: 9.979 - ETA: 1s - loss: 10.00 - ETA: 1s - loss: 10.11 - ETA: 1s - loss: 10.09 - ETA: 1s - loss: 10.07 - ETA: 1s - loss: 10.07 - ETA: 1s - loss: 10.07 - ETA: 1s - loss: 10.08 - ETA: 0s - loss: 10.08 - ETA: 0s - loss: 10.08 - ETA: 0s - loss: 10.20 - ETA: 0s - loss: 10.22 - ETA: 0s - loss: 10.20 - ETA: 0s - loss: 10.26 - ETA: 0s - loss: 10.27 - ETA: 0s - loss: 10.25 - ETA: 0s - loss: 10.27 - ETA: 0s - loss: 10.27 - ETA: 0s - loss: 10.29 - ETA: 0s - loss: 10.27 - ETA: 0s - loss: 10.24 - ETA: 0s - loss: 10.21 - ETA: 0s - loss: 10.26 - ETA: 0s - loss: 10.25 - ETA: 0s - loss: 10.24 - 14s 974us/step - loss: 10.2355 - val_loss: 10.2580\n",
      "Epoch 10/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14152/14152 [==============================] - ETA: 14s - loss: 10.835 - ETA: 12s - loss: 8.711 - ETA: 12s - loss: 10.564 - ETA: 12s - loss: 7.968 - ETA: 12s - loss: 7.25 - ETA: 12s - loss: 6.11 - ETA: 12s - loss: 6.18 - ETA: 12s - loss: 6.35 - ETA: 12s - loss: 5.80 - ETA: 11s - loss: 5.34 - ETA: 11s - loss: 6.43 - ETA: 11s - loss: 7.27 - ETA: 11s - loss: 7.27 - ETA: 11s - loss: 7.55 - ETA: 11s - loss: 7.23 - ETA: 11s - loss: 7.01 - ETA: 11s - loss: 7.34 - ETA: 11s - loss: 7.46 - ETA: 11s - loss: 7.83 - ETA: 11s - loss: 8.11 - ETA: 11s - loss: 8.12 - ETA: 11s - loss: 8.36 - ETA: 11s - loss: 8.29 - ETA: 11s - loss: 8.95 - ETA: 11s - loss: 9.56 - ETA: 11s - loss: 9.60 - ETA: 11s - loss: 9.66 - ETA: 11s - loss: 9.87 - ETA: 11s - loss: 9.88 - ETA: 10s - loss: 9.87 - ETA: 10s - loss: 9.77 - ETA: 10s - loss: 9.66 - ETA: 10s - loss: 9.58 - ETA: 10s - loss: 9.68 - ETA: 10s - loss: 9.52 - ETA: 10s - loss: 9.70 - ETA: 10s - loss: 9.79 - ETA: 10s - loss: 9.67 - ETA: 10s - loss: 9.77 - ETA: 10s - loss: 9.69 - ETA: 10s - loss: 9.56 - ETA: 10s - loss: 9.35 - ETA: 10s - loss: 9.53 - ETA: 10s - loss: 9.39 - ETA: 10s - loss: 9.63 - ETA: 10s - loss: 9.52 - ETA: 10s - loss: 9.58 - ETA: 10s - loss: 9.54 - ETA: 10s - loss: 9.51 - ETA: 10s - loss: 9.50 - ETA: 10s - loss: 9.53 - ETA: 10s - loss: 9.47 - ETA: 10s - loss: 9.40 - ETA: 9s - loss: 9.4422 - ETA: 9s - loss: 9.521 - ETA: 9s - loss: 9.711 - ETA: 9s - loss: 9.688 - ETA: 9s - loss: 9.719 - ETA: 9s - loss: 9.992 - ETA: 9s - loss: 10.13 - ETA: 9s - loss: 10.09 - ETA: 9s - loss: 10.11 - ETA: 9s - loss: 10.12 - ETA: 9s - loss: 10.10 - ETA: 9s - loss: 10.05 - ETA: 9s - loss: 9.9738 - ETA: 9s - loss: 9.894 - ETA: 9s - loss: 9.948 - ETA: 9s - loss: 10.06 - ETA: 9s - loss: 10.06 - ETA: 9s - loss: 10.04 - ETA: 9s - loss: 10.26 - ETA: 9s - loss: 10.16 - ETA: 8s - loss: 10.19 - ETA: 8s - loss: 10.17 - ETA: 8s - loss: 10.29 - ETA: 8s - loss: 10.32 - ETA: 8s - loss: 10.31 - ETA: 8s - loss: 10.29 - ETA: 8s - loss: 10.57 - ETA: 8s - loss: 10.64 - ETA: 8s - loss: 10.71 - ETA: 8s - loss: 10.60 - ETA: 8s - loss: 10.54 - ETA: 8s - loss: 10.50 - ETA: 8s - loss: 10.43 - ETA: 8s - loss: 10.37 - ETA: 8s - loss: 10.32 - ETA: 8s - loss: 10.29 - ETA: 8s - loss: 10.26 - ETA: 8s - loss: 10.23 - ETA: 8s - loss: 10.30 - ETA: 7s - loss: 10.25 - ETA: 7s - loss: 10.19 - ETA: 7s - loss: 10.19 - ETA: 7s - loss: 10.18 - ETA: 7s - loss: 10.15 - ETA: 7s - loss: 10.17 - ETA: 7s - loss: 10.15 - ETA: 7s - loss: 10.27 - ETA: 7s - loss: 10.41 - ETA: 7s - loss: 10.41 - ETA: 7s - loss: 10.40 - ETA: 7s - loss: 10.37 - ETA: 7s - loss: 10.42 - ETA: 7s - loss: 10.39 - ETA: 7s - loss: 10.37 - ETA: 7s - loss: 10.48 - ETA: 7s - loss: 10.50 - ETA: 7s - loss: 10.54 - ETA: 7s - loss: 10.47 - ETA: 7s - loss: 10.46 - ETA: 7s - loss: 10.44 - ETA: 7s - loss: 10.40 - ETA: 7s - loss: 10.34 - ETA: 7s - loss: 10.49 - ETA: 7s - loss: 10.53 - ETA: 6s - loss: 10.51 - ETA: 6s - loss: 10.45 - ETA: 6s - loss: 10.43 - ETA: 6s - loss: 10.37 - ETA: 6s - loss: 10.33 - ETA: 6s - loss: 10.27 - ETA: 6s - loss: 10.25 - ETA: 6s - loss: 10.25 - ETA: 6s - loss: 10.23 - ETA: 6s - loss: 10.27 - ETA: 6s - loss: 10.21 - ETA: 6s - loss: 10.36 - ETA: 6s - loss: 10.31 - ETA: 6s - loss: 10.29 - ETA: 6s - loss: 10.30 - ETA: 6s - loss: 10.24 - ETA: 6s - loss: 10.29 - ETA: 6s - loss: 10.23 - ETA: 6s - loss: 10.23 - ETA: 6s - loss: 10.31 - ETA: 5s - loss: 10.26 - ETA: 5s - loss: 10.29 - ETA: 5s - loss: 10.29 - ETA: 5s - loss: 10.32 - ETA: 5s - loss: 10.30 - ETA: 5s - loss: 10.26 - ETA: 5s - loss: 10.33 - ETA: 5s - loss: 10.29 - ETA: 5s - loss: 10.25 - ETA: 5s - loss: 10.20 - ETA: 5s - loss: 10.18 - ETA: 5s - loss: 10.13 - ETA: 5s - loss: 10.14 - ETA: 5s - loss: 10.18 - ETA: 5s - loss: 10.18 - ETA: 5s - loss: 10.15 - ETA: 5s - loss: 10.12 - ETA: 5s - loss: 10.17 - ETA: 4s - loss: 10.16 - ETA: 4s - loss: 10.16 - ETA: 4s - loss: 10.16 - ETA: 4s - loss: 10.17 - ETA: 4s - loss: 10.20 - ETA: 4s - loss: 10.20 - ETA: 4s - loss: 10.16 - ETA: 4s - loss: 10.22 - ETA: 4s - loss: 10.18 - ETA: 4s - loss: 10.16 - ETA: 4s - loss: 10.12 - ETA: 4s - loss: 10.16 - ETA: 4s - loss: 10.17 - ETA: 4s - loss: 10.20 - ETA: 4s - loss: 10.23 - ETA: 4s - loss: 10.21 - ETA: 4s - loss: 10.27 - ETA: 4s - loss: 10.26 - ETA: 3s - loss: 10.31 - ETA: 3s - loss: 10.33 - ETA: 3s - loss: 10.31 - ETA: 3s - loss: 10.26 - ETA: 3s - loss: 10.22 - ETA: 3s - loss: 10.18 - ETA: 3s - loss: 10.17 - ETA: 3s - loss: 10.15 - ETA: 3s - loss: 10.22 - ETA: 3s - loss: 10.29 - ETA: 3s - loss: 10.38 - ETA: 3s - loss: 10.39 - ETA: 3s - loss: 10.39 - ETA: 3s - loss: 10.40 - ETA: 3s - loss: 10.35 - ETA: 3s - loss: 10.35 - ETA: 3s - loss: 10.36 - ETA: 3s - loss: 10.33 - ETA: 3s - loss: 10.29 - ETA: 2s - loss: 10.35 - ETA: 2s - loss: 10.38 - ETA: 2s - loss: 10.35 - ETA: 2s - loss: 10.32 - ETA: 2s - loss: 10.34 - ETA: 2s - loss: 10.38 - ETA: 2s - loss: 10.41 - ETA: 2s - loss: 10.42 - ETA: 2s - loss: 10.37 - ETA: 2s - loss: 10.35 - ETA: 2s - loss: 10.33 - ETA: 2s - loss: 10.31 - ETA: 2s - loss: 10.31 - ETA: 2s - loss: 10.33 - ETA: 2s - loss: 10.30 - ETA: 2s - loss: 10.31 - ETA: 2s - loss: 10.26 - ETA: 2s - loss: 10.27 - ETA: 2s - loss: 10.24 - ETA: 2s - loss: 10.20 - ETA: 2s - loss: 10.18 - ETA: 1s - loss: 10.19 - ETA: 1s - loss: 10.22 - ETA: 1s - loss: 10.22 - ETA: 1s - loss: 10.24 - ETA: 1s - loss: 10.21 - ETA: 1s - loss: 10.28 - ETA: 1s - loss: 10.26 - ETA: 1s - loss: 10.27 - ETA: 1s - loss: 10.25 - ETA: 1s - loss: 10.35 - ETA: 1s - loss: 10.32 - ETA: 1s - loss: 10.29 - ETA: 1s - loss: 10.35 - ETA: 1s - loss: 10.34 - ETA: 1s - loss: 10.37 - ETA: 1s - loss: 10.40 - ETA: 1s - loss: 10.45 - ETA: 1s - loss: 10.46 - ETA: 0s - loss: 10.43 - ETA: 0s - loss: 10.46 - ETA: 0s - loss: 10.45 - ETA: 0s - loss: 10.48 - ETA: 0s - loss: 10.49 - ETA: 0s - loss: 10.44 - ETA: 0s - loss: 10.50 - ETA: 0s - loss: 10.53 - ETA: 0s - loss: 10.61 - ETA: 0s - loss: 10.64 - ETA: 0s - loss: 10.63 - ETA: 0s - loss: 10.61 - ETA: 0s - loss: 10.64 - ETA: 0s - loss: 10.66 - ETA: 0s - loss: 10.65 - ETA: 0s - loss: 10.62 - ETA: 0s - loss: 10.64 - ETA: 0s - loss: 10.61 - 15s 1ms/step - loss: 10.6764 - val_loss: 12.5360\n",
      "Epoch 11/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8184/14152 [================>.............] - ETA: 12s - loss: 0.07 - ETA: 12s - loss: 6.09 - ETA: 12s - loss: 11.007 - ETA: 12s - loss: 10.854 - ETA: 12s - loss: 11.346 - ETA: 12s - loss: 14.100 - ETA: 12s - loss: 13.275 - ETA: 12s - loss: 11.658 - ETA: 12s - loss: 10.959 - ETA: 12s - loss: 11.326 - ETA: 12s - loss: 10.807 - ETA: 12s - loss: 10.018 - ETA: 12s - loss: 10.338 - ETA: 12s - loss: 10.435 - ETA: 12s - loss: 10.722 - ETA: 12s - loss: 11.031 - ETA: 12s - loss: 10.894 - ETA: 12s - loss: 10.587 - ETA: 12s - loss: 10.433 - ETA: 12s - loss: 10.207 - ETA: 12s - loss: 9.995 - ETA: 12s - loss: 10.085 - ETA: 11s - loss: 10.372 - ETA: 11s - loss: 10.609 - ETA: 11s - loss: 10.756 - ETA: 11s - loss: 10.609 - ETA: 11s - loss: 10.551 - ETA: 11s - loss: 10.589 - ETA: 11s - loss: 10.393 - ETA: 11s - loss: 11.019 - ETA: 11s - loss: 10.906 - ETA: 11s - loss: 11.133 - ETA: 11s - loss: 11.164 - ETA: 11s - loss: 11.282 - ETA: 11s - loss: 11.631 - ETA: 11s - loss: 11.512 - ETA: 11s - loss: 11.230 - ETA: 11s - loss: 11.001 - ETA: 11s - loss: 10.944 - ETA: 11s - loss: 11.013 - ETA: 11s - loss: 11.064 - ETA: 10s - loss: 10.989 - ETA: 10s - loss: 10.920 - ETA: 10s - loss: 10.751 - ETA: 10s - loss: 11.087 - ETA: 10s - loss: 11.082 - ETA: 10s - loss: 11.010 - ETA: 10s - loss: 10.879 - ETA: 10s - loss: 10.803 - ETA: 10s - loss: 10.710 - ETA: 10s - loss: 10.534 - ETA: 10s - loss: 10.587 - ETA: 10s - loss: 10.537 - ETA: 10s - loss: 10.654 - ETA: 10s - loss: 10.604 - ETA: 10s - loss: 10.512 - ETA: 10s - loss: 10.549 - ETA: 9s - loss: 10.475 - ETA: 9s - loss: 10.55 - ETA: 9s - loss: 10.43 - ETA: 9s - loss: 10.49 - ETA: 9s - loss: 10.56 - ETA: 9s - loss: 10.45 - ETA: 9s - loss: 10.33 - ETA: 9s - loss: 10.48 - ETA: 9s - loss: 10.63 - ETA: 9s - loss: 10.64 - ETA: 9s - loss: 10.58 - ETA: 9s - loss: 10.44 - ETA: 9s - loss: 10.35 - ETA: 9s - loss: 10.29 - ETA: 9s - loss: 10.35 - ETA: 9s - loss: 10.48 - ETA: 9s - loss: 10.55 - ETA: 9s - loss: 10.46 - ETA: 8s - loss: 10.47 - ETA: 8s - loss: 10.47 - ETA: 8s - loss: 10.45 - ETA: 8s - loss: 10.42 - ETA: 8s - loss: 10.44 - ETA: 8s - loss: 10.48 - ETA: 8s - loss: 10.36 - ETA: 8s - loss: 10.40 - ETA: 8s - loss: 10.42 - ETA: 8s - loss: 10.45 - ETA: 8s - loss: 10.36 - ETA: 8s - loss: 10.29 - ETA: 8s - loss: 10.25 - ETA: 8s - loss: 10.31 - ETA: 8s - loss: 10.42 - ETA: 8s - loss: 10.47 - ETA: 8s - loss: 10.59 - ETA: 8s - loss: 10.63 - ETA: 7s - loss: 10.64 - ETA: 7s - loss: 10.54 - ETA: 7s - loss: 10.51 - ETA: 7s - loss: 10.52 - ETA: 7s - loss: 10.42 - ETA: 7s - loss: 10.46 - ETA: 7s - loss: 10.49 - ETA: 7s - loss: 10.47 - ETA: 7s - loss: 10.51 - ETA: 7s - loss: 10.56 - ETA: 7s - loss: 10.56 - ETA: 7s - loss: 10.54 - ETA: 7s - loss: 10.59 - ETA: 7s - loss: 10.76 - ETA: 7s - loss: 10.83 - ETA: 7s - loss: 10.78 - ETA: 7s - loss: 10.75 - ETA: 7s - loss: 10.78 - ETA: 6s - loss: 10.88 - ETA: 6s - loss: 10.80 - ETA: 6s - loss: 10.80 - ETA: 6s - loss: 10.86 - ETA: 6s - loss: 10.85 - ETA: 6s - loss: 10.83 - ETA: 6s - loss: 10.80 - ETA: 6s - loss: 10.85 - ETA: 6s - loss: 10.78 - ETA: 6s - loss: 10.78 - ETA: 6s - loss: 10.88 - ETA: 6s - loss: 10.87 - ETA: 6s - loss: 10.82 - ETA: 6s - loss: 10.83 - ETA: 6s - loss: 10.76 - ETA: 6s - loss: 10.72 - ETA: 6s - loss: 10.68 - ETA: 6s - loss: 10.61 - ETA: 6s - loss: 10.58 - ETA: 5s - loss: 10.52 - ETA: 5s - loss: 10.56 - ETA: 5s - loss: 10.59 - ETA: 5s - loss: 10.58 - ETA: 5s - loss: 10.56 - ETA: 5s - loss: 10.54 - ETA: 5s - loss: 10.51 - ETA: 5s - loss: 10.4427"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-10e44f24e904>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss=kappa_loss, optimizer='adam')\n",
    "batch_size = 12\n",
    "epochs = 15\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size = batch_size, epochs = epochs, validation_data=(X_test, y_test), class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 3, ..., 0, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 0, ..., 0, 1, 3], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3079428653383871"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohen_kappa_score(np.argmax(y_test, axis = 1), pred, weights = 'quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25912366797539466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:03,058] Finished trial#0 resulted in value: 0.7408763320246053. Current best value is 0.7408763320246053 with parameters: {'x0': 1.6242941500057828, 'x1': 2.147711414379804, 'x2': 2.8431700416223986}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09689583081445652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:03,219] Finished trial#1 resulted in value: 0.9031041691855435. Current best value is 0.7408763320246053 with parameters: {'x0': 1.6242941500057828, 'x1': 2.147711414379804, 'x2': 2.8431700416223986}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31142511707749976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:03,385] Finished trial#2 resulted in value: 0.6885748829225002. Current best value is 0.6885748829225002 with parameters: {'x0': 1.0178791348247607, 'x1': 1.4653328258586018, 'x2': 2.550565492539211}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22568753158741306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:03,541] Finished trial#3 resulted in value: 0.7743124684125869. Current best value is 0.6885748829225002 with parameters: {'x0': 1.0178791348247607, 'x1': 1.4653328258586018, 'x2': 2.550565492539211}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3629581547147135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:03,698] Finished trial#4 resulted in value: 0.6370418452852865. Current best value is 0.6370418452852865 with parameters: {'x0': 0.7190741746787435, 'x1': 1.7359699443879713, 'x2': 2.175705114525696}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15919813533160276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:03,866] Finished trial#5 resulted in value: 0.8408018646683972. Current best value is 0.6370418452852865 with parameters: {'x0': 0.7190741746787435, 'x1': 1.7359699443879713, 'x2': 2.175705114525696}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019460122531594792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:04,047] Finished trial#6 resulted in value: 0.9805398774684052. Current best value is 0.6370418452852865 with parameters: {'x0': 0.7190741746787435, 'x1': 1.7359699443879713, 'x2': 2.175705114525696}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:04,212] Finished trial#7 resulted in value: 1.0. Current best value is 0.6370418452852865 with parameters: {'x0': 0.7190741746787435, 'x1': 1.7359699443879713, 'x2': 2.175705114525696}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14751480700674946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:04,378] Finished trial#8 resulted in value: 0.8524851929932505. Current best value is 0.6370418452852865 with parameters: {'x0': 0.7190741746787435, 'x1': 1.7359699443879713, 'x2': 2.175705114525696}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35815211025612737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:04,545] Finished trial#9 resulted in value: 0.6418478897438726. Current best value is 0.6370418452852865 with parameters: {'x0': 0.7190741746787435, 'x1': 1.7359699443879713, 'x2': 2.175705114525696}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004812535835586607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:04,727] Finished trial#10 resulted in value: 0.9951874641644134. Current best value is 0.6370418452852865 with parameters: {'x0': 0.7190741746787435, 'x1': 1.7359699443879713, 'x2': 2.175705114525696}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37505850934325946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:04,899] Finished trial#11 resulted in value: 0.6249414906567405. Current best value is 0.6249414906567405 with parameters: {'x0': 0.07590420876349452, 'x1': 1.4742697614872466, 'x2': 2.021553372796637}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1987930851648978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:05,071] Finished trial#12 resulted in value: 0.8012069148351022. Current best value is 0.6249414906567405 with parameters: {'x0': 0.07590420876349452, 'x1': 1.4742697614872466, 'x2': 2.021553372796637}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41331057500750046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:05,241] Finished trial#13 resulted in value: 0.5866894249924995. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.387786955370756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:05,423] Finished trial#14 resulted in value: 0.612213044629244. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3812640932895929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:05,599] Finished trial#15 resulted in value: 0.6187359067104071. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3936743188225308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:05,776] Finished trial#16 resulted in value: 0.6063256811774692. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36395933953757653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:05,952] Finished trial#17 resulted in value: 0.6360406604624235. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.665459282808925e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:06,120] Finished trial#18 resulted in value: 0.9999633454071719. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10222292298482161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:06,288] Finished trial#19 resulted in value: 0.8977770770151784. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3682822443790641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:06,456] Finished trial#20 resulted in value: 0.6317177556209359. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40466111128131765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:06,640] Finished trial#21 resulted in value: 0.5953388887186823. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13654748311987686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:06,810] Finished trial#22 resulted in value: 0.8634525168801231. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3772473072380099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:06,981] Finished trial#23 resulted in value: 0.6227526927619901. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3579481316314812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:07,149] Finished trial#24 resulted in value: 0.6420518683685188. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03761425815779618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:07,323] Finished trial#25 resulted in value: 0.9623857418422038. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30399602029416384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:07,494] Finished trial#26 resulted in value: 0.6960039797058362. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1844751102306752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:07,669] Finished trial#27 resulted in value: 0.8155248897693248. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.398641408555534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:07,843] Finished trial#28 resulted in value: 0.601358591444466. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37813993428140924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:08,014] Finished trial#29 resulted in value: 0.6218600657185908. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4004459553597336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:08,186] Finished trial#30 resulted in value: 0.5995540446402664. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3996153259731573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:08,356] Finished trial#31 resulted in value: 0.6003846740268427. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39937494865018974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:08,524] Finished trial#32 resulted in value: 0.6006250513498103. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30817529123913256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:08,702] Finished trial#33 resulted in value: 0.6918247087608674. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3364879494746551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:08,864] Finished trial#34 resulted in value: 0.6635120505253449. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35005869333212136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:09,030] Finished trial#35 resulted in value: 0.6499413066678786. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3822040773988966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:09,191] Finished trial#36 resulted in value: 0.6177959226011034. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3133617505724764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:09,357] Finished trial#37 resulted in value: 0.6866382494275236. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.413118128878602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:09,523] Finished trial#38 resulted in value: 0.586881871121398. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4010869726425954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:09,692] Finished trial#39 resulted in value: 0.5989130273574046. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12386866611696601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:09,877] Finished trial#40 resulted in value: 0.876131333883034. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4008744732153412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:10,050] Finished trial#41 resulted in value: 0.5991255267846588. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40410006366752216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:10,221] Finished trial#42 resulted in value: 0.5958999363324778. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3329823393839145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:10,393] Finished trial#43 resulted in value: 0.6670176606160855. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39624864051945863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:10,582] Finished trial#44 resulted in value: 0.6037513594805414. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37232539627378525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:10,767] Finished trial#45 resulted in value: 0.6276746037262148. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3573828373768436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:10,945] Finished trial#46 resulted in value: 0.6426171626231564. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39085628170268194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:11,121] Finished trial#47 resulted in value: 0.6091437182973181. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36344449293050574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:11,297] Finished trial#48 resulted in value: 0.6365555070694943. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4009859482505237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:11,469] Finished trial#49 resulted in value: 0.5990140517494763. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37637269440668875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:11,637] Finished trial#50 resulted in value: 0.6236273055933113. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3942183812073715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:11,807] Finished trial#51 resulted in value: 0.6057816187926285. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4001225413368438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:11,985] Finished trial#52 resulted in value: 0.5998774586631562. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3884607261919636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:12,160] Finished trial#53 resulted in value: 0.6115392738080364. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39578248092369217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:12,331] Finished trial#54 resulted in value: 0.6042175190763078. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39514706846484127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:12,515] Finished trial#55 resulted in value: 0.6048529315351587. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12167134654516365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:12,709] Finished trial#56 resulted in value: 0.8783286534548364. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3040791835538278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:12,889] Finished trial#57 resulted in value: 0.6959208164461722. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36680197756825683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:13,080] Finished trial#58 resulted in value: 0.6331980224317432. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4076049284885025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:13,272] Finished trial#59 resulted in value: 0.5923950715114975. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40629628292419884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:13,460] Finished trial#60 resulted in value: 0.5937037170758012. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40885095325293586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:13,638] Finished trial#61 resulted in value: 0.5911490467470641. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39856574252100174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:13,812] Finished trial#62 resulted in value: 0.6014342574789983. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36229085027997665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:13,998] Finished trial#63 resulted in value: 0.6377091497200233. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39626836135428023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:14,175] Finished trial#64 resulted in value: 0.6037316386457198. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3784582501451855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:14,361] Finished trial#65 resulted in value: 0.6215417498548145. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3789067721158922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:14,534] Finished trial#66 resulted in value: 0.6210932278841078. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39819134447624827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:14,709] Finished trial#67 resulted in value: 0.6018086555237517. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38038173327045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:14,886] Finished trial#68 resulted in value: 0.61961826672955. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3280453693008246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:15,064] Finished trial#69 resulted in value: 0.6719546306991754. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3845226694940802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:15,250] Finished trial#70 resulted in value: 0.6154773305059198. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40090498551493525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:15,428] Finished trial#71 resulted in value: 0.5990950144850647. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40114794833613965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:15,616] Finished trial#72 resulted in value: 0.5988520516638604. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4002418014462543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:15,808] Finished trial#73 resulted in value: 0.5997581985537457. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34054303017277177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:16,002] Finished trial#74 resulted in value: 0.6594569698272282. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3901303818322295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:16,190] Finished trial#75 resulted in value: 0.6098696181677705. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37917161894696394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:16,379] Finished trial#76 resulted in value: 0.6208283810530361. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4000159176329666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:16,577] Finished trial#77 resulted in value: 0.5999840823670334. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4048705597133506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:16,772] Finished trial#78 resulted in value: 0.5951294402866494. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3974036354364695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:16,951] Finished trial#79 resulted in value: 0.6025963645635305. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4015368740057017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:17,133] Finished trial#80 resulted in value: 0.5984631259942983. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39946652445193087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:17,319] Finished trial#81 resulted in value: 0.6005334755480691. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4103989215796763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:17,497] Finished trial#82 resulted in value: 0.5896010784203237. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39300049236201506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:17,683] Finished trial#83 resulted in value: 0.6069995076379849. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3883574026446892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:17,859] Finished trial#84 resulted in value: 0.6116425973553108. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41290468298466276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:18,036] Finished trial#85 resulted in value: 0.5870953170153372. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39807728329449255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:18,217] Finished trial#86 resulted in value: 0.6019227167055075. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4058799633340121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:18,404] Finished trial#87 resulted in value: 0.5941200366659879. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3810693149494616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:18,596] Finished trial#88 resulted in value: 0.6189306850505384. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40250177915804486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:18,793] Finished trial#89 resulted in value: 0.5974982208419551. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3983304817163026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:18,990] Finished trial#90 resulted in value: 0.6016695182836974. Current best value is 0.5866894249924995 with parameters: {'x0': 1.2430312401402808, 'x1': 1.694035212426729, 'x2': 2.08440894856065}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41332737788619545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:19,180] Finished trial#91 resulted in value: 0.5866726221138046. Current best value is 0.5866726221138046 with parameters: {'x0': 1.480959111174836, 'x1': 1.5977805724829677, 'x2': 2.015810960483682}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40235780005906985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:19,376] Finished trial#92 resulted in value: 0.5976421999409302. Current best value is 0.5866726221138046 with parameters: {'x0': 1.480959111174836, 'x1': 1.5977805724829677, 'x2': 2.015810960483682}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41541970545451223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:19,566] Finished trial#93 resulted in value: 0.5845802945454878. Current best value is 0.5845802945454878 with parameters: {'x0': 1.2995518388796587, 'x1': 1.7246812398293017, 'x2': 2.0292675881142404}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41361495127346126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:19,761] Finished trial#94 resulted in value: 0.5863850487265387. Current best value is 0.5845802945454878 with parameters: {'x0': 1.2995518388796587, 'x1': 1.7246812398293017, 'x2': 2.0292675881142404}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40282275696393477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:19,951] Finished trial#95 resulted in value: 0.5971772430360652. Current best value is 0.5845802945454878 with parameters: {'x0': 1.2995518388796587, 'x1': 1.7246812398293017, 'x2': 2.0292675881142404}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4082195960746824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:20,131] Finished trial#96 resulted in value: 0.5917804039253176. Current best value is 0.5845802945454878 with parameters: {'x0': 1.2995518388796587, 'x1': 1.7246812398293017, 'x2': 2.0292675881142404}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38887876589612647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:20,321] Finished trial#97 resulted in value: 0.6111212341038735. Current best value is 0.5845802945454878 with parameters: {'x0': 1.2995518388796587, 'x1': 1.7246812398293017, 'x2': 2.0292675881142404}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39597459735915574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:20,509] Finished trial#98 resulted in value: 0.6040254026408443. Current best value is 0.5845802945454878 with parameters: {'x0': 1.2995518388796587, 'x1': 1.7246812398293017, 'x2': 2.0292675881142404}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41097738046761323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:20,698] Finished trial#99 resulted in value: 0.5890226195323868. Current best value is 0.5845802945454878 with parameters: {'x0': 1.2995518388796587, 'x1': 1.7246812398293017, 'x2': 2.0292675881142404}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40582754664697185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:20,905] Finished trial#100 resulted in value: 0.5941724533530282. Current best value is 0.5845802945454878 with parameters: {'x0': 1.2995518388796587, 'x1': 1.7246812398293017, 'x2': 2.0292675881142404}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4018203325656029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:21,104] Finished trial#101 resulted in value: 0.5981796674343971. Current best value is 0.5845802945454878 with parameters: {'x0': 1.2995518388796587, 'x1': 1.7246812398293017, 'x2': 2.0292675881142404}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40452289525153173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:21,305] Finished trial#102 resulted in value: 0.5954771047484683. Current best value is 0.5845802945454878 with parameters: {'x0': 1.2995518388796587, 'x1': 1.7246812398293017, 'x2': 2.0292675881142404}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39922442228768484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:21,494] Finished trial#103 resulted in value: 0.6007755777123152. Current best value is 0.5845802945454878 with parameters: {'x0': 1.2995518388796587, 'x1': 1.7246812398293017, 'x2': 2.0292675881142404}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4035445581152485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:21,684] Finished trial#104 resulted in value: 0.5964554418847515. Current best value is 0.5845802945454878 with parameters: {'x0': 1.2995518388796587, 'x1': 1.7246812398293017, 'x2': 2.0292675881142404}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40719023269284027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:21,883] Finished trial#105 resulted in value: 0.5928097673071597. Current best value is 0.5845802945454878 with parameters: {'x0': 1.2995518388796587, 'x1': 1.7246812398293017, 'x2': 2.0292675881142404}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3903399094999058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:22,092] Finished trial#106 resulted in value: 0.6096600905000942. Current best value is 0.5845802945454878 with parameters: {'x0': 1.2995518388796587, 'x1': 1.7246812398293017, 'x2': 2.0292675881142404}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3795872205414135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:22,289] Finished trial#107 resulted in value: 0.6204127794585865. Current best value is 0.5845802945454878 with parameters: {'x0': 1.2995518388796587, 'x1': 1.7246812398293017, 'x2': 2.0292675881142404}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18613753818482637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:22,505] Finished trial#108 resulted in value: 0.8138624618151736. Current best value is 0.5845802945454878 with parameters: {'x0': 1.2995518388796587, 'x1': 1.7246812398293017, 'x2': 2.0292675881142404}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3991055553264181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:22,697] Finished trial#109 resulted in value: 0.6008944446735819. Current best value is 0.5845802945454878 with parameters: {'x0': 1.2995518388796587, 'x1': 1.7246812398293017, 'x2': 2.0292675881142404}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4156202434771139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:22,894] Finished trial#110 resulted in value: 0.5843797565228861. Current best value is 0.5843797565228861 with parameters: {'x0': 1.3453161859278986, 'x1': 1.714061977975721, 'x2': 2.0951626104228818}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41301266647388735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:23,081] Finished trial#111 resulted in value: 0.5869873335261127. Current best value is 0.5843797565228861 with parameters: {'x0': 1.3453161859278986, 'x1': 1.714061977975721, 'x2': 2.0951626104228818}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41430721959765315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:23,270] Finished trial#112 resulted in value: 0.5856927804023468. Current best value is 0.5843797565228861 with parameters: {'x0': 1.3453161859278986, 'x1': 1.714061977975721, 'x2': 2.0951626104228818}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41663965223294097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:23,459] Finished trial#113 resulted in value: 0.583360347767059. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4085311120884244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:23,645] Finished trial#114 resulted in value: 0.5914688879115756. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3856166777165594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:23,848] Finished trial#115 resulted in value: 0.6143833222834406. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3972627637734334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:24,045] Finished trial#116 resulted in value: 0.6027372362265666. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.414552887230048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:24,244] Finished trial#117 resulted in value: 0.585447112769952. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13496107517316547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:24,462] Finished trial#118 resulted in value: 0.8650389248268345. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.411300132189509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:24,656] Finished trial#119 resulted in value: 0.588699867810491. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3778105766882589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:24,858] Finished trial#120 resulted in value: 0.6221894233117411. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41350262113887637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:25,062] Finished trial#121 resulted in value: 0.5864973788611236. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41422242602193626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:25,260] Finished trial#122 resulted in value: 0.5857775739780637. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4121476434218415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:25,455] Finished trial#123 resulted in value: 0.5878523565781585. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4161464648219704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:25,655] Finished trial#124 resulted in value: 0.5838535351780296. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38459409507746267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:25,853] Finished trial#125 resulted in value: 0.6154059049225373. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3920880519039589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:26,046] Finished trial#126 resulted in value: 0.6079119480960411. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41368909261754117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:26,246] Finished trial#127 resulted in value: 0.5863109073824588. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40731668270833454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:26,452] Finished trial#128 resulted in value: 0.5926833172916655. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40699974290996543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:26,654] Finished trial#129 resulted in value: 0.5930002570900346. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4054153345891991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:26,860] Finished trial#130 resulted in value: 0.5945846654108009. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4127298294490266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:27,073] Finished trial#131 resulted in value: 0.5872701705509734. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40174120969470983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:27,267] Finished trial#132 resulted in value: 0.5982587903052902. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40472069583409587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:27,473] Finished trial#133 resulted in value: 0.5952793041659041. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4144546562992294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:27,666] Finished trial#134 resulted in value: 0.5855453437007706. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4123767493521072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:27,879] Finished trial#135 resulted in value: 0.5876232506478928. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36149476691620286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:28,089] Finished trial#136 resulted in value: 0.6385052330837971. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40941089511419915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:28,301] Finished trial#137 resulted in value: 0.5905891048858009. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41492228720412727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:28,508] Finished trial#138 resulted in value: 0.5850777127958727. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3296243036373544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:28,703] Finished trial#139 resulted in value: 0.6703756963626456. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4104014588600491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:28,906] Finished trial#140 resulted in value: 0.5895985411399509. Current best value is 0.583360347767059 with parameters: {'x0': 1.3569787461404184, 'x1': 1.715912149966611, 'x2': 2.002019880193678}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4181040995765368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:29,108] Finished trial#141 resulted in value: 0.5818959004234632. Current best value is 0.5818959004234632 with parameters: {'x0': 1.250001453903464, 'x1': 1.6072752414895517, 'x2': 2.073004997015076}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41596939798158106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:29,321] Finished trial#142 resulted in value: 0.5840306020184189. Current best value is 0.5818959004234632 with parameters: {'x0': 1.250001453903464, 'x1': 1.6072752414895517, 'x2': 2.073004997015076}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4195311454811098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:29,524] Finished trial#143 resulted in value: 0.5804688545188902. Current best value is 0.5804688545188902 with parameters: {'x0': 1.248389090023118, 'x1': 1.5874335948768517, 'x2': 2.0470967318193147}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4137868130193586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:29,736] Finished trial#144 resulted in value: 0.5862131869806414. Current best value is 0.5804688545188902 with parameters: {'x0': 1.248389090023118, 'x1': 1.5874335948768517, 'x2': 2.0470967318193147}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40518977634893705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:29,938] Finished trial#145 resulted in value: 0.594810223651063. Current best value is 0.5804688545188902 with parameters: {'x0': 1.248389090023118, 'x1': 1.5874335948768517, 'x2': 2.0470967318193147}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41985994295015494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:30,149] Finished trial#146 resulted in value: 0.5801400570498451. Current best value is 0.5801400570498451 with parameters: {'x0': 1.225154658728667, 'x1': 1.558322153723163, 'x2': 2.075248203274682}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3986817517105711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:30,346] Finished trial#147 resulted in value: 0.6013182482894289. Current best value is 0.5801400570498451 with parameters: {'x0': 1.225154658728667, 'x1': 1.558322153723163, 'x2': 2.075248203274682}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4168811887893571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-12-14 23:25:30,548]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-e03366c983ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m                 self._optimize_sequential(func, n_trials, timeout, catch, callbacks,\n\u001b[1;32m--> 260\u001b[1;33m                                           gc_after_trial)\n\u001b[0m\u001b[0;32m    261\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m                 self._optimize_parallel(func, n_trials, timeout, n_jobs, catch, callbacks,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[0;32m    424\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     def _optimize_parallel(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[1;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;31m# type: (...) -> None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m         \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstructs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOMPLETE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_completed_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_log_completed_trial\u001b[1;34m(self, trial_number, value)\u001b[0m\n\u001b[0;32m    579\u001b[0m         self.logger.info('Finished trial#{} resulted in value: {}. '\n\u001b[0;32m    580\u001b[0m                          'Current best value is {} with parameters: {}.'.format(\n\u001b[1;32m--> 581\u001b[1;33m                              trial_number, value, self.best_value, self.best_params))\n\u001b[0m\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\logging\\__init__.py\u001b[0m in \u001b[0;36minfo\u001b[1;34m(self, msg, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1376\u001b[0m         \"\"\"\n\u001b[0;32m   1377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misEnabledFor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mINFO\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1378\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mINFO\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1380\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\logging\\__init__.py\u001b[0m in \u001b[0;36m_log\u001b[1;34m(self, level, msg, args, exc_info, extra, stack_info)\u001b[0m\n\u001b[0;32m   1512\u001b[0m         record = self.makeRecord(self.name, level, fn, lno, msg, args,\n\u001b[0;32m   1513\u001b[0m                                  exc_info, func, extra, sinfo)\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\logging\\__init__.py\u001b[0m in \u001b[0;36mhandle\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   1522\u001b[0m         \"\"\"\n\u001b[0;32m   1523\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisabled\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1524\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallHandlers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0maddHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\logging\\__init__.py\u001b[0m in \u001b[0;36mcallHandlers\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   1584\u001b[0m                 \u001b[0mfound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfound\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1585\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mrecord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlevelno\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mhdlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1586\u001b[1;33m                     \u001b[0mhdlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1587\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1588\u001b[0m                 \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m    \u001b[1;31m#break out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\logging\\__init__.py\u001b[0m in \u001b[0;36mhandle\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m    892\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 894\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    895\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\logging\\__init__.py\u001b[0m in \u001b[0;36memit\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   1026\u001b[0m             \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m             \u001b[1;31m# issue 35046: merged two stream.writes into one.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1028\u001b[1;33m             \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1029\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mRecursionError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# See issue 36272\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__convertor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0misatty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_and_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite_and_convert\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mANSI_CSI_RE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_plain_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_ansi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m             \u001b[0mcursor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\colorama\\ansitowin32.py\u001b[0m in \u001b[0;36mwrite_plain_text\u001b[1;34m(self, text, start, end)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mflush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m                 \u001b[1;31m# and give a timeout to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m                     \u001b[1;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m                     \u001b[1;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "def tres(pred, t):\n",
    "    pred1 = deepcopy(pred)\n",
    "    pred1[pred1 < t[0]] = 0\n",
    "    pred1[(pred1>= t[0])&(pred1 < t[1])] = 1\n",
    "    pred1[(pred1>= t[1])&(pred1 < t[2])] = 2\n",
    "    pred1[pred1 >= t[2]] = 3\n",
    "    \n",
    "    return pred1\n",
    "\n",
    "def objective(trial, pred = pred, y_test = y_test):\n",
    "    x0 = trial.suggest_uniform('x0', pred.min(), pred.max())\n",
    "    x1 = trial.suggest_uniform('x1', x0,  pred.max())\n",
    "    x2 = trial.suggest_uniform('x2', x1,  pred.max())\n",
    "\n",
    "    t = [x0, x1, x2]\n",
    "    pred1 = tres(pred, t)\n",
    "    a = cohen_kappa_score(y_test, pred1, weights = 'quadratic')\n",
    "    print(a)\n",
    "    return 1-a\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
