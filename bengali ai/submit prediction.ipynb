{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import _pickle as pickle\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import cv2\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "import keras\n",
    "import tensorflow\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.applications import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Conv2D, Lambda, Activation,LeakyReLU,ZeroPadding2D, Dense,MaxPool2D,Reshape, Flatten,MaxPooling2D,Dropout, BatchNormalization,UpSampling2D,GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "# from tensorflow.keras.engine.input_layer import Input\n",
    "from keras.layers import merge\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.regularizers import l2\n",
    "import numpy.random as rng\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file,name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'wb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'wb')\n",
    "    pickle.dump(file, outfile)\n",
    "    outfile.close\n",
    "    \n",
    "def load(name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'rb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'rb')\n",
    "    file = pickle.load(outfile)\n",
    "    outfile.close\n",
    "    return file\n",
    "\n",
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "SIZE = 84\n",
    "def bbox(img):\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "    return rmin, rmax, cmin, cmax\n",
    "\n",
    "def crop_resize(img0, size=SIZE, pad=16):\n",
    "    #crop a box around pixels large than the threshold \n",
    "    #some images contain line at the sides\n",
    "    ymin,ymax,xmin,xmax = bbox(img0[5:-5,5:-5] > 80)\n",
    "    #cropping may cut too much, so we need to add it back\n",
    "    xmin = xmin - 13 if (xmin > 13) else 0\n",
    "    ymin = ymin - 10 if (ymin > 10) else 0\n",
    "    xmax = xmax + 13 if (xmax < WIDTH - 13) else WIDTH\n",
    "    ymax = ymax + 10 if (ymax < HEIGHT - 10) else HEIGHT\n",
    "    img = img0[ymin:ymax,xmin:xmax]\n",
    "    #remove lo intensity pixels as noise\n",
    "    img[img < 28] = 0\n",
    "    lx, ly = xmax-xmin,ymax-ymin\n",
    "    l = max(lx,ly) + pad\n",
    "    #make sure that the aspect ratio is kept in rescaling\n",
    "    img = np.pad(img, [((l-ly)//2,), ((l-lx)//2,)], mode='constant')\n",
    "    return cv2.resize(img,(size,size)) /255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [\n",
    "    'train_image_data_0.parquet',\n",
    "    'train_image_data_1.parquet',\n",
    "    'train_image_data_2.parquet',\n",
    "    'train_image_data_3.parquet'\n",
    "]\n",
    "\n",
    "test = [\n",
    "    'test_image_data_0.parquet',\n",
    "    'test_image_data_1.parquet',\n",
    "    'test_image_data_2.parquet',\n",
    "    'test_image_data_3.parquet'\n",
    "]\n",
    "\n",
    "subs = 'sample_submission.csv'\n",
    "\n",
    "models = [\n",
    "    'resnet18',\n",
    "    'densenet121'\n",
    "]\n",
    "\n",
    "weights = [\n",
    "    0.5,\n",
    "    0.5\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing and cropping the images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    df = pd.read_parquet(test[i])\n",
    "    \n",
    "    dataset = list(np.zeros(df.shape[0]))\n",
    "    ids = df['image_id'].values\n",
    "    \n",
    "    for j in tqdm(range(df.shape[0])):\n",
    "        img = 255 - df.iloc[j].values[1:].astype(np.uint8).reshape((137, 236))\n",
    "        img = crop_resize(img)\n",
    "        dataset[j] = img\n",
    "    \n",
    "    dataset = np.array(dataset)\n",
    "    \n",
    "    save((dataset, ids), 'test_set_'+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the preprocessed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(models, weights):\n",
    "    \n",
    "    preds = [[] for i in range(len(models))]\n",
    "    ids = np.array([])\n",
    "    \n",
    "    for i in range(4):\n",
    "        dataset, ids1 = load('test_set_'+str(i))\n",
    "        \n",
    "        ids = np.concatenate([ids, ids1])\n",
    "        \n",
    "        for j in range(len(models)):\n",
    "            print('data : '+str(i)+' model '+str(j))\n",
    "            model = load(models[j], 'models')\n",
    "            \n",
    "            pred = model.predict(dataset.reshape((dataset.shape[0], 84,84,1)))\n",
    "#             print(pred)\n",
    "            preds[j].extend(np.array(pred))\n",
    "    \n",
    "    preds = np.array(preds)\n",
    "    \n",
    "    pred = weights[0] * preds[0]\n",
    "    for i in range(1,len(models)):\n",
    "        pred += preds[i] * weights[i]\n",
    "    \n",
    "    \n",
    "    pred_gr = pred[:,:168]\n",
    "    pred_vd = pred[:,168:179]\n",
    "    pred_cd = pred[:, 179:]\n",
    "        \n",
    "    pred_gr = np.argmax(pred_gr, axis = 1)\n",
    "    pred_vd = np.argmax(pred_vd, axis = 1)\n",
    "    pred_cd = np.argmax(pred_cd, axis = 1)    \n",
    "    \n",
    "    \n",
    "    row_id = []\n",
    "    target = []\n",
    "    for i in range(len(ids)):        \n",
    "        row_id.append(ids[i]+'_consonant_diacritic')\n",
    "        row_id.append(ids[i]+'_grapheme_root')\n",
    "        row_id.append(ids[i]+'_vowel_diacritic')\n",
    "        \n",
    "        target.append(pred_cd[i])\n",
    "        target.append(pred_gr[i])\n",
    "        target.append(pred_vd[i])\n",
    "    \n",
    "    dico = {'row_id':row_id, 'target':target}\n",
    "    \n",
    "    df = pd.DataFrame(dico)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = pd.read_csv(subs)\n",
    "\n",
    "df = prediction(models, weights)\n",
    "\n",
    "df.index = df['row_id']\n",
    "\n",
    "submissions['target'] = df.loc[submissions['row_id'].values]['target'].values.astype(int)\n",
    "\n",
    "submissions.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
