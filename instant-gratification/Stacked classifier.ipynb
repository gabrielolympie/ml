{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lofo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFpr\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import PCA,  KernelPCA\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import neural_network\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "import optuna\n",
    "import skopt\n",
    "import mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = pd.read_csv('vlad_work.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_val = pd.read_csv('test.csv')\n",
    "# y_val = pd.read_csv('vlad_work.csv')['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1121,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for elt in y_val:\n",
    "    if elt>0.5:\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)\n",
    "\n",
    "df_val['target'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df_train, df_test, mappers):\n",
    "    train = df_train[cols].values\n",
    "    test = df_test[cols].values\n",
    "    data = np.concatenate((train,test), axis = 0)\n",
    "    \n",
    "    for elt in mappers:\n",
    "        \n",
    "        mapper = elt.fit(data)\n",
    "        train = mapper.transform(train)\n",
    "        test = mapper.transform(test)\n",
    "        data = np.concatenate((train,test), axis = 0)\n",
    "    return train, test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  0.9431677890011223\n",
      "1  0.9419291338582676\n",
      "2  0.9474968976552806\n",
      "3  0.9384176803531642\n",
      "4  0.8887620192307693\n",
      "5  0.9352056612118531\n",
      "6  0.798327664399093\n",
      "7  0.9166992141730068\n",
      "8  0.9044877819548873\n",
      "9  0.930195177956372\n",
      "10  0.8770342413832035\n",
      "11  0.974763923352633\n",
      "12  0.8449831715526073\n",
      "13  0.9572936170212766\n",
      "14  0.9544488644090847\n",
      "15  0.7695300763175289\n",
      "16  0.9417068567833927\n",
      "17  0.7898166319146327\n",
      "18  0.9536805058458602\n",
      "19  0.9266555812608444\n",
      "20  0.9552669773126575\n",
      "21  0.9432878222523746\n",
      "22  0.9468348101441626\n",
      "23  0.9262195211461958\n",
      "24  0.9476296563247387\n",
      "25  0.9652673663168415\n",
      "26  0.8707554751858549\n",
      "27  0.9354457132042144\n",
      "28  0.9593749132980052\n",
      "29  0.9528709677419356\n",
      "30  0.9456777818050018\n",
      "31  0.9527317088236203\n",
      "32  0.9332098384274983\n",
      "33  0.965101094895748\n",
      "34  0.903556042351223\n",
      "35  0.8782310806602304\n",
      "36  0.9533834586466166\n",
      "37  0.9278078007518797\n",
      "38  0.9539536498567833\n",
      "39  0.9353229571984436\n",
      "40  0.841871551245633\n",
      "41  0.9444635677700061\n",
      "42  0.8882948028997006\n",
      "43  0.9445973134505\n",
      "44  0.9610663598005369\n",
      "45  0.9459933407325194\n",
      "46  0.9448444700460831\n",
      "47  0.9003019359422177\n",
      "48  0.9639892160219103\n",
      "49  0.9357709923664123\n"
     ]
    }
   ],
   "source": [
    "for ind in range(50):\n",
    "#     ind = 10\n",
    "    df_t = df_train[df_train['wheezy-copper-turtle-magic']==ind]\n",
    "    df_v = df_val[df_val['wheezy-copper-turtle-magic']==ind]\n",
    "    y_t= df_t['target'].values\n",
    "    y_v= df_v['target'].values\n",
    "    mappers = [VarianceThreshold(threshold=1.5)]\n",
    "\n",
    "\n",
    "\n",
    "    train, val = transform(df_t, df_v, mappers)\n",
    "\n",
    "\n",
    "    clf = QuadraticDiscriminantAnalysis(reg_param = 0.11)\n",
    "    clf.fit(train, y_t)\n",
    "    y_proba = clf.predict_proba(train)[:,1]\n",
    "\n",
    "    tres = 0.9\n",
    "    y_t[abs(y_t-y_proba)>tres] = 1-y_t[abs(y_t-y_proba)>tres]\n",
    "\n",
    "#     clf = QuadraticDiscriminantAnalysis(reg_param = 0.11)\n",
    "    clf = NuSVC(probability=True, kernel='poly', degree=2, gamma='auto', nu=0.6, coef0=0.08)\n",
    "    clf.fit(val, y_v)\n",
    "\n",
    "    y_proba = clf.predict_proba(train)[:,1]\n",
    "    print(str(ind) +'  '+str(roc_auc_score(y_t, y_proba)))\n",
    "\n",
    "\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(534, 258)"
      ]
     },
     "execution_count": 1138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols1 = [c for c in df.columns if c not in ['id', 'target']]\n",
    "cols = [c for c in df.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train[df_train['wheezy-copper-turtle-magic']==0]\n",
    "# df = df[df['target']==1]\n",
    "# df.to_csv('zero.csv')\n",
    "# df = pd.read_csv('zero.csv')\n",
    "y = df['target'].values\n",
    "y1 = deepcopy(y)\n",
    "\n",
    "# clf = QuadraticDiscriminantAnalysis(reg_param = 0.11)\n",
    "# n_features = VarianceThreshold(threshold=1.5).fit_transform(df[cols].values).shape[1]\n",
    "\n",
    "# X = PCA(n_components=n_features).fit_transform(df[cols].values)\n",
    "# # X = VarianceThreshold(threshold=1.5).fit_transform(df[cols].values)\n",
    "# # X = FastICA(n_components=n_features, random_state=0, max_iter = 1000).fit_transform(df[cols].values)\n",
    "\n",
    "\n",
    "# clf.fit(X, y)\n",
    "# pred = clf.predict(X)\n",
    "# y1[abs(y-pred)>0.9] =1-y1[abs(y-pred)>0.9]\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y1, test_size=0.2, random_state = 42)\n",
    "\n",
    "# y_test = X_test['target']\n",
    "mappers = [\n",
    "    ## Data Augmentation\n",
    "#             PolynomialFeatures(degree=2),\n",
    "    ##Data reduction\n",
    "            VarianceThreshold(threshold=1.5),\n",
    "#              KernelPCA(n_components = 46 , kernel = 'linear', degree = 2)\n",
    "#             PCA(n_components=n_features),\n",
    "#             FastICA(n_components=n_features, random_state=0, max_iter = 500),\n",
    "    \n",
    "    ## Data Augmentation\n",
    "#             PolynomialFeatures(degree=2),\n",
    "    \n",
    "    ## Scaler\n",
    "#             StandardScaler(),\n",
    "#             Normalizer(norm=\"l2\"),\n",
    "#             Normalizer(norm=\"l1\"),\n",
    "#             RobustScaler(),\n",
    "#             MinMaxScaler(),\n",
    "                        ]\n",
    "    \n",
    "X_train, X_test = transform(X_train, X_test, mappers)\n",
    "# X = VarianceThreshold(threshold=1.5).fit_transform(df[cols].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TNuSVM(X_t, y_t, X_v, n_iter):\n",
    "#     mapper = PolynomialFeatures(degree=2)\n",
    "    \n",
    "#     X_t = mapper.fit_transform(X_t)\n",
    "#     X_v = mapper.fit_transform(X_v)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     def objective(trial):\n",
    "#             par = {\n",
    "# #                     'degree': trial.suggest_categorical('degree', [2, 4]),#trial.suggest_int('degree', 1, 5),\n",
    "# # #                   'kernel' : trial.suggest_categorical('kernel', ['rbf', 'linear', 'poly']),\n",
    "#                   'coef0' : trial.suggest_uniform('coef0', 0, 1),\n",
    "#                   'nu' : trial.suggest_uniform('nu', 0.3, 0.6)\n",
    "#                   }\n",
    "\n",
    "            \n",
    "#             clf = NuSVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=4, nu=0.6, coef0=0.08)\n",
    "\n",
    "#             clf.set_params(**par)\n",
    "#             scores = cross_val_score(clf, X, y, cv = 5, scoring = 'roc_auc', n_jobs = 8)\n",
    "#             return 1-scores.mean()\n",
    "# #     study = optuna.create_study()\n",
    "#     study.optimize(objective, n_trials=40)\n",
    "\n",
    "\n",
    "    \n",
    "#     clf = NuSVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=4, nu=0.6, coef0=0.08)\n",
    "#     clf = LinearSVC(random_state=0, tol=1e-5, max_iter = 5000)\n",
    "#     clf.set_params(**study.best_params)\n",
    "    clf = QDA()\n",
    "    clf.fit(X_t, y_t)\n",
    "    y_v = clf.predict(X_v)\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        if i%10 == 0:\n",
    "            print(i)\n",
    "        w_t = np.zeros(X_t.shape[0])+1\n",
    "        \n",
    "        def g(x):\n",
    "#             return x*(2-x)\n",
    "            return x/2\n",
    "        \n",
    "        w_v = np.zeros(X_v.shape[0])+g((i+1)/n_iter)\n",
    "        \n",
    "        weights = np.concatenate((w_t,w_v), axis = 0)\n",
    "        \n",
    "#         clf = NuSVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=4, nu=0.5, coef0=0.08)\n",
    "#         clf = LinearSVC(random_state=0, tol=1e-5,  max_iter = 5000)\n",
    "#         clf.set_params(**study.best_params)\n",
    "        clf = QDA()\n",
    "        clf.fit(np.concatenate((X_t,X_v), axis = 0), np.concatenate((y_t,y_v),axis = 0), sample_weight = weights)\n",
    "        y_v = clf.predict(X_v)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    if y_v.sum() == 0:\n",
    "        y_v[:20] = 1\n",
    "    if (1-y_v).sum() == 0:\n",
    "        y_v[:20] = 0\n",
    "\n",
    "    return y_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current indice :0\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "current indice :1\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "current indice :2\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "results = np.zeros((10,4))\n",
    "\n",
    "col1 = ['Var Switch', 'Var Pas Switch', 'PCA Switch', 'PCA Pas Switch']\n",
    "def f(a,b):\n",
    "    if a==0 and b==0:\n",
    "        return 0\n",
    "    elif a==0 and b==1:\n",
    "        return 1\n",
    "    elif a == 1 and b==0:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "for ind in range(0,3):\n",
    "    print('current indice :'+str(ind))\n",
    "    count_map = 0\n",
    "    for mapper in [VarianceThreshold(threshold=1.5)]  :\n",
    "        count_boolean = 0\n",
    "        boolean == False\n",
    "        for boolean in [True]:\n",
    "            \n",
    "#             ind = 10\n",
    "            train = df_train[df_train['wheezy-copper-turtle-magic']==ind]\n",
    "            val = df_test[df_test['wheezy-copper-turtle-magic']==ind]\n",
    "            y_t = train['target'].values\n",
    "            \n",
    "            mappers = [mapper]\n",
    "            train, val = transform(train, val, mappers)\n",
    "            \n",
    "            if boolean == True:\n",
    "                clf = QuadraticDiscriminantAnalysis(reg_param = 0.11)\n",
    "                clf.fit(train, y_t)\n",
    "                y_proba = clf.predict_proba(train)[:,1]\n",
    "\n",
    "                tres = 0.5\n",
    "                y_t[abs(y_t-y_proba)>tres] = 1-y_t[abs(y_t-y_proba)>tres]\n",
    "\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(train, y_t, test_size=0.2, random_state = 42)            \n",
    "\n",
    "            y_val = TNuSVM(X_train, y_train, val, 60)\n",
    "            \n",
    "            clf = QuadraticDiscriminantAnalysis(reg_param = 0.11)\n",
    "\n",
    "            clf.fit(val,y_val)\n",
    "            pred = clf.predict_proba(X_test)[:,1]\n",
    "            score = roc_auc_score(y_test, pred)\n",
    "            \n",
    "            results[ind, f(count_map, count_boolean)] = score\n",
    "#             results[ind,1] = nu\n",
    "            count_boolean +=1\n",
    "            \n",
    "            \n",
    "        count_map += 1\n",
    "results = pd.DataFrame(results, columns = col1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var Switch</th>\n",
       "      <th>Var Pas Switch</th>\n",
       "      <th>PCA Switch</th>\n",
       "      <th>PCA Pas Switch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.988701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.957851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Var Switch  Var Pas Switch  PCA Switch  PCA Pas Switch\n",
       "0    0.988701             0.0         0.0             0.0\n",
       "1    0.958333             0.0         0.0             0.0\n",
       "2    0.957851             0.0         0.0             0.0\n",
       "3    0.000000             0.0         0.0             0.0\n",
       "4    0.000000             0.0         0.0             0.0\n",
       "5    0.000000             0.0         0.0             0.0\n",
       "6    0.000000             0.0         0.0             0.0\n",
       "7    0.000000             0.0         0.0             0.0\n",
       "8    0.000000             0.0         0.0             0.0\n",
       "9    0.000000             0.0         0.0             0.0"
      ]
     },
     "execution_count": 884,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var Switch</th>\n",
       "      <th>Var Pas Switch</th>\n",
       "      <th>PCA Switch</th>\n",
       "      <th>PCA Pas Switch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.985876</td>\n",
       "      <td>0.974576</td>\n",
       "      <td>0.989092</td>\n",
       "      <td>0.971751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.957176</td>\n",
       "      <td>0.927508</td>\n",
       "      <td>0.926112</td>\n",
       "      <td>0.905172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.960744</td>\n",
       "      <td>0.950413</td>\n",
       "      <td>0.942691</td>\n",
       "      <td>0.942975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.960508</td>\n",
       "      <td>0.950257</td>\n",
       "      <td>0.954327</td>\n",
       "      <td>0.908405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.960433</td>\n",
       "      <td>0.921131</td>\n",
       "      <td>0.932292</td>\n",
       "      <td>0.888765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.978134</td>\n",
       "      <td>0.964364</td>\n",
       "      <td>0.975948</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.980682</td>\n",
       "      <td>0.985513</td>\n",
       "      <td>0.975806</td>\n",
       "      <td>0.968738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.969136</td>\n",
       "      <td>0.946092</td>\n",
       "      <td>0.958719</td>\n",
       "      <td>0.936465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.954614</td>\n",
       "      <td>0.940370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.950357</td>\n",
       "      <td>0.947143</td>\n",
       "      <td>0.926071</td>\n",
       "      <td>0.926786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Var Switch  Var Pas Switch  PCA Switch  PCA Pas Switch\n",
       "0    0.985876        0.974576    0.989092        0.971751\n",
       "1    0.957176        0.927508    0.926112        0.905172\n",
       "2    0.960744        0.950413    0.942691        0.942975\n",
       "3    0.960508        0.950257    0.954327        0.908405\n",
       "4    0.960433        0.921131    0.932292        0.888765\n",
       "5    0.978134        0.964364    0.975948        0.960000\n",
       "6    0.980682        0.985513    0.975806        0.968738\n",
       "7    0.969136        0.946092    0.958719        0.936465\n",
       "8    0.951613        0.926667    0.954614        0.940370\n",
       "9    0.950357        0.947143    0.926071        0.926786"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 845,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0,2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unsupervised_QDA(X, y):\n",
    "    \n",
    "    ## Initialisation : randomly assign labels to points\n",
    "    y = y\n",
    "    \n",
    "    for i in range(10):\n",
    "        clf = QDA()\n",
    "        clf.fit(X, y)\n",
    "    \n",
    "        y = clf.predict(X)\n",
    "    \n",
    "    return y\n",
    "y = unsupervised_QDA(X_train, y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n",
      "0.0 0\n",
      "1.0 1\n",
      "1.0 1\n",
      "1.0 1\n",
      "0.0 0\n"
     ]
    }
   ],
   "source": [
    "for elt in range(y.shape[0]):\n",
    "    print(y[elt], y_train[elt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import EmpiricalCovariance, MinCovDet\n",
    "Mat = MinCovDet(random_state=0).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 46)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mat.covariance_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.covariance import EmpiricalCovariance, MinCovDet\n",
    "\n",
    "def weighted_mean(X, weights):\n",
    "    X1 = np.zeros(X.shape[1])\n",
    "    for elt in range(X.shape[1]):\n",
    "        X2 = X[:,elt]\n",
    "        \n",
    "        std = X2.std()\n",
    "        m = X2.mean()\n",
    "        \n",
    "        X2 = X2[abs(X2-m)<2*std]\n",
    "        \n",
    "#         X1[elt] = (X2*weights).sum()/weights.sum()\n",
    "        X1[elt] = X2.mean()\n",
    "    return X1\n",
    "    \n",
    "def weighted_cov(X, centers, weights):\n",
    "#     Mat = np.zeros((X.shape[1], X.shape[1]))\n",
    "#     for i in range(X.shape[1]):\n",
    "#         for j in range(X.shape[1]):\n",
    "#             a = X[:,i]\n",
    "#             b = X[:,j]\n",
    "#             Mat[i,j] = ((a-centers[i])*(b-centers[j])*weights).sum()/(weights.sum()-1)\n",
    "            \n",
    "    Mat = MinCovDet(random_state=0, support_fraction  = 0.9).fit(X)  \n",
    "    \n",
    "    return Mat.covariance_ \n",
    "    \n",
    "class QDA:\n",
    "    def __init__(self):\n",
    "        self.mv1 = 0\n",
    "        self.mv2 = 0\n",
    "        self.m0 = 0\n",
    "        self.m1 = 0\n",
    "        self.s0 = 0\n",
    "        self.s1 = 0\n",
    "\n",
    "    def get_mv(self,x,y, weights):\n",
    "        ones = (y==1).astype(bool)\n",
    "        x2 = x[ones]\n",
    "        w2 = weights[ones]\n",
    "#         cov1 = np.cov(x2.T)\n",
    "        \n",
    "#         m1 = np.mean(x2, axis = 0)\n",
    "        m1 = weighted_mean(x2, w2)\n",
    "        cov1 = weighted_cov(x2,m1, w2)\n",
    "        self.m1 = m1\n",
    "        self.s1 = cov1\n",
    "        \n",
    "#         print(m1)\n",
    "\n",
    "        zeros = (y==0).astype(bool)\n",
    "        x2b = x[zeros]\n",
    "        w2b = weights[zeros]\n",
    "#         cov2 = np.cov(x2b.T)\n",
    "        \n",
    "#         m2 = np.mean(x2b, axis = 0)\n",
    "        m2 = weighted_mean(x2b, w2b)\n",
    "        cov2 = weighted_cov(x2b,m2,w2b)\n",
    "        self.m0 = m2\n",
    "        self.s0 = cov2\n",
    "        mv1 = multivariate_normal(mean=m1, cov=cov1)\n",
    "        mv2 = multivariate_normal(mean=m2, cov=cov2)\n",
    "\n",
    "        return mv1, mv2\n",
    "\n",
    "    def calc_prob(self,x):\n",
    "        y_pred2 = np.zeros((len(x),))\n",
    "        for i in range(len(x)):\n",
    "            a = self.mv1.pdf(x[i])\n",
    "            b = self.mv2.pdf(x[i])\n",
    "            y_pred2[i] = a/(a+b)\n",
    "        return y_pred2\n",
    "    \n",
    "    def fit(self, x, y, sample_weight = np.zeros(2)):\n",
    "        if sample_weight.sum() == 0:\n",
    "            sample_weight = np.zeros(x.shape[0])+1\n",
    "        self.mv1, self.mv2 = self.get_mv(x, y, sample_weight)\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        pred = np.zeros((X.shape[0],2))\n",
    "        pred[:,0] = 1-self.calc_prob(X)\n",
    "        pred[:,1] = self.calc_prob(X)\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_proba = self.calc_prob(X)\n",
    "        pred = np.zeros(X.shape[0])\n",
    "        for i in range(X.shape[0]):\n",
    "            if y_proba[i] < 0.5:\n",
    "                pred[i] = 0\n",
    "            else:\n",
    "                pred[i] = 1\n",
    "        return pred\n",
    "    def get_params(self, deep):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7886576964628963"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "ind=0\n",
    "train = df_train[df_train['wheezy-copper-turtle-magic']==ind]\n",
    "test = df_val[df_val['wheezy-copper-turtle-magic']==ind]\n",
    "y_train = train['target']\n",
    "train = VarianceThreshold(threshold=1.5).fit_transform(train[cols])\n",
    "test = VarianceThreshold(threshold=1.5).fit_transform(test[cols])\n",
    "\n",
    "clf = GaussianMixture(n_components=2, covariance_type='full', max_iter=500, n_init=30, \n",
    "                      random_state=42, verbose=0, verbose_interval=10, init_params='random')\n",
    "\n",
    "clf.fit(np.concatenate((train,test),axis = 0))\n",
    "# clf.fit(test)\n",
    "pred = clf.predict_proba(train)[:,1]\n",
    "roc_auc_score(y_train,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([170.,   1.,   0.,   2.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   1., 358.]),\n",
       " array([1.25691765e-28, 2.00000000e-02, 4.00000000e-02, 6.00000000e-02,\n",
       "        8.00000000e-02, 1.00000000e-01, 1.20000000e-01, 1.40000000e-01,\n",
       "        1.60000000e-01, 1.80000000e-01, 2.00000000e-01, 2.20000000e-01,\n",
       "        2.40000000e-01, 2.60000000e-01, 2.80000000e-01, 3.00000000e-01,\n",
       "        3.20000000e-01, 3.40000000e-01, 3.60000000e-01, 3.80000000e-01,\n",
       "        4.00000000e-01, 4.20000000e-01, 4.40000000e-01, 4.60000000e-01,\n",
       "        4.80000000e-01, 5.00000000e-01, 5.20000000e-01, 5.40000000e-01,\n",
       "        5.60000000e-01, 5.80000000e-01, 6.00000000e-01, 6.20000000e-01,\n",
       "        6.40000000e-01, 6.60000000e-01, 6.80000000e-01, 7.00000000e-01,\n",
       "        7.20000000e-01, 7.40000000e-01, 7.60000000e-01, 7.80000000e-01,\n",
       "        8.00000000e-01, 8.20000000e-01, 8.40000000e-01, 8.60000000e-01,\n",
       "        8.80000000e-01, 9.00000000e-01, 9.20000000e-01, 9.40000000e-01,\n",
       "        9.60000000e-01, 9.80000000e-01, 1.00000000e+00]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pred, bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "No backend sub-module imported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-266-c8e1a43a837a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m                 \u001b[0mae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Tanh\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                 ae.Layer(\"Sigmoid\", units=n_features)],\n\u001b[1;32m---> 40\u001b[1;33m             learning_rate=0.002,  n_iter=10)\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[0mmyae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sknn\\nn.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, layers, warning, parameters, random_state, learning_rule, learning_rate, learning_momentum, normalize, regularize, weight_decay, dropout_rate, batch_size, n_iter, n_stable, f_stable, valid_set, valid_size, loss_type, callback, debug, verbose, **params)\u001b[0m\n\u001b[0;32m    511\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_logger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 513\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sknn\\ae.py\u001b[0m in \u001b[0;36m_setup\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutoEncoderBackend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sknn\\backend\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, _)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mAutoEncoderBackend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No backend sub-module imported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: No backend sub-module imported."
     ]
    }
   ],
   "source": [
    "df = df_train[df_train['wheezy-copper-turtle-magic']==1]\n",
    "X, y = df[cols].values, df['target'].values\n",
    "X = VarianceThreshold(threshold=1.5).fit_transform(X)\n",
    "n_features = VarianceThreshold(threshold=1.5).fit_transform(X).shape[1]\n",
    "# X = FastICA(n_components=n_features, random_state=0, max_iter = 500).fit_transform(X)\n",
    "# X = PolynomialFeatures(degree=2).fit_transform(X)\n",
    "# X = StandardScaler().fit_transform(X)\n",
    "# X = PCA(n_components=40).fit_transform(X)\n",
    "# clf = QuadraticDiscriminantAnalysis(reg_param = 0.11)\n",
    "# clf.fit(X, y)\n",
    "# y_proba = clf.predict_proba(X)[:,1]\n",
    "# tres = 0.90\n",
    "# y[abs(y-y_proba)>tres] = 1-y[abs(y-y_proba)>tres]\n",
    "# clf = KNeighborsClassifier(n_neighbors=8, p=2, weights=\"uniform\")\n",
    "# clf = LogisticRegression(solver='saga',penalty='l2',C=0.01,tol=0.001, max_iter= 500)\n",
    "\n",
    "# # clf = NuSVC(probability=True, kernel='poly', degree=2, gamma='auto', nu=0.8, coef0=0.08)\n",
    "# # clf = SVC(probability=True, kernel='poly', degree=1, gamma='auto', random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "# clf = QDA()\n",
    "# # clf = QuadraticDiscriminantAnalysis(reg_param = 0.11)\n",
    "# clf.fit(X_train,y_train)\n",
    "# y_proba = clf.predict_proba(X_train)[:,1]\n",
    "# roc_auc_score(y_train, y_proba)\n",
    "# tres = 0.9\n",
    "# y_train[abs(y_train-y_proba)>tres] = 1-y_train[abs(y_train-y_proba)>tres]\n",
    "\n",
    "## Let's try an auto-encoder\n",
    "from sknn import ae, mlp\n",
    "from sknn.backend import AutoEncoderBackend, MultiLayerPerceptronBackend\n",
    "from sknn.backend import lasagne\n",
    "myae = ae.AutoEncoder(\n",
    "            layers=[\n",
    "                ae.Layer(\"Tanh\", units=500),\n",
    "                ae.Layer(\"Tanh\", units=100),\n",
    "                ae.Layer(\"Tanh\", units=50),\n",
    "                ae.Layer(\"Sigmoid\", units=n_features)],\n",
    "            learning_rate=0.002,  n_iter=10)\n",
    "myae.fit(X)\n",
    "\n",
    "\n",
    "\n",
    "# clf = QDA()\n",
    "# clf = QuadraticDiscriminantAnalysis(reg_param = 0.11)\n",
    "\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_proba1 = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "# ## Pseudo labelling\n",
    "\n",
    "# vect = []\n",
    "# y_test1 = []\n",
    "\n",
    "# tres1 = 0.01\n",
    "# for elt in y_proba1:\n",
    "#     if elt > 1-tres1:\n",
    "#         vect.append(True)\n",
    "#         y_test1.append(1)\n",
    "#     elif elt<tres1:\n",
    "#         vect.append(True)\n",
    "#         y_test1.append(0)\n",
    "#     else:\n",
    "#         vect.append(False)\n",
    "        \n",
    "# X1 = np.concatenate((X_train, X_test[vect,:]),axis = 0)\n",
    "# y1 = np.concatenate((y_train, y_test1),axis = 0)\n",
    "# clf = RandomForestClassifier(n_estimators = 500)\n",
    "# clf = NuSVC(probability=True, kernel='poly', degree=2, gamma='auto', random_state=4, nu=0.8, coef0=0.08)\n",
    "clf = QuadraticDiscriminantAnalysis(reg_param = 0.11)\n",
    "clf.fit(X_t, y_t)\n",
    "y_proba1 = clf.predict_proba(X_test)[:,1]\n",
    "        \n",
    "print(roc_auc_score(y_test, y_proba1))\n",
    "\n",
    "# print(cross_val_score(clf, X, y, cv = 5, scoring = 'roc_auc', n_jobs = 8).mean())\n",
    "# print(cross_val_score(clf1, X, y, cv = 5, scoring = 'roc_auc', n_jobs = 8).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x175b2cb5978>"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3dd5xcdb3/8dfnnKnbS3bTGySUhJJAqCKGJlVApCoKKuRaEFGu5QqiYvld9aqIF0RQpKk0rxAwNOkCgSQkISSQQgikZ5PsJlumz+f3x5kkm+1JZnd2Tz7PxyOPzJw5e857vnPmM2e+5zvniKpijDFm4HMKHcAYY0x+WEE3xhifsIJujDE+YQXdGGN8wgq6Mcb4RKBQKx40aJCOGTOmUKs3xpgBac6cORtVtaajxwpW0MeMGcPs2bMLtXpjjBmQROSDzh6zLhdjjPEJK+jGGOMTVtCNMcYnrKAbY4xPWEE3xhifsIJujDE+YQXdGGN8omDj0HeHZtagjf8Lqbng1kL4REh/AGQguD8kF0LqHdAt4FRA5BRILYPkPCANgeHetNAREH8KsnXgHgip+ZB6C7JpkCRoGijZ8XEXnAhFn0Oya9HkKyC1IBGIPQ7Z9SABCIwFZxhk1kJ6DdAEZEGKwd0f2Ow95pRB5CyQMkjOgsz73jpCR0HxFUhmKWRWQ+AgNHAQJJ+F5rsgsx4Ig4RAoqBAdp33XMkA4q1LqsCJgFMCwaMhciLiDvXaLzYd0vPBHY8UnQeZVWjLo7m22R9SiyD9HohLKl3Oq0/VEm9OM2JcBeXDT+C5+xdRWTGbo06qo2ZoEtnWPireMnSrly1yKhRdhmQWo7HHvccDYyHxnJc5cAhbG8fz6qMvMmrfDxg5LkVRWRmuWwokgBAERkFmDaSXA0m8FyMCThRwUWcMc187gOcf3Mi6lQ5VQ2v56Hn7csyJr+NmZoEoSCloAEjltokSCJ3kvS7pud7rHNgfAvtC+h2v/SJnettQ+k1wRoKmIPG89zwDY0GCENgPwsdD7ClIvQGZDd708PFIyTTEqUKzTWjzPRB/BLJbvXWET4Hky5BekXsuJd5rFTgYnHKIPw3ZTaAKmvDaVEIQGA/hj0H8WUgv9p6PRCAwDpwhkFmV2+Yac9tcAJzhEDoSwh+F0GFI4lk0/jSkN4AAUuRNL7rQW0byVTT+JGgMNOtt1wQgdARSdAFkt6AtD0BqgbcdkwJ3JMvf/yRLZi3goMNmUjUYiqpOQEq+DE61t77muyG7AaQEgvtBcDKkl0LqbcjUgwg4paBJb93uYJYs+gj/esghk3L52IXHcujUiYgI2eQ8aLoFkm97bePUQvHF3vur+Q5ILczlGgrRMyG5BNKv597DRyOlV3uba+NvIfEa0Ow9R3cEFF+ORD8B2oS2/J/Xzu5wyKwDbYDQsRA5B1LzvHVlVgNR7zWUMnCqILsCMnW592nYe90FbzskA9ri1a2iy5DIxxHJ//60dHc+dBG5EzgL2KCqB3XwuAC/Bc4AWoDLVfXN7lY8ZcoU3ZUfFmniVbT+CiDd47/pWmA3lrU7f7OrIm1ub8Gr3nvCZcenUyp3P/chAO2W37AxwE+mjeLbv1tJSVmGOS+V8JtrR/KT+95nn4kxIlFF1Xsvdi6YW0+i3fI/XBrmwVtquOZ/VuG63nK6X94OqvDzq0bxyhNlJOPe8zr/yxv44nXrEOn5ctqTXNZt/3cmiNeOHYlAxR9gy9W5D9v+QPBe/0wH08MQPAzS87yC0+Hfurn/d37O0/9cxdDRSQ6f2oST27y81zEIgQMhvYBd3Xb/elMt9/9uMKkEqDqEi8JMvfBYvvGbJLT8fpeXtzMn9/edLMMd5334aBKIdzBDd9tFTwkEj0Gq/oSIu+t/LTJHVad09FhPPiLuAk7r4vHTgfG5f9OA3+9qwO6oZtGGa8hvMd2dZfV2MQdvQ9r2r4H8bEAZvDdjqtV96Gzj/sMPh3HV/1tN9ZAU4WiW335rJFPPaWCfCS1Eot783RfNFN5zaL/8W64fxlU/W00gsGM5u1KE579SwmtPlZGMe4Vm0nFNfPG6dTjOnhRzWmXtrs07K+YAcWi4qh8Vc/CeT9tivm16HFKvdlLMt82Tpu1z3rLJZe6/S5n00R3FHLa1fwrSb7Gr2+66lUH+9tvBJGIO2ayDKsSbE7zz2nNkm/6wy8trL9v1MjLLQBvpuJiTh/W3Wk7qdUj8K0/L26Hbgq6qLwGbu5jlHOAe9cwEKkRkaL4CAl43gDbndZGmc++/E2bIyCSuC8sXRUmnhRM+WU+kaM+XnU55G53j7v6b498zyom37Nh0P/etdTsVlcJrLHSAXjf35VKOP2sLwWD+ljn7+TI66oU49JhNdPyB1Bv66gpuGTQ2I+9LzcfbYDiwstX9Vblp7YjINBGZLSKz6+rqer4GCdN3DW2iJVmyGW9XNxjOollIxHb9q2FHxIFUao92owlHszu98QePSO5hKrOrQuEsibiQzytYhsJZxGm/wHRqW5ePzziR7ufZ1UXmYRkdtXSHL7Oq3q6qU1R1Sk1NhycL63gFgVHgjNrdfGYXjdw3TiZX0Efvl6BqcJoZ91URa97zN5XrQtXgFC1Nu/8BcfL59YRCOzaxJfOL8lpY9piMKHSCXbTrr+vhUxt59u+VpDvofdrd1+KYU7ei2fZZXn+2Gnajr3n39NV6Akj0grwvNR8FfRUwstX9EcCaPCx3J1J1G1CWr6UBRex8ALIngrm/6a0XPXeQCrxRCJTTt3sm3rqu+P467vr5EOIxIZOGH931PgtnFfGvh6tIJrxBEN2+aaUW77kU47XbDlf9bA23XjecWLO3h7f9Xw9Tjj0wzhevX0MwlAVR7v2fwSRiu19Idk1utA0uHW4H7kgYdC8EJvRFmB5y6PitHvRGuBR/Fe+1Cnc8jwwCojstIxxVLv3meu6/uZZMhp1eR3EHQ/QL7Oq2W1qR4bo/rCAczRAtyRAtzhCKOHz2h1fglN/UyXPYFVE6fo54WSPneSOYiO7herojUPwlJNThcc09W3J3o1wARGQM8Hgno1zOBK7CG+VyFHCzqh7Z3TJ3dZQLgGoaTfwLEq96b5zIqbDlekjNYeeDNg5EPgVFl0NyDrTcB9m14FZC9AIo+jySfAWym9HgJG+4XnKmN0RMmyHb6A17zNR5Q/FCR0LxlYhuguSb4NagMhRiueFNTgSCR4FbDakVkF2dG9qV9YYpBY/1hh2m53tDoSKfQHQjmloM2TVAwBuWFjwUYo9B5gMkdBhEToNsAxp7EFJrgBhkNntDpQJjINME2VXec1fAqYbkM3jD/NpyvDzbj9TnNmynFoovg/AJ3vDOzArQJJnURt6emSASXkv1EIeyYWcx79WxJJo+5KCjGqgcFMu1l+baPui1MQGInIqEjvIODCZeAgQNHgrxZ7zlh45F3XEseulJ0skljB6vVNQOAamB7HLQuFcQNeENkyPu5Xaqwan0pjtVNKyv441nNrPq/ZGMnlDF0R97nuKixXjDHidC+FigBbIJiN3XfhuRQVB2PQQP9F7Llru86Zr15i26HMKnQmIG4ELwYESbwR2JBg9HUq+iqSWQWZnb5k5GQsciIqgqmpwLsX+A1kHwcO/1TDwHqcUQ/zudfoRFzofUe0CjN+QtfII3DC/2NCRf956ThL1lBoZBai1kV3rDPDXFjmGeaXCHI0UXoM5Qb5hsdoP3GkkYCe4PoWMRcdHMJki+nPtQdLxtmFBunmO8ZSZeQlPLIL0adBMEDybBucx7bgHVVc8xYpxLpPI0JHw8Ig6aWYfGHob0Wu+94Y6B0BRvyGJqiTdsGIAiiP+FbYMOWpoc3ni2jEx2OEdecDflg7wdOc02os0PQOLfkHkPtD43XPRkcIbmtpW0t+1Ez/fem4lnvXaOnIRETgMUjT3lbYvZehq3Bnnsz2W88WyAQcOHct41ZzDxiGY09Q4kF3vDWyXs1Y30O952QhKogMhUyG6B1GzQJm9acKK3PRH1np9o7gMxDdnN4A5Bis5H3CEdv/Y90NUol54MW/wbMBUYBKwHfkBul0tVb8sNW/xfvJEwLcDnVbXbSr07Bb0jqmm06VZoudcrvoGJSNn3kdDkPV72QJRt+Tts/RE7jtQHgCiU/8gbp+uUQ+QMRJtASpHAyC6W5h+aWopuvd77zQGu96FT9kPE2fGtTzUJyTe8D5TQUYhT2mt5snUneuPH23JqcWr/3Wvr7a809Ra65QZIv4u3U3AmUnYD4hT32jq3bm7kS5O/xZa6rSTjKUQgFA3x1Zu/wOlfOKnjnKpAdreGG+bLHhX03pKvgm7a08RMtPl271tC6Gjvxy5ufgceDVSq3jj83vhRx67Ixh6HLd9j5yFyUSj7Pk7R+YWKVXCqcSCASO//5vGuG+7nwV8+Siqx83DkaEmEhzf8iVAk1OsZdkdXBX1A/VLU9IyEj0bCRxc6Rr8kksdxdnvAiZ5FVjPQ9Guvq8oZDCXX4BR9qtDRCkok/yM/OjPzsTntijmAOMLytz7ggCPH91mWfLGCbkyBOEXnQNE5qCqyZ7+IMruhorbjQRbpVIay6t7rbutN/ernGGbgizXFeOWRN3j10VnEmjv7xZ1pzYp5YXzqG2cRKdp51IsbcBh78CiG7bv7By0LyfbQTd68/H+v8/PP/Q434O0nZDNZvvfXazjmE/kfnmXMnjritMlc+oMLuOcHDxIMuaTTGUbuP5wbH/l2oaPtNjsoavJi45rNXDb+ayRjOw+ZDBeFuHf5rVTWlhcomTFda97SzLK5K6ioLWP0hP4/6mtPT85lTLdeevC1jn/Zo/DywzP7PlAPqSofvLOKpW8uJ5Puq/OFmP6kuLyYQ6dOHBDFvDvW5WLyItYUJ51qXxDT6Qyxpv7Zl75y8WpuOOfnbFy1GXGFQDDAd+75GkedcVihoxmzW2wP3eTFEadPIhhuPyQwEHA58vRJBUjUtUw6w3+e8ENWL11LvCVBrDFO4+Ymfnzhr1n7/vpCxzNmt1hBN3mx3+H7ctJnjiNSvGPUQKQ4zKmfP4GxB48uYLKOzXnmLeLNiXa9RJl0mif++GxhQnVAsw1o4mU0tZBCHe8y+aGphWQbf4c23YGmO/iVcB5Yl4vJm2tu+w+OP/8Y/nXfS4gIJ3/2Y0w+sd3pf/qFhg1byGaz7aankxk2ru7q9P99J9v0e2i6NXfOnIx3abWqO+1XvwOMqqKNP4GWh4AkigtNN6NlP8IpOi+v67KCbvJGRDj8lEM5/JRDCx2lWwcddwDZTPuCHi2JMOXUwncRaeJFaLoNSOSuLwpk3kfrpyGDHitoNrOLUnOg5WF2nOYht91t/QEaOQFxKvO2KutyMXulYfsO4ZTLPrZTF1E4GmL4+KF89FNHFTCZR5vvBmJtpmYh/QGafq8Qkcxu0tg/6fiydm7ubKT5Y3voPqbZRiCd1z0AP/n6rdM45PiJPH7b08Sa45xw8XGc/ZVTCYb6wflesg0dT5eAdzV5M4A4dHiBadl28e78sYLuQ5pZhzZ8C1JvevcD+yDlv0CCB/Z9luQstOlmSC+HwH5IydeRUOG7NMDrIjrxkuM48ZLjCh2lvcjJ0LQUSLR5IAvB/nTxDNMdiZ7tnRe+7TcuzXjXQcgj63LxGdUMuvnTkJqFd0GHFKQXo5s/g2br+zZL4kV08xe9izJk6yD5Crr5c2ji9T7NMRBJ0WfBHcyOq2qJd7v0+4h0dtUd0x9J6FAovhzvojIhvNc0DOW/3Ol8/Plge+h+k3wFsvVsP/CyjabRlkeQks/3WRTd+hPa9x3G0cb/h4Qf6bMcA5E4pVD9CNryICReALcWKfqsVxzMgOOUfgONnuu9lhKG8KmIW5339VhB95vMKu+rXDtx7/JvfUQ1A5kPOn4wvaTPcgxk4pQgJV+Aki8UOorJAwmMhcDYXl2Hdbn4TWAiHV6cV4r6tO9axAXp5OukU9VnOYzZm1hB95vgIRCaxM5XNw96F1iOnNG3WYq/SPsrqEeh+D/6Nocxewkr6D4jIkjlHVA8zbsSulMN0QuR6r/3+cE0Kf4PKPocEAXJ/Su5Eim6tE9zGLO3sPOhm16nGofMRnBrbISGMXvILhJtCkokAoERhY5hjO9Zl4sxxviEFXRjjPEJ63LpZzTbhDb/CeIzQCJQ9Bkkej4i9tlrjOmaFfR+RDWObvoUZFYDuYstb/0pmpqDlP+8oNmMMf2f7fb1J7F/QnYd24u5NxFiM9D0igKFMsYMFFbQ+xFNvgra9hzYgLiQmtf3gYwxA4p1ufQn7nAgiHeWxNYEnNoCBOod9esbeH3GXFzX4aizDqOsqrTQkYzxhR7toYvIaSKyWESWich3O3h8lIg8LyJzReQtEenj35j7g0QvpP1nrANSDqHCX0UnH/55xzNcOvYr3HL1n/jdVX/kkpFf4sWHXit0LGN8oduCLiIucAtwOjABuERE2p5h/3rgQVWdDFwM3JrvoHsDCYxAKn8PTg1IERCGwIFI1X3eya4GuDXvrePWr/+ZZDxFvDlBrClOMpbkF5f/L/UbthQ6njEDXk/20I8ElqnqclVNAvcD57SZR4Ftp9YrB9bkL+LeRcLHIjUve+deqXkKZ9A/EJ/8yvKFB14h08GFmUXglX+8UYBExvhLT/rQhwMrW91fBbT9/v9D4GkR+RpQDJzc0YJEZBowDWDUqFG7mnWvIeJAYN9Cx8i7ZDxFtoOCns0oqUTb4wbGmF3Vkz30Dk6u3fZqp1wC3KWqI4AzgHulg1/CqOrtqjpFVafU1NTselozoB17zhGEIu0vwCwCR591eAESGeMvPSnoq4CRre6PoH2XyheBBwFU9TW8i+YNykdA4x/7Hb4vZ1xxMuGiMCKC4wjhohCf/t55DN1ncKHjGTPg9aTLZRYwXkTGAqvxDnp+us08HwInAXeJyIF4Bb0un0GNP3zlps8z9aJjefGh13Bch5M+/VHGTe7dy3IZs7fotqCralpErgKeAlzgTlVdKCI3ArNVdTpwLXCHiHwDrzvmci3UidZNvzfhmP2ZcMz+hY5hjO/06IdFqjoDmNFm2g2tbi8CPpLfaMYYY3aF/fTfGGN8wgq6Mcb4hBV0Y4zxCSvoxhjjE1bQjTHGJ6ygG2OMT1hBN8YYn7CCbowxPmEF3RhjfMIKujHG+IQVdGOM8Qkr6MYY4xNW0I0xxiesoBtjjE9YQTfGGJ+wgm6MMT5hBd0YY3zCCroxxviEbwt6OpUmnUoXOoYxxvSZHl1TdCDZuHoTv572B+Y8Mx8UDp06kWv/+GUGj64pdDRjjOlVvtpDTyVTfP0j1zPn6flk01mymSzzX1jI1cd8j0QsUeh4xhjTq3xV0Gc+NofG+iaymez2adlMllhTnJcenlnAZMYY0/t8VdBXL1tHMpZsNz3WFGf10rUFSGSMMX3HVwV97MGjCEVD7aZHSyKMPXh0ARIZY0zf8VVBn3LqodSOqiEY2nGsNxB0qRxcwUfOPaKAyYwxpvf5qqC7rstNL/+Yj19+AsXlRRSVRjnp0uO5+bWfEgj6bkCPMcbsRFS1ICueMmWKzp49uyDrNsaYgUpE5qjqlI4e89UeujHG7M2soBtjjE9YQTfGGJ/oUUEXkdNEZLGILBOR73Yyz4UiskhEForIX/Mb0z9UY2Sb7yfbcA3Zxl+jmdWFjmSM8Yluh36IiAvcApwCrAJmich0VV3Uap7xwH8BH1HVehGp7a3AA5lmG9BN50FmExADgmjL3VB5BxI6stDxjDEDXE/20I8ElqnqclVNAvcD57SZ50rgFlWtB1DVDfmN6Q/adBtk1uMVc4AUaAxt+DaFGm1kjPGPnhT04cDKVvdX5aa1th+wn4i8IiIzReS0jhYkItNEZLaIzK6rq9u9xANZ/Ckg1X56djNY14sxZg/15Nc20sG0truTAWA8MBUYAbwsIgepasNOf6R6O3A7eOPQdzntQCeRTh7IdvGY6WvJeJJXHpnFxtWbOeDIcRx03AGIdPQ2MKZ/6UlBXwWMbHV/BLCmg3lmqmoKeF9EFuMV+Fl5SekXRZ+Bxl+yo8sFwIXgQYg7qFCpTCsrF6/mG8ffQDKWJJVIEQgFOODI8fx0xvcIhYOFjmdMl3rS5TILGC8iY0UkBFwMTG8zzyPACQAiMgivC2Z5PoP6gRRdApGTgTBIEUgxuCOQipsKHc3k/OSi37B1YyOxpjjpVIZ4c4J3Zi7hH7/9Z6GjGdOtbvfQVTUtIlcBTwEucKeqLhSRG4HZqjo999jHRWQRkAG+paqbejP4QCTiIhW/QtMrIPUWuEMgOAUR+zlAf7Bx9SZWLlnT7gB1IpbkiT89x0XfPrdAyYzpmR6dsUpVZwAz2ky7odVtBb6Z+2e6IYExEBhTsPVrtgmNPQrpt8AdjxSdhzhVBcvTX2Sz2uEBI++xbCePGNN/2CkI9zKaWYdu+hRkm/D68iNo821QfT8SGFfoeAVVM6Ka2tE1rFq88yGiUCTIyZceX6BUxvScfdffy2jjL7xhktsPzMZBG9Et3ytkrH5BRLjub9dQXF5EuMi7UEq0JMLoCSO44D/PLnA6Y7pne+h7m8TzeIc5WlNIvYVqApFwIVL1G+MmjeW+92/l+b/9mw0rNzHhmP048ozJuK5b6GjGdMsK+l6ns6F3DvaFzVNSUcwnvnxqoWMYs8vsHby3iZ4HtN0LD0D4RERsnLUxA5kV9L2MlF4DwUkgUSDqjYcP7IOU/7jQ0Ywxe8i6XPYyIhGk+l40tQBSiyEwOjcW3n7absxAZwV9LyXBgyF4cKFjGGPyyLpcjDHGJ6ygG2OMT1hBN8YYn7CCbowxPmEF3RhjfMIKujHG+IQVdGOM8Qkr6MYY4xNW0I0xxiesoBtjjE9YQTfGGJ+wgm6MMT5hBd0YY3zCCroxxviEFXRjjPEJK+jGGOMTVtCNMcYnrKAbY4xPWEE3xhifsIJujDE+YQXdGGN8okcFXUROE5HFIrJMRL7bxXzni4iKyJT8RTTGGNMT3RZ0EXGBW4DTgQnAJSIyoYP5SoGrgdfzHdIYY0z3erKHfiSwTFWXq2oSuB84p4P5fgz8AojnMZ8xxpge6klBHw6sbHV/VW7adiIyGRipqo93tSARmSYis0Vkdl1d3S6HNcYY07meFHTpYJpuf1DEAX4DXNvdglT1dlWdoqpTampqep7SGGNMt3pS0FcBI1vdHwGsaXW/FDgIeEFEVgBHA9PtwKgxxvStnhT0WcB4ERkrIiHgYmD6tgdVdYuqDlLVMao6BpgJnK2qs3slsTHGmA51W9BVNQ1cBTwFvAM8qKoLReRGETm7twMaY4zpmUBPZlLVGcCMNtNu6GTeqXseyxhjzK6yX4oaY4xPWEE3xhifsIJujDE+YQXdGGN8wgq6Mcb4hBV0Y4zxCSvoxhjjE1bQjTHGJ6ygG2OMT1hBN8YYn7CCbowxPmEF3RhjfMIKujHG+IQVdGOM8Qkr6MYY4xNW0I0xxiesoBtjjE9YQTfGGJ+wgm6MMT5hBd0YY3zCCroxxviEFXRjjPEJK+jGGOMTVtCNMcYnrKAbY4xPWEE3xhifsIJujDE+YQXdGGN8wgq6Mcb4hBV0Y4zxiR4VdBE5TUQWi8gyEfluB49/U0QWichbIvKsiIzOf1RjYPGsZXzj+O9zVsmlXDr2Kzx221OoaqFjGdMvdFvQRcQFbgFOByYAl4jIhDazzQWmqOohwMPAL/Id1Jj35q/g2hN+yNv/fpdES4L1H9Rx+3/ey30/frjQ0YzpF3qyh34ksExVl6tqErgfOKf1DKr6vKq25O7OBEbkN6YxcO+PHiIZS+40Ld6S4IFfPEq8JVGgVMb0Hz0p6MOBla3ur8pN68wXgSc6ekBEponIbBGZXVdX1/OUxgBL5y7vsHvFcYS6lRsLkMiY/qUnBV06mNZhp6WIXApMAX7Z0eOqeruqTlHVKTU1NT1PaQwwYr9hHU7PpDNUD6vq4zTG9D89KeirgJGt7o8A1rSdSUROBq4DzlZV+/5r8u6z3z+fcDS007RwUYhTP38CRaXRAqUypv/oSUGfBYwXkbEiEgIuBqa3nkFEJgN/wCvmG/If0xg46LgDuf6BbzJkbC2O6xApDnPuVafz1d9+odDRjOkXAt3NoKppEbkKeApwgTtVdaGI3AjMVtXpeF0sJcBDIgLwoaqe3Yu5zV7q6LMO56gzDyMRSxKKBHEc+ymFMdt0W9ABVHUGMKPNtBta3T45z7mM6ZSIECkKFzqGMf2O7d4YY4xPWEE3xhifsIJujDE+YQXdGGN8wgq6Mcb4hBV0Y4zxCSvoxhjjE1bQjTHGJ6ygG2OMT1hBN8YYn7CCbowxPmEF3RhjfMIKujHG+IQVdGOM8Qkr6KZH1i5fz+v/nMOqpWsLHcUY04kenQ/d7L2SiRQ/u+QmZj05l2A4QCqZ4dCpE/nBw9cSjto5yc2eU81AtgGcUryLopndZXvopkt3/+ABZj01j2Q8RfOWGMlYknnPv80f/vPeQkczPpBt/iu64Wi0biq64Qiyjb9GNVvoWAOWFXTTpRm3/4tkLLnTtFQ8xdN3PY+qFiiV8QON/ROafg66BUiAxqD5brTp5kJHG7CsoJsuxZsTHU5PxlNW0H2gsb6J+S8sZNWSNX2+bm36nVfEdxKDlrtRTfd5Hj+wPnTTpYOPP5B5zy2gbe0+4KhxdoHmAUxVufuHD/DQL6cTDAdJJdOMnzyWG6d/h7Kq0r4JkV3fSbjc3rr0UQ4fsXek6dJXf/t5oqVRgiHvsz8QChAtiXD1LVcWOFnfWbdiAzde8CvOqfgcFw2/knt//BDp1MDeg3zpodf4+68fzx0baSEZS7J49jJ+dslNfRcisH/H050KkJK+y+EjtoduujR6wkj+tPA3PPK7J1gyZzn7HDqa864+g9pRNYWO1ie2bNzKV4/4Do31zWhWadka44H/foT3F3zIDQ9eW+h4u+2hX01v152WTmZ466V3qN+whcra8l7PIKXfRjdfDsRbTY1AyXcQkV5fvx9ZQTfdGjS8miv++9JCxyiIx257mnhzAs3u6HNKxJK8/vgcVi9by/BxQwuYbvdt2djY4XQ34NBU39Q3BT10GFTdjTb+CtKLwdWUh8cAABMuSURBVB2OlFyNRE7s9XX7lXW5GNOFd2YuIRlPtZseCAV4f8GHBUiUH0eePhk36LabHooEGbbvkD7LIaHJONX34QyehTPoESvme8gKujFdGD1hJIFQ+8KXSWf7tPDl26ev+xSllSUEw0EARIRwNMTVt07DDbR/vmZgsC4X02tSyRQvPzyTWU/OY9CIas644iSG7jO40LF2yTlfPY3Hb3uadDKzfVowHGDcpDHsc8joAibbM9VDK7ljwa945OYZvPnsAgaPqeX8b5zF/keMK3Q0swekUGOJp0yZorNnz+7TdTbWN/HI755g5uNzqBpSwae+cRaTTjioTzPsLeItCa457npWL11LvDlBIBjADTp8/8FrOeqMwwodb5e8+8ZSfj3tD3y4aCXiOHz0vKP4+u+vpLi8uNDRzF5IROao6pQOH9tbCnpjfRNfmvwt6jdsIZXrEw0Xhbnivz/DuVed3mc5OqPpVaAtENgXkYH/lffB/5nOPT94gESbX5mWVpbw0Po/5u1rfawpxofvrqF6aAWDhlfnZZmdrqs5TiDoEgwFe3U9A9XWTY1sXtfAsH0HE4rYOVl6S1cFfUB2uSTjSea/uIiV765h0IhKNKukkmkmHrM/9Ru2UFZdSs2IKua/sIjmrS1MmjqRx//wDPXrGkgld4wfTrQk+P21dxEtjXDoxyayeV0DFTVlVA6p4P0FH1JZW07F4HLm/ustls59H8cRRh80imQsSVN9MwccOY79jxhHS2OMec8vJBVPUjaolIqacsYePAoRYcPKjSx4cRHltWUcfPwEVr67hiVz3mPswaOIFkdIxz9k7Mifkkl8wNuzSti4tpjKsZfjhid5b5C19Yw5aDRDx9ZSv76B6mGV1K3aTDKepLisiH0njSEQ9F7G9R/UsX7FBjLZLFVDKhl1wHAa65uY+9zbbFq7mX0PGUNlbTnvvL6UIWNrqagp49VHZ7F07goyqTSTT5zImINGk81mcV2HrEL10AqaGlpYtXg1+x2xL+lkhq0bG3FDLplkBkRwgw6ZVJayqhLCxWE2rdnM47c91a6YA7Q0xbh07FfIZpWjzzqcz95wPsXlRby/4EPiLQmiJVEqasp4542llFWVcMjHJhLK9fNuXLOZDR/UMWL/YSRjSf7y07/z9N0v4gYcUvEUIw4YztW3XMEBR45j+fwPaN7Sght0yaSzVNSWISLUr2/ADbhk0hlEhK2bmwgEA1TWlrHotSWIA6MOGEnV0Aoy6QzvL/iQ8YftA0Aqmaakooh5LyykYX0DFYMrGDKmhpKKEorLoyx4cRGuu4XBo5KsXh4hmy3m4OMPZOjYwdu312H71jJq4kg2fFBHOpWhvLqUYCTA4jfeY/i4IVQMLmfrpib2OWQ0kSLv5GdL31zO/BcWUjaolI9dcAzhaJhYc5z5Lywk3hynrLqUsupS9jlk9PYfe3347mriW5dTXrGaBa8laGqsoWpoJcFwCBEIBF02r22gpbGFIWNqad7SQqgoxNa6RpKJNNXDKikqjbJ5bT0NdVtxXGHQ8CrKqkqpHFzOiP2H8fa/32XF2yupqC3jpYdnMvPxOTiukElnOeyUQ5hyyqHsc8goakfVsHH1Jhobmlm/oo7qYVWUVZdQObiCTCpDOpVh3KQxuAGXZDzJq4/OYsOHG1nx9krmPr+AWGOM2tE1HHnqZA48Zj8OO/lgoiVRkvEk815YyKrFaxk2bjCHTp1IOBri3TeWsWTWMspryrxv4CLMeXo+6z+oQxxh6JhaJp10MJW15WQyGZa9+T7ZxCxqBz3Fh0uaqVt3CBUjTqK+LsGoA4ZTVBrlrZffId4Up3Z0DZNPOIhUMs2aZetIp9KUDyrDDbq0bI1RUVvOxlUbSSW96YGgy+b1Dbiuw+DRtZRUFvPBwpUMGl7VK0N/e7SHLiKnAb8FXOCPqvrfbR4PA/cAhwObgItUdUVXy9zdPfQn/vwsN027nWym4xP4uAEHVdo9Lo7sNPSsw78NuqgqmlUixWHiLQk00/XfBCNB0sn0Tst2Ay7VQyupGl7Ju68vhU4WESlK88CCd5j7UjE//dJoUonWx6jbj8N1Ag7ZdHan+0WlUa65bRr/vP1fvPXiQjK5x52AQ1FJlKaG5i7zF5IIhIrCZNNZ0ql0h69PIOjytVuvZNYTc3ljxpsEQgFiTd645a5eT8d1Ot1Gdj8wnb6WjqN88fo1PPtwJcsXRVv9wa6LFHuF/LIbL+KFB15lyez3tj9XxxGOPvtwZj725k7Pzw04VA6p4Ou/n8ad3/sLp1/8Bm88W8Ts58raPIE915P3Uo+XJUK4KEQoEuILP/s0d173V1q2tux0zKItxxGOOfcIXnt09k5tII7gBpwu/3bHzDBp6kEsX/ABU89ewdGn1HPjFWOJN3f9Hmy9LlXdaXvobpsTx1tetCRCOpnm4I8eyPcfupbisqLu87Zezp50uYj3/X8JcAqwCpgFXKKqi1rN8xXgEFX9kohcDHxSVS/qarm7U9DffWMp1xx3/faiNdD99K/vMXR0kmlT9yed2v0BR47jIA6+aZe2RLxhgqlE//115oVfXc/CN4pYOKuEfBXO3flQEkc48bx6QuE0T/ylOm9Z+oKI9Pn5gSJFGe548V2+cNwBpBJ929UZDAc44rTJ/Ogf396lv+uqoPekihwJLFPV5aqaBO4HzmkzzznA3bnbDwMnSS/81OsfNz/hm6IVjmaZ9JEmnvpbFenUnjVVNpv1Tbt0RJV+XcwBjv9EA+/OLSafBXR3vmFoVjnz0jqeeagqr1n6QiGO5+0/KcYLj1SSTvb9CO5UIs2sJ+fSWN+Ut2X25FkMB1a2ur8qN63DedQ7TdoWoN0RKhGZJiKzRWR2XV3dLofdtHbzLv9NfxUtzpDNwKb1QQbaG8+0l04J/eVcZaFolswe7iTsLRobXLbWu+1OPtdXHNelqT5/3aI92QQ72jLaPv2ezIOq3q6qU1R1Sk3Nrh8QOOqMw3xT+xo2BtiyOciUqY04rn/3rvcWWza5OG7/OJ3w68+UMWR0x6c97s8KcfqW5YsijByXwA0U5rWLFIWoHT0ob8vrSUFfBYxsdX8E0PbkydvnEZEAUA7kfXf6zGmnMGhYVb4X2yu2nZ2wc8LN3xnBlBO2MHJcgk6PtnW3nnCAwWNqCEUH5lC6aEkEx+n6nVxRU0Y4Gtp+UKk/uvNnw7ny+2sQR9nd17K1YDhARW359l9y7qSTZghFgoyeOJLH7xnBpd9cn9tR6B8fMt0JF4UZPWHk9gPC3crHppA7NnPfr4awz4QYfdlWIt5z/totV+K6+eu778lB0QDeQdGTgNV4B0U/raoLW83zVeDgVgdFz1PVC7ta7u6Ocmne0sw9P3qQJ+98nlhTHHEF13VxXYeK2nJCkSBVQyuJFIdZ+Mpi0qk0Bxw1nqkXHMMj//skq5atRYBAIEAqlSaTyuAEHAYNqyQUCTFoRDXlNWV8uGgV5YNKCYQCvPXSIhItSUQEcQXNKCJQUVvOeV8/kw/eXc0r/3idZDxJKBJmxPghfPLqMxl54DBu++Y9LHtzOcFIkIOO3Z8Vi1axac1mikqjlFaVMO7gFs7/8mZefizDjHtCtDQ6uMEAoKQS6e0jbqqHVyEKbtChsb6FVDxJRW05p19xEmf9xym8N28Ff/1//2DpnPfIZpQR+w3l5EuPZ+aMN3nzmfmkkxnCxWGKSiO0bGkhGAlRObicdDJD05ZmWra0AEIwHMBxvc/5QNCluLyIpoZmYk0JSiuLCYWDNDfGcv27iqp3MMsNuBSVRQkEXRrqthLLzRMpjnDI8RNItCTYuLaeYDBAKpli7CGjuexHF1FaWcLff/MYLz74GrHGGOGiMOIIW+oaCUWDfPxzU7n0hvNZu3w9D/ziUVa+u5rh44aQiCXZuHozBx49ntETRvLI755g4+pNVNSUM+GY/Xhv/goaNmwhm1HcoENJZQmgNNU3bz/ekEl7Q+aCoQDVwyppbmgh1hwnFAlSWlVCU30LLY0xisuKKK0qJpvNEm9KUL++gUw6ixtwCReFKa0qJpVIEY5s5KiTGpj1bCnrVoYBh9pRNYyaMJwFLy0i3pwkGA5QM3IQiZYEqUSKaEmEVDJDU30ToWiIipoygpEgR595OOd9/Uyy2Sx3fOc+Zj05D8cRTvz0RznjypN46H+m8+JDr5GMJQlFQwzdZzDnXnU6J3/2eOY8/RaP3zadmsFvs2hWlhWLHDJZCIZCREsiqCrJWJJkIkU2myUQ8LY3Ee/guuu6OAGHTCpDIpbcPqLFzY2qGr7fUGpGVDP3ubdp2RojGA5w1JmHcdCxB/Dwbx6nbtXG7dtFtCRC5ZBymupbaN7SQiadwXEdoiURKmrKcAMukZIIJ33mo5x55cnEmxM88adnefGh11i5eA3pRApFc9ubECkKM/WiY7nw2+cy/ZYnePKu50k0JwlHQ0y96FiG7juY//vtE2zduBU34DJu8hgcx2HJnPe84zACwXCQgz96IF/+9WW8+8Z7TL/lSepWbqCkrIVNGyAZB3Gc7flFYOvmJsgqgXCQA47Yl6LSIpbN84b7FpcXEQgH0UwGJxBg66atZNIZiiuKEXFobmjGcR3GTBxBWXUpKxevYcjYWi781jlMOHq/Xa6Be/zDIhE5A7gJb9jinar6UxG5EZitqtNFJALcC0zG2zO/WFWXd7XMQvxS1BhjBro9/mGRqs4AZrSZdkOr23Hggj0JaYwxZs/0k+Pyxhhj9pQVdGOM8Qkr6MYY4xNW0I0xxiesoBtjjE9YQTfGGJ+wgm6MMT5RsCsWiUgd8MFu/vkgYGMe4+RLf8xlmXquP+bqj5mgf+baWzKNVtUOT4ZVsIK+J0Rkdme/lCqk/pjLMvVcf8zVHzNB/8xlmazLxRhjfMMKujHG+MRALei3FzpAJ/pjLsvUc/0xV3/MBP0z116faUD2oRtjjGlvoO6hG2OMacMKujHG+MSAK+gicpqILBaRZSLy3QLmWCEiC0RknojMzk2rEpFnRGRp7v/KPshxp4hsEJG3W03rMId4bs613VsiclgfZvqhiKzOtde83EVTtj32X7lMi0Xk1F7KNFJEnheRd0RkoYh8PTe9YG3VRaZCt1VERN4Qkfm5XD/KTR8rIq/n2uoBEQnlpodz95flHh/Th5nuEpH3W7XVpNz0PtnWc+tyRWSuiDyeu1+wdkJVB8w/vCsmvQfsA4SA+cCEAmVZAQxqM+0XwHdzt78L/LwPchwPHAa83V0O4AzgCbwrMh4NvN6HmX4I/GcH807IvY5hYGzu9XV7IdNQ4LDc7VK8yypOKGRbdZGp0G0lQEnudhB4PdcGD+JdjQzgNuDLudtfAW7L3b4YeKAPM90FnN/B/H2yrefW9U3gr8DjufsFa6eBtod+JLBMVZerahK4HzinwJlaOwe4O3f7buDc3l6hqr5E+wtyd5bjHOAe9cwEKkRkaB9l6sw5wP2qmlDV94FleK9zvjOtVdU3c7cbgXeA4RSwrbrI1Jm+aitV1abc3WDunwInAg/nprdtq21t+DBwkojk9YreXWTqTJ9s6yIyAjgT+GPuvlDAdhpoBX04sLLV/VV0/QboTQo8LSJzRGRabtpgVV0L3psVqC1Qts5yFLr9rsp9/b2zVXdUn2fKfdWdjLeX1y/aqk0mKHBb5boR5gEbgGfwvg00qGq6g3Vvz5V7fAtQ3duZVHVbW/0011a/EZFw20wd5M2nm4BvA9nc/WoK2E4DraB39GlWqHGXH1HVw4DTga+KyPEFyrErCtl+vwf2BSYBa4FfFSKTiJQAfweuUdWtXc3awbReydVBpoK3lapmVHUSMALvW8CBXay7T3K1zSQiBwH/BRwAHAFUAd/pq0wichawQVXntJ7cxXp7PdNAK+irgJGt7o8A1hQiiKquyf2/AfgH3ka/ftvXutz/GwqRrYscBWs/VV2fe0NmgTvY0VXQZ5lEJIhXOP+iqv+Xm1zQtuooU39oq21UtQF4Aa8fukJEtl1YvvW6t+fKPV5Oz7vc9iTTabluK1XVBPBn+ratPgKcLSIr8Lp/T8TbYy9YOw20gj4LGJ87ihzCO7Awva9DiEixiJRuuw18HHg7l+Wy3GyXAY/2dbacznJMBz6XGwFwNLBlW3dDb2vTf/lJvPbaluni3AiAscB44I1eWL8AfwLeUdVft3qoYG3VWaZ+0FY1IlKRux0FTsbr338eOD83W9u22taG5wPPae7IXy9nerfVh7Hg9VW3bqteff1U9b9UdYSqjsGrRc+p6mcoYDv1ylHf3vyHd/R6CV6f3nUFyrAP3miD+cDCbTnw+sOeBZbm/q/qgyx/w/tansLbA/hiZznwvvLdkmu7BcCUPsx0b26db+U27KGt5r8ul2kxcHovZToO7+vtW8C83L8zCtlWXWQqdFsdAszNrf9t4IZW2/0beAdjHwLCuemR3P1lucf36cNMz+Xa6m3gPnaMhOmTbb1VvqnsGOVSsHayn/4bY4xPDLQuF2OMMZ2wgm6MMT5hBd0YY3zCCroxxviEFXRjjPEJK+jGGOMTVtCNMcYn/j/T5MnVc6OzjgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(list(range(y_proba.shape[0])),y_proba, c = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x175b1eaba90>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(list(range(y_proba1.shape[0])),y_proba1, c = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sknn.ae as ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AutoEncoder',\n",
       " 'Layer',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'absolute_import',\n",
       " 'backend',\n",
       " 'itertools',\n",
       " 'log',\n",
       " 'logging',\n",
       " 'nn',\n",
       " 'print_function',\n",
       " 'sklearn',\n",
       " 'time',\n",
       " 'unicode_literals']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=120, style=ProgressStyle(descript"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.9593344394814983\n",
      "Generation 2 - Current best internal CV score: 0.9595994103347044\n",
      "Generation 3 - Current best internal CV score: 0.9595994103347044\n",
      "Generation 4 - Current best internal CV score: 0.9595994103347044\n",
      "Generation 5 - Current best internal CV score: 0.9671349921349922\n",
      "\n",
      "Best pipeline: LogisticRegression(PolynomialFeatures(input_matrix, degree=2, include_bias=False, interaction_only=False), C=0.001, dual=True, penalty=l2)\n"
     ]
    }
   ],
   "source": [
    "df = df_train[df_train['wheezy-copper-turtle-magic']==0]\n",
    "X, y = df[cols].values, df['target'].values\n",
    "X = VarianceThreshold(threshold=1.5).fit_transform(X)\n",
    "\n",
    "clf = QuadraticDiscriminantAnalysis(reg_param = 0.11)\n",
    "clf.fit(X, y)\n",
    "y_proba = clf.predict_proba(X)[:,1]\n",
    "tres = 0.4\n",
    "y[abs(y-y_proba)>tres] = 1-y[abs(y-y_proba)>tres]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "pipeline_optimizer = TPOTClassifier(generations=5, population_size=20, cv=6,random_state=42, verbosity=2, scoring = 'roc_auc', n_jobs=8)\n",
    "pipeline_optimizer.fit(X_train, y_train)\n",
    "pipeline_optimizer.export('tpot_exported_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.972457627118644\n",
      "0.9844632768361582\n"
     ]
    }
   ],
   "source": [
    "pred = pipeline_optimizer.predict_proba(X_test)[:,1]\n",
    "pred1 = pipeline_optimizer.predict(X_test)\n",
    "print(roc_auc_score(y_test, pred))\n",
    "confusion_matrix(y_test, pred1)\n",
    "\n",
    "clf = QuadraticDiscriminantAnalysis(reg_param = 0.11)\n",
    "clf.fit(X_train, y_train)\n",
    "y_proba = clf.predict_proba(X_test)[:,1]\n",
    "print(roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24bce018160>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, pred)\n",
    "plt.plot(fpr,tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9841660802251936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[46,  3],\n",
       "       [ 1, 57]], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = QuadraticDiscriminantAnalysis(reg_param = 0.11)\n",
    "# clf = NuSVC(probability=True, kernel='poly', degree=2, gamma='auto', random_state=4, nu=0.7, coef0=0.08)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict_proba(X_test)[:,1]\n",
    "pred1 = clf.predict(X_test)\n",
    "print(roc_auc_score(y_test, pred))\n",
    "confusion_matrix(y_test, pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   2.,   0.,   0.,   1., 102.,   0.,   0.,   0.,   1.]),\n",
       " array([-0.99999994, -0.80524898, -0.61049802, -0.41574706, -0.2209961 ,\n",
       "        -0.02624515,  0.16850581,  0.36325677,  0.55800773,  0.75275869,\n",
       "         0.94750965]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_test-pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train[df_train['wheezy-copper-turtle-magic']==0]\n",
    "y = df['target'].values\n",
    "X = df[cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(solver='saga',penalty='l2',C=0.01,tol=0.001)\n",
    "clf2 = QuadraticDiscriminantAnalysis(reg_param = 0.01)\n",
    "clf3 = SVC(probability=True, kernel='poly', degree=2, gamma='auto', random_state=42)\n",
    "clf4 = NuSVC(probability=True, kernel='poly', degree=2, gamma='auto', random_state=4, nu=0.8, coef0=0.08)\n",
    "clf5 = MLPClassifier(hidden_layer_sizes=(500, 100))\n",
    "clf6 = KNeighborsClassifier(n_neighbors=15, p=2, weights=\"distance\")\n",
    "\n",
    "clfs = {'logreg' : clf1, 'QDA' : clf2, 'SVC' : clf3, 'NuSVC' : clf4, 'MLP' : clf5, 'KNN' : clf6}\n",
    "\n",
    "pipe5 = Pipeline(steps = [('feat_red', VarianceThreshold(threshold=1.5)),\n",
    "                ('classifier', clf5)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe6 = build_pipeline(clf6, X, y,1, 3,'KNN', scoring = 'roc_auc', cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(pipe3, X, y, cv = 5, scoring = 'roc_auc', n_jobs = 8).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipes = [pipe1, pipe2, pipe3, pipe4, pipe5, pipe6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    w1 = trial.suggest_int('w1', 0, 5)\n",
    "    w2 = trial.suggest_int('w2', 0, 5)\n",
    "    w3 = trial.suggest_int('w3', 0, 5)\n",
    "    w4 = trial.suggest_int('w4', 0, 5)\n",
    "    w5 = trial.suggest_int('w5', 0, 5)\n",
    "    w6 = trial.suggest_int('w6', 0, 5)\n",
    "    \n",
    "    \n",
    "    eclf = EnsembleVoteClassifier(clfs=[pipe1, pipe2, pipe3, pipe4, pipe5, pipe6],\n",
    "                              weights=[w1, w2, w3,w4,w5,w6], voting='soft')\n",
    "    return 1 - cross_val_score(sclf, X, y, cv = 5, scoring = 'roc_auc', n_jobs = 8).mean()\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eclf = EnsembleVoteClassifier(clfs=[pipe1, pipe2, pipe3, pipe4, pipe5, pipe6],\n",
    "                              weights=[1, 5, 3,4,1,1], voting='soft')\n",
    "# sclf = StackingClassifier(classifiers=pipes, meta_classifier=lr, use_probas=True, average_probas=False)\n",
    "cross_val_score(eclf, X, y, cv = 5, scoring = 'roc_auc', n_jobs = 8).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(clf1, X, y,search_space, n_iter, cl, scoring = 'roc_auc', cv = 5):\n",
    "    clf = deepcopy(clf1)\n",
    "    n_features = VarianceThreshold(threshold=1.5).fit_transform(X).shape[1]\n",
    "    best_pipeline = \"\"\n",
    "    best_score  = 0\n",
    "    for i in range(n_iter):\n",
    "        print(\"Current iteration : \"+str(i))\n",
    "        print(clf)\n",
    "        ### Build a pipeline for current classifier\n",
    "        feat_red = [VarianceThreshold(threshold=1.5), PCA(n_components=n_features), \n",
    "                    FastICA(n_components=n_features, random_state=0, max_iter = 400)]\n",
    "\n",
    "        feat_aug = [None, PolynomialFeatures(degree=2)]\n",
    "\n",
    "        scaler = [None, StandardScaler(), Normalizer(norm=\"l2\"),\n",
    "                    Normalizer(norm=\"l1\"), RobustScaler(),\n",
    "                    MinMaxScaler()]\n",
    "        \n",
    "        count = 0\n",
    "        for red in feat_red:\n",
    "            for aug in feat_aug:\n",
    "                for scal in scaler:\n",
    "                    steps = [('feat_red' , red),\n",
    "                        ('feat_aug' , aug),\n",
    "                        ('scaler' , scal),\n",
    "                        ('classifier' , clf)\n",
    "                    ]\n",
    "                    pipeline = Pipeline(steps = steps)\n",
    "                    scores = cross_val_score(pipeline, X, y, cv = 5, scoring = 'roc_auc', n_jobs = 8)\n",
    "                    count +=1\n",
    "                    print(count)\n",
    "                    if scores.mean()>best_score:\n",
    "                        best_score = scores.mean()\n",
    "                        best_pipeline = pipeline    \n",
    "        print(best_pipeline)\n",
    "        \n",
    "        ### Build a classifier for current pipeline\n",
    "        \n",
    "        steps = best_pipeline.steps\n",
    "        clf = steps[-1][1]\n",
    "        \n",
    "        def objective(trial):\n",
    "                \n",
    "                #### Logistic Regression\n",
    "                \n",
    "                \n",
    "                if cl == 'logreg':\n",
    "                    par = {\n",
    "                                'solver' : trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']),\n",
    "                                'C' : trial.suggest_loguniform('C', 0.001, 10),\n",
    "                                'tol' : trial.suggest_uniform('tol', 0.0001, 0.002),\n",
    "                            }\n",
    "                #####  QDA\n",
    "                if cl ==  'QDA':\n",
    "                    par =  {'reg_param' : trial.suggest_uniform('reg_param', 0.0001, 0.999999)}\n",
    "\n",
    "                #### SVC\n",
    "\n",
    "                if cl == 'SVC':\n",
    "                    par = {'degree': trial.suggest_int('degree', 1, 5),\n",
    "                      'kernel' : trial.suggest_categorical('kernel', ['rbf', 'linear', 'poly']),\n",
    "                      'C' : trial.suggest_loguniform('C', 0.001, 10),\n",
    "                      'coef0' : trial.suggest_uniform('tol', 0, 1)}\n",
    "\n",
    "                #### NuSVC\n",
    "                if cl == 'NuSVC':\n",
    "                    par = {'degree': trial.suggest_int('degree', 1, 5),\n",
    "                      'kernel' : trial.suggest_categorical('kernel', ['rbf', 'linear', 'poly']),\n",
    "                      'coef0' : trial.suggest_uniform('tol', 0, 1),\n",
    "                      'nu' : trial.suggest_uniform('nu', 0.5, 0.9)}\n",
    "\n",
    "                #### KNN\n",
    "                if cl == 'KNN':\n",
    "                    par = {'n_neighbors ' : trial.suggest_int('n_neighbors', 5, 40),\n",
    "                  'weights ' :trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
    "                  'p' :trial.suggest_int('p', 1, 5) }\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "              \n",
    "        \n",
    "                clf.n_neighbors = trial.suggest_int('n_neighbors', 5, 40)\n",
    "#                 clf.set_params(**par)\n",
    "#                 clf.reg_param = par['reg_param']\n",
    "                steps[-1] = ('classifier',clf)\n",
    "                pipeline = Pipeline(steps = steps)\n",
    "                scores = cross_val_score(pipeline, X, y, cv = 5, scoring = 'roc_auc', n_jobs = 8)\n",
    "                return 1-scores.mean()\n",
    "        study = optuna.create_study()\n",
    "        study.optimize(objective, n_trials=40)\n",
    "        print(study.best_params)\n",
    "        \n",
    "        clf1 = deepcopy(clf)\n",
    "        \n",
    "        clf1.n_neighbors =study.best_params['n_neighbors']\n",
    "#         clf1.set_params(**study.best_params)\n",
    "#         clf.reg_param = study.best_params['reg_param']\n",
    "        \n",
    "        p = deepcopy(best_pipeline)\n",
    "        p.steps[-1] = ('classifier',clf1)\n",
    "        scores1 = cross_val_score(p, X, y, cv = 5, scoring = 'roc_auc', n_jobs = 8)\n",
    "        scores2 = cross_val_score(best_pipeline, X, y, cv = 5, scoring = 'roc_auc', n_jobs = 8)\n",
    "        if scores1.mean()>scores2.mean():\n",
    "            best_pipeline = p\n",
    "            clf = clf1\n",
    "        print(best_pipeline)\n",
    "        print(max(scores1.mean(),scores2.mean()))\n",
    "        best_score = max(scores1.mean(),scores2.mean())\n",
    "    return best_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Logistic Regression\n",
    "par = {\n",
    "                'solver' : trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']),\n",
    "                'C' : trial.suggest_loguniform('C', 0.001, 10),\n",
    "                'tol' : trial.suggest_uniform('tol', 0.0001, 0.002),\n",
    "            }\n",
    "#####  QDA\n",
    "par =  {'reg_param' : trial.suggest_uniform('reg_param', 0.0001, 0.999999)}\n",
    "\n",
    "#### SVC\n",
    "\n",
    "par = {'degree': trial.suggest_int('degree', 1, 5),\n",
    "      'kernel' : trial.suggest_categorical('kernel', ['rbf', 'linear', 'poly']),\n",
    "      'C' : trial.suggest_loguniform('C', 0.001, 10),\n",
    "      'coef0' : trial.suggest_uniform('tol', 0, 1)}\n",
    "\n",
    "#### NuSVC\n",
    "par = {'degree': trial.suggest_int('degree', 1, 5),\n",
    "      'kernel' : trial.suggest_categorical('kernel', ['rbf', 'linear', 'poly']),\n",
    "      'coef0' : trial.suggest_uniform('tol', 0, 1),\n",
    "      'nu' : trial.suggest_uniform('nu', 0.5, 0.9)}\n",
    "\n",
    "#### MLP Classifier\n",
    "\n",
    "par = {'hidden_layer_sizes' : (trial.suggest_int('hidden_layer_sizes', 1, 1000),200)}\n",
    "#### KNN\n",
    "\n",
    "par = {'n_neighbors ' : trial.suggest_int('n_neighbors', 5, 40),\n",
    "      'weights ' :trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
    "      'p' :trial.suggest_int('p', 1, 5) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2.reg_param = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat_red = [VarianceThreshold(threshold=1.5), PCA(n_components=46), \n",
    "            FastICA(n_components=46, random_state=0, max_iter = 400)]\n",
    "\n",
    "feat_aug = [None, PolynomialFeatures(degree=2)]\n",
    "\n",
    "scaler = [None, StandardScaler(), Normalizer(norm=\"l2\"),\n",
    "            Normalizer(norm=\"l1\"), RobustScaler(),\n",
    "            MinMaxScaler()]\n",
    "pipelines = {}\n",
    "best_scores = {}\n",
    "for classifier in clfs:\n",
    "    print(pipelines)\n",
    "    print(best_scores)\n",
    "    best_score  = 0\n",
    "    count = 0\n",
    "    for red in feat_red:\n",
    "        for aug in feat_aug:\n",
    "            for scal in scaler:\n",
    "                clf = clfs[classifier]\n",
    "                steps = [('feat_red' , red),\n",
    "                    ('feat_aug' , aug),\n",
    "                    ('scaler' , scal),\n",
    "                    ('classifier' , clf)\n",
    "                ]\n",
    "                pipeline = Pipeline(steps = steps)\n",
    "                scores = cross_val_score(pipeline, X, y, cv = 5, scoring = 'roc_auc', n_jobs = 8)\n",
    "                count +=1\n",
    "                print(count)\n",
    "                if scores.mean()>best_score:\n",
    "                    best_score = scores.mean()\n",
    "                    pipelines[classifier] = pipeline\n",
    "                    best_scores[classifier] = best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=15, p=2, weights=\"distance\")\n",
    "clf2 = LogisticRegression(solver='saga',penalty='l2',C=0.01,tol=0.001)\n",
    "clf3 = QuadraticDiscriminantAnalysis(reg_param = 0.11)\n",
    "clf4 = NuSVC(probability=True, kernel='poly', degree=2, gamma='auto', random_state=4, nu=0.8, coef0=0.08)\n",
    "lr = LogisticRegression(solver = 'lbfgs')\n",
    "\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2, clf4], \n",
    "                          meta_classifier=lr, use_probas=True, average_probas=False)\n",
    "sclf.fit(X_train, y_train)\n",
    "\n",
    "pred1 = sclf.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(roc_auc_score(y_test, pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = NuSVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=4, nu=0.8, coef0=0.08)\n",
    "clf = KNeighborsClassifier(n_neighbors=13, p=2, weights=\"distance\")\n",
    "# clf = KNeighborsClassifier(n_neighbors=22, weights=\"uniform\")\n",
    "# clf = PassiveAggressiveClassifier(max_iter=1000, random_state=0,tol=1e-3)\n",
    "# clf = LogisticRegression(solver='saga',penalty='l2',C=0.01,tol=0.001)\n",
    "# clf = QuadraticDiscriminantAnalysis(reg_param = 0.11)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)#[:,1]\n",
    "pred1 = clf.predict_proba(X_test)[:,1]\n",
    "print(roc_auc_score(y_test, pred1))\n",
    "# train = np.concatenate((X_train, X_test), axis = 0)\n",
    "# y = np.concatenate((y_train, pred), axis = 0)\n",
    "# clf.fit(train, y)\n",
    "# pred = clf.predict_proba(X_test)[:,1]\n",
    "# print(roc_auc_score(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clfs = [QuadraticDiscriminantAnalysis(reg_param = 0.11),\n",
    "        NuSVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=4, nu=0.8, coef0=0.08),\n",
    "        LogisticRegression(solver='saga',penalty='l2',C=0.01,tol=0.001),\n",
    "        KNeighborsClassifier(n_neighbors=11, p=2, weights=\"distance\"),\n",
    "        KNeighborsClassifier(n_neighbors=22, weights=\"uniform\")\n",
    "        ]\n",
    "\n",
    "p1 = np.zeros((X_train.shape[0], len(clfs)))\n",
    "p2 = np.zeros((X_test.shape[0], len(clfs)))\n",
    "\n",
    "for i in range(len(clfs)):\n",
    "    clf = clfs[i]\n",
    "    clf.fit(X_train, y_train)\n",
    "    p1[:, i] = clf.predict_proba(X_train)[:,1]\n",
    "    p2[:, i] = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "def objective(trial):\n",
    "    params = []\n",
    "    for elt in range(len(clfs)):\n",
    "        params.append(trial.suggest_uniform('p'+str(elt),0, 1-sum(params)))\n",
    "    \n",
    "    \n",
    "    pred = np.zeros(X_train.shape[0])\n",
    "    \n",
    "    for j in range(len(clfs)):\n",
    "        pred += params[j] * p1[:,j]\n",
    "    \n",
    "    return 1-roc_auc_score(y_train, pred)\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=30, n_jobs = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = np.zeros(X_test.shape[0])\n",
    "count = 0\n",
    "for elt in study.best_params:\n",
    "    pred1 += study.best_params[elt]*p2[:,count]\n",
    "    count+=1\n",
    "\n",
    "roc_auc_score(y_test, pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "true = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(512):\n",
    "    print('***********************                   '+str(i)+'                ************************')\n",
    "    df1 = df_train[df_train['wheezy-copper-turtle-magic']==i]\n",
    "    y = df1['target'].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df1, y, test_size=0.2, random_state = 42)\n",
    "    \n",
    "    n_features = VarianceThreshold(threshold=1.5).fit_transform(X_train[cols]).shape[1]\n",
    "    mappers = [\n",
    "    VarianceThreshold(threshold=1.5),\n",
    "\n",
    "#             PCA(n_components=n_features) ,\n",
    "#             StandardScaler(),\n",
    "#             Normalizer(norm=\"l2\"),\n",
    "#             Normalizer(norm=\"l1\"),\n",
    "#             PolynomialFeatures(degree=2),\n",
    "#             RobustScaler(),\n",
    "#             MinMaxScaler(),             \n",
    "    \n",
    "          ]\n",
    "    \n",
    "    \n",
    "    X_train, X_test = transform(X_train, X_test, mappers)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    parameters = {'n_neighbors':list(range(7,30))\n",
    "                 }\n",
    "    \n",
    "#     knn = KNeighborsClassifier( p = 2,weights=\"distance\")\n",
    "#     clf = GridSearchCV(knn, parameters, cv=5, scoring = 'roc_auc', n_jobs = 8, iid = True)\n",
    "    \n",
    "    clf = QuadraticDiscriminantAnalysis(reg_param = 0.111)\n",
    "#     clf = KNeighborsClassifier(n_neighbors=13, p=2 , weights=\"distance\")\n",
    "#     clf = LogisticRegression(C=0.01,solver = 'lbfgs', dual=False, penalty=\"l2\")\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    pred1 = clf.predict_proba(X_test)[:,1]\n",
    "    for i in range(3):\n",
    "        X1 = X_test[pred1>0.999999]\n",
    "        X0 = X_test[pred1<0.000001]\n",
    "        y1 = np.zeros(X1.shape[0])+1\n",
    "        y0 = np.zeros(X0.shape[0])\n",
    "        X_train = np.concatenate((X_train, X1, X0))\n",
    "        y_train = np.concatenate((y_train, y1, y0))\n",
    "        clf.fit(X_train, y_train)\n",
    "        pred1 = clf.predict_proba(X_test)[:,1]\n",
    "        print(roc_auc_score(y_test, pred1))\n",
    "    \n",
    "    \n",
    "    pred1 = clf.predict_proba(X_test)[:,1]\n",
    "#     pred1 = scale_result(X_test, clf)\n",
    "    \n",
    "    pred += list(pred1)\n",
    "    true += list(y_test)\n",
    "    \n",
    "roc_auc_score(true, pred)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
