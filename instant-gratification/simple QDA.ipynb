{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nfrom sklearn.decomposition import PCA\n# Any results you write to the current directory are saved as output.\n\nimport matplotlib.pyplot as plt\nfrom copy import deepcopy\nimport pandas as pd\nimport numpy as np\nimport random\nimport gc\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.decomposition import FastICA\nfrom sklearn.feature_selection import SelectKBest, chi2, SelectFpr\nfrom sklearn.decomposition import NMF\nfrom sklearn.decomposition import PCA,  KernelPCA\n\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import neural_network\nfrom sklearn.svm import NuSVC\nfrom sklearn.svm import SVC\n\nfrom mlxtend.classifier import StackingClassifier\nfrom mlxtend.classifier import EnsembleVoteClassifier\nimport optuna\nimport skopt\nimport mlxtend","execution_count":1,"outputs":[{"output_type":"stream","text":"['train.csv', 'sample_submission.csv', 'test.csv']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/train.csv')\ndf_test = pd.read_csv('../input/test.csv')\nsubmission = pd.read_csv('../input/sample_submission.csv')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = [c for c in df_train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def transform(df_train, df_test, mappers):\n    train = df_train[cols].values\n    test = df_test[cols].values\n    data = np.concatenate((train,test), axis = 0)\n    \n    for elt in mappers:\n        \n        mapper = elt.fit(data)\n        train = mapper.transform(train)\n        test = mapper.transform(test)\n        data = np.concatenate((train,test), axis = 0)\n    return train, test","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ind = 0\ndf = df_train[df_train['wheezy-copper-turtle-magic']==ind]\ny = df['target'].values\nX_val = df_test[df_test['wheezy-copper-turtle-magic']==ind]\n\nX_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state = 42)\n\nX_train  = VarianceThreshold(threshold=1.5).fit_transform(X_train[cols])\nX_test  = VarianceThreshold(threshold=1.5).fit_transform(X_test[cols])\n\n# X_train, X_test = transform(X_train, X_test, mappers)\n\nX_val  = VarianceThreshold(threshold=1.5).fit_transform(X_val[cols])\n\ntitle = []\nfor elt in range(X_train.shape[1]):\n    title.append('c'+str(elt))\n\nclf = QuadraticDiscriminantAnalysis(reg_param = 0.11)\nclf.fit(X_train, y_train)\n\npred_test_proba = clf.predict_proba(X_test)[:,1]\npred_test = clf.predict(X_test)\npred_val = clf.predict(X_val)\ndf_training = pd.DataFrame(X_val, columns = title)\ndf_training['target'] = pred_val\ndf_training = df_training.loc[:,:]\n\n\n\nbase_score = roc_auc_score(y_test, pred_test_proba)\nprint(base_score)\nprint(confusion_matrix(y_test, pred_test))\ntrain = X_train\ny = y_train\n\nfor i in range(10):\n    train = np.concatenate((X_train, df_training[title]), axis = 0)\n    y = np.concatenate((y_train, df_training['target']), axis = 0 )\n    \n    clf = QuadraticDiscriminantAnalysis(reg_param = 0.11)\n    clf.fit(train, y)\n    pred_test_proba = clf.predict_proba(X_test)[:,1]\n    \n    baseline = roc_auc_score(y_test, pred_test_proba)\n    \n    df_trial = deepcopy(df_training)\n    pred_trial = clf.predict(df_training[title])\n    clf = QuadraticDiscriminantAnalysis(reg_param = 0.11)\n    clf.fit(np.concatenate((X_train, df_trial[title]), axis = 0), np.concatenate((y_train, pred_trial), axis = 0 ))\n    \n    score = roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n    if score > baseline:\n        df_training['target'] = pred_trial\n    print(score)\n    \n# for i in range(200):\n#     print(i)\n#     df_val = pd.DataFrame(X_val, columns = title)\n#     df_val['target'] = pred_val\n    \n#     df_sample = df_val.sample(frac = 0.01)\n    \n#     X_sample = df_sample[title]\n#     y_sample = df_sample['target']\n    \n    \n#     train = np.concatenate((train, df_training[title], X_sample), axis = 0)\n#     y = np.concatenate((y, df_training['target'],y_sample), axis = 0 )\n    \n# #     train = np.concatenate((train, X_sample), axis = 0)\n# #     y = np.concatenate((y,y_sample), axis = 0 )\n    \n#     clf = QuadraticDiscriminantAnalysis(reg_param = 0.11)\n#     clf.fit(train, y)\n    \n#     pred_test_proba = clf.predict_proba(X_test)[:,1]\n    \n    \n#     score = roc_auc_score(y_test, pred_test_proba)\n    \n#     if score > base_score:\n#         base_score = score\n#         pred_val = clf.predict(X_val)\n#         df_training = pd.concat([df_training, df_sample])\n        \n# #         X_train = np.concatenate((X_train, X_sample), axis = 0)\n# #         y_train = np.concatenate((y_train, y_sample), axis = 0)\n    \n#     df_training = df_training.drop_duplicates(subset = title, keep = False)\n#     print(score)\n    \n","execution_count":77,"outputs":[{"output_type":"stream","text":"0.9629237288135594\n[[45  3]\n [ 3 56]]\n0.9721045197740114\n0.9721045197740114\n0.9721045197740114\n0.9721045197740114\n0.9721045197740114\n0.9721045197740114\n0.9721045197740114\n0.9721045197740114\n0.9721045197740114\n0.9721045197740114\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(base_score)","execution_count":78,"outputs":[{"output_type":"stream","text":"0.9629237288135594\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_training = df_training.drop_duplicates(subset = title, keep = False)\nX_t = df_training[title].values\ny_t = df_training['target']\nclf = QuadraticDiscriminantAnalysis(reg_param = 0.11)\nclf.fit(np.concatenate((X_t, X_test), axis = 0),np.concatenate((y_t, y_test), axis = 0))\n\nclf.fit(X_t, y_t)\npred = clf.predict_proba(X_train)[:,1]\nroc_auc_score(y_train, pred)","execution_count":79,"outputs":[{"output_type":"execute_result","execution_count":79,"data":{"text/plain":"0.9456607755209707"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_training.shape","execution_count":80,"outputs":[{"output_type":"execute_result","execution_count":80,"data":{"text/plain":"(253, 47)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nind = 0\ndf = df_train[df_train['wheezy-copper-turtle-magic']==ind]\ny = df['target'].values\n\nX_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state = 42)\nX_val = df_test[df_test['wheezy-copper-turtle-magic']==ind][cols]\nmappers = [\n    ## Data Augmentation\n#             PolynomialFeatures(degree=2),\n    ##Data reduction\n            VarianceThreshold(threshold=1.5),\n#              KernelPCA(n_components = 46 , kernel = 'linear', degree = 2)\n#             PCA(n_components=46, whiten = True),\n#             FastICA(n_components=46, random_state=0, max_iter = 500),\n    \n    ## Data Augmentation\n#             PolynomialFeatures(degree=2),\n    \n    ## Scaler\n#             StandardScaler(),\n#             Normalizer(norm=\"l2\"),\n#             Normalizer(norm=\"l1\"),\n#             RobustScaler(),\n#             MinMaxScaler(),\n                        ]\nX_train, X_test = transform(X_train, X_test, mappers)\nX_val  = VarianceThreshold(threshold=1.5).fit_transform(X_val)","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n# clf = LinearDiscriminantAnalysis()\nclf = QuadraticDiscriminantAnalysis(reg_param = 0.11)\n# clf = NuSVC(probability=True, kernel='poly', degree=2, gamma='auto', random_state=2, nu=0.7, coef0=0.08)\n\nclf.fit(X_train, y_train)  \n\n\npred = clf.predict_proba(X_test)[:,1]\npred1 = clf.predict(X_test)\n\n# pred2 = clf.predict(np.concatenate((X_test, X_val), axis = 0))\npred2 = clf.predict(X_val)\n\nprint(roc_auc_score(y_test, pred))\nprint(confusion_matrix(y_test, pred1))","execution_count":42,"outputs":[{"output_type":"stream","text":"0.9629237288135594\n[[45  3]\n [ 3 56]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title = []\nfor elt in range(X_train.shape[1]):\n    title.append('c'+str(elt))\ncurrent_max = roc_auc_score(y_test, pred)\n# df_m = pd.DataFrame(np.concatenate((X_test, X_val), axis = 0), columns = title)\ndf_m = pd.DataFrame(X_val, columns = title)\ndf_m['target'] = pred2\ndf_m = df_m.loc[-1:,:]\n\nprint(df_m.shape)\nfor i in range(200):\n#     df_ch = pd.DataFrame(np.concatenate((X_test, X_val), axis = 0), columns = title)\n    df_ch = pd.DataFrame(X_val, columns = title)\n    df_ch['target'] = pred2\n\n    df_ch1 = df_ch.sample(frac = 0.01)\n\n    X1 = df_ch1[title].values\n    y1 = df_ch1['target'].values\n    \n    clf = QuadraticDiscriminantAnalysis(reg_param = 0.11)\n#     clf = NuSVC(probability=True, kernel='poly', degree=2, gamma='auto', random_state=2, nu=0.7, coef0=0.08)\n\n    clf.fit(np.concatenate((X_train, X1), axis = 0), np.concatenate((y_train, y1), axis = 0))  \n\n\n    pred = clf.predict_proba(X_test)[:,1]\n    pred1 = clf.predict(X_test)\n\n#     pred2 = clf.predict(np.concatenate((X_test, X_val), axis = 0))\n    pred2 = clf.predict(X_val)\n    if roc_auc_score(y_test, pred) > current_max:\n        current_max = roc_auc_score(y_test, pred)\n        X_train = np.concatenate((X_train, X1), axis = 0)\n        y_train = np.concatenate((y_train, y1), axis = 0)\n        df_m = pd.concat([df_m, df_ch1])\n#     df_m = df_m.drop_duplicates()\n    print(roc_auc_score(y_test, pred))\n    \nprint(confusion_matrix(y_test, pred1))","execution_count":44,"outputs":[{"output_type":"stream","text":"(253, 47)\n0.974223163841808\n0.9745762711864407\n0.9749293785310735\n0.9752824858757063\n0.9749293785310735\n0.9766949152542374\n0.9766949152542374\n0.9777542372881357\n0.9781073446327685\n0.9777542372881356\n0.9777542372881357\n0.9781073446327685\n0.9784604519774012\n0.9781073446327685\n0.9774011299435029\n0.9781073446327684\n0.9770480225988701\n0.980225988700565\n0.9798728813559322\n0.978813559322034\n0.9795197740112995\n0.9798728813559322\n0.9805790960451978\n0.9805790960451978\n0.9805790960451978\n0.980225988700565\n0.9809322033898306\n0.9791666666666667\n0.9816384180790961\n0.9809322033898304\n0.9823446327683616\n0.9805790960451978\n0.9816384180790961\n0.9823446327683616\n0.9826977401129944\n0.9819915254237288\n0.9823446327683617\n0.9816384180790961\n0.9826977401129945\n0.9844632768361582\n0.9837570621468927\n0.9841101694915254\n0.9844632768361582\n0.9837570621468927\n0.9837570621468926\n0.9837570621468927\n0.9826977401129944\n0.9830508474576272\n0.9844632768361582\n0.983050847457627\n0.984816384180791\n0.9844632768361582\n0.9830508474576272\n0.984816384180791\n0.9844632768361582\n0.9841101694915254\n0.9841101694915255\n0.9830508474576272\n0.9837570621468927\n0.9830508474576272\n0.9844632768361582\n0.9837570621468927\n0.9826977401129943\n0.9841101694915254\n0.98340395480226\n0.984816384180791\n0.9844632768361582\n0.984816384180791\n0.9837570621468927\n0.9844632768361582\n0.9823446327683617\n0.9837570621468927\n0.9837570621468926\n0.98340395480226\n0.9837570621468926\n0.9834039548022598\n0.9830508474576272\n0.9837570621468927\n0.9851694915254238\n0.9851694915254238\n0.98340395480226\n0.9844632768361582\n0.9841101694915255\n0.98340395480226\n0.9826977401129944\n0.9819915254237289\n0.9844632768361582\n0.9830508474576272\n0.9837570621468927\n0.9841101694915254\n0.9837570621468926\n0.9844632768361582\n0.98340395480226\n0.9844632768361582\n0.9844632768361582\n0.9834039548022598\n0.9841101694915255\n0.984816384180791\n0.9844632768361582\n0.9841101694915254\n0.9851694915254238\n0.9841101694915254\n0.9837570621468927\n0.984816384180791\n0.9841101694915255\n0.9826977401129944\n0.984816384180791\n0.9841101694915255\n0.9830508474576272\n0.9844632768361582\n0.9844632768361582\n0.9837570621468927\n0.98340395480226\n0.9841101694915254\n0.9851694915254238\n0.9837570621468926\n0.9841101694915254\n0.9826977401129944\n0.9844632768361582\n0.984816384180791\n0.984816384180791\n0.9837570621468927\n0.9819915254237288\n0.9841101694915254\n0.9837570621468927\n0.9841101694915255\n0.9837570621468927\n0.9841101694915254\n0.9841101694915255\n0.9851694915254238\n0.9837570621468926\n0.984816384180791\n0.9851694915254238\n0.9834039548022598\n0.9841101694915254\n0.9844632768361582\n0.9837570621468927\n0.9830508474576272\n0.9830508474576272\n0.9830508474576272\n0.9851694915254238\n0.9841101694915254\n0.9841101694915255\n0.984816384180791\n0.98340395480226\n0.9837570621468926\n0.9844632768361582\n0.9837570621468927\n0.9819915254237288\n0.9844632768361582\n0.984816384180791\n0.9844632768361582\n0.984816384180791\n0.9841101694915254\n0.9837570621468927\n0.9844632768361582\n0.9826977401129944\n0.9830508474576273\n0.9844632768361582\n0.9841101694915254\n0.9830508474576272\n0.9841101694915254\n0.9837570621468927\n0.984816384180791\n0.984816384180791\n0.9841101694915254\n0.9841101694915254\n0.9851694915254238\n0.9851694915254238\n0.98340395480226\n0.9830508474576272\n0.9851694915254238\n0.9830508474576272\n0.983050847457627\n0.9844632768361582\n0.9841101694915254\n0.9851694915254238\n0.984816384180791\n0.984816384180791\n0.9837570621468927\n0.984816384180791\n0.984816384180791\n0.9851694915254238\n0.98340395480226\n0.9851694915254238\n0.9834039548022598\n0.9851694915254238\n0.9844632768361582\n0.9841101694915255\n0.9851694915254238\n0.9841101694915255\n0.9834039548022598\n0.9851694915254238\n0.9844632768361582\n0.9841101694915254\n0.9837570621468926\n0.9841101694915255\n0.9844632768361582\n0.98340395480226\n0.9844632768361582\n[[45  3]\n [ 2 57]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_t = df_m[title].values\ny_t = df_m['target']\nclf = QuadraticDiscriminantAnalysis(reg_param = 0.11)\nclf.fit(X_t, y_t)\npred = clf.predict_proba(X_train)[:,1]\nroc_auc_score(y_train, pred)","execution_count":47,"outputs":[{"output_type":"execute_result","execution_count":47,"data":{"text/plain":"0.935889826782731"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_m = df_m.drop_duplicates(subset = title, keep = False)#.shape\ndf_m.shape","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"(255, 47)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = np.zeros(df_test.shape[0])\nfor i in range(512):\n    print(i)\n    train =  df_train[df_train['wheezy-copper-turtle-magic']==i]\n    test =  df_test[df_test['wheezy-copper-turtle-magic']==i]\n    y_train = train['target'].values\n    \n    train = train[cols]\n    test = test[cols]\n    \n    \n    n_features = VarianceThreshold(threshold=1.5).fit_transform(train[cols]).shape[1]\n    mapper = PCA(n_components=n_features, whiten = True)\n    mapper.fit(np.concatenate((train, test), axis=0))\n    train = mapper.fit_transform(train)\n    test = mapper.fit_transform(test)\n    \n    clf = QuadraticDiscriminantAnalysis(reg_param = 0.11)\n    \n    clf.fit(train, y_train)\n    \n    pred1 = clf.predict_proba(test)[:,1]\n    for count in range(2):\n        X1 = test[pred1>0.9999999999999999]\n        X0 = test[pred1<0.0000000000000001]\n        y1 = np.zeros(X1.shape[0])+1\n        y0 = np.zeros(X0.shape[0])\n        train = np.concatenate((train, X1, X0))\n        y_train = np.concatenate((y_train, y1, y0))\n        clf.fit(train, y_train)\n        pred1 = clf.predict_proba(test)[:,1]\n    \n    \n    pred[df_test['wheezy-copper-turtle-magic']==i] = clf.predict_proba(test)[:,1]\n\n\n    \n    \n    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['target'] = pred\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}