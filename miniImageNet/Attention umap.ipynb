{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.utils as np_utils\n",
    "import gc\n",
    "import _pickle as pickle\n",
    "import resnet2\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "def save(file,name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'wb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'wb')\n",
    "    pickle.dump(file, outfile)\n",
    "    outfile.close\n",
    "    \n",
    "def load(name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'rb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'rb')\n",
    "    file = pickle.load(outfile)\n",
    "    outfile.close\n",
    "    return file\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "          tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "          tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "      ])\n",
    "\n",
    "class VisionAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model = 512,batch_size = 128, n_neighbors = 15, d_proj = None, dff = 512, rate = 0.2, training = True, temperature = 3):\n",
    "        super(VisionAttention, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.top_k = n_neighbors\n",
    "        self.d_proj = d_proj\n",
    "        self.batch_size = batch_size\n",
    "        self.temperature = temperature\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        if d_proj is not None:\n",
    "            self.projection = tf.keras.layers.Dense(d_proj)\n",
    "        \n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    \n",
    "    def call(self, v, training = True):\n",
    "        ## v of shape batch_size * d_model\n",
    "        # normalization\n",
    "        normalized_v = tf.linalg.normalize(v, ord='euclidean', axis=1, name=None)[0]\n",
    "        cosine_matrix = tf.matmul(normalized_v, normalized_v, transpose_b=True)\n",
    "#         cosine_matrix = 0.5 - tf.math.divide(cosine_matrix, 2)\n",
    "        \n",
    "        ## Computing local umap distances\n",
    "        top_k_distances, ind_k = tf.math.top_k(cosine_matrix, k=self.top_k+1, sorted=True)\n",
    "#         top_k_distances = top_k_distances[:, 1:]\n",
    "        \n",
    "        cosine_matrix = 0.5 - tf.math.divide(cosine_matrix, 2)\n",
    "        top_k_distances = 0.5 - tf.math.divide(top_k_distances, 2)\n",
    "        \n",
    "        mean = tf.math.reduce_mean(top_k_distances, axis=-1, keepdims=False, name=None)\n",
    "        std = tf.math.reduce_std(top_k_distances, axis=-1, keepdims=False, name=None)*self.temperature\n",
    "\n",
    "        umap_matrix = tf.math.exp(-(cosine_matrix - mean)/std)\n",
    "        umap_matrixT = tf.transpose(umap_matrix)\n",
    "        mult_matrix = tf.math.multiply(umap_matrix, umap_matrixT)\n",
    "        \n",
    "#         diagonal = np.zeros(mult_matrix.shape[0])\n",
    "        \n",
    "        ## Computing umap similarity matrix\n",
    "        umap_sim_matrix = umap_matrix + umap_matrixT - mult_matrix\n",
    "        \n",
    "#         umap_sim_matrix = tf.linalg.set_diag(umap_sim_matrix, diagonal)\n",
    "        # softmax attention\n",
    "        \n",
    "        attention_weights = tf.nn.softmax( - umap_sim_matrix, axis=-1)\n",
    "        attn_output = tf.matmul(attention_weights, v, transpose_b=False)\n",
    "        \n",
    "        ## feed forward\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(v + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(v + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        if self.d_proj == None:\n",
    "            return out2\n",
    "        else:\n",
    "            \n",
    "            projected = self.projection(out2)\n",
    "            return projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OT = pickle.load(open('miniImageNet_category_split_train_phase_train.pickle', 'rb'), encoding='latin1')\n",
    "# OT1 = pickle.load(open('miniImageNet_category_split_train_phase_val.pickle', 'rb'), encoding='latin1')\n",
    "# OT2 = pickle.load(open('miniImageNet_category_split_train_phase_test.pickle', 'rb'), encoding='latin1')\n",
    "\n",
    "for i in range(5):\n",
    "    plt.figure(i)\n",
    "    fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1,5)\n",
    "    for j in range(5):\n",
    "        fig.axes[j].get_xaxis().set_visible(False)\n",
    "        fig.axes[j].get_yaxis().set_visible(False)\n",
    "    ax1.imshow(OT['data'][600*i+1])\n",
    "    ax2.imshow(OT['data'][600*i+2])    \n",
    "    ax3.imshow(OT['data'][600*i+3])\n",
    "    ax4.imshow(OT['data'][600*i+4])\n",
    "    ax5.imshow(OT['data'][600*i+5])\n",
    "    \n",
    "Y_meta = np.array(OT['labels'])\n",
    "X_meta = OT['data']\n",
    "\n",
    "# Y_meta = np.concatenate([Y_meta, np.array(OT1['labels'])], axis = 0)\n",
    "# Y_meta = np.concatenate([Y_meta, np.array(OT2['labels'])], axis = 0)\n",
    "\n",
    "# X_meta = np.concatenate([X_meta, OT1['data']], axis = 0)\n",
    "# X_meta = np.concatenate([X_meta, OT2['data']], axis = 0)\n",
    "\n",
    "X_meta = (X_meta / 255)-0.5\n",
    "\n",
    "y_meta = np_utils.to_categorical(Y_meta)\n",
    "del OT\n",
    "# del OT1\n",
    "# del OT2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparing layers\n",
    "\n",
    "build = resnet2.ResnetBuilder()\n",
    "residual = build.build_resnet_18((84,84,3),64)\n",
    "\n",
    "uproj = VisionAttention(d_model = residual.output.shape[-1],batch_size = 128, n_neighbors = 15, d_proj = None, dff = 512, temperature = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape = (84,84,3), batch_size = batch_size)\n",
    "resnet_features = residual(inputs)\n",
    "\n",
    "projected = uproj(resnet_features)\n",
    "\n",
    "output = tf.keras.layers.Dense(64, activation = 'softmax')(projected)\n",
    "\n",
    "model = tf.keras.Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
    "                         width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
    "                         horizontal_flip=True, fill_mode=\"nearest\")\n",
    "aug_val = ImageDataGenerator(rotation_range=0, zoom_range=0,\n",
    "                         width_shift_range=0, height_shift_range=0, shear_range=0,\n",
    "                         horizontal_flip=True, fill_mode=\"nearest\")\n",
    "optimizer=SGD(lr=0.1)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer=optimizer,#keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_meta, y_meta, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_meta\n",
    "del y_meta\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[0] / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose = 1,min_delta=0.005,\n",
    "                              patience=3, min_lr=3e-7)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=6, verbose=1, mode='auto',baseline=None, restore_best_weights=True)\n",
    "\n",
    "\n",
    "batch_size = batch_size\n",
    "epochs = 40\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(aug.flow(X_train, y_train, batch_size=batch_size),\n",
    "        validation_data=aug_val.flow(X_test, y_test,batch_size=batch_size), steps_per_epoch=len(X_train) // batch_size,\n",
    "        epochs=epochs, callbacks=[early_stop, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OT1 = pickle.load(open('miniImageNet_category_split_test.pickle', 'rb'), encoding='latin1')\n",
    "OT2 = pickle.load(open('miniImageNet_category_split_val.pickle', 'rb'), encoding='latin1')\n",
    "\n",
    "from copy import deepcopy\n",
    "Y_val = deepcopy(OT2['labels'])\n",
    "X_val = deepcopy(OT2['data'])\n",
    "\n",
    "## Concatenating val and test datas in order to get more classes for experiment\n",
    "for i in OT1['labels']:\n",
    "    Y_val.append(i)\n",
    "X_val = np.concatenate([X_val, OT1['data']], axis = 0)\n",
    "\n",
    "## Restructuring the images into an array of size 64*600*84*84*3 to ease the acces to a given class\n",
    "tab = []\n",
    "for i in range(36):\n",
    "    tab.append([])\n",
    "\n",
    "for i in range(len(Y_val)):\n",
    "    tab[Y_val[i]-64].append(X_val[i])\n",
    "\n",
    "X = np.array(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "k = 5\n",
    "import random\n",
    "\n",
    "## A function in order to generate a random array of n distincts values between m and M\n",
    "def choose_n_classes(n, m, M):\n",
    "    tab = []\n",
    "    while len(tab)<n:\n",
    "        r = random.randint(m,M)\n",
    "        if not(r in tab):\n",
    "            tab.append(r)\n",
    "    tab.sort()\n",
    "    tab = np.array(tab)\n",
    "    \n",
    "    dico = {}\n",
    "    for i in range(n):\n",
    "        dico[tab[i]] = i\n",
    "    \n",
    "    return tab, dico\n",
    "\n",
    "\n",
    "## A function to generate data ready for an experiment, tab and dico are here in order to repeat the experiment \n",
    "## on the same 5 classes, but with a different number of drawn sample in the class\n",
    "def build_dataset(X, n,k,batch_size = 128, value = True, tab = True, dico = True):\n",
    "    if value == True:\n",
    "        tab, dico = choose_n_classes(n, 64,99)\n",
    "    \n",
    "    x_train = []\n",
    "    x_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    \n",
    "    print(dico)\n",
    "    \n",
    "    for elt in tab:\n",
    "        ind, dico1 = choose_n_classes(k, 0, 600)\n",
    "        ind1, dico2 = choose_n_classes(100, 0, 600)\n",
    "        for i in range(600):\n",
    "            if i in ind:\n",
    "                x_train.append(X[elt-64,i])\n",
    "                y_train.append(dico[elt])\n",
    "#             elif i in ind1:\n",
    "#                 x_test.append(X[elt-64,i])\n",
    "#                 y_test.append(dico[elt])\n",
    "            else:\n",
    "                x_test.append(X[elt-64,i])\n",
    "                y_test.append(dico[elt])\n",
    "                \n",
    "    x_train = np.array(x_train)\n",
    "    x_test = np.array(x_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    \n",
    "    if batch_size is not None:          \n",
    "        shuffle_id = np.random.choice(list(range(len(x_test))), size = batch_size - k*n)\n",
    "        x_test = x_test[shuffle_id]\n",
    "        y_test = y_test[shuffle_id]\n",
    "                                      \n",
    "                                      \n",
    "    return np.array(x_train), np.array(x_test), np.array(y_train), np.array(y_test), tab, dico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "build = resnet2.ResnetBuilder()\n",
    "residual = build.build_resnet_18((84,84,3),64)\n",
    "\n",
    "uproj = VisionAttention(d_model = residual.output.shape[-1], n_neighbors = 15, d_proj = None, temperature = 3)\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape = (84,84,3), batch_size = batch_size)\n",
    "resnet_features = residual(inputs)\n",
    "\n",
    "projected = uproj(resnet_features)\n",
    "\n",
    "output = tf.keras.layers.Dense(64, activation = 'softmax')(projected)\n",
    "\n",
    "model_transfert = tf.keras.Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transfert.load_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(128, 84, 84, 3)]        0         \n",
      "_________________________________________________________________\n",
      "model (Model)                multiple                  11179648  \n",
      "_________________________________________________________________\n",
      "vision_attention (VisionAtte (128, 512)                527360    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (128, 64)                 32832     \n",
      "=================================================================\n",
      "Total params: 11,739,840\n",
      "Trainable params: 11,732,032\n",
      "Non-trainable params: 7,808\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_transfert.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = model_transfert.input\n",
    "outputs = model_transfert.get_layer('vision_attention').output\n",
    "model = tf.keras.Model(inputs=inputs,   outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(128, 84, 84, 3)]        0         \n",
      "_________________________________________________________________\n",
      "model (Model)                multiple                  11179648  \n",
      "_________________________________________________________________\n",
      "vision_attention (VisionAtte (128, 512)                527360    \n",
      "=================================================================\n",
      "Total params: 11,707,008\n",
      "Trainable params: 11,699,200\n",
      "Non-trainable params: 7,808\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(n, k):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, tab, dico = build_dataset(X, n, k, batch_size = batch_size)\n",
    "    print(X_train.shape)\n",
    "    Xall = np.concatenate([X_train, X_test])\n",
    "    print(Xall.shape)\n",
    "    with tf.device('/GPU:0'):\n",
    "        Xemb = model.predict(Xall)\n",
    "    \n",
    "    print(Xemb.shape)\n",
    "    \n",
    "    Xt = Xemb[:len(X_train)]\n",
    "    Xv = Xemb[len(X_train):]\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0, solver='saga', multi_class='multinomial', max_iter = 1000, penalty='l2')\n",
    "    clf.fit(Xt,y_train)\n",
    "    \n",
    "    y_pred = clf.predict(Xv)\n",
    "    \n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    return accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{73: 0, 78: 1, 84: 2, 85: 3, 88: 4}\n",
      "(25, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.5048543689320388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5048543689320388"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5\n",
    "k = 5\n",
    "\n",
    "experiment(n,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{64: 0, 72: 1, 75: 2, 80: 3, 91: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.34959349593495936\n",
      "{80: 0, 82: 1, 89: 2, 93: 3, 97: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.21951219512195122\n",
      "{69: 0, 70: 1, 71: 2, 80: 3, 96: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3008130081300813\n",
      "{72: 0, 88: 1, 95: 2, 96: 3, 97: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.2682926829268293\n",
      "{74: 0, 82: 1, 83: 2, 94: 3, 99: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.2601626016260163\n",
      "{69: 0, 81: 1, 86: 2, 89: 3, 95: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.16260162601626016\n",
      "{65: 0, 69: 1, 73: 2, 82: 3, 83: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.34959349593495936\n",
      "{70: 0, 71: 1, 72: 2, 82: 3, 84: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.2764227642276423\n",
      "{68: 0, 74: 1, 79: 2, 87: 3, 93: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3008130081300813\n",
      "{65: 0, 67: 1, 69: 2, 70: 3, 77: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3008130081300813\n",
      "{75: 0, 78: 1, 82: 2, 84: 3, 91: 4}\n",
      "(4, 84, 84, 3)\n",
      "(127, 84, 84, 3)\n",
      "(127, 512)\n",
      "0.15447154471544716\n",
      "{65: 0, 71: 1, 77: 2, 82: 3, 84: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.34959349593495936\n",
      "{78: 0, 79: 1, 85: 2, 93: 3, 96: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3333333333333333\n",
      "{67: 0, 73: 1, 74: 2, 85: 3, 90: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.34146341463414637\n",
      "{68: 0, 71: 1, 76: 2, 84: 3, 98: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3983739837398374\n",
      "{66: 0, 71: 1, 78: 2, 79: 3, 81: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.4146341463414634\n",
      "{64: 0, 75: 1, 84: 2, 89: 3, 93: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3333333333333333\n",
      "{72: 0, 74: 1, 90: 2, 94: 3, 98: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.5040650406504065\n",
      "{67: 0, 69: 1, 76: 2, 92: 3, 96: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3902439024390244\n",
      "{76: 0, 82: 1, 84: 2, 97: 3, 98: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3008130081300813\n",
      "{65: 0, 67: 1, 71: 2, 74: 3, 90: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.35772357723577236\n",
      "{65: 0, 66: 1, 67: 2, 76: 3, 82: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.2032520325203252\n",
      "{65: 0, 71: 1, 77: 2, 91: 3, 98: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.4796747967479675\n",
      "{64: 0, 67: 1, 72: 2, 82: 3, 84: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3252032520325203\n",
      "{64: 0, 78: 1, 89: 2, 90: 3, 95: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.17073170731707318\n",
      "{68: 0, 71: 1, 74: 2, 90: 3, 99: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.44715447154471544\n",
      "{64: 0, 65: 1, 71: 2, 84: 3, 93: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.4146341463414634\n",
      "{65: 0, 77: 1, 81: 2, 98: 3, 99: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.2926829268292683\n",
      "{65: 0, 68: 1, 71: 2, 89: 3, 90: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.25203252032520324\n",
      "{72: 0, 88: 1, 92: 2, 94: 3, 95: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.35772357723577236\n",
      "{68: 0, 72: 1, 77: 2, 78: 3, 89: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.37398373983739835\n",
      "{77: 0, 78: 1, 90: 2, 91: 3, 97: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.25203252032520324\n",
      "{65: 0, 73: 1, 79: 2, 90: 3, 94: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.35772357723577236\n",
      "{66: 0, 71: 1, 83: 2, 84: 3, 95: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3089430894308943\n",
      "{68: 0, 76: 1, 78: 2, 82: 3, 96: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.2032520325203252\n",
      "{70: 0, 75: 1, 84: 2, 92: 3, 95: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.2764227642276423\n",
      "{66: 0, 76: 1, 84: 2, 92: 3, 97: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3902439024390244\n",
      "{82: 0, 84: 1, 85: 2, 86: 3, 92: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.2032520325203252\n",
      "{67: 0, 76: 1, 86: 2, 88: 3, 99: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3333333333333333\n",
      "{66: 0, 72: 1, 84: 2, 89: 3, 99: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.2601626016260163\n",
      "{70: 0, 72: 1, 78: 2, 83: 3, 89: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.35772357723577236\n",
      "{74: 0, 78: 1, 83: 2, 84: 3, 90: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3008130081300813\n",
      "{76: 0, 79: 1, 84: 2, 86: 3, 96: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.2926829268292683\n",
      "{67: 0, 75: 1, 80: 2, 83: 3, 84: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3333333333333333\n",
      "{80: 0, 88: 1, 93: 2, 95: 3, 98: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3902439024390244\n",
      "{74: 0, 87: 1, 88: 2, 93: 3, 97: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.2926829268292683\n",
      "{65: 0, 74: 1, 80: 2, 96: 3, 99: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.43089430894308944\n",
      "{65: 0, 68: 1, 69: 2, 86: 3, 92: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3008130081300813\n",
      "{64: 0, 65: 1, 70: 2, 78: 3, 88: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.34959349593495936\n",
      "{71: 0, 76: 1, 84: 2, 86: 3, 93: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.37398373983739835\n",
      "{68: 0, 74: 1, 79: 2, 84: 3, 92: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.4146341463414634\n",
      "{64: 0, 67: 1, 75: 2, 83: 3, 87: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3089430894308943\n",
      "{68: 0, 70: 1, 86: 2, 93: 3, 95: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.2682926829268293\n",
      "{65: 0, 67: 1, 70: 2, 89: 3, 92: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3821138211382114\n",
      "{65: 0, 70: 1, 71: 2, 80: 3, 83: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.2601626016260163\n",
      "{65: 0, 72: 1, 81: 2, 93: 3, 95: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3902439024390244\n",
      "{78: 0, 81: 1, 83: 2, 85: 3, 94: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.43089430894308944\n",
      "{77: 0, 83: 1, 91: 2, 97: 3, 98: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.44715447154471544\n",
      "{79: 0, 84: 1, 85: 2, 91: 3, 94: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.45528455284552843\n",
      "{68: 0, 70: 1, 74: 2, 78: 3, 82: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.2601626016260163\n",
      "{66: 0, 78: 1, 79: 2, 82: 3, 96: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.2601626016260163\n",
      "{67: 0, 73: 1, 89: 2, 92: 3, 97: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.4065040650406504\n",
      "{68: 0, 77: 1, 80: 2, 91: 3, 92: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.34959349593495936\n",
      "{65: 0, 87: 1, 88: 2, 92: 3, 99: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3902439024390244\n",
      "{74: 0, 84: 1, 86: 2, 93: 3, 99: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3333333333333333\n",
      "{67: 0, 74: 1, 75: 2, 87: 3, 90: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.34146341463414637\n",
      "{69: 0, 77: 1, 79: 2, 83: 3, 94: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.2601626016260163\n",
      "{68: 0, 82: 1, 86: 2, 89: 3, 99: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.2926829268292683\n",
      "{78: 0, 83: 1, 85: 2, 92: 3, 93: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.34959349593495936\n",
      "{65: 0, 80: 1, 83: 2, 84: 3, 97: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.44715447154471544\n",
      "{70: 0, 78: 1, 86: 2, 89: 3, 95: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.2845528455284553\n",
      "{64: 0, 66: 1, 80: 2, 89: 3, 98: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.4634146341463415\n",
      "{64: 0, 67: 1, 70: 2, 71: 3, 90: 4}\n",
      "(4, 84, 84, 3)\n",
      "(127, 84, 84, 3)\n",
      "(127, 512)\n",
      "0.3089430894308943\n",
      "{74: 0, 87: 1, 94: 2, 96: 3, 99: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3333333333333333\n",
      "{71: 0, 81: 1, 94: 2, 95: 3, 96: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3170731707317073\n",
      "{68: 0, 69: 1, 80: 2, 84: 3, 89: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3333333333333333\n",
      "{71: 0, 72: 1, 77: 2, 78: 3, 84: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3089430894308943\n",
      "{87: 0, 91: 1, 96: 2, 98: 3, 99: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.5853658536585366\n",
      "{67: 0, 70: 1, 88: 2, 95: 3, 99: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3008130081300813\n",
      "{67: 0, 73: 1, 80: 2, 84: 3, 96: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n",
      "(128, 512)\n",
      "0.3252032520325203\n",
      "{77: 0, 85: 1, 86: 2, 91: 3, 99: 4}\n",
      "(5, 84, 84, 3)\n",
      "(128, 84, 84, 3)\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "k = 1\n",
    "\n",
    "res = []\n",
    "\n",
    "for i in range(100):\n",
    "    res.append(experiment(n,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
