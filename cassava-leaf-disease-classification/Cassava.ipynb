{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import gc\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import _pickle as pickle\n",
    "import tensorflow as tf\n",
    "def save(file,name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'wb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'wb')\n",
    "    pickle.dump(file, outfile, protocol=4)\n",
    "    outfile.close\n",
    "    \n",
    "def load(name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'rb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'rb')\n",
    "    file = pickle.load(outfile)\n",
    "    outfile.close\n",
    "    return file\n",
    "\n",
    "import cv2\n",
    "from multiprocess import Pool\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_csv('train.csv')\n",
    "df = df.sample(n = df.shape[0])\n",
    "# df = pd.concat([df[df['label'] == i].sample(n = min(df[df['label'] == i].shape[0], 2500), replace = False) for i in range(5)])\n",
    "# df = df.sample(n = df.shape[0])\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['image_id'].values, df['label'].values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc(path2, im_size = 299):\n",
    "    import imageio\n",
    "    import cv2\n",
    "    path, save_path = path2\n",
    "    img = imageio.imread('./train_images/'+path)\n",
    "    img = img.astype('float32')\n",
    "    print(img.shape)\n",
    "    img = cv2.resize(img, (800, 600))\n",
    "    img = img.astype('uint8')\n",
    "    imageio.imwrite(save_path + '/' + path, img)\n",
    "    \n",
    "train_inputs = list(zip(X_train, np.array(['./raw/train/'+str(elt) for elt in y_train])))\n",
    "test_inputs = list(zip(X_test, np.array(['./raw/test/'+str(elt) for elt in y_test])))\n",
    "\n",
    "p = Pool(10)\n",
    "a = p.map(proc, test_inputs)\n",
    "a = p.map(proc, train_inputs)\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resnet\n",
    "build = resnet.ResnetBuilder()\n",
    "model = build.build_resnet_18((299,299,3),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape = (800,600,3))\n",
    "\n",
    "x = hub.KerasLayer(\"https://tfhub.dev/tensorflow/efficientnet/b7/classification/1\", trainable = True)(inputs)\n",
    "\n",
    "# x = hub.KerasLayer(\"https://tfhub.dev/google/inaturalist/inception_v3/feature_vector/4\",\n",
    "#                    trainable=True)(inputs)\n",
    "\n",
    "x = tf.keras.layers.Dense(5, activation = 'softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./checkpoint/weights.h5')\n",
    "# model.load_weights('./checkpoint/efficient/weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "train_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                    rescale=1./255, rotation_range=20, zoom_range=0.15,\n",
    "                         width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
    "                         horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "test_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                    rescale=1./255, shear_range=0, zoom_range=0,\n",
    "                    horizontal_flip=False, rotation_range=0, width_shift_range=0,\n",
    "                     height_shift_range=0)\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.DirectoryIterator(\n",
    "                    './raw/train', train_data_generator, target_size=(800, 600),\n",
    "                    batch_size=batch_size)\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.DirectoryIterator(\n",
    "                    './raw/test',test_data_generator, target_size=(800, 600),\n",
    "                    batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "model.compile(loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "             optimizer = SGD(0.01),\n",
    "#              optimizer = RMSprop(0.01),\n",
    "#              optimizer = Adam(0.0001),\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=8, verbose=1, \n",
    "                                                mode='min', restore_best_weights=True)\n",
    "\n",
    "reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, \n",
    "                           mode='min', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "callbacks =[early, reduce]\n",
    "\n",
    "epochs = 100\n",
    "steps_per_epoch = int(8529/batch_size)\n",
    "validation_steps = int(2133/batch_size)\n",
    "\n",
    "# tg = train_gen()\n",
    "\n",
    "history = model.fit(train_datagen, validation_data = test_datagen, epochs = epochs, \n",
    "                   steps_per_epoch = steps_per_epoch, validation_steps = validation_steps,\n",
    "                   callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  model.save_weights('./checkpoint/inception/weights')\n",
    "model.save_weights('./checkpoint/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "Y = []\n",
    "pred = []\n",
    "for x, y in test_datagen:\n",
    "    if c >= 100:\n",
    "        break\n",
    "    else:\n",
    "        p = model.predict(x)\n",
    "        Y.append(y)\n",
    "        pred.append(p)\n",
    "        \n",
    "    print(c)\n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.concatenate(Y)\n",
    "pred = np.concatenate(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = np.argmax(Y, axis = -1)\n",
    "pred1 = np.argmax(pred, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pred1 == Y1).sum()/len(Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
