{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import random\n",
    "import gc\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as pickle\n",
    "\n",
    "def save(file,name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'wb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'wb')\n",
    "    pickle.dump(file, outfile)\n",
    "    outfile.close\n",
    "    \n",
    "def load(name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'rb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'rb')\n",
    "    file = pickle.load(outfile)\n",
    "    outfile.close\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('sales_train_validation.csv')\n",
    "calendar = pd.read_csv('calendar.csv')\n",
    "prices = pd.read_csv('sell_prices.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "prices['id'] = prices['item_id'] + '_' + prices['store_id'] +'_'+ 'validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a dico to export ids into state, dept, store, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_id = {}\n",
    "\n",
    "sales.index = sales['id']\n",
    "\n",
    "for elt in tqdm(sales['id'].unique()):\n",
    "    a = sales.loc[elt]\n",
    "    \n",
    "    item_id = a['item_id']\n",
    "    dept_id = a['dept_id']\n",
    "    store_id = a['store_id']\n",
    "    cat_id = a['cat_id']\n",
    "    state_id = a['state_id']\n",
    "    \n",
    "#     dico_id[elt] = (item_id, dept_id, store_id, cat_id, state_id)\n",
    "    dico_id[elt] = (cat_id, dept_id, item_id, state_id, store_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(dico_id, 'dico_id', 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building data2 Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar.index = calendar['d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = deepcopy(calendar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2[['wm_yr_wk', 'd', 'wday', 'month', 'year', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorise(df, col):\n",
    "    unique = df[col].unique()\n",
    "    \n",
    "    dico = {}\n",
    "    for i, elt in enumerate(unique):\n",
    "        dico[elt] = i\n",
    "    \n",
    "    df = df.replace({col: dico})\n",
    "    return df, dico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2, dico_wday = categorise(data2, 'wday')\n",
    "data2, dico_month = categorise(data2, 'month')\n",
    "data2, dico_year = categorise(data2, 'year')\n",
    "data2, dico_event_name_1 = categorise(data2, 'event_name_1')\n",
    "data2, dico_event_type_1 = categorise(data2, 'event_type_1')\n",
    "data2, dico_event_name_2 = categorise(data2, 'event_name_2')\n",
    "data2, dico_event_type_2 = categorise(data2, 'event_type_2')\n",
    "\n",
    "dicos = {'dico_wday':dico_wday, 'dico_month':dico_month, 'dico_year':dico_year,\n",
    "         'dico_event_name_1':dico_event_name_1, 'dico_event_type_1':dico_event_type_1, \n",
    "         'dico_event_name_2':dico_event_name_2, 'dico_event_type_2':dico_event_type_2 }\n",
    "\n",
    "save(dicos, 'dico_events', 'data')\n",
    "\n",
    "save(data2, 'data2', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building data3 Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding day information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_ref = load('data2', 'data')\n",
    "date_ref.index = date_ref['wm_yr_wk']\n",
    "date_ref = date_ref[['d']]\n",
    "prices.index = prices['wm_yr_wk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = prices.join(date_ref, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data3 = sales[['id', 'store_id', 'state_id', 'item_id']]\n",
    "data3.index = data3['id'] \n",
    "\n",
    "# data3['ISs'] = data3['item_id'] + '_' + data3['store_id']\n",
    "data3['IS'] = data3['item_id'] + '_' + data3['state_id']\n",
    "data3['I'] = data3['item_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elt in tqdm(prices['d'].unique()):\n",
    "    temp = prices[prices['d'] == elt]\n",
    "    temp.index = temp['id']\n",
    "    temp = temp[['sell_price']]\n",
    "    temp.columns = [elt]\n",
    "    data3 = data3.join(temp, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_price = data3.groupby('IS').mean()\n",
    "state_price = state_price.reset_index()\n",
    "state_price['IS'] = state_price['IS'].apply(lambda x : x+'_validation')\n",
    "state_price.columns = ['id'] + [elt for elt in state_price.columns[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ex state id : 'FOODS_1_001_CA_validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_price = data3.groupby('I').mean()\n",
    "global_price = global_price.reset_index()\n",
    "global_price['I'] = global_price['I'].apply(lambda x : x+'_validation')\n",
    "global_price.columns = ['id'] + [elt for elt in global_price.columns[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ex global id : 'FOODS_1_005_validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data3.drop(columns = ['store_id', 'state_id', 'item_id', 'IS', 'I'])\n",
    "data3 = pd.concat([data3, state_price, global_price])\n",
    "data3.index = data3['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(data3, 'data3', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = load('data3', 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building data5 quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5 = deepcopy(sales)\n",
    "data5['IS'] = data5['item_id'] + '_' + data5['state_id']\n",
    "data5['I'] = data5['item_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_q = data5.groupby('IS').sum()\n",
    "state_q = state_q.reset_index()\n",
    "state_q['IS'] = state_q['IS'].apply(lambda x : x+'_validation')\n",
    "state_q.columns = ['id'] + [elt for elt in state_q.columns[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ex state q : 'FOODS_1_001_CA_validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_q = data5.groupby('I').sum()\n",
    "global_q = global_q.reset_index()\n",
    "global_q['I'] = global_q['I'].apply(lambda x : x+'_validation')\n",
    "global_q.columns = ['id'] + [elt for elt in global_q.columns[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ex global q : 'FOODS_1_003_validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5 = data5.drop(columns = ['item_id','dept_id', 'cat_id', 'store_id', 'state_id', 'IS', 'I'])\n",
    "data5 = pd.concat([data5, state_q, global_q])\n",
    "data5.index = data5['id']\n",
    "save(data5, 'data5', 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building data1 sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = load('data3', 'data')\n",
    "data5 = load('data5', 'data')\n",
    "dico_id = load('dico_id', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data3.loc[list(dico_id.keys())]\n",
    "data5 = data5.loc[list(dico_id.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data3.fillna(-1)\n",
    "data1 = deepcopy(data5)\n",
    "cols = data5.columns[1:]\n",
    "\n",
    "d3 = data3[cols].values\n",
    "d1 = data1[cols].values\n",
    "\n",
    "d1 = (d1*d3)\n",
    "\n",
    "for i, elt in tqdm(enumerate(cols), total = len(cols)):\n",
    "    data1[elt] = d1[:,i]\n",
    "    \n",
    "save(data1, 'data1', 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building data 4 granular sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = load('data1', 'data')\n",
    "dico_id = load('dico_id', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['cat_id'] = data1['id'].apply(lambda x : dico_id[x][0])\n",
    "data1['dept_id'] = data1['id'].apply(lambda x : dico_id[x][1])\n",
    "data1['item_id'] = data1['id'].apply(lambda x : dico_id[x][2])\n",
    "data1['state_id'] = data1['id'].apply(lambda x : dico_id[x][3])\n",
    "data1['store_id'] = data1['id'].apply(lambda x : dico_id[x][4])\n",
    "\n",
    "data1['IS'] = data1['item_id'] + '_' + data1['state_id']\n",
    "data1['I'] = data1['item_id']\n",
    "\n",
    "data1['DSs'] = data1['dept_id'] + '_' + data1['store_id']\n",
    "data1['DS'] = data1['dept_id'] + '_' + data1['state_id']\n",
    "data1['D'] = data1['dept_id']\n",
    "\n",
    "data1['CSs'] = data1['cat_id'] + '_' + data1['store_id']\n",
    "data1['CS'] = data1['cat_id'] + '_' + data1['state_id']\n",
    "data1['C'] = data1['cat_id']\n",
    "\n",
    "data1['S'] = data1['state_id']\n",
    "data1['s'] = data1['store_id']\n",
    "data1['Global'] = 'Global'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(col):\n",
    "    c = data1.groupby(col).sum()\n",
    "    c = c.reset_index()\n",
    "    c[col] = c[col].apply(lambda x : x+'_validation')\n",
    "    c.columns = ['id'] + [elt for elt in c.columns[1:]]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = build('CS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "list1 = ['IS', 'I', 'DSs', 'DS', 'D', 'CSs', 'CS', 'C', 'S', 's', 'Global']\n",
    "\n",
    "for elt in list1 : \n",
    "    df.append(build(elt))\n",
    "    \n",
    "data4 = pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(data4, 'data4', 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = load('data1', 'data') # Sales\n",
    "data2 = load('data2', 'data') # Event\n",
    "data3 = load('data3', 'data') # Price\n",
    "data4 = load('data4', 'data') # Sales granular\n",
    "data5 = load('data5', 'data') # Quantity\n",
    "\n",
    "data6 = pd.concat([data1, data4])\n",
    "data6.index = data6['id']\n",
    "data3 = data3.fillna(-1)\n",
    "dico_id = load('dico_id', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [\n",
    "#     'cat',\n",
    "#     'dep',\n",
    "#     'item',\n",
    "#     'state',\n",
    "#     'store',\n",
    "    \n",
    "    'wday',\n",
    "    'month',\n",
    "    'year',\n",
    "    \n",
    "    \n",
    "    'name1',\n",
    "    'type1',\n",
    "    'name2',\n",
    "    'type2',\n",
    "    'snap_ca',\n",
    "    'snap_tx',\n",
    "    'snap_wi',\n",
    "    \n",
    "    'PISs',\n",
    "    'PIS',\n",
    "    'PI',\n",
    "    \n",
    "    'ISs',\n",
    "    'IS',\n",
    "    'I',\n",
    "    'DSs',\n",
    "    'DS',\n",
    "    'D',\n",
    "    'CSs',\n",
    "    'CS',\n",
    "    'C',\n",
    "    's',\n",
    "    'S',\n",
    "    'Global',\n",
    "    \n",
    "    'QISs',\n",
    "    'QIS',\n",
    "    'QI'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_one_example(item_full_id, end_of_past, past_len = 150, pred_len = 28, train = True, end_of_time = 1914):\n",
    "    \n",
    "    vect = np.zeros((past_len + pred_len - 1 , 28))\n",
    "    \n",
    "    c_past = ['d_'+str(end_of_past-elt) for elt in range(past_len)]\n",
    "    c_past.reverse()\n",
    "    c_pred = ['d_'+str(end_of_past + elt) for elt in range(1,pred_len) if end_of_past + elt < end_of_time]\n",
    "    c_target = ['d_'+str(end_of_past + elt) for elt in range(1,pred_len+1)]\n",
    "    \n",
    "    \n",
    "    ## Event Data\n",
    "    a = data2.loc[c_past + c_pred][data2.columns[2:]].values\n",
    "    vect[:a.shape[0], :10] = a\n",
    "    \n",
    "    ## Tags\n",
    "    cat_id, dept_id, item_id, state_id, store_id = dico_id[item_full_id]\n",
    "\n",
    "    ISs = item_id + '_' + store_id + '_validation'\n",
    "    IS = item_id + '_' + state_id + '_validation'\n",
    "    I = item_id + '_validation'\n",
    "\n",
    "    DSs = dept_id + '_' + store_id + '_validation'\n",
    "    DS = dept_id + '_' + state_id + '_validation'\n",
    "    D = dept_id + '_validation'\n",
    "\n",
    "    CSs = cat_id + '_' + store_id + '_validation'\n",
    "    CS = cat_id + '_' + state_id + '_validation'\n",
    "    C = cat_id + '_validation'\n",
    "\n",
    "    s = store_id + '_validation'\n",
    "    S = state_id + '_validation'\n",
    "    gl = 'Global_validation'\n",
    "\n",
    "    price_tag = [ISs, IS, I]\n",
    "    sales_tag = [ISs, IS, I, DSs, DS, D, CSs, CS, C, s, S, gl]\n",
    "    quantity_tag = [ISs, IS, I]\n",
    "    \n",
    "    ## Price Data\n",
    "    a = data3.loc[price_tag][c_past + c_pred].values.T\n",
    "    vect[:a.shape[0], 10:13] = a\n",
    "    \n",
    "    ## Sales\n",
    "    a = data6.loc[sales_tag][c_past + c_pred].values.T\n",
    "    vect[:a.shape[0] , 13:25] = a\n",
    "    \n",
    "    ## Quantity input\n",
    "    a = data5.loc[quantity_tag][c_past + c_pred].values.T\n",
    "    vect[:a.shape[0] , 25:] = a\n",
    "    \n",
    "    ## Target\n",
    "    if train == True : \n",
    "        target = data5.loc[[ISs]][c_target].values[0]\n",
    "    else:\n",
    "        target = None\n",
    "    \n",
    "    return vect, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch(n = 10000, start_eop = 150, end_eop = 1200, past_len = 100, pred_len = 28, end_of_time = 1914):\n",
    "    X = list(np.zeros(n))\n",
    "    y = list(np.zeros(n))\n",
    "    \n",
    "    pool = data1['id'].unique()\n",
    "    \n",
    "    t = list(range(start_eop, end_eop))\n",
    "    \n",
    "    for elt in tqdm(range(n)):\n",
    "        \n",
    "        item_full_id = random.choice(pool)\n",
    "        end_of_past = random.choice(t)\n",
    "        \n",
    "        vect, target = build_one_example(item_full_id, end_of_past, past_len = past_len, pred_len = 28, train = True, end_of_time=end_of_time)\n",
    "        \n",
    "        X[elt] = vect\n",
    "        y[elt] = target\n",
    "        \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1fe67487426424db740c828f7d09d97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = create_batch(n = 100, start_eop = 1200, end_eop = 1914, past_len = 100, pred_len = 28, end_of_time = 1914)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd7c2687bd242c6a6ea35873b011760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = create_batch(n = 10000, start_eop = 1200, end_eop = 1850, past_len = 100, pred_len = 28, end_of_time = 1914)\n",
    "save((X,y), 'test_set', 'batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eff7b218a36473699f33f214940b31d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8d3a712a1b4833ac79819874a438fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc949438c6224f49892c98a4af92bb14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb16e582b6240adb869d03a0c210ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba91dbb6f86478da4fb9815482f5366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a2d6dd6e274428395acba254c654d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0846fb81b66349a39e505a0f31673cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bbde641ff4d440eb8047263ed15828a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ead143dd454103a041a25bc0e841c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c229f8a5af40d6a41d1707ad848174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db6137f49314bf5971763a8b67184fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49563939c7954269abf09e1a126eb116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91869ae7edd74ac59f0e7daed8e2a05d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b51ff15c5e419fa537dda2216ca8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beaae3ca4d90417a83cb7c6b69364a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36756711114e4d2185cbea620cde0fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9fc9c6131224cf3a8c5611e2aae1565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2155015ccce34fb7b435e012b88899d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b888edbdc6774ce08969fe028b24e0d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9e536afdac49df9159a2cea12efbd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10808f833c4a48589d224f06cd95f20c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for elt in tqdm(range(20)):\n",
    "    X, y = create_batch(n = 10000, start_eop = 150, end_eop = 1200, past_len = 100, pred_len = 28, end_of_time = 1914)\n",
    "    save((X,y), 'train_set_'+str(elt), 'batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_transformers2 import *\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed, Embedding, Concatenate, Dropout\n",
    "from tensorflow.keras import Input, Model\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameters\n",
    "cat_dim = [7,12,6,31,5,5,3]\n",
    "cat_out_dim = [7,12,6,31,5,5,3]\n",
    "bidirectional_decoder = False\n",
    "maximum_position_encoding = 127\n",
    "d_model = 64\n",
    "num_heads = 8\n",
    "dff = 1024\n",
    "rate = 0.1\n",
    "num_layers = 1\n",
    "\n",
    "### Declaration of some layers\n",
    "pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "dec_layers = [GPTDecoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "### Model architecture\n",
    "inputs = Input(shape = (127, 28))\n",
    "\n",
    "cat_inputs = tf.cast(inputs[:,:,:7], dtype = 'int32')\n",
    "num_inputs = inputs[:,:,7:]\n",
    "\n",
    "cats = list(np.zeros(7))\n",
    "for elt in range(len(cat_dim)):\n",
    "    cats[elt] = Embedding(cat_dim[elt], cat_out_dim[elt])(cat_inputs[:,:,elt])\n",
    "    \n",
    "categorical_embedding = Concatenate(axis = -1)(cats)\n",
    "\n",
    "num_embedding = TimeDistributed(Dense(28, activation = 'relu'))(num_inputs)\n",
    "\n",
    "time_series =  Concatenate(axis = -1)([categorical_embedding, num_embedding])\n",
    "\n",
    "time_series = TimeDistributed(Dense(64, activation = 'relu'))(time_series)\n",
    "\n",
    "seq_len = tf.shape(time_series)[1]\n",
    "attention_weights = {}\n",
    "        \n",
    "if bidirectional_decoder == False:\n",
    "    look_ahead_mask = create_look_ahead_mask(seq_len)\n",
    "#     dec_target_padding_mask = create_padding_mask(x)\n",
    "#     mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "else:\n",
    "#     mask = create_padding_mask(x)\n",
    "    mask = None\n",
    "\n",
    "# mask = None\n",
    "time_series *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "time_series += pos_encoding[:, :seq_len, :]\n",
    "\n",
    "time_series = Dropout(rate)(time_series)\n",
    "\n",
    "x = time_series\n",
    "for i in range(num_layers):\n",
    "    x, block1 = dec_layers[i](x, training = True, look_ahead_mask = mask)\n",
    "\n",
    "    attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "    \n",
    "prediction = TimeDistributed(Dense(1, activation = 'linear'))(x)\n",
    "\n",
    "output = prediction[:,-28:,:]\n",
    "\n",
    "model = Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_29 (InputLayer)           [(None, 127, 28)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_292 ( [(None, 127, 7)]     0           input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast_26 (TensorFlow [(None, 127, 7)]     0           tf_op_layer_strided_slice_292[0][\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_294 ( [(None, 127)]        0           tf_op_layer_Cast_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_295 ( [(None, 127)]        0           tf_op_layer_Cast_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_296 ( [(None, 127)]        0           tf_op_layer_Cast_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_297 ( [(None, 127)]        0           tf_op_layer_Cast_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_298 ( [(None, 127)]        0           tf_op_layer_Cast_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_299 ( [(None, 127)]        0           tf_op_layer_Cast_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_300 ( [(None, 127)]        0           tf_op_layer_Cast_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_183 (Embedding)       (None, 127, 7)       49          tf_op_layer_strided_slice_294[0][\n",
      "__________________________________________________________________________________________________\n",
      "embedding_184 (Embedding)       (None, 127, 12)      144         tf_op_layer_strided_slice_295[0][\n",
      "__________________________________________________________________________________________________\n",
      "embedding_185 (Embedding)       (None, 127, 6)       36          tf_op_layer_strided_slice_296[0][\n",
      "__________________________________________________________________________________________________\n",
      "embedding_186 (Embedding)       (None, 127, 31)      961         tf_op_layer_strided_slice_297[0][\n",
      "__________________________________________________________________________________________________\n",
      "embedding_187 (Embedding)       (None, 127, 5)       25          tf_op_layer_strided_slice_298[0][\n",
      "__________________________________________________________________________________________________\n",
      "embedding_188 (Embedding)       (None, 127, 5)       25          tf_op_layer_strided_slice_299[0][\n",
      "__________________________________________________________________________________________________\n",
      "embedding_189 (Embedding)       (None, 127, 3)       9           tf_op_layer_strided_slice_300[0][\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_293 ( [(None, 127, 21)]    0           input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 127, 69)      0           embedding_183[0][0]              \n",
      "                                                                 embedding_184[0][0]              \n",
      "                                                                 embedding_185[0][0]              \n",
      "                                                                 embedding_186[0][0]              \n",
      "                                                                 embedding_187[0][0]              \n",
      "                                                                 embedding_188[0][0]              \n",
      "                                                                 embedding_189[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_14 (TimeDistri (None, 127, 28)      616         tf_op_layer_strided_slice_293[0][\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 127, 97)      0           concatenate_50[0][0]             \n",
      "                                                                 time_distributed_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_15 (TimeDistri (None, 127, 64)      6272        concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape_21 (TensorFlo [(3,)]               0           time_distributed_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_301 ( [()]                 0           tf_op_layer_Shape_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_302/s [(3,)]               0           tf_op_layer_strided_slice_301[0][\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_22 (TensorFlowO [(None, 127, 64)]    0           time_distributed_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_302 ( [(1, None, 64)]      0           tf_op_layer_strided_slice_302/sta\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_21 (TensorFlowO [(None, 127, 64)]    0           tf_op_layer_mul_22[0][0]         \n",
      "                                                                 tf_op_layer_strided_slice_302[0][\n",
      "__________________________________________________________________________________________________\n",
      "dropout_408 (Dropout)           (None, 127, 64)      0           tf_op_layer_add_21[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "gpt_decoder_layer_132 (GPTDecod ((None, 127, 64), (N 149056      dropout_408[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_16 (TimeDistri (None, 127, 1)       65          gpt_decoder_layer_132[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_303 ( [(None, 28, 1)]      0           time_distributed_16[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 157,258\n",
      "Trainable params: 157,258\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load('train_set_0', 'batch')\n",
    "X_test, y_test = load('test_set', 'batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "def rmse(label, prediction):\n",
    "    RMSE = tf.sqrt(tf.losses.mean_squared_error(label, prediction))\n",
    "    return RMSE\n",
    "\n",
    "loss_classif     =  rmse#'mse'# find the right loss for multi-class classification\n",
    "optimizer        =  Adam(3e-5, 1e-8) # find the right optimizer\n",
    "metrics_classif  =  ['accuracy']\n",
    "\n",
    "model.compile(loss=loss_classif,\n",
    "              optimizer=optimizer)#,\n",
    "#               metrics=metrics_classif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "10000/10000 [==============================] - 16s 2ms/sample - loss: 1.5449 - val_loss: 1.6903\n",
      "Epoch 2/5\n",
      "10000/10000 [==============================] - 14s 1ms/sample - loss: 1.4992 - val_loss: 1.6957\n",
      "Epoch 3/5\n",
      "10000/10000 [==============================] - 14s 1ms/sample - loss: 1.4944 - val_loss: 1.7134\n",
      "Epoch 4/5\n",
      "10000/10000 [==============================] - 14s 1ms/sample - loss: 1.4924 - val_loss: 1.6934\n",
      "Epoch 5/5\n",
      "10000/10000 [==============================] - 14s 1ms/sample - loss: 1.4907 - val_loss: 1.7097\n"
     ]
    }
   ],
   "source": [
    "bs = 8\n",
    "n_epochs = 5\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=bs, epochs=n_epochs, validation_data=(X_test,  y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************         EPOCH  0    ***************************************\n",
      "**********************Batch  0\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "10000/10000 [==============================] - 22s 2ms/sample - loss: 14.7318 - val_loss: 16.1880\n",
      "**********************Batch  1\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "10000/10000 [==============================] - 17s 2ms/sample - loss: 20.6611 - val_loss: 16.1880\n",
      "**********************Batch  2\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "10000/10000 [==============================] - 17s 2ms/sample - loss: 16.3937 - val_loss: 16.1880\n",
      "**********************Batch  3\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      " 2560/10000 [======>.......................] - ETA: 8s - loss: 19.4734"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-165-6c5e5d6f5a50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_set_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'batch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCH = 2\n",
    "\n",
    "bs = 128\n",
    "n_epochs = 1\n",
    "\n",
    "for e in range(EPOCH):\n",
    "    print('************************         EPOCH  '+str(e)+'    ***************************************')\n",
    "    \n",
    "    for b in range(20):\n",
    "        print('**********************Batch  '+str(b))\n",
    "        \n",
    "        X_train, y_train = load('train_set_'+str(b), 'batch')\n",
    "        \n",
    "        history = model.fit(X_train, y_train, batch_size=bs, epochs=n_epochs, validation_data=(X_test,  y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 1106\n",
    "a = model.predict(X_train[ind:ind+1])\n",
    "a = a.reshape(a.shape[1])\n",
    "b = y_train[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09718734, 0.08795158, 0.0790975 , 0.06608121, 0.05314694,\n",
       "       0.03076402, 0.07591003, 0.12050926, 0.05555088, 0.10176709,\n",
       "       0.04196538, 0.02705426, 0.07230114, 0.07384706, 0.07674184,\n",
       "       0.06930135, 0.09066   , 0.03451683, 0.10416551, 0.0569393 ,\n",
       "       0.04092109, 0.05007923, 0.11880596, 0.05527979, 0.07599157,\n",
       "       0.0599381 , 0.09939766, 0.01635136], dtype=float32)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 2, 3, 1, 1, 1, 0, 1, 8, 1, 1, 1, 0, 1, 0, 2, 0, 0, 1, 0, 0,\n",
       "       0, 5, 2, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1aa79c11248>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(b, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
