{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import _pickle as pickle\n",
    "def save(file,name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'wb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'wb')\n",
    "    pickle.dump(file, outfile)\n",
    "    outfile.close\n",
    "    \n",
    "def load(name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'rb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'rb')\n",
    "    file = pickle.load(outfile)\n",
    "    outfile.close\n",
    "    return file\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification, TFBertModel, RobertaTokenizer, TFRobertaModel, TFRobertaMainLayer\n",
    "import tensorflow as tf\n",
    "\n",
    "def equal(a, b):\n",
    "#     assert len(a) == len(b)\n",
    "    val = True\n",
    "    for i in range(len(a)):\n",
    "        if a[i] != b[i]:\n",
    "            val = False\n",
    "    return val\n",
    "\n",
    "import difflib\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "max_length = 64\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=True)\n",
    "max_length = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = df_train.iloc[14]\n",
    "s1 = ' '.join(line['sentiment'].split())\n",
    "s2 = ' '.join(line['text'].split())\n",
    "s3 = ' '.join(line['selected_text'].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s1)\n",
    "print(s2)\n",
    "print(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(s1,s2,s3, max_length):\n",
    "    encoded = tokenizer.encode_plus(s1, s2, add_special_tokens = True, max_length = max_length, pad_to_max_length = True)\n",
    "    encoded_answer1 = tokenizer.encode_plus('</s> ' + s3, add_special_tokens = False)\n",
    "    encoded_answer2 = tokenizer.encode_plus('start ' + s3, add_special_tokens = False)\n",
    "\n",
    "    input_id = np.array(encoded['input_ids'])\n",
    "    input_masks = np.array(encoded['attention_mask'])\n",
    "    input_types = np.array(encoded['token_type_ids'])\n",
    "\n",
    "    answer1 = np.array(encoded_answer1['input_ids'][1:])\n",
    "    answer2 = np.array(encoded_answer2['input_ids'][1:])\n",
    "\n",
    "    ## End and Start token\n",
    "    start = np.zeros(len(input_id))\n",
    "    end = np.zeros(len(input_id))\n",
    "    valid = np.zeros(len(input_id))\n",
    "    \n",
    "    found = False\n",
    "    for i in range(len(input_id) - len(answer1)):\n",
    "        if equal(input_id[i: i + len(answer1)],answer1):\n",
    "            st = i\n",
    "            en = i + len(answer1) -1\n",
    "#             print(input_id[st: en +1])\n",
    "#             print(tokenizer.decode(input_id[st: en+1]))\n",
    "            found = True\n",
    "\n",
    "        elif equal(input_id[i: i + len(answer2)],answer2):\n",
    "            st = i\n",
    "            en = i + len(answer2) -1\n",
    "#             print(input_id[st: en +1])\n",
    "#             print(tokenizer.decode(input_id[st: en+1]))\n",
    "            found = True\n",
    "    if found == False:\n",
    "        print('no answer found')\n",
    "    else:\n",
    "        start[st] = 1\n",
    "        end[en] = 1\n",
    "        valid[st:en+1] = 1\n",
    "        \n",
    "    for i in range(len(input_masks)):\n",
    "        if input_masks[i] == 0:\n",
    "            start[i] = 2\n",
    "            end[i] = 2\n",
    "            valid[i] = 2\n",
    "            \n",
    "    ## token ids\n",
    "    input_types[3:] = 1\n",
    "\n",
    "    for elt in range(len(input_masks)):\n",
    "        if input_masks[elt] == 0:\n",
    "            input_types[elt] = 0\n",
    "            \n",
    "    return input_id, input_masks, input_types, start, end, valid, found*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_id, input_masks, input_types, start, end, valid, found = extract(s1,s2,s3,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "X_type = []\n",
    "X_masks = []\n",
    "\n",
    "token_start = []\n",
    "token_end = []\n",
    "token = []\n",
    "\n",
    "X_text = []\n",
    "Y_text = []\n",
    "\n",
    "found_count = 0\n",
    "max_length = 64\n",
    "for index, line in tqdm(df_train.iterrows(), total = df_train.shape[0]):\n",
    "    s1 = ' '.join(line['sentiment'].split())\n",
    "    s2 = ' '.join(str(line['text']).split())\n",
    "    s3 = ' '.join(str(line['selected_text']).split())\n",
    "    \n",
    "    input_id, input_masks, input_types, start, end, valid, found = extract(s1,s2,s3, max_length)\n",
    "    \n",
    "    found_count += found\n",
    "    \n",
    "    X.append(input_id)\n",
    "    X_type.append(input_types)\n",
    "    X_masks.append(input_masks)\n",
    "    \n",
    "    token_start.append(start)\n",
    "    token_end.append(end)\n",
    "    token.append(valid)\n",
    "    \n",
    "    X_text.append(s2)\n",
    "    Y_text.append(line['selected_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 5\n",
    "a = X[ind]\n",
    "\n",
    "ts = token_start[ind]\n",
    "te = token_end[ind]\n",
    "ts = ts[ts !=2]\n",
    "te = te[te !=2]\n",
    "print(a)\n",
    "# print(Y[ind])\n",
    "print(tokenizer.decode(a))\n",
    "print(tokenizer.decode(a[np.argmax(ts):np.argmax(te)+1]))\n",
    "print(Y_text[ind])\n",
    "print(X_type[ind])\n",
    "print(X_masks[ind])\n",
    "print(token_start[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save((X, X_type, X_masks, X_text, Y_text, token_start, token_end, token), 'train_set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, X_type, X_masks, X_text, Y_text, token_start, token_end, token) = load('train_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "X = np.array(X)\n",
    "X_type = np.array(X_type)\n",
    "X_masks = np.array(X_masks)\n",
    "\n",
    "token_start = np.array(token_start)\n",
    "token_end = np.array(token_end)\n",
    "token = np.array(token)\n",
    "\n",
    "both = np.concatenate([token_start.reshape(token_start.shape[0], token_start.shape[1], 1), token_end.reshape(token_end.shape[0], token_end.shape[1], 1)], axis = -1)\n",
    "both[both == 2] = 0\n",
    "token_start[token_start == 2] = 0\n",
    "# token_end[token_end == 2] = 0\n",
    "# token[token == 2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(token):\n",
    "    a = []\n",
    "    for elt in token:\n",
    "        c = 0\n",
    "        for i in elt:\n",
    "            if i == 1:\n",
    "                c+=1\n",
    "        a.append(c)\n",
    "    return np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_ids, X_test_ids, y_train_start, y_test_start = train_test_split(X, token_start, random_state=42, test_size=0.1)\n",
    "X_train_mask, X_test_mask, Y_text_train, Y_text_test = train_test_split(X_masks, Y_text, random_state=42, test_size=0.1)\n",
    "X_train_type, X_test_type, X_text_train, X_text_test = train_test_split(X_type, X_text, random_state=42, test_size=0.1)\n",
    "y_train_end, y_test_end, token_train, token_test = train_test_split(token_end, token, random_state=42, test_size=0.1)\n",
    "\n",
    "X_train = [X_train_ids, X_train_mask, X_train_type]\n",
    "X_test = [X_test_ids, X_test_mask, X_test_type]\n",
    "\n",
    "# y_train = [y_train_start, y_train_end]\n",
    "# y_test = [y_test_start, y_test_end]\n",
    "\n",
    "y_train = [token_train, count(token_train)]\n",
    "y_test = [token_test, count(token_test)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, TimeDistributed, Embedding, Concatenate\n",
    "\n",
    "max_length = 64\n",
    "\n",
    "inputs_ids = Input(shape = (max_length,), dtype = 'int32')\n",
    "inputs_mask = Input(shape = (max_length,), dtype = 'int32')\n",
    "inputs_type = Input(shape = (max_length,), dtype = 'float32')\n",
    "\n",
    "inputs = [inputs_ids, inputs_mask, inputs_type]\n",
    "\n",
    "# sentence_encoder = TFBertModel.from_pretrained(\n",
    "#     \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.  \n",
    "#     output_attentions = False, # Whether the model returns attentions weights.\n",
    "#     output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    "# )\n",
    "\n",
    "sentence_encoder = TFRobertaModel.from_pretrained('roberta-base',\n",
    "                                               output_attentions = False,\n",
    "                                               output_hidden_states = False,\n",
    "                                               )\n",
    "sentence_encoder.config.type_vocab_size = 2 \n",
    "sentence_encoder.roberta.embeddings.token_type_embeddings = Embedding(2, sentence_encoder.config.hidden_size)\n",
    "\n",
    "sentence_encoder.load_weights('./checkpoints/roberta_layer_epoch_'+str(0)+'_batch_'+str(14)+'/checkpoint.h5py')\n",
    "\n",
    "encoded = sentence_encoder(inputs_ids, attention_mask = inputs_mask, token_type_ids = inputs_type)\n",
    "pooled_encoded = encoded[0]\n",
    "pooled_encoded_1 = encoded[1]\n",
    "drop = Dropout(0.3)(pooled_encoded)\n",
    "\n",
    "out1 = TimeDistributed(Dense(1, activation = 'sigmoid'))(drop)\n",
    "out2 = Dense(1, activation = 'relu')(pooled_encoded_1)\n",
    "# out2 = TimeDistributed(Dense(1, activation = 'sigmoid'))(drop)\n",
    "\n",
    "# out1 = Dense(1, activation = 'sigmoid')(drop)\n",
    "# out2 = Dense(1, activation = 'sigmoid')(drop)\n",
    "\n",
    "out = [out1, out2]\n",
    "# out = Concatenate(axis = -1)([out1, out2])\n",
    "# out = TimeDistributed(Dense(2, activation = 'sigmoid'))(drop)\n",
    "\n",
    "model = Model(inputs, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_roberta_model (TFRobertaMode ((None, 64, 768), (N 124646400   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 64, 768)      0           tf_roberta_model[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 64, 1)        769         dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            769         tf_roberta_model[0][1]           \n",
      "==================================================================================================\n",
      "Total params: 124,647,938\n",
      "Trainable params: 124,647,938\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_cross_entropy(real, pred):\n",
    "    \n",
    "    real = tf.cast(real, dtype = pred.dtype)\n",
    "    \n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 2))\n",
    "    mask = tf.cast(mask, dtype = real.dtype)\n",
    "    \n",
    "    loss = (real*tf.math.log(pred) + (1-real)*tf.math.log(1-pred))*mask\n",
    "#     print(loss)\n",
    "    loss = - tf.reduce_mean(loss)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def inter_len(real, pred):\n",
    "    \n",
    "    real = tf.cast(real, dtype = pred.dtype)\n",
    "    \n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 2))\n",
    "    mask = tf.cast(mask, dtype = real.dtype)\n",
    "    \n",
    "    real = real*mask\n",
    "    pred = pred*mask\n",
    "#     print(real)\n",
    "#     print(pred)\n",
    "    categorical_pred = tf.cast(tf.math.greater(pred, 0.5), dtype = pred.dtype)\n",
    "    \n",
    "    inter = tf.reduce_sum(real*categorical_pred)\n",
    "    p = tf.reduce_sum(categorical_pred)\n",
    "    r = tf.reduce_sum(real)\n",
    "#     print(inter)\n",
    "#     print(p)\n",
    "#     print(r)\n",
    "    \n",
    "    loss = inter/(p+r-inter)\n",
    "    \n",
    "    return 1-loss\n",
    "\n",
    "def custom_loss(real, pred, ratio = 0.5):\n",
    "    \n",
    "    loss1 = masked_cross_entropy(real, pred)\n",
    "    loss2 = inter_len(real, pred)\n",
    "    \n",
    "    loss = ratio*loss1 + (1-ratio)*loss2\n",
    "    \n",
    "    return loss*100\n",
    "\n",
    "def jaccard_metric(real, pred):\n",
    "    real = tf.cast(real, dtype = pred.dtype)\n",
    "    \n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 2))\n",
    "    mask = tf.cast(mask, dtype = real.dtype)\n",
    "    \n",
    "    real = real*mask\n",
    "    pred = pred*mask\n",
    "    \n",
    "    categorical_pred = tf.cast(tf.math.greater(pred, 0.5), dtype = pred.dtype)\n",
    "    \n",
    "    inter = tf.reduce_sum(real*categorical_pred)\n",
    "    p = tf.reduce_sum(categorical_pred)\n",
    "    r = tf.reduce_sum(real)\n",
    "    metric = inter/(p+r-inter)\n",
    "    return metric\n",
    "\n",
    "def acc(real, pred):\n",
    "    real = tf.cast(real, dtype = pred.dtype)\n",
    "    \n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 2))\n",
    "    mask = tf.cast(mask, dtype = real.dtype)\n",
    "    \n",
    "    categorical_pred = tf.cast(tf.math.greater(pred, 0.5), dtype = pred.dtype)\n",
    "    \n",
    "    is_equal = tf.cast(real==categorical_pred, real.dtype)\n",
    "    \n",
    "    n_true = tf.math.reduce_sum(is_equal * mask)\n",
    "    \n",
    "    return n_true / tf.math.reduce_sum(mask)\n",
    "    \n",
    "# def custom_loss(true, pred):\n",
    "    \n",
    "#     true = tf.cast(true, dtype = pred.dtype)\n",
    "#     st_true = true[:, 0]\n",
    "#     en_true = true[:, 1]\n",
    "    \n",
    "#     st_pred = pred[:, 0]\n",
    "#     en_pred = pred[:, 1]\n",
    "    \n",
    "#     mask = tf.math.logical_not(tf.math.equal(st_true, 2))\n",
    "#     mask = tf.cast(mask, dtype = st_true.dtype)\n",
    "    \n",
    "#     ## Categorical crossentropy\n",
    "#     loss_start = masked_cross_entropy(st_true, st_pred)\n",
    "#     loss_en = masked_cross_entropy(en_true, en_pred)\n",
    "    \n",
    "    \n",
    "#     ## Jaccard\n",
    "#     st_true = st_true*mask\n",
    "#     en_true = en_true*mask\n",
    "    \n",
    "#     st_pred = st_pred*mask\n",
    "#     en_pred = en_pred*mask\n",
    "    \n",
    "#     stt = tf.math.argmax(st_true)\n",
    "#     ent = tf.math.argmax(en_true)\n",
    "    \n",
    "#     stp = tf.math.argmax(st_pred)\n",
    "#     enp = tf.math.argmax(en_pred)\n",
    "    \n",
    "#     lp = tf.math.maximum(enp - stp + 1 , 0)\n",
    "#     lt = tf.math.maximum(ent - stt + 1, 0)\n",
    "    \n",
    "# #     int1 = tf.math.maximum(ent - stp + 1, 0)\n",
    "# #     int2 = tf.math.maximum(enp - stt + 1, 0)\n",
    "#     int_abs = tf.math.minimum(ent - stp + 1, enp - stt + 1)\n",
    "#     int_abs = tf.math.maximum(int_abs, 0)\n",
    "    \n",
    "#     jac = int_abs / ( lp+ lt - int_abs)\n",
    "    \n",
    "# #     return loss_start, loss_en, jac\n",
    "#     return 0.5 * loss_start + 0.5 * loss_en# + 0.2 * (1-jac)\n",
    "    \n",
    "# def acc_start(true, pred):\n",
    "#     true = tf.cast(true, dtype = pred.dtype)\n",
    "#     st_true = true[:, 0]\n",
    "#     st_pred = pred[:, 0]\n",
    "    \n",
    "#     mask = tf.math.logical_not(tf.math.equal(st_true, 2))\n",
    "#     mask = tf.cast(mask, dtype = st_true.dtype)\n",
    "    \n",
    "#     st_true = st_true * mask\n",
    "#     st_pred = st_pred * mask\n",
    "    \n",
    "#     r= tf.math.argmax(st_true)\n",
    "#     p = tf.math.argmax(st_pred)\n",
    "  \n",
    "#     return tf.cast(p==r, true.dtype)\n",
    "\n",
    "# def acc_end(true, pred):\n",
    "#     true = tf.cast(true, dtype = pred.dtype)\n",
    "#     en_true = true[:, 1]\n",
    "#     en_pred = pred[:, 1]\n",
    "    \n",
    "#     mask = tf.math.logical_not(tf.math.equal(en_true, 2))\n",
    "#     mask = tf.cast(mask, dtype = en_true.dtype)\n",
    "    \n",
    "#     en_true = en_true * mask\n",
    "#     en_pred = en_pred * mask\n",
    "    \n",
    "#     r= tf.math.argmax(en_true)\n",
    "#     p = tf.math.argmax(en_pred)\n",
    "  \n",
    "#     return tf.cast(p==r, true.dtype)\n",
    "\n",
    "# def acc(true, pred):\n",
    "#     true = tf.cast(true, dtype = pred.dtype)\n",
    "#     mask = tf.math.logical_not(tf.math.equal(true, 2))\n",
    "#     mask = tf.cast(mask, dtype = true.dtype)\n",
    "    \n",
    "#     r= tf.math.argmax(true)\n",
    "#     p= tf.math.argmax(pred)\n",
    "#     return tf.cast(p==r, true.dtype)\n",
    "    \n",
    "    \n",
    "# def jaccard_metric(true, pred):\n",
    "#     true = tf.cast(true, dtype = pred.dtype)\n",
    "#     st_true = true[:, 0]\n",
    "#     en_true = true[:, 1]\n",
    "    \n",
    "#     st_pred = pred[:, 0]\n",
    "#     en_pred = pred[:, 1]\n",
    "    \n",
    "#     mask = tf.math.logical_not(tf.math.equal(st_true, 2))\n",
    "#     mask = tf.cast(mask, dtype = st_true.dtype)\n",
    "    \n",
    "#     ## Jaccard\n",
    "#     st_true = st_true*mask\n",
    "#     en_true = en_true*mask\n",
    "    \n",
    "#     st_pred = st_pred*mask\n",
    "#     en_pred = en_pred*mask\n",
    "    \n",
    "#     stt = tf.math.argmax(st_true)\n",
    "#     ent = tf.math.argmax(en_true)\n",
    "    \n",
    "#     stp = tf.math.argmax(st_pred)\n",
    "#     enp = tf.math.argmax(en_pred)\n",
    "    \n",
    "#     lp = tf.math.maximum(enp - stp + 1 , 0)\n",
    "#     lt = tf.math.maximum(ent - stt + 1, 0)\n",
    "    \n",
    "# #     int1 = tf.math.maximum(ent - stp + 1, 0)\n",
    "# #     int2 = tf.math.maximum(enp - stt + 1, 0)\n",
    "#     int_abs = tf.math.minimum(ent - stp + 1, enp - stt + 1)\n",
    "#     int_abs = tf.math.maximum(int_abs, 0)\n",
    "    \n",
    "#     jac = int_abs / ( lp+ lt - int_abs)\n",
    "    \n",
    "#     return jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24732 samples, validate on 2749 samples\n",
      "Epoch 1/3\n",
      "24732/24732 [==============================] - 277s 11ms/sample - loss: 54.9064 - time_distributed_loss: 22.8112 - dense_1_loss: 32.0903 - time_distributed_jaccard_metric: 0.6714 - time_distributed_acc: 0.8538 - dense_1_jaccard_metric: 9.9376 - dense_1_acc: 0.1710 - val_loss: 45.1709 - val_time_distributed_loss: 18.9938 - val_dense_1_loss: 26.1555 - val_time_distributed_jaccard_metric: 0.7240 - val_time_distributed_acc: 0.8814 - val_dense_1_jaccard_metric: 10.1287 - val_dense_1_acc: 0.1798\n",
      "Epoch 2/3\n",
      "24732/24732 [==============================] - 264s 11ms/sample - loss: 46.8688 - time_distributed_loss: 20.2064 - dense_1_loss: 26.6588 - time_distributed_jaccard_metric: 0.7075 - time_distributed_acc: 0.8742 - dense_1_jaccard_metric: 9.9658 - dense_1_acc: 0.1716 - val_loss: 45.2753 - val_time_distributed_loss: 18.9997 - val_dense_1_loss: 26.2536 - val_time_distributed_jaccard_metric: 0.7223 - val_time_distributed_acc: 0.8824 - val_dense_1_jaccard_metric: 10.1283 - val_dense_1_acc: 0.1794\n",
      "Epoch 3/3\n",
      "  672/24732 [..............................] - ETA: 4:07 - loss: 46.9313 - time_distributed_loss: 19.9976 - dense_1_loss: 26.9337 - time_distributed_jaccard_metric: 0.7099 - time_distributed_acc: 0.8766 - dense_1_jaccard_metric: 10.1745 - dense_1_acc: 0.1761WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,time_distributed_loss,dense_1_loss,time_distributed_jaccard_metric,time_distributed_acc,dense_1_jaccard_metric,dense_1_acc\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,time_distributed_loss,dense_1_loss,time_distributed_jaccard_metric,time_distributed_acc,dense_1_jaccard_metric,dense_1_acc,lr\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-2e59f9401bec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#, batch_size=bs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mearly\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "loss_classif     =  'categorical_crossentropy'# find the right loss for multi-class classification\n",
    "optimizer        =  Adam(3e-5, 1e-8) # find the right optimizer\n",
    "metrics_classif  =  ['accuracy']\n",
    "\n",
    "model.compile(loss=[custom_loss, 'mse'],\n",
    "              optimizer=optimizer,\n",
    "              metrics=[jaccard_metric, acc])\n",
    "\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=4, verbose=1, \n",
    "                                                mode='auto', restore_best_weights=True)\n",
    "reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, \n",
    "                                                     mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "bs = 32\n",
    "n_epochs = 2\n",
    "#, batch_size=bs\n",
    "history = model.fit(X_train, y_train, batch_size=bs, epochs=n_epochs, validation_data=(X_test,  y_test), callbacks = [early, reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24732 samples, validate on 2749 samples\n",
      "24732/24732 [==============================] - 281s 11ms/sample - loss: 41.9101 - time_distributed_loss: 19.1629 - dense_1_loss: 22.7548 - time_distributed_jaccard_metric: 0.7219 - time_distributed_acc: 0.8792 - dense_1_jaccard_metric: 9.9706 - dense_1_acc: 0.1716 - val_loss: 42.9139 - val_time_distributed_loss: 18.7169 - val_dense_1_loss: 24.1762 - val_time_distributed_jaccard_metric: 0.7317 - val_time_distributed_acc: 0.8823 - val_dense_1_jaccard_metric: 10.1287 - val_dense_1_acc: 0.1798\n"
     ]
    }
   ],
   "source": [
    "loss_classif     =  'categorical_crossentropy'# find the right loss for multi-class classification\n",
    "optimizer        =  Adam(3e-6, 1e-8) # find the right optimizer\n",
    "metrics_classif  =  ['accuracy']\n",
    "\n",
    "model.compile(loss=[custom_loss, 'mse'],\n",
    "              optimizer=optimizer,\n",
    "              metrics=[jaccard_metric, acc])\n",
    "\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=4, verbose=1, \n",
    "                                                mode='auto', restore_best_weights=True)\n",
    "reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, \n",
    "                                                     mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "bs = 32\n",
    "n_epochs = 1\n",
    "#, batch_size=bs\n",
    "history = model.fit(X_train, y_train, batch_size=bs, epochs=n_epochs, validation_data=(X_test,  y_test), callbacks = [early, reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "# pred = pred.reshape(pred.shape[0], pred.shape[1])\n",
    "\n",
    "pred = [pred[0].reshape(pred[0].shape[0], pred[0].shape[1]), pred[1].reshape(pred[1].shape[0])]\n",
    "\n",
    "# pred[0] = pred[0].reshape(pred[0].shape[0], pred[0].shape[1])\n",
    "# pred[1] = pred[1].reshape(pred[1].shape[0], pred[1].shape[1])\n",
    "\n",
    "# pred = [0,0]\n",
    "# pred[0] = pred1[:,:,0]\n",
    "# pred[1] = pred1[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wee. done with advance audit paper\n",
      "wee. done with advance audit paper\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = 9\n",
    "\n",
    "\n",
    "plt.plot(pred[0][ind])\n",
    "plt.plot(y_test[0][ind])\n",
    "# plt.figure(0)\n",
    "# plt.plot(pred[0][ind])\n",
    "# plt.plot(y_test[0][ind])\n",
    "# # plt.plot(y_test[ind][:,0])\n",
    "# plt.figure(2)\n",
    "# plt.plot(pred[1][ind])\n",
    "# plt.plot(y_test[1][ind])\n",
    "# # plt.plot(y_test[ind][:,1])\n",
    "\n",
    "print(Y_text_test[ind])\n",
    "# st = np.argmax(pred[0][ind])\n",
    "# en = np.argmax(pred[1][ind][st:]) + st\n",
    "# vect = X_test[0][ind, st:en+1]\n",
    "\n",
    "# vect = X_test[0][ind, pred[ind] >= 0.5]\n",
    "# vect = vect[vect != 1]\n",
    "\n",
    "vect = X_test[0][ind]\n",
    "\n",
    "p = pred[0][ind]\n",
    "n_token = int(pred[1][ind])+1\n",
    "\n",
    "p = p[vect != 1]\n",
    "p = np.argsort(p)[-n_token:]\n",
    "p = np.sort(p)\n",
    "vect = vect[p]\n",
    "vect = vect[vect != 1]\n",
    "\n",
    "vect = tokenizer.decode(vect)\n",
    "print(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(pred, X, X_text, x):\n",
    "    prediction = []\n",
    "    for i, elt in tqdm(enumerate(X[0]), total = len(X[0])):\n",
    "        \n",
    "#         st = np.argmax(pred[0][i])\n",
    "#         en = np.argmax(pred[1][i][st:]) + st\n",
    "        \n",
    "#         print(st)\n",
    "        \n",
    "#         vect = X_test[0][i, pred[i] >= x]\n",
    "#         vect = vect[vect != 1]\n",
    "#         vect = tokenizer.decode(vect)\n",
    "        \n",
    "#         vect = X[0][i, st:en+1]\n",
    "#         vect = tokenizer.decode(vect)\n",
    "        \n",
    "        # get closest inference\n",
    "        \n",
    "        vect = X_test[0][ind]\n",
    "\n",
    "        p = pred[0][ind]\n",
    "        n_token = int(pred[1][ind])+1\n",
    "\n",
    "        p = p[vect != 1]\n",
    "        p = np.argsort(p)[-n_token:]\n",
    "        p = np.sort(p)\n",
    "        vect = vect[p]\n",
    "        vect = vect[vect != 1]\n",
    "        \n",
    "         \n",
    "        vect = tokenizer.decode(vect)\n",
    "        \n",
    "        vect = vect.split()\n",
    "        true = X_text[i].lower().split()\n",
    "        vect1 = []\n",
    "        for elt in vect:\n",
    "            inf = difflib.get_close_matches(elt, true)\n",
    "            if len(inf) == 0:\n",
    "                vect1.append(elt)\n",
    "            else:\n",
    "                vect1.append(inf[0])\n",
    "        vect1 = ' '.join(vect1)\n",
    "        \n",
    "        prediction.append(vect1)\n",
    "#         prediction.append(' '.join(vect))\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "def evaluate(prediction, true):\n",
    "    value = []\n",
    "    for i in range(len(prediction)):\n",
    "        str1 = true[i]\n",
    "        str2 = prediction[i]\n",
    "        \n",
    "        value.append(jaccard(str1, str2))\n",
    "    score = np.mean(value)\n",
    "    \n",
    "    return value, score\n",
    "\n",
    "import optuna\n",
    "def objective(trial):\n",
    "    x = trial.suggest_uniform('x', 0, 1)\n",
    "    \n",
    "    prediction = inference(pred, X_test, X_text_test, x)\n",
    "    value,j = evaluate(prediction, Y_text_test)\n",
    "    print(j)\n",
    "    \n",
    "    return 1-j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = study.best_params['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b53f41a492e49329281c2a3f966eb40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2749.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = inference(pred, X_test, X_text_test, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "value, score = evaluate(prediction, Y_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023119052436251425"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.541e+03, 1.920e+02, 1.500e+01, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
