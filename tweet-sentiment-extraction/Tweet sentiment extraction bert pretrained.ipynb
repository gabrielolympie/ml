{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import _pickle as pickle\n",
    "def save(file,name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'wb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'wb')\n",
    "    pickle.dump(file, outfile)\n",
    "    outfile.close\n",
    "    \n",
    "def load(name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'rb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'rb')\n",
    "    file = pickle.load(outfile)\n",
    "    outfile.close\n",
    "    return file\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification, TFBertModel, RobertaTokenizer, TFRobertaModel, TFRobertaMainLayer\n",
    "import tensorflow as tf\n",
    "\n",
    "def equal(a, b):\n",
    "#     assert len(a) == len(b)\n",
    "    val = True\n",
    "    for i in range(len(a)):\n",
    "        if a[i] != b[i]:\n",
    "            val = False\n",
    "    return val\n",
    "\n",
    "import difflib\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "max_length = 64\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=True)\n",
    "max_length = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = df_train.iloc[31]\n",
    "s1 = ' '.join(line['sentiment'].split())\n",
    "s2 = ' '.join(line['text'].split())\n",
    "s3 = ' '.join(line['selected_text'].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n",
      "i hope unni will make the audition . fighting dahye unni !\n",
      "hope\n"
     ]
    }
   ],
   "source": [
    "print(s1)\n",
    "print(s2)\n",
    "print(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(s1,s2,s3, max_length):\n",
    "    encoded = tokenizer.encode_plus(s1, s2, add_special_tokens = True, max_length = max_length, pad_to_max_length = True)\n",
    "    encoded_answer1 = tokenizer.encode_plus('</s> ' + s3, add_special_tokens = False)\n",
    "    encoded_answer2 = tokenizer.encode_plus('start ' + s3, add_special_tokens = False)\n",
    "\n",
    "    input_id = np.array(encoded['input_ids'])\n",
    "    input_masks = np.array(encoded['attention_mask'])\n",
    "    input_types = np.array(encoded['token_type_ids'])\n",
    "\n",
    "    answer1 = np.array(encoded_answer1['input_ids'][1:])\n",
    "    answer2 = np.array(encoded_answer2['input_ids'][1:])\n",
    "\n",
    "    ## End and Start token\n",
    "    start = np.zeros(len(input_id))\n",
    "    end = np.zeros(len(input_id))\n",
    "\n",
    "    found = False\n",
    "    for i in range(len(input_id) - len(answer1)):\n",
    "        if equal(input_id[i: i + len(answer1)],answer1):\n",
    "            st = i\n",
    "            en = i + len(answer1) -1\n",
    "#             print(input_id[st: en +1])\n",
    "#             print(tokenizer.decode(input_id[st: en+1]))\n",
    "            found = True\n",
    "\n",
    "        elif equal(input_id[i: i + len(answer2)],answer2):\n",
    "            st = i\n",
    "            en = i + len(answer2) -1\n",
    "#             print(input_id[st: en +1])\n",
    "#             print(tokenizer.decode(input_id[st: en+1]))\n",
    "            found = True\n",
    "    if found == False:\n",
    "        print('no answer found')\n",
    "    else:\n",
    "        start[st] = 1\n",
    "        end[en] = 1\n",
    "    \n",
    "    for i in range(len(input_masks)):\n",
    "        if input_masks[i] == 0:\n",
    "            start[i] = 2\n",
    "            end[i] = 2\n",
    "\n",
    "    ## token ids\n",
    "    input_types[3:] = 1\n",
    "\n",
    "    for elt in range(len(input_masks)):\n",
    "        if input_masks[elt] == 0:\n",
    "            input_types[elt] = 0\n",
    "            \n",
    "    return input_id, input_masks, input_types, start, end, found*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_id, input_masks, input_types, start, end, found = extract(s1,s2,s3,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c505c90e6bc44e769d3467b82df802fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27481.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "no answer found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "X_type = []\n",
    "X_masks = []\n",
    "\n",
    "token_start = []\n",
    "token_end = []\n",
    "\n",
    "X_text = []\n",
    "Y_text = []\n",
    "\n",
    "found_count = 0\n",
    "max_length = 64\n",
    "for index, line in tqdm(df_train.iterrows(), total = df_train.shape[0]):\n",
    "    s1 = ' '.join(line['sentiment'].split())\n",
    "    s2 = ' '.join(str(line['text']).split())\n",
    "    s3 = ' '.join(str(line['selected_text']).split())\n",
    "    \n",
    "    input_id, input_masks, input_types, start, end, found = extract(s1,s2,s3, max_length)\n",
    "    \n",
    "    found_count += found\n",
    "    \n",
    "    X.append(input_id)\n",
    "    X_type.append(input_types)\n",
    "    X_masks.append(input_masks)\n",
    "    \n",
    "    token_start.append(start)\n",
    "    token_end.append(end)\n",
    "    \n",
    "    X_text.append(s2)\n",
    "    Y_text.append(line['selected_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25446"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27481"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27481, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0 12516     2     2  8166   640  1401     4   417 15244   428  7928\n",
      "  4469     4   175    73  9426   506   111   103 36778 10242  3923    13\n",
      "     5   275   910 15574  7900    15  6872     2     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1]\n",
      "<s>neutral</s></s>http://www.dothebouncy.com/smf - some shameless plugging for the best rangers forum on earth</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "http://www.dothebouncy.com/smf - some shameless plugging for the best rangers forum on earth\n",
      "http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth\n",
      "[0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "ind = 5\n",
    "a = X[ind]\n",
    "\n",
    "ts = token_start[ind]\n",
    "te = token_end[ind]\n",
    "ts = ts[ts !=2]\n",
    "te = te[te !=2]\n",
    "print(a)\n",
    "# print(Y[ind])\n",
    "print(tokenizer.decode(a))\n",
    "print(tokenizer.decode(a[np.argmax(ts):np.argmax(te)+1]))\n",
    "print(Y_text[ind])\n",
    "print(X_type[ind])\n",
    "print(X_masks[ind])\n",
    "print(token_start[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save((X, X_type, X_masks, X_text, Y_text, token_start, token_end), 'train_set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, X_type, X_masks, X_text, Y_text, token_start, token_end) = load('train_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "X = np.array(X)\n",
    "X_type = np.array(X_type)\n",
    "X_masks = np.array(X_masks)\n",
    "\n",
    "token_start = np.array(token_start)\n",
    "token_end = np.array(token_end)\n",
    "\n",
    "both = np.concatenate([token_start.reshape(token_start.shape[0], token_start.shape[1], 1), token_end.reshape(token_end.shape[0], token_end.shape[1], 1)], axis = -1)\n",
    "both[both == 2] = 0\n",
    "token_start[token_start == 2] = 0\n",
    "token_end[token_end == 2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_ids, X_test_ids, y_train_start, y_test_start = train_test_split(X, token_start, random_state=42, test_size=0.1)\n",
    "X_train_mask, X_test_mask, Y_text_train, Y_text_test = train_test_split(X_masks, Y_text, random_state=42, test_size=0.1)\n",
    "X_train_type, X_test_type, X_text_train, X_text_test = train_test_split(X_type, X_text, random_state=42, test_size=0.1)\n",
    "y_train_end, y_test_end, both_train, both_test = train_test_split(token_end, both, random_state=42, test_size=0.1)\n",
    "\n",
    "X_train = [X_train_ids, X_train_mask, X_train_type]\n",
    "X_test = [X_test_ids, X_test_mask, X_test_type]\n",
    "\n",
    "y_train = [y_train_start, y_train_end]\n",
    "y_test = [y_test_start, y_test_end]\n",
    "\n",
    "# y_train = both_train\n",
    "# y_test = both_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, TimeDistributed, Embedding, Concatenate\n",
    "\n",
    "max_length = 64\n",
    "\n",
    "inputs_ids = Input(shape = (max_length,), dtype = 'int32')\n",
    "inputs_mask = Input(shape = (max_length,), dtype = 'int32')\n",
    "inputs_type = Input(shape = (max_length,), dtype = 'float32')\n",
    "\n",
    "inputs = [inputs_ids, inputs_mask, inputs_type]\n",
    "\n",
    "# sentence_encoder = TFBertModel.from_pretrained(\n",
    "#     \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.  \n",
    "#     output_attentions = False, # Whether the model returns attentions weights.\n",
    "#     output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    "# )\n",
    "\n",
    "sentence_encoder = TFRobertaModel.from_pretrained('roberta-base',\n",
    "                                               output_attentions = False,\n",
    "                                               output_hidden_states = False,\n",
    "                                               )\n",
    "sentence_encoder.config.type_vocab_size = 2 \n",
    "sentence_encoder.roberta.embeddings.token_type_embeddings = Embedding(2, sentence_encoder.config.hidden_size)\n",
    "\n",
    "sentence_encoder.load_weights('./checkpoints/roberta_layer_epoch_'+str(0)+'_batch_'+str(14)+'/checkpoint.h5py')\n",
    "\n",
    "encoded = sentence_encoder(inputs_ids, attention_mask = inputs_mask, token_type_ids = inputs_type)\n",
    "pooled_encoded = encoded[0]\n",
    "\n",
    "drop = Dropout(0.3)(pooled_encoded)\n",
    "\n",
    "out1 = TimeDistributed(Dense(1, activation = 'sigmoid'))(drop)\n",
    "out2 = TimeDistributed(Dense(1, activation = 'sigmoid'))(drop)\n",
    "\n",
    "# out1 = Dense(1, activation = 'sigmoid')(drop)\n",
    "# out2 = Dense(1, activation = 'sigmoid')(drop)\n",
    "\n",
    "out = [out1, out2]\n",
    "# out = Concatenate(axis = -1)([out1, out2])\n",
    "# out = TimeDistributed(Dense(2, activation = 'sigmoid'))(drop)\n",
    "\n",
    "model = Model(inputs, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_roberta_model_1 (TFRobertaMo ((None, 64, 768), (N 124646400   input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 64, 768)      0           tf_roberta_model_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64, 1)        769         dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64, 1)        769         dropout_77[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 124,647,938\n",
      "Trainable params: 124,647,938\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_cross_entropy(real, pred):\n",
    "    \n",
    "    real = tf.cast(real, dtype = pred.dtype)\n",
    "    \n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 2))\n",
    "    mask = tf.cast(mask, dtype = real.dtype)\n",
    "    \n",
    "    loss = (real*tf.math.log(pred) + (1-real)*tf.math.log(1-pred))*mask\n",
    "#     print(loss)\n",
    "    loss = - tf.reduce_mean(loss)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# def inter_len(real, pred):\n",
    "    \n",
    "#     real = tf.cast(real, dtype = pred.dtype)\n",
    "    \n",
    "#     mask = tf.math.logical_not(tf.math.equal(real, 2))\n",
    "#     mask = tf.cast(mask, dtype = real.dtype)\n",
    "    \n",
    "#     real = real*mask\n",
    "#     pred = pred*mask\n",
    "# #     print(real)\n",
    "# #     print(pred)\n",
    "#     categorical_pred = tf.cast(tf.math.greater(pred, 0.5), dtype = pred.dtype)\n",
    "    \n",
    "#     inter = tf.reduce_sum(real*categorical_pred)\n",
    "#     p = tf.reduce_sum(categorical_pred)\n",
    "#     r = tf.reduce_sum(real)\n",
    "# #     print(inter)\n",
    "# #     print(p)\n",
    "# #     print(r)\n",
    "    \n",
    "#     loss = inter/(p+r-inter)\n",
    "    \n",
    "#     return 1-loss\n",
    "\n",
    "# def custom_loss(real, pred, ratio = 0.7):\n",
    "    \n",
    "#     loss1 = masked_cross_entropy(real, pred)\n",
    "#     loss2 = inter_len(real, pred)\n",
    "    \n",
    "#     loss = ratio*loss1 + (1-ratio)*loss2\n",
    "    \n",
    "#     return loss\n",
    "\n",
    "# def jaccard_metric(real, pred):\n",
    "#     real = tf.cast(real, dtype = pred.dtype)\n",
    "    \n",
    "#     mask = tf.math.logical_not(tf.math.equal(real, 2))\n",
    "#     mask = tf.cast(mask, dtype = real.dtype)\n",
    "    \n",
    "#     real = real*mask\n",
    "#     pred = pred*mask\n",
    "    \n",
    "#     categorical_pred = tf.cast(tf.math.greater(pred, 0.5), dtype = pred.dtype)\n",
    "    \n",
    "#     inter = tf.reduce_sum(real*categorical_pred)\n",
    "#     p = tf.reduce_sum(categorical_pred)\n",
    "#     r = tf.reduce_sum(real)\n",
    "#     metric = inter/(p+r-inter)\n",
    "#     return metric\n",
    "\n",
    "\n",
    "def custom_loss(true, pred):\n",
    "    \n",
    "    true = tf.cast(true, dtype = pred.dtype)\n",
    "    st_true = true[:, 0]\n",
    "    en_true = true[:, 1]\n",
    "    \n",
    "    st_pred = pred[:, 0]\n",
    "    en_pred = pred[:, 1]\n",
    "    \n",
    "    mask = tf.math.logical_not(tf.math.equal(st_true, 2))\n",
    "    mask = tf.cast(mask, dtype = st_true.dtype)\n",
    "    \n",
    "    ## Categorical crossentropy\n",
    "    loss_start = masked_cross_entropy(st_true, st_pred)\n",
    "    loss_en = masked_cross_entropy(en_true, en_pred)\n",
    "    \n",
    "    \n",
    "    ## Jaccard\n",
    "    st_true = st_true*mask\n",
    "    en_true = en_true*mask\n",
    "    \n",
    "    st_pred = st_pred*mask\n",
    "    en_pred = en_pred*mask\n",
    "    \n",
    "    stt = tf.math.argmax(st_true)\n",
    "    ent = tf.math.argmax(en_true)\n",
    "    \n",
    "    stp = tf.math.argmax(st_pred)\n",
    "    enp = tf.math.argmax(en_pred)\n",
    "    \n",
    "    lp = tf.math.maximum(enp - stp + 1 , 0)\n",
    "    lt = tf.math.maximum(ent - stt + 1, 0)\n",
    "    \n",
    "#     int1 = tf.math.maximum(ent - stp + 1, 0)\n",
    "#     int2 = tf.math.maximum(enp - stt + 1, 0)\n",
    "    int_abs = tf.math.minimum(ent - stp + 1, enp - stt + 1)\n",
    "    int_abs = tf.math.maximum(int_abs, 0)\n",
    "    \n",
    "    jac = int_abs / ( lp+ lt - int_abs)\n",
    "    \n",
    "#     return loss_start, loss_en, jac\n",
    "    return 0.5 * loss_start + 0.5 * loss_en# + 0.2 * (1-jac)\n",
    "    \n",
    "def acc_start(true, pred):\n",
    "    true = tf.cast(true, dtype = pred.dtype)\n",
    "    st_true = true[:, 0]\n",
    "    st_pred = pred[:, 0]\n",
    "    \n",
    "    mask = tf.math.logical_not(tf.math.equal(st_true, 2))\n",
    "    mask = tf.cast(mask, dtype = st_true.dtype)\n",
    "    \n",
    "    st_true = st_true * mask\n",
    "    st_pred = st_pred * mask\n",
    "    \n",
    "    r= tf.math.argmax(st_true)\n",
    "    p = tf.math.argmax(st_pred)\n",
    "  \n",
    "    return tf.cast(p==r, true.dtype)\n",
    "\n",
    "def acc_end(true, pred):\n",
    "    true = tf.cast(true, dtype = pred.dtype)\n",
    "    en_true = true[:, 1]\n",
    "    en_pred = pred[:, 1]\n",
    "    \n",
    "    mask = tf.math.logical_not(tf.math.equal(en_true, 2))\n",
    "    mask = tf.cast(mask, dtype = en_true.dtype)\n",
    "    \n",
    "    en_true = en_true * mask\n",
    "    en_pred = en_pred * mask\n",
    "    \n",
    "    r= tf.math.argmax(en_true)\n",
    "    p = tf.math.argmax(en_pred)\n",
    "  \n",
    "    return tf.cast(p==r, true.dtype)\n",
    "\n",
    "def acc(true, pred):\n",
    "    true = tf.cast(true, dtype = pred.dtype)\n",
    "    mask = tf.math.logical_not(tf.math.equal(true, 2))\n",
    "    mask = tf.cast(mask, dtype = true.dtype)\n",
    "    \n",
    "    r= tf.math.argmax(true)\n",
    "    p= tf.math.argmax(pred)\n",
    "    return tf.cast(p==r, true.dtype)\n",
    "    \n",
    "    \n",
    "def jaccard_metric(true, pred):\n",
    "    true = tf.cast(true, dtype = pred.dtype)\n",
    "    st_true = true[:, 0]\n",
    "    en_true = true[:, 1]\n",
    "    \n",
    "    st_pred = pred[:, 0]\n",
    "    en_pred = pred[:, 1]\n",
    "    \n",
    "    mask = tf.math.logical_not(tf.math.equal(st_true, 2))\n",
    "    mask = tf.cast(mask, dtype = st_true.dtype)\n",
    "    \n",
    "    ## Jaccard\n",
    "    st_true = st_true*mask\n",
    "    en_true = en_true*mask\n",
    "    \n",
    "    st_pred = st_pred*mask\n",
    "    en_pred = en_pred*mask\n",
    "    \n",
    "    stt = tf.math.argmax(st_true)\n",
    "    ent = tf.math.argmax(en_true)\n",
    "    \n",
    "    stp = tf.math.argmax(st_pred)\n",
    "    enp = tf.math.argmax(en_pred)\n",
    "    \n",
    "    lp = tf.math.maximum(enp - stp + 1 , 0)\n",
    "    lt = tf.math.maximum(ent - stt + 1, 0)\n",
    "    \n",
    "#     int1 = tf.math.maximum(ent - stp + 1, 0)\n",
    "#     int2 = tf.math.maximum(enp - stt + 1, 0)\n",
    "    int_abs = tf.math.minimum(ent - stp + 1, enp - stt + 1)\n",
    "    int_abs = tf.math.maximum(int_abs, 0)\n",
    "    \n",
    "    jac = int_abs / ( lp+ lt - int_abs)\n",
    "    \n",
    "    return jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array([[1,0,0,0,0],\n",
    "                    [0,0,0,1,0]])\n",
    "p = np.array([[0.95,0.1,0.1,0.1,0.2],\n",
    "                    [0.1,0.1,0.1,0.9,0.2]])\n",
    "true = tf.constant(t.T)\n",
    "pred = tf.constant(p.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24732"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24732 samples, validate on 2749 samples\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_1/roberta/pooler/dense/kernel:0', 'tf_roberta_model_1/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_1/roberta/pooler/dense/kernel:0', 'tf_roberta_model_1/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "24732/24732 [==============================] - 301s 12ms/sample - loss: 1.8255 - dense_2_loss: 0.9012 - dense_3_loss: 0.9242 - dense_2_accuracy: 0.9786 - dense_2_acc: 0.0968 - dense_3_accuracy: 0.9774 - dense_3_acc: 0.1762 - val_loss: 1.4146 - val_dense_2_loss: 0.7177 - val_dense_3_loss: 0.6971 - val_dense_2_accuracy: 0.9872 - val_dense_2_acc: 0.1094 - val_dense_3_accuracy: 0.9854 - val_dense_3_acc: 0.1969\n",
      "Epoch 2/3\n",
      "24732/24732 [==============================] - 290s 12ms/sample - loss: 1.3577 - dense_2_loss: 0.6963 - dense_3_loss: 0.6613 - dense_2_accuracy: 0.9864 - dense_2_acc: 0.1098 - dense_3_accuracy: 0.9876 - dense_3_acc: 0.1962 - val_loss: 1.3570 - val_dense_2_loss: 0.6966 - val_dense_3_loss: 0.6604 - val_dense_2_accuracy: 0.9844 - val_dense_2_acc: 0.1103 - val_dense_3_accuracy: 0.9862 - val_dense_3_acc: 0.1928\n",
      "Epoch 3/3\n",
      " 1408/24732 [>.............................] - ETA: 4:23 - loss: 1.1928 - dense_2_loss: 0.6137 - dense_3_loss: 0.5791 - dense_2_accuracy: 0.9882 - dense_2_acc: 0.1214 - dense_3_accuracy: 0.9891 - dense_3_acc: 0.2129WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,dense_2_loss,dense_3_loss,dense_2_accuracy,dense_2_acc,dense_3_accuracy,dense_3_acc\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,dense_2_loss,dense_3_loss,dense_2_accuracy,dense_2_acc,dense_3_accuracy,dense_3_acc,lr\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-0f4afd867393>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#, batch_size=bs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mearly\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "loss_classif     =  'categorical_crossentropy'# find the right loss for multi-class classification\n",
    "optimizer        =  Adam(3e-5, 1e-8) # find the right optimizer\n",
    "metrics_classif  =  ['accuracy']\n",
    "\n",
    "model.compile(loss=loss_classif,\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy', acc])\n",
    "\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=4, verbose=1, \n",
    "                                                mode='auto', restore_best_weights=True)\n",
    "reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, \n",
    "                                                     mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "bs = 32\n",
    "n_epochs = 3\n",
    "#, batch_size=bs\n",
    "history = model.fit(X_train, y_train, batch_size=bs, epochs=n_epochs, validation_data=(X_test,  y_test), callbacks = [early, reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24732 samples, validate on 2749 samples\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_1/roberta/pooler/dense/kernel:0', 'tf_roberta_model_1/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_1/roberta/pooler/dense/kernel:0', 'tf_roberta_model_1/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "24732/24732 [==============================] - 307s 12ms/sample - loss: 1.1502 - dense_2_loss: 0.5893 - dense_3_loss: 0.5609 - dense_2_acc: 0.1171 - dense_3_acc: 0.2117 - val_loss: 1.3495 - val_dense_2_loss: 0.6844 - val_dense_3_loss: 0.6650 - val_dense_2_acc: 0.1174 - val_dense_3_acc: 0.2024\n"
     ]
    }
   ],
   "source": [
    "loss_classif     =  'categorical_crossentropy'# find the right loss for multi-class classification\n",
    "optimizer        =  Adam(3e-6, 1e-8) # find the right optimizer\n",
    "metrics_classif  =  ['accuracy']\n",
    "\n",
    "model.compile(loss=loss_classif,\n",
    "              optimizer=optimizer,\n",
    "              metrics=[acc])\n",
    "\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=4, verbose=1, \n",
    "                                                mode='auto', restore_best_weights=True)\n",
    "reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, \n",
    "                                                     mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "bs = 32\n",
    "n_epochs = 1\n",
    "#, batch_size=bs\n",
    "history = model.fit(X_train, y_train, batch_size=bs, epochs=n_epochs, validation_data=(X_test,  y_test), callbacks = [early, reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "# pred = pred.reshape(pred.shape[0], pred.shape[1])\n",
    "\n",
    "pred[0] = pred[0].reshape(pred[0].shape[0], pred[0].shape[1])\n",
    "pred[1] = pred[1].reshape(pred[1].shape[0], pred[1].shape[1])\n",
    "\n",
    "# pred = [0,0]\n",
    "# pred[0] = pred1[:,:,0]\n",
    "# pred[1] = pred1[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2749, 64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I wish I could go\n",
      " wish\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = 25\n",
    "plt.figure(0)\n",
    "plt.plot(pred[0][ind])\n",
    "plt.plot(y_test[0][ind])\n",
    "# plt.plot(y_test[ind][:,0])\n",
    "plt.figure(2)\n",
    "plt.plot(pred[1][ind])\n",
    "plt.plot(y_test[1][ind])\n",
    "# plt.plot(y_test[ind][:,1])\n",
    "\n",
    "print(Y_text_test[ind])\n",
    "st = np.argmax(pred[0][ind])\n",
    "en = np.argmax(pred[1][ind][st:]) + st\n",
    "vect = X_test[0][ind, st:en+1]\n",
    "vect = tokenizer.decode(vect)\n",
    "print(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(pred, X, X_text):\n",
    "    prediction = []\n",
    "    for i, elt in tqdm(enumerate(X[0]), total = len(X[0])):\n",
    "        \n",
    "        st = np.argmax(pred[0][i])\n",
    "        en = np.argmax(pred[1][i][st:]) + st\n",
    "        \n",
    "#         print(st)\n",
    "        \n",
    "        vect = X[0][i, st:en+1]\n",
    "        vect = tokenizer.decode(vect)\n",
    "        \n",
    "        # get closest inference\n",
    "        vect = vect.split()\n",
    "        true = X_text[i].lower().split()\n",
    "        vect1 = []\n",
    "        for elt in vect:\n",
    "            inf = difflib.get_close_matches(elt, true)\n",
    "            if len(inf) == 0:\n",
    "                vect1.append(elt)\n",
    "            else:\n",
    "                vect1.append(inf[0])\n",
    "        vect1 = ' '.join(vect1)\n",
    "        \n",
    "        prediction.append(vect1)\n",
    "#         prediction.append(' '.join(vect))\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "def evaluate(prediction, true):\n",
    "    value = []\n",
    "    for i in range(len(prediction)):\n",
    "        str1 = true[i]\n",
    "        str2 = prediction[i]\n",
    "        \n",
    "        value.append(jaccard(str1, str2))\n",
    "    score = np.mean(value)\n",
    "    \n",
    "    return value, score\n",
    "\n",
    "# import optuna\n",
    "# def objective(trial):\n",
    "#     x = trial.suggest_uniform('x', 0, 1)\n",
    "    \n",
    "#     prediction = inference(pred, X_test, x, X_text_test)\n",
    "#     value,j = evaluate(prediction, Y_text_test)\n",
    "#     print(j)\n",
    "    \n",
    "#     return 1-j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbbcbc3515d0447a87a39c39eb428fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2749.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = inference(pred, X_test, X_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "value, score = evaluate(prediction, Y_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.711801843272163"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 267.,  145.,  182.,  130.,   44.,  236.,   43.,   33.,   65.,\n",
       "        1604.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
