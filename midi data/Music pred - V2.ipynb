{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mido  # importe la bibliothèque MidO qui gère aussi RtMidi\n",
    "import time  # importe le module Time Python\n",
    "import pretty_midi\n",
    "from tqdm.auto import tqdm\n",
    "pd.set_option('display.max_rows',150)\n",
    "import _pickle as pickle\n",
    "import os\n",
    "def save(file,name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'wb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'wb')\n",
    "    pickle.dump(file, outfile)\n",
    "    outfile.close\n",
    "    \n",
    "def load(name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'rb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'rb')\n",
    "    file = pickle.load(outfile)\n",
    "    outfile.close\n",
    "    return file\n",
    "\n",
    "import random\n",
    "import gc\n",
    "\n",
    "from tf_transformers2 import *\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, TimeDistributed, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(mid):\n",
    "    try:\n",
    "        port = mido.open_output('Microsoft GS Wavetable Synth 0')\n",
    "\n",
    "        # chemin absolu vers le fichier .mid, ici \"blackvelvet.mid\"\n",
    "\n",
    "\n",
    "        # affiche chemin fichier Midi + son type + nb de pistes + nb de messages dans fichier\n",
    "        print(\"=>\", mid, \"...\\n... ...\")\n",
    "\n",
    "        # calcul + affiche la durée de lecture du fichier Midi en h:m:s\n",
    "        print(\"=> Durée de lecture =\", time.strftime('%Hh:%Mm:%Ss', time.gmtime(mid.length)))\n",
    "        print(\"=> Lecture en cours...\")\n",
    "\n",
    "        for msg in mid.play():  \n",
    "            port.send(msg)\n",
    "\n",
    "        port.close()  # ferme proprement le port Midi\n",
    "        print(\"=> Fichier MIDI lu... ARRÊT !\")\n",
    "    except:\n",
    "        print('interrupted')\n",
    "        port.close()\n",
    "        \n",
    "def play_from_pretty(mid):\n",
    "    mid.write('temp.mid')\n",
    "    mid1 = mido.MidiFile('temp.mid')\n",
    "    play(mid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play(mid.tracks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = pretty_midi.PrettyMIDI('./data/0/009count.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inst_to_seq(inst):\n",
    "    \n",
    "    inst_code = inst.program\n",
    "    inst_type_code = inst.is_drum*1\n",
    "    inst_name = inst.name\n",
    "    ins = []\n",
    "    inst_type = []\n",
    "    name = []\n",
    "    t = []\n",
    "    d = []\n",
    "    p = []\n",
    "    v = []\n",
    "    \n",
    "    \n",
    "    for note in inst.notes:\n",
    "        name.append(inst_name)\n",
    "        ins.append(inst_code)\n",
    "        inst_type.append(inst_type_code)\n",
    "        t.append(note.start)\n",
    "        d.append(-note.start + note.end)\n",
    "        p.append(note.pitch)\n",
    "        v.append(note.velocity)\n",
    "        \n",
    "    ins = np.array(ins)\n",
    "    inst_type = np.array(inst_type)\n",
    "    tim = np.array(t)\n",
    "    num = np.array([d, p, v]).T\n",
    "    return ins, inst_type, tim, num, name\n",
    "    \n",
    "def mid_to_seq(mid):\n",
    "    \n",
    "    ins = []\n",
    "    ins_type = []\n",
    "    tim = []\n",
    "    num = []\n",
    "    name = []\n",
    "    \n",
    "    for inst in mid.instruments:\n",
    "        i, it, t, n, na = inst_to_seq(inst)\n",
    "        \n",
    "        ins.append(i)\n",
    "        ins_type.append(it)\n",
    "        tim.append(t)\n",
    "        num.append(n)\n",
    "        name.append(na)\n",
    "    \n",
    "    ins = np.concatenate(ins).astype(int)\n",
    "    ins_type = np.concatenate(ins_type).astype(float)\n",
    "    tim = np.concatenate(tim).astype(float)\n",
    "    num = np.concatenate(num).astype(float)\n",
    "    name = np.concatenate(name).astype(str)\n",
    "    \n",
    "    sort_index = np.argsort(tim)\n",
    "    \n",
    "    ins = ins[sort_index]\n",
    "    ins_type = ins_type[sort_index]\n",
    "    tim = tim[sort_index]\n",
    "    num = num[sort_index]\n",
    "    name = name[sort_index]\n",
    "    \n",
    "    seq = {\n",
    "        'instruments' : ins,\n",
    "        'is_drum' : ins_type,\n",
    "        'time' : tim,\n",
    "        'num' : num,\n",
    "        'name' : name\n",
    "    }\n",
    "    return seq\n",
    "\n",
    "def seq_to_mid(seq):\n",
    "    ins, ins_type, tim, num, name = seq['instruments'], seq['is_drum'], seq['time'], seq['num'], seq['name']\n",
    "    \n",
    "    instru = np.unique(ins)\n",
    "    \n",
    "    mid = pretty_midi.PrettyMIDI()\n",
    "    for i in instru:\n",
    "        is_drum = (np.unique(ins_type[ins == i])[0] == 1)\n",
    "        inst_name = (np.unique(name)[0] == 1)\n",
    "        \n",
    "        inst = pretty_midi.Instrument(program=i, is_drum = is_drum, name = inst_name)\n",
    "        \n",
    "        time_start = tim[ins == i]\n",
    "        duration = num[ins == i, 0]\n",
    "        pitch = num[ins == i, 1]\n",
    "        velocity = num[ins == i, 2]\n",
    "        \n",
    "        for j, t in enumerate(time_start):\n",
    "            note = pretty_midi.Note(velocity=int(round(velocity[j], 0)), pitch=int(round(pitch[j], 0)), start=t, end=t +duration[j])\n",
    "            inst.notes.append(note)\n",
    "        mid.instruments.append(inst)\n",
    "    return mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = mid_to_seq(mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid1 = seq_to_mid(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_from_pretty(mid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file = []\n",
    "for path, subdirs, files in os.walk('./data'):\n",
    "    for name in files:\n",
    "        path_file.append(os.path.join(path, name))\n",
    "#         print(os.path.join(path, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file_clean  =[]\n",
    "for elt in path_file:\n",
    "    if elt[-3:].lower() == 'mid':\n",
    "        path_file_clean.append(elt.replace('\\\\', '/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = []\n",
    "not_added  =[]\n",
    "count= 0\n",
    "count_not_added = 0\n",
    "for elt in tqdm(path_file_clean):\n",
    "    try:\n",
    "        mid = pretty_midi.PrettyMIDI(elt)\n",
    "        seq = mid_to_seq(mid)\n",
    "        batch.append(seq)\n",
    "        if len(batch) == 500:\n",
    "            save(batch, './batch/batch_'+str(count))\n",
    "            count+=1\n",
    "            batch = []\n",
    "    except:\n",
    "        not_added.append(elt)\n",
    "        print(elt)\n",
    "        print(count_not_added)\n",
    "        count_not_added+=1\n",
    "        \n",
    "save(batch, './batch/batch_'+str(count))      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch_loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batch = load('batch_0', 'batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequence(x, max_len = 256, start = True):\n",
    "    inst  = x['instruments']\n",
    "    drum = x['is_drum']\n",
    "    tim = x['time']\n",
    "    num = x['num']\n",
    "    \n",
    "    size = len(inst)\n",
    "    \n",
    "    \n",
    "    sort_indices = np.argsort(tim)\n",
    "    \n",
    "    for elt in np.unique(tim):\n",
    "        indices_to_resort = sort_indices[tim == elt]\n",
    "        \n",
    "        s = np.argsort(inst[indices_to_resort])\n",
    "        indices_to_resort = indices_to_resort[s]\n",
    "        sort_indices[tim == elt] = indices_to_resort\n",
    "    inst = inst[sort_indices]\n",
    "    drum = drum[sort_indices]\n",
    "    num = num[sort_indices]\n",
    "    \n",
    "    \n",
    "    if size < max_len + 10:\n",
    "        inst = np.concatenate([inst, np.zeros(max_len+10)+154])\n",
    "        drum = np.concatenate([drum, np.zeros(max_len+10)])\n",
    "        tim = np.concatenate([tim, np.zeros(max_len+10)])\n",
    "        num = np.concatenate([num, np.zeros((max_len+10, 3))])\n",
    "    \n",
    "    if start == True:\n",
    "        start_tok = 0\n",
    "        first = 150\n",
    "    else:\n",
    "        try:\n",
    "            start_tok = random.randint(10, size - max_len -10)\n",
    "            first = 151\n",
    "        except:\n",
    "            start_tok = 0\n",
    "            first = 150\n",
    "    \n",
    "    unique_inst = np.unique(inst)\n",
    "    \n",
    "    seq = [first]\n",
    "    for elt in unique_inst:\n",
    "        seq.append(elt)\n",
    "    seq.append(152)\n",
    "    \n",
    "    size1 = len(seq)\n",
    "    \n",
    "    seq = np.array(seq)\n",
    "    \n",
    "    seq = np.concatenate([seq, inst[start_tok : start_tok + max_len + 1 - size1]]).astype(int)\n",
    "    seq_drum = np.concatenate([np.zeros(size1), drum[start_tok : start_tok + max_len + 1 - size1]]).astype(int)\n",
    "    seq_tim = np.concatenate([np.zeros(size1), tim[start_tok : start_tok + max_len + 1 - size1]]).astype('float')\n",
    "    seq_num = np.concatenate([np.zeros((size1,3)), num[start_tok : start_tok + max_len + 1 - size1,:]]).astype('float')\n",
    "    \n",
    "    return seq, seq_drum, seq_tim, seq_num\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq, seq_drum, seq_tim, seq_num = build_sequence(batch[0], max_len = 256, start = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_tim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq[seq_tim == seq_tim[25]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class Generator(Sequence):\n",
    "    def __init__(self,file_list, batch_size = 32, start_rate = 0.2, max_len = 256, model_inst = None, model_delta = None):\n",
    "        self.file_list = file_list\n",
    "        self.batch_size = batch_size\n",
    "        self.start_rate = start_rate\n",
    "        self.max_len = max_len\n",
    "        self.model_inst = model_inst\n",
    "        self.model_delta = model_delta\n",
    "                 \n",
    "                 \n",
    "    def __len__(self):\n",
    "        return int(10000000)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        gc.collect()\n",
    "        file = random.choice(self.file_list).split('.')[0]\n",
    "        total_batch = load(file, 'batch')\n",
    "        \n",
    "        batch = np.random.choice(total_batch, size = self.batch_size)\n",
    "        \n",
    "        del total_batch\n",
    "        gc.collect()\n",
    "        \n",
    "        seq_inst = []\n",
    "        seq_drum = []\n",
    "        seq_time = []\n",
    "        seq_num = []\n",
    "        \n",
    "        for seq in batch:\n",
    "            \n",
    "            r = random.uniform(0,1)\n",
    "            if r < self.start_rate:\n",
    "                start = True\n",
    "            else:\n",
    "                start = False\n",
    "            \n",
    "            si, sd, st, sn = build_sequence(seq, max_len = self.max_len, start = start)\n",
    "#             print(st.shape)\n",
    "            seq_inst.append(si)\n",
    "            seq_drum.append(sd)\n",
    "            seq_time.append(st)\n",
    "            seq_num.append(sn)\n",
    "        \n",
    "        del batch\n",
    "        gc.collect()\n",
    "        \n",
    "        seq_inst = np.array(seq_inst)\n",
    "        seq_drum = np.array(seq_drum)\n",
    "        seq_time = np.array(seq_time)\n",
    "        delta_time = seq_time[:, :-1] - seq_time[:,1:]\n",
    "#         print(delta_time.shape)\n",
    "#         print(seq_time.shape)\n",
    "        seq_time = seq_time.reshape((seq_time.shape[0], seq_time.shape[1], 1))\n",
    "#         delta_time = delta_time.reshape((delta_time.shape[0], delta_time.shape[1], 1))\n",
    "        seq_num = np.array(seq_num)\n",
    "        \n",
    "        X = [seq_inst[:,:-1], seq_drum[:,:-1],seq_time[:,:-1],seq_num[:,:-1]]\n",
    "        y = [seq_inst[:,1:], seq_drum[:,1:],delta_time,seq_num[:,1:,0],seq_num[:,1:,1],seq_num[:,1:,2]]\n",
    "                 \n",
    "        if self.model_inst == None:\n",
    "            return X, y[0]\n",
    "        \n",
    "        elif (self.model_inst != None) & (self.model_delta == None):\n",
    "            pred_ind = self.model_inst.predict(X)\n",
    "            pred_ind = np.argmax(pred_ind, axis = -1)\n",
    "            X.append(pred_ind)\n",
    "            return X, y[2]\n",
    "        else:\n",
    "            pred_ind = self.model_inst.predict(X)\n",
    "            pred_delta = self.model_delta.predict(X)\n",
    "            pred_ind = np.argmax(pred_ind, axis = -1)\n",
    "            pred_delta = np.argmax(pred_delta, axis = -1)\n",
    "            X.append(pred_ind)\n",
    "            X.append(pred_delta)\n",
    "            return X, y[3:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir('./batch')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(file_list, batch_size = 4, start_rate = 0.2, max_len = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X, y = gen[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDecoder(tf.keras.layers.Layer):    \n",
    "    def __init__(self, num_layers, d_model, num_heads, dff,\n",
    "               maximum_position_encoding, num_types = 2, rate=0.1, bidirectional_decoder = False):\n",
    "        super(GPTDecoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(155, d_model)\n",
    "        self.drum_embedding = tf.keras.layers.Embedding(2, d_model)\n",
    "        \n",
    "        self.time_encoding = tf.keras.layers.Dense(d_model, activation = 'relu')\n",
    "        \n",
    "        self.num_encoding = tf.keras.layers.Dense(d_model, activation = 'relu')\n",
    "        self.delta_encoding = tf.keras.layers.Dense(d_model, activation = 'relu')\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "        \n",
    "        self.conc = tf.keras.layers.Concatenate()\n",
    "        self.agg = tf.keras.layers.Dense(d_model, activation = 'relu')\n",
    "        \n",
    "        self.dec_layers = [GPTDecoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "        self.bidirectional_decoder = bidirectional_decoder\n",
    "    \n",
    "    def call(self, x, training = True, drum_ids = None, time_ids = None, num_ids = None, pred_x = None, pred_delta = None):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "        \n",
    "        if self.bidirectional_decoder == False:\n",
    "            look_ahead_mask = create_look_ahead_mask(tf.shape(x)[1])\n",
    "            dec_target_padding_mask = create_padding_mask(x, pad_token = 154)\n",
    "            mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "        else:\n",
    "            mask = create_padding_mask(x, pad_token = 154)\n",
    "        \n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        \n",
    "#         c = [x]\n",
    "#         c.append(self.time_encoding(time_ids))\n",
    "#         c.append(self.drum_embedding(drum_ids))\n",
    "#         c.append(self.num_encoding(num_ids))\n",
    "        \n",
    "        \n",
    "#         if pred_x is not None:\n",
    "#             c.append(self.embedding(pred_x))\n",
    "#         if pred_delta:\n",
    "#             c.append(self.delta_encoding(x))\n",
    "        \n",
    "#         x = self.conc(c)\n",
    "#         x = self.agg(x)\n",
    "        \n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1 = self.dec_layers[i](x, training, look_ahead_mask = mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "#            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_ind = GPTDecoder(num_layers = 2, d_model = 256, num_heads = 8, dff = 512,\n",
    "                   maximum_position_encoding = 1024, num_types = 2, rate=0.1, bidirectional_decoder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 512\n",
    "inputs_inst = Input(shape = (max_len,))\n",
    "drum_ids = Input(shape = ( max_len,))\n",
    "time_ids = Input(shape = ( max_len,1))\n",
    "num_ids = Input(shape = ( max_len,3))\n",
    "\n",
    "inputs = [inputs_inst, drum_ids, time_ids, num_ids]\n",
    "\n",
    "encoded, _ = decoder_ind(inputs_inst, training = True, drum_ids = drum_ids, time_ids = time_ids, num_ids = num_ids)\n",
    "\n",
    "output_inst = tf.keras.layers.Dense(156, name = 'inst')(encoded)\n",
    "# output_drum = tf.keras.layers.Dense(2, activation = 'softmax', name = 'drum')(encoded)\n",
    "# output_time = tf.keras.layers.Dense(1, activation = 'linear', name = 'time')(encoded)\n",
    "# output_duration = tf.keras.layers.Dense(1, activation = 'linear', name = 'duration')(encoded)\n",
    "# output_pitch = tf.keras.layers.Dense(130, activation = 'softmax', name = 'pitch')(encoded)\n",
    "# output_velocity = tf.keras.layers.Dense(130, activation = 'softmax', name = 'velocity')(encoded)\n",
    "\n",
    "\n",
    "# outputs = [output_inst]\n",
    "\n",
    "model_ind = Model(inputs, output_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 512, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 512, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gpt_decoder (GPTDecoder)        ((None, 512, 256), { 1093888     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "inst (Dense)                    (None, 512, 156)     40092       gpt_decoder[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,133,980\n",
      "Trainable params: 1,133,980\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_ind.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                    from_logits=True, reduction='none')\n",
    "\n",
    "losses = [loss_object]\n",
    "\n",
    "loss_classif     =  losses# find the right loss for multi-class classification\n",
    "optimizer        =  Adam(3e-5, 1e-8) # find the right optimizer\n",
    "metrics_classif  =  ['accuracy']\n",
    "\n",
    "model_ind.compile(loss=loss_classif,\n",
    "              optimizer=optimizer,\n",
    "              metrics=metrics_classif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 100 steps, validate on 512 samples\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 175s 2s/step - loss: 2.9375 - accuracy: 0.4853 - val_loss: 2.7825 - val_accuracy: 0.4899\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 264s 3s/step - loss: 2.2565 - accuracy: 0.5855 - val_loss: 2.3750 - val_accuracy: 0.5386\n",
      "Epoch 3/10\n",
      " 10/100 [==>...........................] - ETA: 6:36 - loss: 2.3197 - accuracy: 0.5621"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-f5bd52ec1ee4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/GPU:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_ind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#, callbacks = [early, reduce])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_list = os.listdir('./batch')[:-1]\n",
    "test_list = [ os.listdir('./batch')[-1]]\n",
    "## Test_set\n",
    "gen = Generator(test_list, batch_size = 512, start_rate = 0.2, max_len = max_len)\n",
    "x_test, y_test = gen[0]\n",
    "gen = Generator(train_list, batch_size = 32, start_rate = 0.2, max_len = max_len)\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=4, verbose=1, \n",
    "                                                mode='auto', restore_best_weights=True)\n",
    "reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, \n",
    "                                                     mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "# bs = 128\n",
    "n_epochs = 10\n",
    "steps_per_epoch = 100\n",
    "#, batch_size=bs\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model_ind.fit(gen,  epochs=n_epochs,steps_per_epoch = steps_per_epoch, validation_data=(x_test,  y_test))#, callbacks = [early, reduce])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints/model_inst.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 1s 3ms/sample\n"
     ]
    }
   ],
   "source": [
    "pred = model_ind.predict(x_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(pred, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  50,   0,  24,   1,  38,  60,  40,  40,  32,  50,  32,  32,\n",
       "        38,   0,  50,   0,   0,  40,  50,  45,  25,  27,  24,  40,  24,\n",
       "        40,  32,  60,   1,  19,  71,  24,  25,  24,   0,  24,  24,  32,\n",
       "        32,  24,  24,  25,  40,  32,  24,  25,  25,  25,  25,  24,  25,\n",
       "        40,  40,  40,  40,   0,  24,   0,  50,  25,  25,  25,  25,   1,\n",
       "        24,  26,  26,  43,  32,  24,   0,  32,  26,  26,  48,  48,  32,\n",
       "        50,  48,  32,  50,  58,  58,   0,   0,   0,  50,  40,  24,   0,\n",
       "        32,  25,  32,  25,  24,  40,   1,  32,  40,   1,  32,   1,   1,\n",
       "        24,   1,  24,  32,   1,   1,  32,  26,  26,  26,  26,   1,  32,\n",
       "        40,  26,  26, 154,  25,  33,   1,  40,  16,  40,  40,  40,  40,\n",
       "        25,  25,  48,   1,  25,  25,  25,  26,  26,  40,   0,  16,  26,\n",
       "        40,  40,  40,  50,   1,  48,  24,  48,   1,  25,  25,   0,  24,\n",
       "        26,  45,  50,   1,  32,  16,  40,  25,   0,  45,  24,  24,  50,\n",
       "        48,  48,  24,  16,  26,   0,   0,  24,  26,  24,  32,  16,  48,\n",
       "        25,  32,  32,  16,  48,  33,  32,  32,  32,  24,  24,  25,  32,\n",
       "        40,  32,  50,  48,  16,   1,  32,  32,   0,   0,   0,  40,   0,\n",
       "         0,   0,  25,  14,  25,   0,  25,  25,   0,   0,  25,  40,   0,\n",
       "        32,  24,   0,  32,  24,   0,  16,   0,  25,  32,  32,  24, 154,\n",
       "        32,  32,  32,  12,   0,  25,  25,   0,  24,  24,  25,  27,  32,\n",
       "        32,  32,  32,  16,   1,  40,  32,  32,  48,   0,  48,   0,   0,\n",
       "         0,  32,  32,   0,  32,   0,   1,  32,   1,  25,  56,  40,  32,\n",
       "        40,  32,   0,   0,   0,  40,  40,   0,  32,  40,  32,  24,   0,\n",
       "        40,  40,  40,  32,  24,   1,  40,  40,   0,   0,  32,   1,   1,\n",
       "         0,  32,  19, 154,  24,  40,  25,   0,  24,   0,  24,   0, 128,\n",
       "        40,  40,  40,   1,  48,   0,  40,  40,  16,  16,  40,  50,  26,\n",
       "        40,  40,   0,   0,  25,  40,  25,   0,  58,  24,   0,  24,   0,\n",
       "        25,   0,  58,  48,   0,  40,  25,  24,  24,  40,  40,  24,  40,\n",
       "        32,  25,   2,  48,  32,  32,  48,  48,  25,  25,  16,  48,  58,\n",
       "        26,  40,  25,  40,  25,  25,  25,  25,  25,  25,  40,  19,  48,\n",
       "        32,  40,  48, 154,  32,   0,  49,  25,  40,  40,  40,  40,   0,\n",
       "        40,  50,   0,  40,  40,  40, 154,   0,  32,  25,  50,  60,   1,\n",
       "         1,  40,  40,   0,  32,   1,   0,  40,  40,  40,  32,  50,  32,\n",
       "         0,   0,  33,  32,  48, 154,  45,  45,  40,  60,   1,  32,   0,\n",
       "         0,   0,   1,   0,  32,   0,  32,   1,  32,  32,  32,  32,   0,\n",
       "         1,  32,  32,  25,   1,  40,  25,  40,  32,  19,  32,  40,  32,\n",
       "       154,  32,  32,  32,  19, 154,   0,   0,  32,  24,   1,  24,   1,\n",
       "        32,  25,  25,  32,  25,  32,  32,  32,  32,  48,   1,  16,  26,\n",
       "        49,  26,  25,  25,  25,   0,  25,  45,   0,  32,  45,  25,  25,\n",
       "        32,  16,  19,  16,  33,   0,   0,   0, 154,   1,   0,  25,  25,\n",
       "        25,  25,  25,  25, 154], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151,  11,  32,  45,  50,  72, 152,  50,  72,  32,  45,  72,  32,\n",
       "        45,  72,  45,  72,  32,  32,  45,  72,  32,  45,  72,  32,  32,\n",
       "        32,  32,  45,  72,  32,  45,  72,  32,  45,  72,  45,  72,  32,\n",
       "        32,  32,  45,  72,  32,  32,  45,  72,  32,  32,  32,  45,  72,\n",
       "        32,  32,  32,  45,  72,  45,  72,  45,  72,  32,  32,  32,  45,\n",
       "        72,  32,  45,  72,  32,  45,  72,  32,  32,  32,  45,  72,  32,\n",
       "        45,  72,  32,  45,  72,  45,  72,  32,  32,  45,  72,  45,  72,\n",
       "        32,  32,  32,  32,  32,  45,  50,  32,  45,  50,  32,  45,  50,\n",
       "        45,  50,  32,  32,  45,  50,  32,  45,  50,  32,  45,  50,  32,\n",
       "        32,  32,  45,  50,  32,  45,  50,  32,  45,  50,  45,  50,  32,\n",
       "        32,  32,  45,  50,  32,  32,  45,  50,  32,  32,  32,  45,  50,\n",
       "        32,  32,  32,  45,  50,  45,  50,  45,  50,  32,  32,  32,  45,\n",
       "        50,  32,  45,  50,  32,  45,  50,  32,  32,  32,  45,  50,  45,\n",
       "        50,  45,  50,  45,  50,  32,  32,  45,  50,  45,  50,  45,  72,\n",
       "        32,  32,  32,  45,  72,  32,  32,  32,  32,  45,  72,  32,  32,\n",
       "        32,  32,  45,  72,  45,  72,  32,  32,  45,  72,  32,  32,  45,\n",
       "        72,  32,  32,  45,  72,  32,  32,  32,  45,  72,  32,  32,  32,\n",
       "        32,  45,  72,  32,  45,  72,  32,  32,  32,  32,  32,  45,  72,\n",
       "        32,  32,  32,  45,  72,  32,  32,  32,  45,  72,  45,  72,  32,\n",
       "        45,  72,  32,  45,  72,  32,  32,  32,  45,  72,  45,  72,  45,\n",
       "        72,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,\n",
       "        32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  45,  72,\n",
       "        32,  32,  32,  32,  45,  72,  32,  32,  32,  32,  45,  72,  45,\n",
       "        72,  32,  32,  45,  72,  32,  32,  45,  72,  32,  32,  45,  72,\n",
       "        32,  32,  32,  45,  72,  32,  32,  32,  32,  45,  72,  45,  72,\n",
       "        32,  32,  32,  32,  32,  32,  32,  45,  72,  45,  72,  45,  72,\n",
       "        32,  32,  45,  72,  32,  32,  32,  45,  72,  32,  32,  45,  72,\n",
       "        32,  32,  45,  72,  32,  32,  45,  72,  32,  32,  32,  45,  72,\n",
       "        32,  32,  32,  32,  32,  32,  32,  45,  72,  32,  32,  45,  72,\n",
       "        32,  32,  45,  72,  32,  32,  45,  72,  32,  32,  45,  72,  32,\n",
       "        32,  45,  72,  32,  32,  45,  72,  32,  32,  32,  45,  45,  50,\n",
       "        72,  32,  32,  32,  32,  45,  50,  32,  32,  32,  32,  45,  50,\n",
       "        45,  50,  32,  32,  45,  50,  32,  32,  32,  45,  50,  32,  32,\n",
       "        32,  45,  50,  32,  32,  32,  32,  45,  50,  32,  32,  32,  32,\n",
       "        45,  50,  32,  32,  45,  50,  32,  32,  32,  32,  32,  32,  32,\n",
       "        45,  50,  32,  32,  45,  50,  32,  32,  32,  45,  50,  45,  50,\n",
       "        32,  45,  50,  32,  45,  50,  32,  32,  32,  45,  50,  45,  50,\n",
       "        45,  50,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,  32,\n",
       "        32,  32,  32,  32,  32,  32,  32,  45,  45,  50,  72,  32,  32,\n",
       "        32,  32,  45,  45,  50])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0][ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(file_list, batch_size = 4, start_rate = 0.2, max_len = max_len, model_inst = model_ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X, y = gen[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
