{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mido  # importe la bibliothèque MidO qui gère aussi RtMidi\n",
    "import time  # importe le module Time Python\n",
    "import pretty_midi\n",
    "from tqdm.auto import tqdm\n",
    "pd.set_option('display.max_rows',150)\n",
    "import _pickle as pickle\n",
    "import os\n",
    "def save(file,name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'wb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'wb')\n",
    "    pickle.dump(file, outfile)\n",
    "    outfile.close\n",
    "    \n",
    "def load(name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'rb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'rb')\n",
    "    file = pickle.load(outfile)\n",
    "    outfile.close\n",
    "    return file\n",
    "\n",
    "import random\n",
    "import gc\n",
    "\n",
    "from tf_transformers2 import *\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, TimeDistributed, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(mid):\n",
    "    try:\n",
    "        port = mido.open_output('Microsoft GS Wavetable Synth 0')\n",
    "\n",
    "        # chemin absolu vers le fichier .mid, ici \"blackvelvet.mid\"\n",
    "\n",
    "\n",
    "        # affiche chemin fichier Midi + son type + nb de pistes + nb de messages dans fichier\n",
    "        print(\"=>\", mid, \"...\\n... ...\")\n",
    "\n",
    "        # calcul + affiche la durée de lecture du fichier Midi en h:m:s\n",
    "        print(\"=> Durée de lecture =\", time.strftime('%Hh:%Mm:%Ss', time.gmtime(mid.length)))\n",
    "        print(\"=> Lecture en cours...\")\n",
    "\n",
    "        for msg in mid.play():  \n",
    "            port.send(msg)\n",
    "\n",
    "        port.close()  # ferme proprement le port Midi\n",
    "        print(\"=> Fichier MIDI lu... ARRÊT !\")\n",
    "    except:\n",
    "        print('interrupted')\n",
    "        port.close()\n",
    "        \n",
    "def play_from_pretty(mid):\n",
    "    mid.write('temp.mid')\n",
    "    mid1 = mido.MidiFile('temp.mid')\n",
    "    play(mid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play(mid.tracks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = pretty_midi.PrettyMIDI('./data/0/009count.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_PrettyMIDI__tick_to_time',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_load_instruments',\n",
       " '_load_metadata',\n",
       " '_load_tempo_changes',\n",
       " '_tick_scales',\n",
       " '_update_tick_to_time',\n",
       " 'adjust_times',\n",
       " 'estimate_beat_start',\n",
       " 'estimate_tempi',\n",
       " 'estimate_tempo',\n",
       " 'fluidsynth',\n",
       " 'get_beats',\n",
       " 'get_chroma',\n",
       " 'get_downbeats',\n",
       " 'get_end_time',\n",
       " 'get_onsets',\n",
       " 'get_piano_roll',\n",
       " 'get_pitch_class_histogram',\n",
       " 'get_pitch_class_transition_matrix',\n",
       " 'get_tempo_changes',\n",
       " 'instruments',\n",
       " 'key_signature_changes',\n",
       " 'lyrics',\n",
       " 'remove_invalid_notes',\n",
       " 'resolution',\n",
       " 'synthesize',\n",
       " 'tick_to_time',\n",
       " 'time_signature_changes',\n",
       " 'time_to_tick',\n",
       " 'write']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> <midi file 'temp.mid' type 1, 8 tracks, 10284 messages> ...\n",
      "... ...\n",
      "=> Durée de lecture = 00h:04m:57s\n",
      "=> Lecture en cours...\n",
      "interrupted\n"
     ]
    }
   ],
   "source": [
    "play_from_pretty(mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319242.44825096196"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5033/4)*mid.estimate_tempo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mid.get_piano_roll(fs = mid.estimate_tempo()/60*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Instrument(program=1, is_drum=False, name=\"\"),\n",
       " Instrument(program=8, is_drum=False, name=\"\"),\n",
       " Instrument(program=25, is_drum=False, name=\"\"),\n",
       " Instrument(program=33, is_drum=False, name=\"\"),\n",
       " Instrument(program=48, is_drum=False, name=\"\"),\n",
       " Instrument(program=16, is_drum=True, name=\"\"),\n",
       " Instrument(program=52, is_drum=False, name=\"\")]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mid.instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method get_piano_roll in module pretty_midi.pretty_midi:\n",
      "\n",
      "get_piano_roll(fs=100, times=None, pedal_threshold=64) method of pretty_midi.pretty_midi.PrettyMIDI instance\n",
      "    Compute a piano roll matrix of the MIDI data.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    fs : int\n",
      "        Sampling frequency of the columns, i.e. each column is spaced apart\n",
      "        by ``1./fs`` seconds.\n",
      "    times : np.ndarray\n",
      "        Times of the start of each column in the piano roll.\n",
      "        Default ``None`` which is ``np.arange(0, get_end_time(), 1./fs)``.\n",
      "    pedal_threshold : int\n",
      "        Value of control change 64 (sustain pedal) message that is less\n",
      "        than this value is reflected as pedal-off.  Pedals will be\n",
      "        reflected as elongation of notes in the piano roll.\n",
      "        If None, then CC64 message is ignored.\n",
      "        Default is 64.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    piano_roll : np.ndarray, shape=(128,times.shape[0])\n",
      "        Piano roll of MIDI data, flattened across instruments.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(mid.get_piano_roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.     ,   4.03125,   4.8125 ,   5.15625,   5.5    ,   5.625  ,\n",
       "         6.125  ,   6.25   ,   6.5625 ,   7.3125 ,   7.5    ,   7.59375,\n",
       "         7.96875,   8.15625,   8.59375,   9.1875 ,  10.125  ,  10.9375 ,\n",
       "        11.25   ,  11.71875,  12.125  ,  12.1875 ,  12.25   ,  13.5    ,\n",
       "        13.59375,  14.0625 ,  14.75   ,  15.     ,  15.3125 ,  16.71875,\n",
       "        18.375  ,  29.     ,  33.     ,  37.     ,  43.     ,  45.     ,\n",
       "        50.     ,  51.     ,  55.     ,  59.     ,  60.     ,  61.     ,\n",
       "        63.     ,  63.28125,  63.4375 ,  65.     ,  65.8125 ,  68.     ,\n",
       "        69.     ,  70.     ,  70.6875 ,  70.875  ,  72.     ,  72.1875 ,\n",
       "        72.5    ,  73.40625,  74.     ,  75.     ,  77.     ,  77.03125,\n",
       "        78.     ,  78.75   ,  78.84375,  79.     ,  80.     ,  81.     ,\n",
       "        82.     ,  82.5    ,  82.6875 ,  83.     ,  84.     ,  84.375  ,\n",
       "        85.     ,  85.75   ,  86.     ,  87.     ,  88.     ,  88.8125 ,\n",
       "        89.     ,  90.     ,  91.     ,  91.875  ,  92.     ,  93.     ,\n",
       "        93.75   ,  94.     ,  95.     ,  96.     ,  97.     ,  98.     ,\n",
       "        99.     , 100.     , 101.     , 102.     , 102.59375, 103.     ,\n",
       "       103.1875 , 103.25   , 104.     , 105.     , 106.     , 106.15625,\n",
       "       106.25   , 107.     , 108.     , 108.1875 , 109.     , 109.3125 ,\n",
       "       110.     , 111.     , 112.     , 113.     , 114.     , 114.4375 ,\n",
       "       116.     , 117.     , 117.25   , 118.     , 119.     , 120.     ,\n",
       "       120.0625 , 121.     , 122.     , 124.     , 125.     , 126.96875,\n",
       "       127.     , 129.     , 131.     , 135.     , 138.     , 144.     ,\n",
       "       144.40625, 147.     , 153.     , 154.     , 154.8125 , 155.     ,\n",
       "       156.     , 156.4375 , 158.     , 160.     , 161.     , 161.0625 ,\n",
       "       161.84375, 162.     , 163.     , 165.6875 , 166.     , 167.     ,\n",
       "       168.28125, 168.6875 , 169.     , 169.6875 , 169.875  , 170.     ,\n",
       "       171.     , 172.     , 172.40625, 173.     , 174.     , 174.75   ,\n",
       "       175.     , 175.40625, 175.875  , 176.     , 176.84375, 176.875  ,\n",
       "       177.     , 177.625  , 177.84375, 178.     , 178.0625 , 178.875  ,\n",
       "       179.     , 180.     , 180.6875 , 181.     , 181.75   , 181.9375 ,\n",
       "       182.     , 183.     , 183.75   , 184.     , 184.75   , 185.     ,\n",
       "       186.     , 186.8125 , 187.     , 187.8125 , 188.     , 188.6875 ,\n",
       "       188.75   , 189.     , 190.     , 190.875  , 191.     , 191.75   ,\n",
       "       192.     , 193.     , 194.     , 195.     , 195.5    , 195.75   ,\n",
       "       196.     , 196.8125 , 197.     , 198.     , 199.     , 199.5    ,\n",
       "       200.     , 202.     , 203.     , 204.     , 205.     , 206.     ,\n",
       "       207.     , 208.     , 209.     , 210.     , 211.     , 212.     ,\n",
       "       213.     , 214.     , 215.     , 215.25   , 217.     , 218.     ,\n",
       "       219.     , 220.     , 221.     , 222.25   , 223.     , 224.     ,\n",
       "       224.25   , 225.     , 226.     , 227.     , 228.     , 229.     ,\n",
       "       230.     , 232.     , 233.     , 234.     , 235.     , 237.     ,\n",
       "       254.     , 256.     , 264.     , 264.75   , 266.     , 267.5625 ,\n",
       "       272.     , 276.     , 284.     , 285.28125, 289.9375 , 292.     ,\n",
       "       292.75   , 293.     , 293.75   , 294.     , 297.625  , 300.6875 ,\n",
       "       302.     , 304.     , 305.9375 , 306.     , 313.     , 316.     ,\n",
       "       319.     , 320.     , 398.6875 , 401.75   , 404.8125 , 414.     ])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inst_to_seq(inst):\n",
    "    \n",
    "    inst_code = inst.program\n",
    "    inst_type_code = inst.is_drum*1\n",
    "    inst_name = inst.name\n",
    "    ins = []\n",
    "    inst_type = []\n",
    "    name = []\n",
    "    t = []\n",
    "    d = []\n",
    "    p = []\n",
    "    v = []\n",
    "    \n",
    "    \n",
    "    for note in inst.notes:\n",
    "        name.append(inst_name)\n",
    "        ins.append(inst_code)\n",
    "        inst_type.append(inst_type_code)\n",
    "        t.append(note.start)\n",
    "        d.append(-note.start + note.end)\n",
    "        p.append(note.pitch)\n",
    "        v.append(note.velocity)\n",
    "        \n",
    "    ins = np.array(ins)\n",
    "    inst_type = np.array(inst_type)\n",
    "    tim = np.array(t)\n",
    "    num = np.array([d, p, v]).T\n",
    "    return ins, inst_type, tim, num, name\n",
    "    \n",
    "def mid_to_seq(mid):\n",
    "    \n",
    "    ins = []\n",
    "    ins_type = []\n",
    "    tim = []\n",
    "    num = []\n",
    "    name = []\n",
    "    \n",
    "    for inst in mid.instruments:\n",
    "        i, it, t, n, na = inst_to_seq(inst)\n",
    "        \n",
    "        ins.append(i)\n",
    "        ins_type.append(it)\n",
    "        tim.append(t)\n",
    "        num.append(n)\n",
    "        name.append(na)\n",
    "    \n",
    "    ins = np.concatenate(ins).astype(int)\n",
    "    ins_type = np.concatenate(ins_type).astype(float)\n",
    "    tim = np.concatenate(tim).astype(float)\n",
    "    num = np.concatenate(num).astype(float)\n",
    "    name = np.concatenate(name).astype(str)\n",
    "    \n",
    "    sort_index = np.argsort(tim)\n",
    "    \n",
    "    ins = ins[sort_index]\n",
    "    ins_type = ins_type[sort_index]\n",
    "    tim = tim[sort_index]\n",
    "    num = num[sort_index]\n",
    "    name = name[sort_index]\n",
    "    \n",
    "    seq = {\n",
    "        'instruments' : ins,\n",
    "        'is_drum' : ins_type,\n",
    "        'time' : tim,\n",
    "        'num' : num,\n",
    "        'name' : name\n",
    "    }\n",
    "    return seq\n",
    "\n",
    "def seq_to_mid(seq):\n",
    "    ins, ins_type, tim, num, name = seq['instruments'], seq['is_drum'], seq['time'], seq['num'], seq['name']\n",
    "    \n",
    "    instru = np.unique(ins)\n",
    "    \n",
    "    mid = pretty_midi.PrettyMIDI()\n",
    "    for i in instru:\n",
    "        is_drum = (np.unique(ins_type[ins == i])[0] == 1)\n",
    "        inst_name = (np.unique(name)[0] == 1)\n",
    "        \n",
    "        inst = pretty_midi.Instrument(program=i, is_drum = is_drum, name = inst_name)\n",
    "        \n",
    "        time_start = tim[ins == i]\n",
    "        duration = num[ins == i, 0]\n",
    "        pitch = num[ins == i, 1]\n",
    "        velocity = num[ins == i, 2]\n",
    "        \n",
    "        for j, t in enumerate(time_start):\n",
    "            note = pretty_midi.Note(velocity=int(round(velocity[j], 0)), pitch=int(round(pitch[j], 0)), start=t, end=t +duration[j])\n",
    "            inst.notes.append(note)\n",
    "        mid.instruments.append(inst)\n",
    "    return mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = mid_to_seq(mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid1 = seq_to_mid(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_from_pretty(mid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file = []\n",
    "for path, subdirs, files in os.walk('./data'):\n",
    "    for name in files:\n",
    "        path_file.append(os.path.join(path, name))\n",
    "#         print(os.path.join(path, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file_clean  =[]\n",
    "for elt in path_file:\n",
    "    if elt[-3:].lower() == 'mid':\n",
    "        path_file_clean.append(elt.replace('\\\\', '/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = []\n",
    "not_added  =[]\n",
    "count= 0\n",
    "count_not_added = 0\n",
    "for elt in tqdm(path_file_clean):\n",
    "    try:\n",
    "        mid = pretty_midi.PrettyMIDI(elt)\n",
    "        seq = mid_to_seq(mid)\n",
    "        batch.append(seq)\n",
    "        if len(batch) == 500:\n",
    "            save(batch, './batch/batch_'+str(count))\n",
    "            count+=1\n",
    "            batch = []\n",
    "    except:\n",
    "        not_added.append(elt)\n",
    "        print(elt)\n",
    "        print(count_not_added)\n",
    "        count_not_added+=1\n",
    "        \n",
    "save(batch, './batch/batch_'+str(count))      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch_loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batch = load('batch_0', 'batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequence(x, max_len = 256, start = True):\n",
    "    inst  = x['instruments']\n",
    "    drum = x['is_drum']\n",
    "    tim = x['time']\n",
    "    num = x['num']\n",
    "    \n",
    "    size = len(inst)\n",
    "    \n",
    "    \n",
    "    sort_indices = np.argsort(tim)\n",
    "    \n",
    "    for elt in np.unique(tim):\n",
    "        indices_to_resort = sort_indices[tim == elt]\n",
    "        \n",
    "        s = np.argsort(inst[indices_to_resort])\n",
    "        indices_to_resort = indices_to_resort[s]\n",
    "        sort_indices[tim == elt] = indices_to_resort\n",
    "    inst = inst[sort_indices]\n",
    "    drum = drum[sort_indices]\n",
    "    num = num[sort_indices]\n",
    "    \n",
    "    \n",
    "    if size < max_len + 10:\n",
    "        inst = np.concatenate([inst, np.zeros(max_len+10)+154])\n",
    "        drum = np.concatenate([drum, np.zeros(max_len+10)])\n",
    "        tim = np.concatenate([tim, np.zeros(max_len+10)])\n",
    "        num = np.concatenate([num, np.zeros((max_len+10, 3))])\n",
    "    \n",
    "    if start == True:\n",
    "        start_tok = 0\n",
    "        first = 150\n",
    "    else:\n",
    "        try:\n",
    "            start_tok = random.randint(10, size - max_len -10)\n",
    "            first = 151\n",
    "        except:\n",
    "            start_tok = 0\n",
    "            first = 150\n",
    "    \n",
    "    unique_inst = np.unique(inst)\n",
    "    \n",
    "    seq = [first]\n",
    "    for elt in unique_inst:\n",
    "        seq.append(elt)\n",
    "    seq.append(152)\n",
    "    \n",
    "    size1 = len(seq)\n",
    "    \n",
    "    seq = np.array(seq)\n",
    "    \n",
    "    seq = np.concatenate([seq, inst[start_tok : start_tok + max_len + 1 - size1]]).astype(int)\n",
    "    seq_drum = np.concatenate([np.zeros(size1), drum[start_tok : start_tok + max_len + 1 - size1]]).astype(int)\n",
    "    seq_tim = np.concatenate([np.zeros(size1), tim[start_tok : start_tok + max_len + 1 - size1]]).astype('float')\n",
    "    seq_num = np.concatenate([np.zeros((size1,3)), num[start_tok : start_tok + max_len + 1 - size1,:]]).astype('float')\n",
    "    \n",
    "    return seq, seq_drum, seq_tim, seq_num\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq, seq_drum, seq_tim, seq_num = build_sequence(batch[0], max_len = 256, start = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_tim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq[seq_tim == seq_tim[25]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class Generator(Sequence):\n",
    "    def __init__(self,file_list, batch_size = 32, start_rate = 0.2, max_len = 256, model_inst = None, model_delta = None):\n",
    "        self.file_list = file_list\n",
    "        self.batch_size = batch_size\n",
    "        self.start_rate = start_rate\n",
    "        self.max_len = max_len\n",
    "        self.model_inst = model_inst\n",
    "        self.model_delta = model_delta\n",
    "                 \n",
    "                 \n",
    "    def __len__(self):\n",
    "        return int(10000000)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        gc.collect()\n",
    "        file = random.choice(self.file_list).split('.')[0]\n",
    "        total_batch = load(file, 'batch')\n",
    "        \n",
    "        batch = np.random.choice(total_batch, size = self.batch_size)\n",
    "        \n",
    "        del total_batch\n",
    "        gc.collect()\n",
    "        \n",
    "        seq_inst = []\n",
    "        seq_drum = []\n",
    "        seq_time = []\n",
    "        seq_num = []\n",
    "        \n",
    "        for seq in batch:\n",
    "            \n",
    "            r = random.uniform(0,1)\n",
    "            if r < self.start_rate:\n",
    "                start = True\n",
    "            else:\n",
    "                start = False\n",
    "            \n",
    "            si, sd, st, sn = build_sequence(seq, max_len = self.max_len, start = start)\n",
    "#             print(st.shape)\n",
    "            seq_inst.append(si)\n",
    "            seq_drum.append(sd)\n",
    "            seq_time.append(st)\n",
    "            seq_num.append(sn)\n",
    "        \n",
    "        del batch\n",
    "        gc.collect()\n",
    "        \n",
    "        seq_inst = np.array(seq_inst)\n",
    "        seq_drum = np.array(seq_drum)\n",
    "        seq_time = np.array(seq_time)\n",
    "        delta_time = seq_time[:, :-1] - seq_time[:,1:]\n",
    "#         print(delta_time.shape)\n",
    "#         print(seq_time.shape)\n",
    "        seq_time = seq_time.reshape((seq_time.shape[0], seq_time.shape[1], 1))\n",
    "#         delta_time = delta_time.reshape((delta_time.shape[0], delta_time.shape[1], 1))\n",
    "        seq_num = np.array(seq_num)\n",
    "        \n",
    "        X = [seq_inst[:,:-1], seq_drum[:,:-1],seq_time[:,:-1],seq_num[:,:-1]]\n",
    "        y = [seq_inst[:,1:], seq_drum[:,1:],delta_time,seq_num[:,1:,0],seq_num[:,1:,1],seq_num[:,1:,2]]\n",
    "                 \n",
    "        if self.model_inst == None:\n",
    "            return X, y[0]\n",
    "        \n",
    "        elif (self.model_inst != None) & (self.model_delta == None):\n",
    "            pred_ind = self.model_inst.predict(X)\n",
    "            pred_ind = np.argmax(pred_ind, axis = -1)\n",
    "            X.append(pred_ind)\n",
    "            return X, y[2]\n",
    "        else:\n",
    "            pred_ind = self.model_inst.predict(X)\n",
    "            pred_delta = self.model_delta.predict(X)\n",
    "            pred_ind = np.argmax(pred_ind, axis = -1)\n",
    "            pred_delta = np.argmax(pred_delta, axis = -1)\n",
    "            X.append(pred_ind)\n",
    "            X.append(pred_delta)\n",
    "            return X, y[3:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir('./batch')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(file_list, batch_size = 4, start_rate = 0.2, max_len = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X, y = gen[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDecoder(tf.keras.layers.Layer):    \n",
    "    def __init__(self, num_layers, d_model, num_heads, dff,\n",
    "               maximum_position_encoding, num_types = 2, rate=0.1, bidirectional_decoder = False):\n",
    "        super(GPTDecoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(155, d_model)\n",
    "        self.drum_embedding = tf.keras.layers.Embedding(2, d_model)\n",
    "        \n",
    "        self.time_encoding = tf.keras.layers.Dense(d_model, activation = 'relu')\n",
    "        \n",
    "        self.num_encoding = tf.keras.layers.Dense(d_model, activation = 'relu')\n",
    "        self.delta_encoding = tf.keras.layers.Dense(d_model, activation = 'relu')\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "        \n",
    "        self.conc = tf.keras.layers.Concatenate()\n",
    "        self.agg = tf.keras.layers.Dense(d_model, activation = 'relu')\n",
    "        \n",
    "        self.dec_layers = [GPTDecoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "        self.bidirectional_decoder = bidirectional_decoder\n",
    "    \n",
    "    def call(self, x, training = True, drum_ids = None, time_ids = None, num_ids = None, pred_x = None, pred_delta = None):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "        \n",
    "        if self.bidirectional_decoder == False:\n",
    "            look_ahead_mask = create_look_ahead_mask(tf.shape(x)[1])\n",
    "            dec_target_padding_mask = create_padding_mask(x, pad_token = 154)\n",
    "            mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "        else:\n",
    "            mask = create_padding_mask(x, pad_token = 154)\n",
    "        \n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        \n",
    "#         c = [x]\n",
    "#         c.append(self.time_encoding(time_ids))\n",
    "#         c.append(self.drum_embedding(drum_ids))\n",
    "#         c.append(self.num_encoding(num_ids))\n",
    "        \n",
    "        \n",
    "#         if pred_x is not None:\n",
    "#             c.append(self.embedding(pred_x))\n",
    "#         if pred_delta:\n",
    "#             c.append(self.delta_encoding(x))\n",
    "        \n",
    "#         x = self.conc(c)\n",
    "#         x = self.agg(x)\n",
    "        \n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1 = self.dec_layers[i](x, training, look_ahead_mask = mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "#            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_ind = GPTDecoder(num_layers = 2, d_model = 256, num_heads = 8, dff = 512,\n",
    "                   maximum_position_encoding = 1024, num_types = 2, rate=0.1, bidirectional_decoder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 512\n",
    "inputs_inst = Input(shape = (max_len,))\n",
    "drum_ids = Input(shape = ( max_len,))\n",
    "time_ids = Input(shape = ( max_len,1))\n",
    "num_ids = Input(shape = ( max_len,3))\n",
    "\n",
    "inputs = [inputs_inst, drum_ids, time_ids, num_ids]\n",
    "\n",
    "encoded, _ = decoder_ind(inputs_inst, training = True, drum_ids = drum_ids, time_ids = time_ids, num_ids = num_ids)\n",
    "\n",
    "output_inst = tf.keras.layers.Dense(156, name = 'inst')(encoded)\n",
    "# output_drum = tf.keras.layers.Dense(2, activation = 'softmax', name = 'drum')(encoded)\n",
    "# output_time = tf.keras.layers.Dense(1, activation = 'linear', name = 'time')(encoded)\n",
    "# output_duration = tf.keras.layers.Dense(1, activation = 'linear', name = 'duration')(encoded)\n",
    "# output_pitch = tf.keras.layers.Dense(130, activation = 'softmax', name = 'pitch')(encoded)\n",
    "# output_velocity = tf.keras.layers.Dense(130, activation = 'softmax', name = 'velocity')(encoded)\n",
    "\n",
    "\n",
    "# outputs = [output_inst]\n",
    "\n",
    "model_ind = Model(inputs, output_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ind.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                    from_logits=True, reduction='none')\n",
    "\n",
    "losses = [loss_object]\n",
    "\n",
    "loss_classif     =  losses# find the right loss for multi-class classification\n",
    "optimizer        =  Adam(3e-5, 1e-8) # find the right optimizer\n",
    "metrics_classif  =  ['accuracy']\n",
    "\n",
    "model_ind.compile(loss=loss_classif,\n",
    "              optimizer=optimizer,\n",
    "              metrics=metrics_classif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_list = os.listdir('./batch')[:-1]\n",
    "test_list = [ os.listdir('./batch')[-1]]\n",
    "## Test_set\n",
    "gen = Generator(test_list, batch_size = 512, start_rate = 0.2, max_len = max_len)\n",
    "x_test, y_test = gen[0]\n",
    "gen = Generator(train_list, batch_size = 32, start_rate = 0.2, max_len = max_len)\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=4, verbose=1, \n",
    "                                                mode='auto', restore_best_weights=True)\n",
    "reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, \n",
    "                                                     mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "# bs = 128\n",
    "n_epochs = 10\n",
    "steps_per_epoch = 100\n",
    "#, batch_size=bs\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model_ind.fit(gen,  epochs=n_epochs,steps_per_epoch = steps_per_epoch, validation_data=(x_test,  y_test))#, callbacks = [early, reduce])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints/model_inst.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_ind.predict(x_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(pred, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[0][ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(file_list, batch_size = 4, start_rate = 0.2, max_len = max_len, model_inst = model_ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X, y = gen[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
