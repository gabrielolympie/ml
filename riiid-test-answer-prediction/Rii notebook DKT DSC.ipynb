{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import _pickle as pickle\n",
    "import gc\n",
    "from multiprocess import Pool\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "def save(file,name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'wb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'wb')\n",
    "    pickle.dump(file, outfile, protocol=4)\n",
    "    outfile.close\n",
    "    \n",
    "def load(name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'rb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'rb')\n",
    "    file = pickle.load(outfile)\n",
    "    outfile.close\n",
    "    return file\n",
    "\n",
    "class Discretiser:\n",
    "    def __init__(self, nbins):\n",
    "        self.nbins = nbins-1\n",
    "        self.map_to = np.arange(self.nbins)/self.nbins\n",
    "        \n",
    "    def fit(self, X):\n",
    "        ## X is a one dimension np array\n",
    "        self.map_from = np.quantile(X, self.map_to)\n",
    "        \n",
    "    def transform(self, X):\n",
    "        X1 = (np.interp(X, self.map_from, self.map_to, left=0, right=1, period=None) * self.nbins).astype(int)\n",
    "        return X1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load('train_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user, data in tqdm(train.groupby('user_id'), total = train['user_id'].nunique()):\n",
    "    save(data, str(user), 'individual_users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user = train[train['user_id'] == 115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_sequence(df_user):\n",
    "    import numpy as np\n",
    "    df_user =  df_user.sort_values(by = 'timestamp')\n",
    "    df_user.index = list(range(df_user.shape[0]))\n",
    "    \n",
    "    df_user['content_type'] =  df_user['content_type_id'].apply(lambda x : 'q' if x == 0 else 'l')\n",
    "    df_user['content_seq'] = df_user['content_type'].astype(str) + '_' + df_user['content_id'].astype(str)\n",
    "    \n",
    "    ## Encoder\n",
    "    exercise_id = df_user['content_seq'].values\n",
    "    container_id = df_user['task_container_id'].values\n",
    "    timestamp = df_user['timestamp'].values/1000  ## Conversion in s\n",
    "    \n",
    "    ## Decoder\n",
    "    correctness = df_user['answered_correctly'].values\n",
    "    answer = df_user['user_answer'].values\n",
    "    \n",
    "    elapsed_time = df_user['prior_question_elapsed_time'].fillna(0).values[1:]/1000 ## Already Padded ## Conversion in s\n",
    "    prior_question_had_explanation = df_user['prior_question_had_explanation'].fillna(0).values[1:]*1 ## Already Padded\n",
    "    \n",
    "    lag_time = np.concatenate([[0],timestamp[1:] - timestamp[:-1] + elapsed_time])\n",
    "    \n",
    "    dico = {\n",
    "        'exercise_id' : exercise_id,\n",
    "        'container_id' : container_id,\n",
    "        'timestamp' : timestamp,\n",
    "        'correctness' : correctness,\n",
    "        'answer' : answer, \n",
    "        'elapsed_time' : elapsed_time,\n",
    "        'prior_question_had_explanation' : prior_question_had_explanation,\n",
    "        'lag_time' : lag_time\n",
    "    }\n",
    "    return dico\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dico = build_user_sequence(test_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico['lag_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2000\n",
    "count = 0\n",
    "vect = []\n",
    "p = Pool(12)\n",
    "\n",
    "for elt in tqdm(train.groupby('user_id'), total = train['user_id'].nunique()):\n",
    "    vect.append(elt)\n",
    "    if len(vect) == batch_size:\n",
    "        vect = np.array(vect)\n",
    "        vect_user = vect[:,0]\n",
    "        vect_data = vect[:,1]\n",
    "        vect = []\n",
    "        \n",
    "        processed_dico = p.map(build_user_sequence, vect_data)\n",
    "        \n",
    "        # saving as batches of 2000\n",
    "        dico_user = {}\n",
    "        for i, elt in enumerate(vect_user):\n",
    "            dico_user[elt] = processed_dico[i]\n",
    "        save(dico_user, 'batch_'+str(count), 'user_batch_saint_2000')\n",
    "        \n",
    "        # saving as batches of 100\n",
    "        dico_user = {}\n",
    "        count1 = 0\n",
    "        for i, elt in enumerate(vect_user):\n",
    "            dico_user[elt] = processed_dico[i]\n",
    "            if len(dico_user.keys()) == 100:\n",
    "                save(dico_user, 'batch_'+str(count)+'_'+str(count1), 'user_batch_saint_100')\n",
    "                dico_user = {}\n",
    "                count1+=1\n",
    "        count += 1\n",
    "        \n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = load('batch_0', 'user_batch_saint_2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dico_utags, dico_gtags, dico_parts, dico_tags) = load('dico_tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dico[115]['exercise_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tags(ids, dico):\n",
    "    tags = np.zeros((len(ids), 188))\n",
    "    \n",
    "    def map_apply(x):\n",
    "        try:\n",
    "            return dico[x]\n",
    "        except:\n",
    "            return []\n",
    "    \n",
    "    found_tags = list(map(map_apply, ids))\n",
    "    \n",
    "    for i , elt in enumerate(found_tags):\n",
    "        for j in elt:\n",
    "            tags[i,j] += 1\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t = apply_tags(test, dico_tags)\n",
    "c = dico[115]['correctness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['q_5692', 'q_5716', 'q_128', 'q_7860', 'q_7922', 'q_156', 'q_51',\n",
       "       'q_50', 'q_7896', 'q_7863', 'q_152', 'q_104', 'q_108', 'q_7900',\n",
       "       'q_7901', 'q_7971', 'q_25', 'q_183', 'q_7926', 'q_7927', 'q_4',\n",
       "       'q_7984', 'q_45', 'q_185', 'q_55', 'q_7876', 'q_6', 'q_172',\n",
       "       'q_7898', 'q_175', 'q_100', 'q_7859', 'q_57', 'q_7948', 'q_151',\n",
       "       'q_167', 'q_7897', 'q_7882', 'q_7962', 'q_1278', 'q_2065',\n",
       "       'q_2064', 'q_2063', 'q_3363', 'q_3365', 'q_3364'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 188)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pos = np.multiply(t , np.array([c for _ in range(188)]).T == 1)\n",
    "neg = np.multiply(t , np.array([c for _ in range(188)]).T == 0)\n",
    "neu = np.multiply(t , np.array([c for _ in range(188)]).T == -1)\n",
    "\n",
    "advanced_vect = np.nan_to_num((neu + pos - neg)/np.cumsum(t, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vects = []\n",
    "labels = []\n",
    "ids = []\n",
    "for elt in tqdm(dico):\n",
    "    t = dico[elt]['exercise_id']\n",
    "    c = dico[elt]['correctness']\n",
    "    \n",
    "    t1 = apply_tags(t, dico_tags)\n",
    "    t = apply_tags(np.concatenate([[-1], t[:-1]]), dico_tags)\n",
    "\n",
    "    pos = np.multiply(t , np.array([c for _ in range(188)]).T == 1)\n",
    "    neg = np.multiply(t , np.array([c for _ in range(188)]).T == 0)\n",
    "    neu = np.multiply(t , np.array([c for _ in range(188)]).T == -1)\n",
    "\n",
    "    advanced_vect = np.nan_to_num((np.cumsum(neu, axis = 0) + np.cumsum(pos, axis = 0) - np.cumsum(neg, axis = 0))/np.cumsum(t, axis = 0))\n",
    "\n",
    "    relevant = np.concatenate([t1, advanced_vect], axis = 1)\n",
    "    print(relevant.shape)\n",
    "    all_vects.append(relevant)\n",
    "    labels.append(c)\n",
    "    ids.append([elt for _ in c])\n",
    "\n",
    "all_vects = np.concatenate(all_vects, axis = 0)\n",
    "labels = np.concatenate(labels, axis = 0)\n",
    "ids = np.concatenate(ids, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vects = all_vects[labels != -1]\n",
    "labels = labels[labels != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train = all_vects[:450000]\n",
    "X_test = all_vects[450000:]\n",
    "\n",
    "y_train = labels[:450000]\n",
    "y_test = labels[450000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "clf = lgb.LGBMClassifier(max_depth = 3, n_estimators = 500, n_jobs = 12, silent = False)\n",
    "clf.fit(X_train, y_train, eval_set =(X_test, y_test), eval_metric = 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and discretisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## timestamp encoder\n",
    "dico_user = load('batch_'+str(0), 'user_batch_saint_2000')\n",
    "el = []\n",
    "for elt in dico_user:\n",
    "    ela = dico_user[elt]['timestamp']\n",
    "    ela[np.isnan(ela)] = 0\n",
    "    el += list(ela)\n",
    "timestamp_enc = Discretiser(300)\n",
    "timestamp_enc.fit(el)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Elapsed time encoder\n",
    "dico_user = load('batch_'+str(0), 'user_batch_saint_2000')\n",
    "el = []\n",
    "for elt in dico_user:\n",
    "    ela = dico_user[elt]['elapsed_time']\n",
    "    ela[np.isnan(ela)] = 0\n",
    "    el += list(ela)\n",
    "elapsed_enc = Discretiser(300)\n",
    "elapsed_enc.fit(el)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lag time encoder\n",
    "dico_user = load('batch_'+str(0), 'user_batch_saint_2000')\n",
    "el = []\n",
    "for elt in dico_user:\n",
    "    ela = dico_user[elt]['lag_time']\n",
    "    ela[np.isnan(ela)] = 0\n",
    "    el += list(ela)\n",
    "lag_time_enc = Discretiser(300)\n",
    "lag_time_enc.fit(el)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question mean encoder\n",
    "dico_question = load('dico_questions_mean')\n",
    "val = list(dico_question.values())\n",
    "qmean_enc = Discretiser(300)\n",
    "qmean_enc.fit(val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving\n",
    "save((timestamp_enc, elapsed_enc, lag_time_enc, qmean_enc), 'discrete_encoders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building tokenizer\n",
    "lectures = pd.read_csv('lectures.csv')\n",
    "questions = pd.read_csv('questions.csv')\n",
    "user_answer = np.array([-1,0,1,2,3])\n",
    "answered_correctly = np.array([-1,0,1])\n",
    "\n",
    "lectures_id = lectures['lecture_id'].unique()\n",
    "question_id = questions['question_id'].unique()\n",
    "\n",
    "lectures_id = ['l_' +  elt for elt in  lectures_id.astype(str)]\n",
    "question_id = ['q_' +  elt for elt in  question_id.astype(str)]\n",
    "\n",
    "all_tokens = np.array(['[PAD]', '[CLS]', '[SEP]', '[MASK]'] + lectures_id + question_id)\n",
    "\n",
    "tokenizer = Tokenizer(filters = '')\n",
    "\n",
    "tokenizer.fit_on_texts(\n",
    "    all_tokens\n",
    ")\n",
    "\n",
    "save(tokenizer, 'tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('questions.csv')\n",
    "df1 = pd.read_csv('lectures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_tab(x):\n",
    "    if str(x)!='nan':\n",
    "        x = np.array(str(x).split(' ')).astype(int)\n",
    "    else:\n",
    "        x = []\n",
    "    x.sort()\n",
    "    return x\n",
    "\n",
    "def apply(x):\n",
    "    return 'q_'+str(x)\n",
    "\n",
    "def apply1(x):\n",
    "    return 'l_'+str(x)\n",
    "\n",
    "df['tag'] = df['tags'].apply(to_tab)\n",
    "df1['tag'] = df1['tag'].apply(lambda x  :[x])\n",
    "df['qu'] = df['question_id'].apply(apply)\n",
    "df1['l'] = df1['lecture_id'].apply(apply1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tag'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionnaries():\n",
    "    df = pd.read_csv('questions.csv')\n",
    "    df1 = pd.read_csv('lectures.csv')\n",
    "\n",
    "    def apply(x):\n",
    "        return 'q_'+str(x)\n",
    "\n",
    "    def apply1(x):\n",
    "        return 'l_'+str(x)\n",
    "\n",
    "    def to_tab(x):\n",
    "        if str(x)!='nan':\n",
    "            x = np.array(str(x).split(' ')).astype(int)\n",
    "        else:\n",
    "            x = []\n",
    "        x.sort()\n",
    "        return x\n",
    "\n",
    "    df['tag'] = df['tags'].apply(to_tab)\n",
    "    df['qu'] = df['question_id'].apply(apply)\n",
    "    df1['l'] = df1['lecture_id'].apply(apply1)\n",
    "\n",
    "    ## unique tags part\n",
    "    tags_to_utags = {}\n",
    "    count = 0\n",
    "    for elt in df1['tag']:\n",
    "        if elt in tags_to_utags:\n",
    "            1\n",
    "        else:\n",
    "            tags_to_utags[str(elt)] = count\n",
    "            count+=1\n",
    "\n",
    "    for elt in df['tags']:\n",
    "        if elt in tags_to_utags:\n",
    "            1\n",
    "        else:\n",
    "            tags_to_utags[elt] = count\n",
    "            count+=1\n",
    "    df['utags'] = df['tags'].astype(str).replace(tags_to_utags)\n",
    "    df1['utags'] = df1['tag'].astype(str).replace(tags_to_utags)\n",
    "\n",
    "    ## Graph tags part\n",
    "    dico_l = {}\n",
    "    for t, data in df1.groupby('tag'):\n",
    "        dico_l[t] = data['l'].unique()\n",
    "\n",
    "    import networkx as nx\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(df['qu'])\n",
    "    G.add_nodes_from(df1['l'])\n",
    "\n",
    "    for i, elt in enumerate(tqdm(df['tag'])):\n",
    "        for j in elt:\n",
    "            try:\n",
    "                lec = dico_l[j]\n",
    "            except:\n",
    "                lec = []\n",
    "            for k in lec:\n",
    "                G.add_edge(df['qu'].iloc[i], k)\n",
    "\n",
    "    co = list(nx.connected_components(G))\n",
    "\n",
    "    tags_to_gtags = {}\n",
    "    count = 0\n",
    "    for i, elt in enumerate(tqdm(co)):\n",
    "        for j in elt:\n",
    "            tags_to_gtags[j] = i\n",
    "\n",
    "    df['gtags'] = df['qu'].replace(tags_to_gtags)\n",
    "    df1['gtags'] = df1['l'].replace(tags_to_gtags)\n",
    "    \n",
    "    df1['tag'] = df1['tag'].apply(lambda x  :[x])\n",
    "    \n",
    "    dico_utags = {}\n",
    "    dico_gtags = {}\n",
    "    dico_parts = {}\n",
    "    dico_tags = {}\n",
    "    \n",
    "    for pair in zip(df['qu'], df['utags'], df['gtags'], df['part'], df['tag']):\n",
    "        dico_utags[pair[0]] = pair[1]\n",
    "        dico_gtags[pair[0]] = pair[2]\n",
    "        dico_parts[pair[0]] = pair[3]\n",
    "        dico_tags[pair[0]] = pair[4]\n",
    "        \n",
    "    for pair in zip(df1['l'], df1['utags'], df1['gtags'], df1['part'], df1['tag']):\n",
    "        dico_utags[pair[0]] = pair[1]\n",
    "        dico_gtags[pair[0]] = pair[2]\n",
    "        dico_parts[pair[0]] = pair[3]\n",
    "        dico_tags[pair[0]] = pair[4]\n",
    "        \n",
    "    \n",
    "    \n",
    "    return dico_utags, dico_gtags, dico_parts, dico_tags\n",
    "\n",
    "dico_utags, dico_gtags, dico_parts, dico_tags = create_dictionnaries()\n",
    "\n",
    "save((dico_utags, dico_gtags, dico_parts, dico_tags), 'dico_tags')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sequence Modelling\n",
    "sequence_ids   emb1_main # tokenizer values + cls, pad et mask tokens\n",
    "answer_corr    emb2     # 0,1,2,+mask = 3\n",
    "part           emb8     # 6 parts\n",
    "timestamp      emb3     float discretized in 300 int values\n",
    "answer         emb4     # 0,1,2,3,4,+mask = 5\n",
    "elapsed_time   emb5     float discretized in 300 int values\n",
    "explained      emb6     # 2 possible, lectures put to 0\n",
    "avg_correct    emb7     float discretized in 300 int values\n",
    "\n",
    "## MLM loss\n",
    "sequence unmasked\n",
    "answer_corr unmasked\n",
    "\n",
    "## Next answer prediction loss\n",
    "[CLS] Query [SEP] Sequence Model\n",
    "\n",
    "Sequence Model as in sequence modelling\n",
    "\n",
    "Query\n",
    "question_id     ## id question      \n",
    "answer_corr     ## Mask token\n",
    "part            ## 6 parts\n",
    "timestamp       float discretized in 300 values\n",
    "answer          ## Masked to -1\n",
    "elapsed_time    ## 0\n",
    "explained   0   ## 0\n",
    "avg_correct     ## average score of the question discretized in 300 int values\n",
    "\n",
    "output : unmasked answer_corr    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self,batch_size=32, max_len = 128, folder = 'user_batch_saint_100', strategy = 'begin', mask_rate = 0.15, seq_mask_rate = 0.5, bidirectionnal = True):\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = load('tokenizer')\n",
    "        self.max_len = max_len\n",
    "        self.folder = folder\n",
    "        self.dico_question = load('dico_questions_mean')\n",
    "        self.dico_utags, self.dico_gtags, self.dico_parts = load('dico_tags')\n",
    "        self.timestamp_enc, self.elapsed_enc,self.lag_time_enc, self.qmean_enc = load('discrete_encoders')\n",
    "        self.strategy = strategy\n",
    "        self.mask_rate = mask_rate\n",
    "        self.seq_mask_rate = seq_mask_rate\n",
    "        self.bidirectionnal = bidirectionnal\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 1000000\n",
    "    \n",
    "    def initiate_dico(self):\n",
    "        list_encoder = ['exercise', 'part', 'utag', 'gtag', 'timestamp', 'question_mean']\n",
    "        list_decoder = ['correct', 'answer', 'elapsed_time', 'lag_time', 'was_explained', 'question_mean_bis']\n",
    "        list_output = ['exercise', 'answer', 'correct']\n",
    "        \n",
    "        dico_input = {}\n",
    "        for elt in list_encoder + list_decoder:\n",
    "            if elt == 'exercise':\n",
    "                dico_input[elt] = np.zeros((self.batch_size, self.max_len)).astype(str)\n",
    "            else:\n",
    "                if elt != 'question_mean_bis':\n",
    "                    dico_input[elt] = np.zeros((self.batch_size, self.max_len)).astype('int32')\n",
    "                else:\n",
    "                    dico_input[elt] = np.zeros((self.batch_size, self.max_len)).astype('float32')\n",
    "        \n",
    "        dico_output = {}\n",
    "        for elt in list_output:\n",
    "            if elt == 'exercise':\n",
    "                dico_output[elt] = np.zeros((self.batch_size, self.max_len)).astype(str)\n",
    "            else:\n",
    "                dico_output[elt] = np.zeros((self.batch_size, self.max_len)).astype('int32')\n",
    "        return dico_input, dico_output\n",
    "\n",
    "    def map_part(self, ids):\n",
    "        def replace_dico_part(x):\n",
    "            try:\n",
    "                return self.dico_parts[x]\n",
    "            except:\n",
    "                return 0\n",
    "        return np.array(list(map(replace_dico_part,ids)))\n",
    "    \n",
    "    def map_utags(self, ids):\n",
    "        def replace_dico_utags(x):\n",
    "            try:\n",
    "                if str(self.dico_utags[x]) != 'nan':\n",
    "                    return str(self.dico_utags[x])\n",
    "                else:\n",
    "                    return 0\n",
    "            except:\n",
    "                return 0\n",
    "        return np.array(list(map(replace_dico_utags,ids)))\n",
    "    \n",
    "    def map_gtags(self, ids):\n",
    "        def replace_dico_gtags(x):\n",
    "            try:\n",
    "                if str(self.dico_gtags[x]) != 'nan':\n",
    "                    return str(self.dico_gtags[x])\n",
    "                else:\n",
    "                    return 0\n",
    "            except:\n",
    "                return 0\n",
    "        return np.array(list(map(replace_dico_gtags,ids)))\n",
    "    \n",
    "    def map_mean(self, ids):\n",
    "        def replace_dico_question(x):\n",
    "            try:\n",
    "                return self.dico_question[x]\n",
    "            except:\n",
    "                return 0.5\n",
    "        return np.array(list(map(replace_dico_question,ids))).astype('float32')\n",
    "\n",
    "\n",
    "    \n",
    "    def update_dico(self, dico_input, dico_output, input_vals, output_vals, i):\n",
    "        list_encoder = ['exercise', 'part', 'utag', 'gtag', 'timestamp', 'question_mean']\n",
    "        list_decoder = ['correct', 'answer', 'elapsed_time', 'lag_time', 'was_explained', 'question_mean_bis']\n",
    "        list_output = ['exercise', 'answer', 'correct']\n",
    "        \n",
    "        for j, elt in enumerate(list_encoder + list_decoder):\n",
    "            dico_input[elt][i] = input_vals[j]\n",
    "        \n",
    "        for j, elt in enumerate(list_output):\n",
    "            dico_output[elt][i] = output_vals[j]\n",
    "        return dico_input, dico_output\n",
    "\n",
    "    def remove_na(self, x):\n",
    "        x = np.array(list(x))\n",
    "        x[np.isnan(x)] = 0\n",
    "        return x\n",
    "    \n",
    "    def apply_mask(self, x, mask, pad_token, mask_token):\n",
    "        x_out = []\n",
    "        x_in = []\n",
    "        for i, elt in enumerate(mask):\n",
    "            if mask[i] == 1:\n",
    "                x_out.append(x[i])\n",
    "                x_in.append(mask_token)\n",
    "            else:\n",
    "                x_out.append(pad_token)\n",
    "                x_in.append(x[i])\n",
    "        return np.array(x_in), np.array(x_out)\n",
    "\n",
    "    def build_sequence(self, user_history):\n",
    "        dico_sequence = deepcopy(user_history)        \n",
    "        dico_sequence['elapsed_time'] = self.remove_na(dico_sequence['elapsed_time'])\n",
    "        dico_sequence['lag_time'] = self.remove_na(dico_sequence['lag_time'])\n",
    "        dico_sequence['prior_question_had_explanation'] = self.remove_na(dico_sequence['prior_question_had_explanation'])\n",
    "        \n",
    "        dico_sequence['elapsed_time'] = np.concatenate([dico_sequence['elapsed_time'], [0]])\n",
    "        dico_sequence['prior_question_had_explanation'] = np.concatenate([dico_sequence['prior_question_had_explanation'], [0]])\n",
    "        \n",
    "        \n",
    "        ## Cut sequence\n",
    "        if self.strategy == 'begin':\n",
    "            for elt in dico_sequence:\n",
    "                dico_sequence[elt] = dico_sequence[elt][:self.max_len]\n",
    "        else:\n",
    "            for elt in dico_sequence:\n",
    "                dico_sequence[elt] = dico_sequence[elt][-self.max_len:]\n",
    "        \n",
    "        \n",
    "        \n",
    "         ## Masking\n",
    "        # Either mask question => mask parts, qmean, answer, correctness 0.5%\n",
    "        # Or mask correctness => mask answer, elapsed_time, lag_time, explanation 0.5%\n",
    "        # In all case, mask the last question answer, but we keep its signification\n",
    "        \n",
    "        if self.bidirectionnal == True:\n",
    "            r = random.uniform(0,1)\n",
    "            if r < self.seq_mask_rate:\n",
    "                # masking on the question_id\n",
    "                masks = np.random.choice([0,1],replace = True, size = len(dico_sequence['exercise_id'])-1, p = [1-self.mask_rate,self.mask_rate])\n",
    "\n",
    "    #             print(masks.shape)\n",
    "    #             print(dico_sequence['elapsed_time'].shape)\n",
    "    #             print('\\n')\n",
    "\n",
    "                dico_sequence['elapsed_time'], _ = self.apply_mask(dico_sequence['elapsed_time'], masks, 0, 0)     \n",
    "                dico_sequence['prior_question_had_explanation'], _ = self.apply_mask(dico_sequence['prior_question_had_explanation'], masks, 0, 0) \n",
    "\n",
    "                masks = np.concatenate([masks, [0]])\n",
    "                dico_sequence['exercise_id'], dico_sequence['exercise_id_out'] = self.apply_mask(dico_sequence['exercise_id'], masks, '[PAD]', '[MASK]')            \n",
    "                masks[-1] = 1\n",
    "                dico_sequence['answer'], dico_sequence['answer_out'] = self.apply_mask(dico_sequence['answer'], masks, -1, -1)\n",
    "                dico_sequence['correctness'], dico_sequence['correctness_out'] = self.apply_mask(dico_sequence['correctness'], masks, -1, -1)\n",
    "\n",
    "            else:\n",
    "                # Masking only a part of the answers\n",
    "                dico_sequence['exercise_id_out'] = deepcopy(np.array(['[PAD]' for elt in dico_sequence['exercise_id']]))\n",
    "                masks = np.random.choice([0,1],replace = True, size = len(dico_sequence['correctness'])-1, p = [1-self.mask_rate,self.mask_rate])\n",
    "\n",
    "    #             print(masks.shape)\n",
    "    #             print(dico_sequence['elapsed_time'].shape)\n",
    "    #             print('\\n')\n",
    "\n",
    "                dico_sequence['elapsed_time'], _ = self.apply_mask(dico_sequence['elapsed_time'], masks, 0, 0)    \n",
    "                dico_sequence['prior_question_had_explanation'], _ = self.apply_mask(dico_sequence['prior_question_had_explanation'], masks, 0, 0)\n",
    "\n",
    "                masks = np.concatenate([masks, [1]])\n",
    "                dico_sequence['correctness'], dico_sequence['correctness_out'] = self.apply_mask(dico_sequence['correctness'], masks, -1, -1)\n",
    "                dico_sequence['answer'], dico_sequence['answer_out'] = self.apply_mask(dico_sequence['answer'], masks, -1, -1)\n",
    "        \n",
    "        else:\n",
    "            dico_sequence['exercise_id_out'] = dico_sequence['exercise_id']\n",
    "            dico_sequence['correctness_out'] = dico_sequence['correctness']\n",
    "            dico_sequence['answer_out'] = dico_sequence['answer']\n",
    "        \n",
    "        ## Pad sequence\n",
    "        pad_tokens = ['[PAD]', 0, 0, -1, -1, 0, 0, 0, '[PAD]', -1, -1]\n",
    "        for j, elt in enumerate(dico_sequence):\n",
    "            size = len(dico_sequence[elt])\n",
    "            if size <= self.max_len:\n",
    "                adding = self.max_len - size\n",
    "                tok = pad_tokens[j]\n",
    "                if type(tok) == str:\n",
    "                    add = np.array([tok for elt in range(adding)])\n",
    "                else:\n",
    "                    add = np.zeros(adding) + tok\n",
    "                dico_sequence[elt] = np.concatenate([dico_sequence[elt], add], axis = 0)\n",
    "#                 print(dico_sequence[elt].shape)\n",
    "\n",
    "        if self.bidirectionnal == False:\n",
    "            input_vals = [\n",
    "                dico_sequence['exercise_id'],\n",
    "                self.map_part(dico_sequence['exercise_id']),\n",
    "                self.map_utags(dico_sequence['exercise_id']),\n",
    "                self.map_gtags(dico_sequence['exercise_id']),\n",
    "                self.timestamp_enc.transform(dico_sequence['timestamp']),\n",
    "                self.qmean_enc.transform(self.map_mean(dico_sequence['exercise_id'])),\n",
    "\n",
    "                np.concatenate([[0], dico_sequence['correctness'] + 1])[:-1],\n",
    "                np.concatenate([[0], dico_sequence['answer'] + 1])[:-1],\n",
    "                np.concatenate([[0], self.elapsed_enc.transform(dico_sequence['elapsed_time'])])[:-1],\n",
    "                self.lag_time_enc.transform(dico_sequence['lag_time']),\n",
    "                np.concatenate([[0], dico_sequence['prior_question_had_explanation']])[:-1],\n",
    "                \n",
    "                self.map_mean(dico_sequence['exercise_id'])*10\n",
    "            ]\n",
    "            \n",
    "            dico_sequence['correctness_out'][dico_sequence['correctness_out'] == -1] = 2\n",
    "            \n",
    "            output_vals = [\n",
    "                np.concatenate([dico_sequence['exercise_id_out'][1:], ['[PAD]']]),\n",
    "                dico_sequence['answer_out'] + 1,\n",
    "                dico_sequence['correctness_out'],\n",
    "            ]\n",
    "            \n",
    "        else:\n",
    "            input_vals = [\n",
    "                dico_sequence['exercise_id'],\n",
    "                self.map_part(dico_sequence['exercise_id']),\n",
    "                self.map_utags(dico_sequence['exercise_id']),\n",
    "                self.map_gtags(dico_sequence['exercise_id']),\n",
    "                self.timestamp_enc.transform(dico_sequence['timestamp']),\n",
    "                self.qmean_enc.transform(self.map_mean(dico_sequence['exercise_id'])),\n",
    "\n",
    "                dico_sequence['correctness'] + 1,\n",
    "                dico_sequence['answer'] + 1,\n",
    "                self.elapsed_enc.transform(dico_sequence['elapsed_time']),\n",
    "                self.lag_time_enc.transform(dico_sequence['lag_time']),\n",
    "                dico_sequence['prior_question_had_explanation'],\n",
    "                \n",
    "                self.map_mean(dico_sequence['exercise_id'])*10,\n",
    "            ]\n",
    "            \n",
    "        \n",
    "            \n",
    "            dico_sequence['correctness_out'][dico_sequence['correctness_out'] == -1] = 2\n",
    "            \n",
    "            output_vals = [\n",
    "                dico_sequence['exercise_id_out'],\n",
    "                dico_sequence['answer_out'] + 1,\n",
    "                dico_sequence['correctness_out'],\n",
    "            ]\n",
    "        \n",
    "#         print(self.map_mean(dico_sequence['exercise_id']))\n",
    "#         x = np.zeros((11,self.max_len))\n",
    "#         y = np.zeros((3, self.max_len))\n",
    "        return input_vals,output_vals\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ## Load random batch\n",
    "        file_name = random.choice(os.listdir('./'+self.folder))\n",
    "        dico_user = load(file_name.split('.')[0], self.folder)\n",
    "        \n",
    "        list_user = np.random.choice(list(dico_user.keys()), size = self.batch_size)\n",
    "        \n",
    "        dico_input, dico_output = self.initiate_dico()\n",
    "        \n",
    "        \n",
    "        for i, elt in enumerate(list_user):\n",
    "            user_history = dico_user[elt]\n",
    "            input_vals, output_vals = self.build_sequence(user_history)\n",
    "#             print(input_vals[-1])\n",
    "            dico_input, dico_output = self.update_dico(dico_input, dico_output, input_vals, output_vals, i)\n",
    "#         print(dico_input['question_mean_bis'])\n",
    "        x = deepcopy(dico_input['exercise'])\n",
    "        dico_input['exercise'] = np.array(self.tokenizer.texts_to_sequences([\" \".join(list(x)[elt]) for elt in range(len(x))]))\n",
    "        \n",
    "        x = deepcopy(dico_output['exercise'])\n",
    "        dico_output['exercise'] = np.array(self.tokenizer.texts_to_sequences([\" \".join(list(x)[elt]) for elt in range(len(x))]))\n",
    "        \n",
    "        X = []\n",
    "        for elt in dico_input:\n",
    "            if elt != 'question_mean_bis':\n",
    "                X.append(np.array(list(dico_input[elt])).astype('int32'))\n",
    "            else:\n",
    "                X.append(np.array(list(dico_input[elt])).astype('float32').reshape((self.batch_size, self.max_len, 1)))\n",
    "            \n",
    "#         y = list(np.array(list(dico_output.values())).astype('int32')) \n",
    "#         print(dico_output.keys())\n",
    "        y = dico_output['correct'].astype('int32').reshape((self.batch_size, self.max_len, 1))*10\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "\n",
    "    def __get_data(self, batch):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = DataGenerator(batch_size=32, max_len = 128, folder = 'user_batch_saint_100', strategy = 'end', mask_rate = 0.15, seq_mask_rate = 0.9, bidirectionnal = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x, y = gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elt in x:\n",
    "    print(elt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elt in y:\n",
    "    print(elt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_transformers2 import *\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, TimeDistributed, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaintBert(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers = 2, d_model = 512, num_heads = 8, \n",
    "                 dff = 1024, input_vocab_size = 14000, maximum_position_encoding = 512, \n",
    "                 rate=0, bidirectional_encoder = True, layer_type = 'attention'):\n",
    "        super(SaintBert, self).__init__()\n",
    "        self.layer_type = layer_type\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        \n",
    "        ## Additional embeddings\n",
    "        self.part_embedding = tf.keras.layers.Embedding(8, d_model)\n",
    "        self.utag_embedding = tf.keras.layers.Embedding(1900, d_model)\n",
    "        self.gtag_embedding = tf.keras.layers.Embedding(100, d_model)\n",
    "        self.timestamp_embedding = tf.keras.layers.Embedding(301, d_model)\n",
    "        self.question_mean_embedding = tf.keras.layers.Embedding(301, d_model)\n",
    "        \n",
    "        self.correct_embedding = tf.keras.layers.Embedding(3, d_model)\n",
    "        self.answer_embedding = tf.keras.layers.Embedding(8, d_model)   \n",
    "        self.elapsed_time_embedding = tf.keras.layers.Embedding(301, d_model)\n",
    "        self.lag_time_embedding = tf.keras.layers.Embedding(301, d_model)\n",
    "        self.was_explained_embedding = tf.keras.layers.Embedding(2, d_model)\n",
    "        \n",
    "        self.conc1 = tf.keras.layers.Concatenate(axis = -1)\n",
    "        self.agg1 = tf.keras.layers.Dense(d_model, activation = 'relu')\n",
    "        \n",
    "        self.conc2 = tf.keras.layers.Concatenate(axis = -1)\n",
    "        self.agg2 = tf.keras.layers.Dense(d_model, activation = 'relu')\n",
    "        \n",
    "        self.conc3 = tf.keras.layers.Concatenate(axis = -1)\n",
    "        self.agg3 = tf.keras.layers.Dense(d_model, activation = 'relu')\n",
    "        \n",
    "        self.conc4 = tf.keras.layers.Concatenate(axis = -1)\n",
    "        self.agg4 = tf.keras.layers.Dense(d_model, activation = 'relu')\n",
    "        \n",
    "        \n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                self.d_model)\n",
    "        if 'lstm' in layer_type:\n",
    "            self.lstm_layers = [tf.keras.layers.LSTM(d_model, return_sequences = True) \n",
    "                                for _ in range(num_layers)]\n",
    "        if 'attention' in layer_type:\n",
    "            self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                               for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "        self.bidirectional_encoder = bidirectional_encoder\n",
    "        \n",
    "    def call(self, x, training,\n",
    "             part = None,\n",
    "             utag = None,\n",
    "             gtag = None,\n",
    "             timestamp = None,\n",
    "             question_mean = None,\n",
    "             correct = None,\n",
    "             answer = None,\n",
    "             elapsed_time = None,\n",
    "             lag_time = None,\n",
    "             was_explained = None,\n",
    "             take = ['part', 'utag', 'gtag', 'timestamp', 'question_mean',\n",
    "                    'correct', 'answer', 'elapsed_time', 'lag_time', 'was_explained']\n",
    "            ):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        \n",
    "        if self.bidirectional_encoder == False:\n",
    "            look_ahead_mask = create_look_ahead_mask(tf.shape(x)[1])\n",
    "            dec_target_padding_mask = create_padding_mask(x, pad_token = 1)\n",
    "            mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "        else:\n",
    "            mask = create_padding_mask(x, pad_token = 1)\n",
    "        \n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "#         x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        \n",
    "        \n",
    "        part_emb = self.part_embedding(part)\n",
    "        utag_emb = self.utag_embedding(utag)\n",
    "        gtag_emb = self.gtag_embedding(gtag)\n",
    "        timestamp_emb = self.timestamp_embedding(timestamp)\n",
    "        question_mean_emb = self.question_mean_embedding(question_mean)\n",
    "        \n",
    "        correct_emb = self.correct_embedding(correct)\n",
    "        answer_emb = self.answer_embedding(answer)\n",
    "        elapsed_time_emb = self.elapsed_time_embedding(elapsed_time)\n",
    "        lag_time_emb = self.lag_time_embedding(lag_time)\n",
    "        was_explained_emb = self.was_explained_embedding(was_explained)\n",
    "        \n",
    "        question_features = self.conc1([x, part_emb, utag_emb, gtag_emb, question_mean_emb])\n",
    "        question_features = self.agg1(question_features)\n",
    "        \n",
    "        perf_features = self.conc2([correct_emb, answer_emb, elapsed_time_emb, was_explained_emb])\n",
    "        perf_features = self.agg2(perf_features)\n",
    "        \n",
    "        time_features = self.conc3([timestamp_emb, lag_time_emb])\n",
    "        time_features = self.agg3(time_features)\n",
    "        \n",
    "        all_features = self.conc4([question_features, perf_features, time_features])\n",
    "        x = self.agg4(all_features)\n",
    "        \n",
    "#         if 'part' in take:\n",
    "#             x += part_emb\n",
    "        \n",
    "#         if 'utag' in take:\n",
    "#             x += utag_emb\n",
    "            \n",
    "#         if 'gtag' in take:\n",
    "#             x += gtag_emb\n",
    "            \n",
    "#         if 'timestamp' in take:\n",
    "#             x += timestamp_emb\n",
    "            \n",
    "#         if 'question_mean' in take:\n",
    "#             x += question_mean_emb\n",
    "        \n",
    "#         if 'correct' in take:\n",
    "#             x += correct_emb\n",
    "        \n",
    "#         if 'answer' in take:\n",
    "#             x += answer_emb\n",
    "            \n",
    "#         if 'elapsed_time' in take:\n",
    "#             x += elapsed_time_emb\n",
    "            \n",
    "#         if 'lag_time' in take:\n",
    "#             x += lag_time_emb\n",
    "            \n",
    "#         if 'was_explained' in take:\n",
    "#             x += was_explained_emb\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        if self.layer_type == 'attention':\n",
    "            for i in range(self.num_layers):\n",
    "                x = self.enc_layers[i](x, training, mask)\n",
    "                \n",
    "        elif self.layer_type == 'lstm_attention':\n",
    "            for i in range(self.num_layers):\n",
    "                x = self.lstm_layers[i](x)\n",
    "                x = self.enc_layers[i](x, training, mask)\n",
    "        else:\n",
    "            for i in range(self.num_layers):\n",
    "                x = self.lstm_layers[i](x)\n",
    "                \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 128\n",
    "\n",
    "inputs_exercise = tf.keras.Input(shape = (max_len,))\n",
    "inputs_part = tf.keras.Input(shape = (max_len,))\n",
    "inputs_utag = tf.keras.Input(shape = (max_len,))\n",
    "inputs_gtag = tf.keras.Input(shape = (max_len,))\n",
    "inputs_timestamp = tf.keras.Input(shape = (max_len,))\n",
    "inputs_question_mean = tf.keras.Input(shape = (max_len,))\n",
    "\n",
    "inputs_correct = tf.keras.Input(shape = (max_len,))\n",
    "inputs_answer = tf.keras.Input(shape = (max_len,))\n",
    "inputs_elapsed_time = tf.keras.Input(shape = (max_len,))\n",
    "inputs_lag_time = tf.keras.Input(shape = (max_len,))\n",
    "inputs_was_explained = tf.keras.Input(shape = (max_len,))\n",
    "\n",
    "inputs_question_mean_bis = tf.keras.Input(shape = (max_len,1))\n",
    "\n",
    "# list_encoder = ['exercise', 'part', 'utag', 'gtag', 'timestamp', 'question_mean']\n",
    "# list_decoder = ['correct', 'answer', 'elapsed_time', 'lag_time', 'was_explained']\n",
    "# list_output = ['exercise', 'answer', 'correct']\n",
    "\n",
    "inputs = [\n",
    "    inputs_exercise,\n",
    "    inputs_part,\n",
    "    inputs_utag,\n",
    "    inputs_gtag,\n",
    "    inputs_timestamp,\n",
    "    inputs_question_mean,\n",
    "    \n",
    "    inputs_correct,\n",
    "    inputs_answer,\n",
    "    inputs_elapsed_time,\n",
    "    inputs_lag_time,\n",
    "    inputs_was_explained,\n",
    "    \n",
    "    inputs_question_mean_bis\n",
    "]\n",
    "\n",
    "\n",
    "encoder = SaintBert(\n",
    "        num_layers = 8, d_model = 512, num_heads = 8, \n",
    "        dff = 1024, input_vocab_size = 14000, maximum_position_encoding = max_len, \n",
    "        rate=0, bidirectional_encoder = False, layer_type = 'attention'\n",
    "    )\n",
    "\n",
    "call_encoder = [\n",
    "    'part', \n",
    "    'utag', \n",
    "    'gtag', \n",
    "    'timestamp', \n",
    "    'question_mean',\n",
    "                    \n",
    "    'correct', \n",
    "    'answer', \n",
    "    'elapsed_time', \n",
    "    'lag_time', \n",
    "    'was_explained',\n",
    "]\n",
    "\n",
    "\n",
    "encoded = encoder(inputs_exercise, training = True,\n",
    "             part = inputs_part,\n",
    "             utag = inputs_utag,\n",
    "             gtag = inputs_gtag,\n",
    "             timestamp = inputs_timestamp,\n",
    "             question_mean = inputs_question_mean,\n",
    "             correct = inputs_correct,\n",
    "             answer = inputs_answer,\n",
    "             elapsed_time = inputs_elapsed_time,\n",
    "             lag_time = inputs_lag_time,\n",
    "             was_explained = inputs_was_explained,\n",
    "             take = call_encoder,\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "# question_emb = tf.keras.layers.Embedding(14000, 16)(inputs_exercise)\n",
    "# part_emb = tf.keras.layers.Embedding(8, 16)(inputs_part)\n",
    "# utag_emb = tf.keras.layers.Embedding(1900, 16)(inputs_utag)\n",
    "# gtag_emb = tf.keras.layers.Embedding(100, 16)(inputs_gtag)\n",
    "# question_mean_emb = tf.keras.layers.Embedding(301, 16)(inputs_question_mean)\n",
    "\n",
    "question_emb = encoder.embedding(inputs_exercise)\n",
    "part_emb = encoder.part_embedding(inputs_part)\n",
    "utag_emb = encoder.utag_embedding(inputs_utag)\n",
    "gtag_emb = encoder.gtag_embedding(inputs_gtag)\n",
    "question_mean_emb = encoder.question_mean_embedding(inputs_question_mean)       \n",
    "\n",
    "conc_qu = tf.keras.layers.Concatenate(axis = -1)\n",
    "agg_qu = tf.keras.layers.Dense(512, activation = 'relu')\n",
    "\n",
    "\n",
    "question_rep = conc_qu([question_emb, part_emb, utag_emb, gtag_emb, question_mean_emb])\n",
    "question_rep = agg_qu(question_rep)\n",
    "\n",
    "embedding = tf.keras.layers.Dense(512, activation = 'relu')(encoded)\n",
    "# embedding = tf.keras.layers.Dense(512, activation = 'relu')(embedding)\n",
    "\n",
    "\n",
    "embedding =  tf.keras.layers.Concatenate(axis = -1)([embedding, question_rep])\n",
    "\n",
    "embedding = tf.keras.layers.Dense(512, activation = 'relu')(embedding)\n",
    "embedding =  tf.keras.layers.Dense(512, activation = 'relu')(embedding)\n",
    "\n",
    "# question_head = tf.keras.layers.Dense(14000, activation = 'softmax', name = 'question_head')(embedding)\n",
    "\n",
    "correct_head = tf.keras.layers.Dense(1, activation = 'linear')(embedding)\n",
    "correct_head = tf.keras.layers.Concatenate(axis = -1)([correct_head, inputs_question_mean_bis])\n",
    "correct_head = tf.keras.layers.Dense(1, activation = 'linear')(correct_head)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# answer_head = tf.keras.layers.Dense(5, activation = 'softmax', name = 'answer_head')(encoded)\n",
    "# correct_head = tf.keras.layers.Dense(3, activation = 'softmax', name = 'correct_head')(encoded)\n",
    "\n",
    "# outputs = [\n",
    "#     question_head,\n",
    "# #     answer_head,\n",
    "#     correct_head,\n",
    "# ]\n",
    "\n",
    "model = Model(inputs, correct_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./weights_saint/regression_gpt_0.782.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUCCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, validation=None, logs = {}, dico_params = {}, from_path = None):\n",
    "        super(AUCCallback, self).__init__()\n",
    "#         self.train = train\n",
    "        self.validation = validation\n",
    "        self.epoch = []\n",
    "#     def on_epoch_begin(self, epoch, logs={}):\n",
    "#         keys = list(logs.keys())\n",
    "#         print(\"Start epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        ## Roc auc calculation on test set\n",
    "        x_val, y_val = self.validation[0], self.validation[1]\n",
    "        pred = model.predict(x_val, verbose = 0)\n",
    "        \n",
    "        ## Two computation of roc_auc : on whole sequence and on last element       \n",
    "        ## Whole sequence \n",
    "        \n",
    "        \n",
    "        \n",
    "        y_true = y_val[1]\n",
    "        y_pred = pred[1]\n",
    "        \n",
    "        y_pred = y_pred.reshape(y_true.shape[0] * y_true.shape[1] * y_true.shape[2])\n",
    "        y_true = y_true.reshape(y_true.shape[0] * y_true.shape[1] * y_true.shape[2])\n",
    "        \n",
    "        y_pred = y_pred[y_true != 20]\n",
    "        y_true = y_true[y_true != 20]\n",
    "        \n",
    "        y_pred = y_pred\n",
    "        y_true = y_true\n",
    "        \n",
    "        y_true = y_true.astype(int)\n",
    "        \n",
    "        roc_auc = roc_auc_score(y_true, y_pred)\n",
    "        \n",
    "        logs['roc_auc'] = roc_auc\n",
    "        print(logs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                    from_logits=True, reduction='none')\n",
    "\n",
    "# loss_object = tf.keras.losses.MAE()\n",
    "\n",
    "def loss_mae(real, pred):\n",
    "#     y_true = tf.constant(np.random.randint(0, 3, size=(4, 12, 1)).astype('float32'))\n",
    "#     y_pred = tf.constant(np.random.random(size=(4,12, 1)).astype('float32'))\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 20))\n",
    "    loss = tf.keras.losses.MSE(real, pred)\n",
    "    mask = tf.cast(mask, dtype = loss.dtype)\n",
    "#     mask = tf.reshape(mask, shape = [-1, max_len])\n",
    "    mask = mask[:,:,0]\n",
    "    loss *= mask\n",
    "    loss = tf.math.reduce_sum(loss) / tf.math.reduce_sum(mask)\n",
    "    return loss\n",
    "\n",
    "def loss_qu(real_qu, pred_qu):\n",
    "    mask_qu = tf.math.logical_not(tf.math.equal(real_qu, 1))\n",
    "    loss_qu_ = loss_object(real_qu, pred_qu)\n",
    "    mask_qu = tf.cast(mask_qu , dtype=loss_qu_.dtype)\n",
    "    loss_qu_ *= mask_qu\n",
    "    loss_qu_ = tf.reduce_mean(loss_qu_)\n",
    "    return loss_qu_\n",
    "\n",
    "def loss_co(real_co, pred_co):\n",
    "    mask_co = tf.math.logical_not(tf.math.equal(real_co, 0))\n",
    "    loss_co_ = loss_object(real_co, pred_co)\n",
    "    mask_co = tf.cast(mask_co , dtype=loss_co_.dtype)\n",
    "    loss_co_ *= mask_co\n",
    "    loss_co_ = tf.reduce_mean(loss_co_)\n",
    "    return loss_co_*5\n",
    "\n",
    "def loss_an(real_an, pred_an):\n",
    "    mask_an = tf.math.logical_not(tf.math.equal(real_an, 0))\n",
    "    loss_an_ = loss_object(real_an, pred_an)\n",
    "    mask_an = tf.cast(mask_an , dtype=loss_an_.dtype)\n",
    "    loss_an_ *= mask_an\n",
    "    loss_an_ = tf.reduce_mean(loss_an_)\n",
    "    return loss_an_*5\n",
    "\n",
    "def acc_qu(true, pred):\n",
    "    mask = tf.cast(tf.math.logical_not(tf.math.equal(true, 1)),dtype = true.dtype)\n",
    "#     pred = pred[:,:,:3]\n",
    "    pred = tf.math.argmax(pred, axis=-1, output_type=tf.dtypes.int64, name=None)\n",
    "    pred = tf.cast(pred, dtype = true.dtype)\n",
    "    pred = pred*mask\n",
    "    true = true*mask\n",
    "    equal = tf.cast(tf.math.equal(pred, true), dtype = true.dtype)\n",
    "    n_equal = tf.math.reduce_sum(equal)\n",
    "    n_mask = tf.math.reduce_sum(mask)\n",
    "    n_tot = tf.math.reduce_sum(tf.cast(tf.math.greater(true, -1), dtype = true.dtype))\n",
    "    n_masked = n_tot - n_mask\n",
    "    return (n_equal - n_masked) / ((n_tot - n_masked))\n",
    "\n",
    "def acc_co(true, pred):\n",
    "    mask = tf.cast(tf.math.logical_not(tf.math.equal(true, 0)),dtype = true.dtype)\n",
    "#     pred = pred[:,:,:3]\n",
    "    pred = tf.math.argmax(pred, axis=-1, output_type=tf.dtypes.int64, name=None)\n",
    "    pred = tf.cast(pred, dtype = true.dtype)\n",
    "    pred = pred*mask\n",
    "    true = true*mask\n",
    "    equal = tf.cast(tf.math.equal(pred, true), dtype = true.dtype)\n",
    "    n_equal = tf.math.reduce_sum(equal)\n",
    "    n_mask = tf.math.reduce_sum(mask)\n",
    "    n_tot = tf.math.reduce_sum(tf.cast(tf.math.greater(true, -1), dtype = true.dtype))\n",
    "    n_masked = n_tot - n_mask\n",
    "    return (n_equal - n_masked) / (n_tot - n_masked)\n",
    "\n",
    "def acc_an(true, pred):\n",
    "    mask = tf.cast(tf.math.logical_not(tf.math.equal(true, 0)),dtype = true.dtype)\n",
    "#     pred = pred[:,:,:3]\n",
    "    pred = tf.math.argmax(pred, axis=-1, output_type=tf.dtypes.int64, name=None)\n",
    "    pred = tf.cast(pred, dtype = true.dtype)\n",
    "    pred = pred*mask\n",
    "    true = true*mask\n",
    "    equal = tf.cast(tf.math.equal(pred, true), dtype = true.dtype)\n",
    "    n_equal = tf.math.reduce_sum(equal)\n",
    "    n_mask = tf.math.reduce_sum(mask)\n",
    "    n_tot = tf.math.reduce_sum(tf.cast(tf.math.greater(true, -1), dtype = true.dtype))\n",
    "    n_masked = n_tot - n_mask\n",
    "    return (n_equal - n_masked) / (n_tot - n_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature = 8\n",
    "# batch_size = 32\n",
    "# seq_len = max_len\n",
    "\n",
    "# def loss_auc(true, pred, batch_size = 32):\n",
    "#     mask = tf.cast(tf.math.logical_not(tf.math.equal(true, 2)),dtype = true.dtype)\n",
    "#     true *= mask\n",
    "    \n",
    "#     pred = tf.reshape(pred, [-1,1])\n",
    "#     true = tf.reshape(true, [-1,1])\n",
    "    \n",
    "#     pred = tf.repeat(pred, batch_size*seq_len, axis = -1)\n",
    "    \n",
    "#     diff1 = tf.math.exp(- temperature * (pred - tf.transpose(pred)))\n",
    "    \n",
    "#     true = tf.repeat(true, batch_size*seq_len, axis = -1)\n",
    "#     zero_un_comp = tf.cast(tf.math.maximum(true - tf.transpose(true), 0), dtype = diff1.dtype)\n",
    "#     diff1 *= zero_un_comp\n",
    "#     return tf.math.reduce_sum(diff1)/tf.math.reduce_sum(zero_un_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "# losses = [loss_cl, loss_qu, loss_co, loss_an]\n",
    "lr = 3e-5\n",
    "qu = 0\n",
    "an = 0.33\n",
    "co = 1\n",
    "\n",
    "dico_params = {\n",
    "    'lr':lr,\n",
    "    'qu': qu,\n",
    "    'an':an,\n",
    "    'co':co\n",
    "}\n",
    "\n",
    "\n",
    "losses = { \"question_head\": loss_qu, \n",
    "#           'answer_head': loss_an, \n",
    "          'correct_head': loss_mae}\n",
    "\n",
    "lossWeights = {\"question_head\": qu, \n",
    "#                'answer_head': an, \n",
    "               'correct_head': co}\n",
    "\n",
    "metrics = { \n",
    "    \"question_head\": acc_qu, \n",
    "#            'answer_head': acc_an, \n",
    "#            'correct_head': acc_co\n",
    "          }\n",
    "\n",
    "\n",
    "\n",
    "loss_classif     =  loss_mae # find the right loss for multi-class classification\n",
    "optimizer        = Adam(lr, 1e-8) # find the right optimizer\n",
    "metrics_classif  =  metrics\n",
    "\n",
    "model.compile(\n",
    "#     loss='binary_crossentropy',\n",
    "    loss = losses,\n",
    "              optimizer=optimizer,\n",
    "              metrics=metrics_classif,\n",
    "             loss_weights=lossWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(batch_size=32, max_len = max_len, folder = 'user_batch_saint_100', strategy = 'end', mask_rate = 0.15, seq_mask_rate = 1, bidirectionnal = False)\n",
    "test_gen = DataGenerator(batch_size=512, max_len = max_len, folder = 'user_batch_saint_test', strategy = 'end', mask_rate = 0.15, seq_mask_rate = 1, bidirectionnal = False)\n",
    "x_test, y_test = test_gen[0]\n",
    "x_train, y_train = train_gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=7, verbose=1, \n",
    "                                                mode='auto', restore_best_weights=True)\n",
    "reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, \n",
    "                                                     mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "\n",
    "# history = CustomCallback(validation = (x_test,  y_test), dico_params = dico_params)#, from_path = './history_sb++/history_epoch_44')\n",
    "\n",
    "# callbacks = [history]\n",
    "callbacks = [AUCCallback(validation=(x_test, y_test), logs = {}), early, reduce]\n",
    "\n",
    "batch_size = 32\n",
    "n_epochs = 500\n",
    "steps_per_epoch = 200\n",
    "\n",
    "model.fit(train_gen, epochs=n_epochs,\n",
    "                    steps_per_epoch = steps_per_epoch, \n",
    "                    validation_data=(x_test,  y_test), \n",
    "                    max_queue_size=20,\n",
    "#                     workers=6,\n",
    "                    callbacks = callbacks,\n",
    "                    verbose = 1\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights('./weights_saint/saintgpt_8l_36_question_6.76_correct_70.75_auc_75.72.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = DataGenerator(batch_size=1500, max_len = max_len, folder = 'user_batch_saint_test', strategy = 'end', mask_rate = 0.15, seq_mask_rate = 1, bidirectionnal = False)\n",
    "x_val, y_val = test_gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_val, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights('./weights_saint/regression_gpt_0.782.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred[:,:,0]\n",
    "true = y_val[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 0\n",
    "M = 128\n",
    "\n",
    "y_pred = pred[:,m:M]\n",
    "y_true = true[:,m:M]\n",
    "\n",
    "y_pred = y_pred.reshape(y_true.shape[0] * y_true.shape[1])\n",
    "y_true = y_true.reshape(y_true.shape[0] * y_true.shape[1])\n",
    "\n",
    "y_pred = y_pred[y_true != 20]/10\n",
    "y_true = y_true[y_true != 20]/10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_true, (y_pred >= 0.5)*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing embedding with gbdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = DataGenerator(batch_size=1500, max_len = max_len, folder = 'user_batch_saint_test', strategy = 'end', mask_rate = 0.15, seq_mask_rate = 1, bidirectionnal = False)\n",
    "x_val, y_val = test_gen[0]\n",
    "\n",
    "# test_gen = DataGenerator(batch_size=64, max_len = max_len, folder = 'user_batch_saint_100', strategy = 'end', mask_rate = 0.15, seq_mask_rate = 1, bidirectionnal = False)\n",
    "# x_val1, y_val1 = test_gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = model.inputs\n",
    "out = model.get_layer('dense_56').output\n",
    "model1 = Model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val1, y_val2 = test_gen[0]\n",
    "y_val2 = y_val2[:,:,0]/10\n",
    "emb2 = model1.predict(x_val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val1[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate([emb2, x_val1[-1]], axis = -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = DataGenerator(batch_size=64, max_len = max_len, folder = 'user_batch_saint_100', strategy = 'end', mask_rate = 0.15, seq_mask_rate = 1, bidirectionnal = False)\n",
    "emb1 = None\n",
    "y_val1 = None\n",
    "for i in tqdm(range(100)):\n",
    "    x_val1, y_val2 = test_gen[0]\n",
    "    y_val2 = y_val2[:,:,0]/10\n",
    "    emb2 = model1.predict(x_val1)\n",
    "    emb2 = np.concatenate([emb2, x_val1[-1]], axis = -1)\n",
    "    if emb1 is not None:\n",
    "        emb1 = np.concatenate([emb1, emb2])\n",
    "        y_val1 = np.concatenate([y_val1, y_val2])\n",
    "    else:\n",
    "        emb1 = deepcopy(emb2)\n",
    "        y_val1 = deepcopy(y_val2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = model1.predict(x_val, verbose = 1)\n",
    "emb = np.concatenate([emb, x_val[-1]], axis = -1)\n",
    "# emb1 = model1.predict(x_val1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = y_val[:,:,0]/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt =  []\n",
    "yt = []\n",
    "\n",
    "for i, elt in enumerate(tqdm(x_val[0])):\n",
    "    for j, ids in enumerate(elt):\n",
    "        if ids != 1:\n",
    "            if y_val[i,j] < 2:\n",
    "                Xt.append(emb[i,j,:])\n",
    "                yt.append(y_val[i, j])\n",
    "                        \n",
    "Xt = np.array(Xt)\n",
    "yt = np.array(yt)\n",
    "\n",
    "Xv = []\n",
    "yv = []\n",
    "\n",
    "for i, elt in enumerate(tqdm(emb1)):\n",
    "    for j, ids in enumerate(elt):\n",
    "        if y_val1[i,j] < 2:\n",
    "                Xv.append(emb1[i,j,:])\n",
    "                yv.append(y_val1[i, j])\n",
    "\n",
    "Xv = np.array(Xv)\n",
    "yv = np.array(yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids_to_keep = np.random.choice(list(range(len(Xv))), size = 200000)\n",
    "# Xv = Xv[ids_to_keep]\n",
    "# yv = yv[ids_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xv, yv, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "reducer = umap.UMAP(metric='cosine',\n",
    "     n_components=32, n_neighbors=15, \n",
    "     verbose=True)\n",
    "\n",
    "reducer.fit(X_train[:30000], y_train[:30000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "reducer = PCA(n_components=32)\n",
    "reducer.fit(X_train[:30000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = reducer.transform(X_train)\n",
    "X_test1 = reducer.transform(X_test)\n",
    "Xt1 = reducer.transform(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(reducer, 'umap_reducer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "clf = lgb.LGBMClassifier(max_depth = -1, n_estimators = 500, n_jobs = 12, silent = False, early_stopping_rounds = 15)\n",
    "clf.fit(X_train1, y_train, eval_set =(Xt1, yt), eval_metric = 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(Xt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(yt, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict_proba(Xt1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(yt, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(clf, 'lightgbm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeDataGenerator:\n",
    "    \n",
    "    def __init__(self):\n",
    "        '''\n",
    "        self.data will be a dictionnary to iterate over the stored data\n",
    "        self.all_rows will be the rows of the train set that are used by the generato\n",
    "        self.data_index will be all the data available in the dataset        \n",
    "        '''\n",
    "        self.data = None\n",
    "        self.all_rows = None\n",
    "        self.data_index = None\n",
    "        return None\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        sub = sample[['row_id', 'group_num']].copy()\n",
    "        sub['answered_correctly'] = np.zeros(sub.shape[0])+0.5\n",
    "        return (sample, sub)\n",
    "    \n",
    "    \n",
    "    def load(self, save_name):\n",
    "        self.data,self.all_rows = load(save_name)\n",
    "        self.data_index = np.array(list(self.data.keys()))\n",
    "    \n",
    "    def build_from_train(self, train, n_users, beginner_rate = 0.3, save_name = 'fake_train_generator'):\n",
    "        \"\"\"\n",
    "        train will be the training set you loaded\n",
    "        n_users is a number of user from whom you will sample the data\n",
    "        beginner_rate is the rate of these users who will begin their journey during test\n",
    "        save_name : the name under which the item will be saved\n",
    "        \"\"\"\n",
    "        \n",
    "        ## Sampling a restricted list of users\n",
    "        user_list = train['user_id'].unique()\n",
    "        test_user_list = np.random.choice(user_list, size = n_users)\n",
    "        train.index = train['user_id']\n",
    "        test_data_non_filter = train.loc[test_user_list]\n",
    "        test_data_non_filter.index = list(range(test_data_non_filter.shape[0]))\n",
    "        \n",
    "        ## building a dictionnary with all the rows and container id from a user\n",
    "        dico_user = {}\n",
    "        def agg(x):\n",
    "            return [elt for elt in x]\n",
    "        \n",
    "        print(\"Generating user dictionnary\")\n",
    "        for user, frame in tqdm(test_data_non_filter.groupby('user_id'), total =test_data_non_filter['user_id'].nunique()):\n",
    "            if frame.shape[0] > 0:\n",
    "                dico_user[user] = {}\n",
    "\n",
    "                dico_user[user]['min_indice'] = frame['task_container_id'].min()\n",
    "                dico_user[user]['max_indice'] = frame['task_container_id'].max()\n",
    "\n",
    "                r = random.uniform(0,1)\n",
    "                if r < beginner_rate:\n",
    "                    dico_user[user]['current_indice'] = dico_user[user]['min_indice']\n",
    "                else:\n",
    "                    dico_user[user]['current_indice'] = random.randint(dico_user[user]['min_indice'],dico_user[user]['max_indice']-2)\n",
    "\n",
    "                row_ids = frame[['task_container_id','row_id']].groupby('task_container_id').agg(agg)\n",
    "                row_ids = row_ids.to_dict()['row_id']\n",
    "                dico_user[user]['row_ids'] = row_ids\n",
    "\n",
    "        work_dico = deepcopy(dico_user)\n",
    "        \n",
    "        ## Choosing batch_data to generate\n",
    "        work_dico = deepcopy(dico_user)\n",
    "        batches = {}\n",
    "\n",
    "        all_rows = []\n",
    "        batch_number = 0\n",
    "        \n",
    "        print('Creating batches')\n",
    "        while len(work_dico)> 1:\n",
    "\n",
    "            size = random.randint(20,500)\n",
    "            size = min(size, len(work_dico))\n",
    "\n",
    "\n",
    "            batch = []\n",
    "\n",
    "            users = np.random.choice(np.array(list(work_dico.keys())),replace = False,  size = size)\n",
    "\n",
    "            for u in users:\n",
    "                try:\n",
    "                    batch.extend(work_dico[u]['row_ids'][work_dico[u]['current_indice']])\n",
    "                    all_rows.extend(work_dico[u]['row_ids'][work_dico[u]['current_indice']])\n",
    "                    work_dico[u]['current_indice'] += 1\n",
    "                    if work_dico[u]['current_indice'] == work_dico[u]['max_indice']:\n",
    "                        work_dico.pop(u)\n",
    "                except:\n",
    "                    work_dico.pop(u)\n",
    "\n",
    "            batches[batch_number] = batch\n",
    "            batch_number += 1\n",
    "        \n",
    "        ## building data\n",
    "\n",
    "        data = {}\n",
    "        \n",
    "        print(\"Building dataset\")\n",
    "        test_data_non_filter.index = test_data_non_filter['row_id']\n",
    "        for i in tqdm(batches):\n",
    "            current_data = test_data_non_filter.loc[np.array(batches[i])]\n",
    "            current_data['group_num'] = i\n",
    "\n",
    "            current_data['prior_group_answers_correct'] = [np.nan for elt in range(current_data.shape[0])]\n",
    "            current_data['prior_group_responses'] = [np.nan for elt in range(current_data.shape[0])]\n",
    "\n",
    "            if i != 0:\n",
    "                current_data['prior_group_answers_correct'].iloc[0] = saved_correct_answer\n",
    "                current_data['prior_group_responses'].iloc[0] = saved_answer\n",
    "\n",
    "            saved_answer = str(list(current_data[current_data['content_type_id'] == 0]['user_answer'].values))\n",
    "            saved_correct_answer = str(list(current_data[current_data['content_type_id'] == 0]['answered_correctly'].values))\n",
    "            current_data = current_data.drop(columns = ['user_answer', 'answered_correctly'])\n",
    "\n",
    "            data[i] = current_data\n",
    "\n",
    "        save((data,np.array(all_rows)) , save_name)\n",
    "        \n",
    "        self.data = data\n",
    "        self.all_rows = np.array(all_rows)\n",
    "        self.data_index = np.array(list(data.keys()))\n",
    "        print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = FakeDataGenerator()\n",
    "# env.build_from_train(train, 15000, beginner_rate = 0.3, save_name = 'fake_train_generator')\n",
    "env.load('fake_train_generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, sub = env[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = load('train_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.index = train['user_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create():\n",
    "    return {\n",
    "                'exercise_id' : np.array([]),\n",
    "                'container_id' : np.array([]),\n",
    "                'timestamp' : np.array([]),\n",
    "                'correctness' : np.array([]),\n",
    "                'answer' : np.array([]), \n",
    "                'elapsed_time' : np.array([]),\n",
    "                'prior_question_had_explanation' : np.array([]),\n",
    "                'lag_time' : np.array([]),\n",
    "                'first_line' : True\n",
    "            }\n",
    "\n",
    "def update_data(data, data_sav, sub_sav):\n",
    "    prior_correct = data['prior_group_answers_correct'].iloc[0]\n",
    "    prior_answer = data['prior_group_responses'].iloc[0]\n",
    "\n",
    "    prior_correct = np.array(prior_correct.replace('[', '').replace(']', '').split(', ')).astype(int)\n",
    "    prior_answer = np.array(prior_answer.replace('[', '').replace(']', '').split(', ')).astype(int)\n",
    "\n",
    "    corr = np.zeros(data_sav.shape[0]) - 1 \n",
    "    ans = np.zeros(data_sav.shape[0]) - 1\n",
    "\n",
    "    boole = data_sav['content_type_id'].values == 0\n",
    "\n",
    "    corr[boole] = prior_correct\n",
    "    ans[boole] = prior_answer\n",
    "\n",
    "    data_sav['answered_correctly'] = corr\n",
    "    data_sav['user_answer'] = ans\n",
    "    sub_sav['answered_correctly_truth'] = corr\n",
    "    \n",
    "    sub_sav = sub_sav[boole]\n",
    "    \n",
    "    return data_sav, sub_sav\n",
    "\n",
    "def update_dico_user(dico_user, data_sav):\n",
    "    data_sav = data_sav.sort_values(by = ['timestamp'])\n",
    "    for i, line in data_sav.iterrows():\n",
    "        user = line['user_id']\n",
    "        exid = line['content_id']\n",
    "        tid = line['content_type_id']\n",
    "        exid = 'q_'+str(exid) if tid == 0 else 'l_' + str(exid)\n",
    "\n",
    "        dico_user[user]['exercise_id'] = np.concatenate([dico_user[user]['exercise_id'], [exid]])\n",
    "        dico_user[user]['container_id'] = np.concatenate([dico_user[user]['container_id'], [line['task_container_id']]])\n",
    "        dico_user[user]['timestamp'] = np.concatenate([dico_user[user]['timestamp'], [line['timestamp']/1000]])\n",
    "        dico_user[user]['correctness'] = np.concatenate([dico_user[user]['correctness'], [line['answered_correctly']]])\n",
    "        dico_user[user]['answer'] = np.concatenate([dico_user[user]['answer'], [line['user_answer']]])\n",
    "\n",
    "        ## two other depend on if this is the first line\n",
    "        if dico_user[user]['first_line']:\n",
    "            dico_user[user]['first_line'] = False\n",
    "            dico_user[user]['lag_time'] = np.concatenate([dico_user[user]['lag_time'], [0]])\n",
    "\n",
    "        else:\n",
    "            el = line['prior_question_elapsed_time']\n",
    "            if str(el) == 'nan':\n",
    "                el = 0\n",
    "            dico_user[user]['elapsed_time'] = np.concatenate([dico_user[user]['elapsed_time'], [el]])\n",
    "\n",
    "            pr = line['prior_question_had_explanation']\n",
    "            if str(pr) == 'nan':\n",
    "                pr = 0\n",
    "            pr = pr*1\n",
    "            dico_user[user]['prior_question_had_explanation'] = np.concatenate([dico_user[user]['prior_question_had_explanation'], [pr]])\n",
    "\n",
    "            lag = dico_user[user]['timestamp'][-1] - dico_user[user]['timestamp'][-2] + el\n",
    "            if lag < 0:\n",
    "                lag = 0\n",
    "            dico_user[user]['lag_time'] = np.concatenate([dico_user[user]['lag_time'], [lag]])\n",
    "    return dico_user\n",
    "\n",
    "\n",
    "dico_question = load('dico_questions_mean')\n",
    "dico_utags, dico_gtags, dico_parts = load('dico_tags')\n",
    "timestamp_enc, elapsed_enc,lag_time_enc, qmean_enc = load('discrete_encoders')\n",
    "tokenizer = load('tokenizer')\n",
    "\n",
    "def map_part( ids):\n",
    "    def replace_dico_part(x):\n",
    "        try:\n",
    "            return dico_parts[x]\n",
    "        except:\n",
    "            return 0\n",
    "    return np.array(list(map(replace_dico_part,ids)))\n",
    "\n",
    "def map_utags( ids):\n",
    "    def replace_dico_utags(x):\n",
    "        try:\n",
    "            if str(dico_utags[x]) != 'nan':\n",
    "                return str(self.dico_utags[x])\n",
    "            else:\n",
    "                return 0\n",
    "        except:\n",
    "            return 0\n",
    "    return np.array(list(map(replace_dico_utags,ids)))\n",
    "\n",
    "def map_gtags( ids):\n",
    "    def replace_dico_gtags(x):\n",
    "        try:\n",
    "            if str(dico_gtags[x]) != 'nan':\n",
    "                return str(dico_gtags[x])\n",
    "            else:\n",
    "                return 0\n",
    "        except:\n",
    "            return 0\n",
    "    return np.array(list(map(replace_dico_gtags,ids)))\n",
    "\n",
    "def map_mean(ids):\n",
    "    def replace_dico_question(x):\n",
    "        try:\n",
    "            return dico_question[x]\n",
    "        except:\n",
    "            return 0.5\n",
    "    return np.array(list(map(replace_dico_question,ids)))\n",
    "\n",
    "def remove_na(x):\n",
    "    x = np.array(list(x))\n",
    "    x[np.isnan(x)] = 0\n",
    "    return x\n",
    "\n",
    "def build_sequence(user_history, new_inputs, max_len = 128):\n",
    "    ## new input : (exercise_id, timestamp, elapsed)\n",
    "    \n",
    "    dico_sequence = deepcopy(user_history)        \n",
    "    dico_sequence['elapsed_time'] = remove_na(dico_sequence['elapsed_time'])\n",
    "    dico_sequence['lag_time'] = remove_na(dico_sequence['lag_time'])\n",
    "    dico_sequence['prior_question_had_explanation'] = remove_na(dico_sequence['prior_question_had_explanation'])\n",
    "\n",
    "    dico_sequence['elapsed_time'] = np.concatenate([dico_sequence['elapsed_time'], [0]])\n",
    "    dico_sequence['prior_question_had_explanation'] = np.concatenate([dico_sequence['prior_question_had_explanation'], [0]])\n",
    "\n",
    "\n",
    "    ## Cut sequence\n",
    "    for elt in dico_sequence:\n",
    "        if elt != 'first_line':\n",
    "            dico_sequence[elt] = dico_sequence[elt][-(max_len-1):]\n",
    "        \n",
    "    ## Adding new elements\n",
    "    dico_sequence['exercise_id'] = np.concatenate([dico_sequence['exercise_id'], [new_inputs[0]]])\n",
    "    dico_sequence['timestamp'] = np.concatenate([dico_sequence['timestamp'], [new_inputs[1]]])\n",
    "    try:\n",
    "        lag = dico_sequence['timestamp'][-1] - dico_sequence['timestamp'][-2] + new_inputs[2]\n",
    "    except:\n",
    "        lag = 0\n",
    "    if lag < 0:\n",
    "        lag = 0\n",
    "    dico_sequence['lag_time'] = np.concatenate([dico_sequence['lag_time'], [lag]])\n",
    "    query_id = len(dico_sequence['exercise_id']) - 1\n",
    "    \n",
    "    ## Pad sequence\n",
    "    pad_tokens = ['[PAD]', 0, 0, -1, -1, 0, 0, 0, '[PAD]', -1, -1]\n",
    "    for j, elt in enumerate(dico_sequence):\n",
    "        if elt != 'first_line':\n",
    "            size = len(dico_sequence[elt])\n",
    "            if size <= max_len:\n",
    "                adding = max_len - size\n",
    "                tok = pad_tokens[j]\n",
    "                if type(tok) == str:\n",
    "                    add = np.array([tok for elt in range(adding)])\n",
    "                else:\n",
    "                    add = np.zeros(adding) + tok\n",
    "                dico_sequence[elt] = np.concatenate([dico_sequence[elt], add], axis = 0)\n",
    "#                 print(dico_sequence[elt].shape)\n",
    "    lags =  lag_time_enc.transform(dico_sequence['lag_time'])\n",
    "    lags[lags<0] = 0\n",
    "    \n",
    "    input_vals = [\n",
    "        dico_sequence['exercise_id'],\n",
    "        map_part(dico_sequence['exercise_id']),\n",
    "        map_utags(dico_sequence['exercise_id']),\n",
    "        map_gtags(dico_sequence['exercise_id']),\n",
    "        timestamp_enc.transform(dico_sequence['timestamp']),\n",
    "        qmean_enc.transform(map_mean(dico_sequence['exercise_id'])),\n",
    "\n",
    "        np.concatenate([[0], dico_sequence['correctness'] + 1])[:-1],\n",
    "        np.concatenate([[0], dico_sequence['answer'] + 1])[:-1],\n",
    "        np.concatenate([[0], elapsed_enc.transform(dico_sequence['elapsed_time'])])[:-1],\n",
    "        lags,\n",
    "        np.concatenate([[0], dico_sequence['prior_question_had_explanation']])[:-1],\n",
    "    ]\n",
    "    return input_vals, query_id\n",
    "\n",
    "def initiate_dico(batch_size, max_len = 128):\n",
    "    list_encoder = ['exercise', 'part', 'utag', 'gtag', 'timestamp', 'question_mean']\n",
    "    list_decoder = ['correct', 'answer', 'elapsed_time', 'lag_time', 'was_explained']\n",
    "    list_output = ['exercise', 'answer', 'correct']\n",
    "\n",
    "    dico_input = {}\n",
    "    for elt in list_encoder + list_decoder:\n",
    "        if elt == 'exercise':\n",
    "            dico_input[elt] = np.zeros((batch_size, max_len)).astype(str)\n",
    "        else:\n",
    "            dico_input[elt] = np.zeros((batch_size, max_len)).astype('int32')\n",
    "    return dico_input\n",
    "\n",
    "def update_dico(dico_input, input_vals, i):\n",
    "    list_encoder = ['exercise', 'part', 'utag', 'gtag', 'timestamp', 'question_mean']\n",
    "    list_decoder = ['correct', 'answer', 'elapsed_time', 'lag_time', 'was_explained']\n",
    "    list_output = ['exercise', 'answer', 'correct']\n",
    "\n",
    "    for j, elt in enumerate(list_encoder + list_decoder):\n",
    "        dico_input[elt][i] = input_vals[j]\n",
    "    return dico_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dico_user = {}\n",
    "data_sav = None\n",
    "count = 0\n",
    "\n",
    "all_sub = None\n",
    "\n",
    "for i in tqdm(env.data_index):\n",
    "    data, sub = env[i]\n",
    "    \n",
    "    for elt in data['user_id'].unique():\n",
    "        # Loading every piece of information available from past\n",
    "        if not(elt in dico_user):\n",
    "            try:\n",
    "#                 print(elt)\n",
    "                dico_user[elt] = load(str(elt), 'ind_user')\n",
    "                dico_user[elt]['first_line'] = False\n",
    "            except:\n",
    "                dico_user[elt] = create()\n",
    "        \n",
    "    ## Updating data_sav with the new informations\n",
    "    if count != 0:\n",
    "        ## Include values in the mix\n",
    "        data_sav, sub_sav = update_data(data, data_sav, sub_sav)\n",
    "        \n",
    "        if all_sub is not None:\n",
    "            all_sub = pd.concat([all_sub, sub_sav])\n",
    "        else:\n",
    "            all_sub = sub_sav.copy()\n",
    "        print(roc_auc_score(all_sub['answered_correctly_truth'], all_sub['answered_correctly']))\n",
    "        \n",
    "        ## Update dictionnary with data of previous batch\n",
    "        dico_user = update_dico_user(dico_user, data_sav)\n",
    "    \n",
    "    ## Build input for the deep learning model\n",
    "    dico_input = initiate_dico(data.shape[0])\n",
    "    \n",
    "    data.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    query_ids = []\n",
    "    for i, line in data.iterrows():\n",
    "        user = line['user_id']\n",
    "        exid = line['content_id']\n",
    "        tid = line['content_type_id']\n",
    "        exid = 'q_'+str(exid) if tid == 0 else 'l_' + str(exid)\n",
    "        \n",
    "        t = line['timestamp'] / 1000\n",
    "        el = line['prior_question_elapsed_time'] / 1000\n",
    "        \n",
    "        input_vals, query_id = build_sequence(dico_user[user], (exid, t, el))\n",
    "        query_ids.append(query_id)\n",
    "        dico_input = update_dico(dico_input, input_vals, i)\n",
    "    \n",
    "    x = deepcopy(dico_input['exercise'])\n",
    "    dico_input['exercise'] = np.array(tokenizer.texts_to_sequences([\" \".join(list(x)[elt]) for elt in range(len(x))]))\n",
    "    \n",
    "    X = list(np.array(list(dico_input.values())).astype('int32'))\n",
    "    \n",
    "    ## Lgbm variant\n",
    "    predicted = model1.predict(X)\n",
    "    X1 = []\n",
    "    \n",
    "    print(query_ids)\n",
    "    \n",
    "    for i, j in enumerate(query_ids):\n",
    "        X1.append(predicted[i,j,:])\n",
    "    X1 = np.array(X1)\n",
    "    p = clf.predict_proba(X1)[:,1]\n",
    "    \n",
    "    ## Deep Variant\n",
    "#     p1 = model.predict(X)[2][:,:,2]\n",
    "    \n",
    "#     p = []\n",
    "#     for i, j in enumerate(query_ids):\n",
    "#         p.append(p1[i,j])\n",
    "    \n",
    "    sub['answered_correctly'] = p\n",
    "                \n",
    "    data_sav = data.copy()\n",
    "    sub_sav = sub.copy()\n",
    "    count += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self,batch_size=32, max_len = 128, folder = 'user_batch_saint_100', strategy = 'begin', mask_rate = 0.15, seq_mask_rate = 0.5, bidirectionnal = True):\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = load('tokenizer')\n",
    "        self.max_len = max_len\n",
    "        self.folder = folder\n",
    "        self.dico_question = load('dico_questions_mean')\n",
    "        self.dico_utags, self.dico_gtags, self.dico_parts = load('dico_tags')\n",
    "        self.timestamp_enc, self.elapsed_enc,self.lag_time_enc, self.qmean_enc = load('discrete_encoders')\n",
    "        self.strategy = strategy\n",
    "        self.mask_rate = mask_rate\n",
    "        self.seq_mask_rate = seq_mask_rate\n",
    "        self.bidirectionnal = bidirectionnal\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 1000000\n",
    "    \n",
    "    def initiate_dico(self):\n",
    "        list_encoder = ['exercise', 'part', 'utag', 'gtag', 'timestamp', 'question_mean']\n",
    "        list_decoder = ['correct', 'answer', 'elapsed_time', 'lag_time', 'was_explained']\n",
    "        list_output = ['exercise', 'answer', 'correct']\n",
    "        \n",
    "        dico_input = {}\n",
    "        for elt in list_encoder + list_decoder:\n",
    "            if elt == 'exercise':\n",
    "                dico_input[elt] = np.zeros((self.batch_size, self.max_len)).astype(str)\n",
    "            else:\n",
    "                dico_input[elt] = np.zeros((self.batch_size, self.max_len)).astype('int32')\n",
    "        \n",
    "        dico_output = {}\n",
    "        for elt in list_output:\n",
    "            if elt == 'exercise':\n",
    "                dico_output[elt] = np.zeros((self.batch_size, self.max_len)).astype(str)\n",
    "            else:\n",
    "                dico_output[elt] = np.zeros((self.batch_size, self.max_len)).astype('int32')\n",
    "        return dico_input, dico_output\n",
    "\n",
    "    def map_part(self, ids):\n",
    "        def replace_dico_part(x):\n",
    "            try:\n",
    "                return self.dico_parts[x]\n",
    "            except:\n",
    "                return 0\n",
    "        return np.array(list(map(replace_dico_part,ids)))\n",
    "    \n",
    "    def map_utags(self, ids):\n",
    "        def replace_dico_utags(x):\n",
    "            try:\n",
    "                if str(self.dico_utags[x]) != 'nan':\n",
    "                    return str(self.dico_utags[x])\n",
    "                else:\n",
    "                    return 0\n",
    "            except:\n",
    "                return 0\n",
    "        return np.array(list(map(replace_dico_utags,ids)))\n",
    "    \n",
    "    def map_gtags(self, ids):\n",
    "        def replace_dico_gtags(x):\n",
    "            try:\n",
    "                if str(self.dico_gtags[x]) != 'nan':\n",
    "                    return str(self.dico_gtags[x])\n",
    "                else:\n",
    "                    return 0\n",
    "            except:\n",
    "                return 0\n",
    "        return np.array(list(map(replace_dico_gtags,ids)))\n",
    "    \n",
    "    def map_mean(self, ids):\n",
    "        def replace_dico_question(x):\n",
    "            try:\n",
    "                return self.dico_question[x]\n",
    "            except:\n",
    "                return 0.5\n",
    "        return np.array(list(map(replace_dico_question,ids)))\n",
    "\n",
    "\n",
    "    \n",
    "    def update_dico(self, dico_input, dico_output, input_vals, output_vals, i):\n",
    "        list_encoder = ['exercise', 'part', 'utag', 'gtag', 'timestamp', 'question_mean']\n",
    "        list_decoder = ['correct', 'answer', 'elapsed_time', 'lag_time', 'was_explained']\n",
    "        list_output = ['exercise', 'answer', 'correct']\n",
    "        \n",
    "        for j, elt in enumerate(list_encoder + list_decoder):\n",
    "            dico_input[elt][i] = input_vals[j]\n",
    "        \n",
    "        for j, elt in enumerate(list_output):\n",
    "            dico_output[elt][i] = output_vals[j]\n",
    "        return dico_input, dico_output\n",
    "\n",
    "    def remove_na(self, x):\n",
    "        x = np.array(list(x))\n",
    "        x[np.isnan(x)] = 0\n",
    "        return x\n",
    "    \n",
    "    def apply_mask(self, x, mask, pad_token, mask_token):\n",
    "        x_out = []\n",
    "        x_in = []\n",
    "        for i, elt in enumerate(mask):\n",
    "            if mask[i] == 1:\n",
    "                x_out.append(x[i])\n",
    "                x_in.append(mask_token)\n",
    "            else:\n",
    "                x_out.append(pad_token)\n",
    "                x_in.append(x[i])\n",
    "        return np.array(x_in), np.array(x_out)\n",
    "\n",
    "    def build_sequence(self, user_history):\n",
    "        dico_sequence = deepcopy(user_history)        \n",
    "        dico_sequence['elapsed_time'] = self.remove_na(dico_sequence['elapsed_time'])\n",
    "        dico_sequence['lag_time'] = self.remove_na(dico_sequence['lag_time'])\n",
    "        dico_sequence['prior_question_had_explanation'] = self.remove_na(dico_sequence['prior_question_had_explanation'])\n",
    "        \n",
    "        dico_sequence['elapsed_time'] = np.concatenate([dico_sequence['elapsed_time'], [0]])\n",
    "        dico_sequence['prior_question_had_explanation'] = np.concatenate([dico_sequence['prior_question_had_explanation'], [0]])\n",
    "        \n",
    "        \n",
    "        ## Cut sequence\n",
    "        if self.strategy == 'begin':\n",
    "            for elt in dico_sequence:\n",
    "                dico_sequence[elt] = dico_sequence[elt][:self.max_len]\n",
    "        else:\n",
    "            for elt in dico_sequence:\n",
    "                dico_sequence[elt] = dico_sequence[elt][-self.max_len:]\n",
    "        \n",
    "        \n",
    "        \n",
    "         ## Masking\n",
    "        # Either mask question => mask parts, qmean, answer, correctness 0.5%\n",
    "        # Or mask correctness => mask answer, elapsed_time, lag_time, explanation 0.5%\n",
    "        # In all case, mask the last question answer, but we keep its signification\n",
    "        \n",
    "        if self.bidirectionnal == True:\n",
    "            r = random.uniform(0,1)\n",
    "            if r < self.seq_mask_rate:\n",
    "                # masking on the question_id\n",
    "                masks = np.random.choice([0,1],replace = True, size = len(dico_sequence['exercise_id'])-1, p = [1-self.mask_rate,self.mask_rate])\n",
    "\n",
    "    #             print(masks.shape)\n",
    "    #             print(dico_sequence['elapsed_time'].shape)\n",
    "    #             print('\\n')\n",
    "\n",
    "                dico_sequence['elapsed_time'], _ = self.apply_mask(dico_sequence['elapsed_time'], masks, 0, 0)     \n",
    "                dico_sequence['prior_question_had_explanation'], _ = self.apply_mask(dico_sequence['prior_question_had_explanation'], masks, 0, 0) \n",
    "\n",
    "                masks = np.concatenate([masks, [0]])\n",
    "                dico_sequence['exercise_id'], dico_sequence['exercise_id_out'] = self.apply_mask(dico_sequence['exercise_id'], masks, '[PAD]', '[MASK]')            \n",
    "                masks[-1] = 1\n",
    "                dico_sequence['answer'], dico_sequence['answer_out'] = self.apply_mask(dico_sequence['answer'], masks, -1, -1)\n",
    "                dico_sequence['correctness'], dico_sequence['correctness_out'] = self.apply_mask(dico_sequence['correctness'], masks, -1, -1)\n",
    "\n",
    "            else:\n",
    "                # Masking only a part of the answers\n",
    "                dico_sequence['exercise_id_out'] = deepcopy(np.array(['[PAD]' for elt in dico_sequence['exercise_id']]))\n",
    "                masks = np.random.choice([0,1],replace = True, size = len(dico_sequence['correctness'])-1, p = [1-self.mask_rate,self.mask_rate])\n",
    "\n",
    "    #             print(masks.shape)\n",
    "    #             print(dico_sequence['elapsed_time'].shape)\n",
    "    #             print('\\n')\n",
    "\n",
    "                dico_sequence['elapsed_time'], _ = self.apply_mask(dico_sequence['elapsed_time'], masks, 0, 0)    \n",
    "                dico_sequence['prior_question_had_explanation'], _ = self.apply_mask(dico_sequence['prior_question_had_explanation'], masks, 0, 0)\n",
    "\n",
    "                masks = np.concatenate([masks, [1]])\n",
    "                dico_sequence['correctness'], dico_sequence['correctness_out'] = self.apply_mask(dico_sequence['correctness'], masks, -1, -1)\n",
    "                dico_sequence['answer'], dico_sequence['answer_out'] = self.apply_mask(dico_sequence['answer'], masks, -1, -1)\n",
    "        \n",
    "        else:\n",
    "            dico_sequence['exercise_id_out'] = dico_sequence['exercise_id']\n",
    "            dico_sequence['correctness_out'] = dico_sequence['correctness']\n",
    "            dico_sequence['answer_out'] = dico_sequence['answer']\n",
    "        \n",
    "        ## Pad sequence\n",
    "        pad_tokens = ['[PAD]', 0, 0, -1, -1, 0, 0, 0, '[PAD]', -1, -1]\n",
    "        for j, elt in enumerate(dico_sequence):\n",
    "            size = len(dico_sequence[elt])\n",
    "            if size <= self.max_len:\n",
    "                adding = self.max_len - size\n",
    "                tok = pad_tokens[j]\n",
    "                if type(tok) == str:\n",
    "                    add = np.array([tok for elt in range(adding)])\n",
    "                else:\n",
    "                    add = np.zeros(adding) + tok\n",
    "                dico_sequence[elt] = np.concatenate([dico_sequence[elt], add], axis = 0)\n",
    "#                 print(dico_sequence[elt].shape)\n",
    "\n",
    "        if self.bidirectionnal == False:\n",
    "            input_vals = [\n",
    "                dico_sequence['exercise_id'],\n",
    "                self.map_part(dico_sequence['exercise_id']),\n",
    "                self.map_utags(dico_sequence['exercise_id']),\n",
    "                self.map_gtags(dico_sequence['exercise_id']),\n",
    "                self.timestamp_enc.transform(dico_sequence['timestamp']),\n",
    "                self.qmean_enc.transform(self.map_mean(dico_sequence['exercise_id'])),\n",
    "\n",
    "                np.concatenate([[0], dico_sequence['correctness'] + 1])[:-1],\n",
    "                np.concatenate([[0], dico_sequence['answer'] + 1])[:-1],\n",
    "                np.concatenate([[0], self.elapsed_enc.transform(dico_sequence['elapsed_time'])])[:-1],\n",
    "                self.lag_time_enc.transform(dico_sequence['lag_time']),\n",
    "                np.concatenate([[0], dico_sequence['prior_question_had_explanation']])[:-1],\n",
    "            ]\n",
    "\n",
    "            output_vals = [\n",
    "                np.concatenate([dico_sequence['exercise_id_out'][1:], ['[PAD]']]),\n",
    "                dico_sequence['answer_out'] + 1,\n",
    "                dico_sequence['correctness_out'] + 1,\n",
    "            ]\n",
    "            \n",
    "        else:\n",
    "            input_vals = [\n",
    "                dico_sequence['exercise_id'],\n",
    "                self.map_part(dico_sequence['exercise_id']),\n",
    "                self.map_utags(dico_sequence['exercise_id']),\n",
    "                self.map_gtags(dico_sequence['exercise_id']),\n",
    "                self.timestamp_enc.transform(dico_sequence['timestamp']),\n",
    "                self.qmean_enc.transform(self.map_mean(dico_sequence['exercise_id'])),\n",
    "\n",
    "                dico_sequence['correctness'] + 1,\n",
    "                dico_sequence['answer'] + 1,\n",
    "                self.elapsed_enc.transform(dico_sequence['elapsed_time']),\n",
    "                self.lag_time_enc.transform(dico_sequence['lag_time']),\n",
    "                dico_sequence['prior_question_had_explanation'],\n",
    "            ]\n",
    "\n",
    "            output_vals = [\n",
    "                dico_sequence['exercise_id_out'],\n",
    "                dico_sequence['answer_out'] + 1,\n",
    "                dico_sequence['correctness_out'] + 1,\n",
    "            ]\n",
    "        \n",
    "        \n",
    "#         x = np.zeros((11,self.max_len))\n",
    "#         y = np.zeros((3, self.max_len))\n",
    "        return input_vals,output_vals\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ## Load random batch\n",
    "        file_name = random.choice(os.listdir('./'+self.folder))\n",
    "        dico_user = load(file_name.split('.')[0], self.folder)\n",
    "        \n",
    "        list_user = np.random.choice(list(dico_user.keys()), size = self.batch_size)\n",
    "        \n",
    "        dico_input, dico_output = self.initiate_dico()\n",
    "        \n",
    "        \n",
    "        for i, elt in enumerate(list_user):\n",
    "            user_history = dico_user[elt]\n",
    "            input_vals, output_vals = self.build_sequence(user_history)\n",
    "            dico_input, dico_output = self.update_dico(dico_input, dico_output, input_vals, output_vals, i)\n",
    "        \n",
    "        x = deepcopy(dico_input['exercise'])\n",
    "        dico_input['exercise'] = np.array(self.tokenizer.texts_to_sequences([\" \".join(list(x)[elt]) for elt in range(len(x))]))\n",
    "        \n",
    "        x = deepcopy(dico_output['exercise'])\n",
    "        dico_output['exercise'] = np.array(self.tokenizer.texts_to_sequences([\" \".join(list(x)[elt]) for elt in range(len(x))]))\n",
    "        \n",
    "        X = list(np.array(list(dico_input.values())).astype('int32'))\n",
    "        y = list(np.array(list(dico_output.values())).astype('int32')) \n",
    "        \n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "\n",
    "    def __get_data(self, batch):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_sequence(df_user):\n",
    "    import numpy as np\n",
    "    df_user =  df_user.sort_values(by = 'timestamp')\n",
    "    df_user.index = list(range(df_user.shape[0]))\n",
    "    \n",
    "    df_user['content_type'] =  df_user['content_type_id'].apply(lambda x : 'q' if x == 0 else 'l')\n",
    "    df_user['content_seq'] = df_user['content_type'].astype(str) + '_' + df_user['content_id'].astype(str)\n",
    "    \n",
    "    ## Encoder\n",
    "    exercise_id = df_user['content_seq'].values\n",
    "    container_id = df_user['task_container_id'].values\n",
    "    timestamp = df_user['timestamp'].values/1000  ## Conversion in s\n",
    "    \n",
    "    ## Decoder\n",
    "    correctness = df_user['answered_correctly'].values\n",
    "    answer = df_user['user_answer'].values\n",
    "    \n",
    "    elapsed_time = df_user['prior_question_elapsed_time'].fillna(0).values[1:]/1000 ## Already Padded ## Conversion in s\n",
    "    prior_question_had_explanation = df_user['prior_question_had_explanation'].fillna(0).values[1:]*1 ## Already Padded\n",
    "    \n",
    "    lag_time = np.concatenate([[0],timestamp[1:] - timestamp[:-1] + elapsed_time])\n",
    "    \n",
    "    dico = {\n",
    "        'exercise_id' : exercise_id,\n",
    "        'container_id' : container_id,\n",
    "        'timestamp' : timestamp,\n",
    "        'correctness' : correctness,\n",
    "        'answer' : answer, \n",
    "        'elapsed_time' : elapsed_time,\n",
    "        'prior_question_had_explanation' : prior_question_had_explanation,\n",
    "        'lag_time' : lag_time\n",
    "    }\n",
    "    return dico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "b = 0\n",
    "for elt in tqdm(dico_user.keys()):\n",
    "    c = dico_user[elt]\n",
    "    if len(c['exercise_id']) <= 1:\n",
    "        a += 1\n",
    "    else:\n",
    "        b+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ameliorations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add context on lecture and tasks\n",
    "\n",
    "cluster lecture and tasks\n",
    "\n",
    "give average score of a given task\n",
    "\n",
    "enhance test set with train set (optimization constraint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
