{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import _pickle as pickle\n",
    "import gc\n",
    "from multiprocess import Pool\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "def save(file,name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'wb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'wb')\n",
    "    pickle.dump(file, outfile, protocol=4)\n",
    "    outfile.close\n",
    "    \n",
    "def load(name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'rb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'rb')\n",
    "    file = pickle.load(outfile)\n",
    "    outfile.close\n",
    "    return file\n",
    "\n",
    "class Discretiser:\n",
    "    def __init__(self, nbins):\n",
    "        self.nbins = nbins-1\n",
    "        self.map_to = np.arange(self.nbins)/self.nbins\n",
    "        \n",
    "    def fit(self, X):\n",
    "        ## X is a one dimension np array\n",
    "        self.map_from = np.quantile(X, self.map_to)\n",
    "        \n",
    "    def transform(self, X):\n",
    "        X1 = (np.interp(X, self.map_from, self.map_to, left=0, right=1, period=None) * self.nbins).astype(int)\n",
    "        return X1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch  Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = load('train_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_user = train[train['user_id'] == 115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_user_sequence(df_user):\n",
    "    \n",
    "#     df_user =  df_user.sort_values(by = 'timestamp')\n",
    "#     df_user.index = list(range(df_user.shape[0]))\n",
    "    \n",
    "#     df_user['content_type'] =  df_user['content_type_id'].apply(lambda x : 'q' if x == 0 else 'l')\n",
    "#     df_user['content_seq'] = df_user['content_type'].astype(str) + '_' + df_user['content_id'].astype(str)\n",
    "    \n",
    "#     ## Encoder\n",
    "#     exercise_id = df_user['content_seq'].values\n",
    "#     container_id = df_user['task_container_id'].values\n",
    "#     timestamp = df_user['timestamp'].values\n",
    "    \n",
    "#     ## Decoder\n",
    "#     correctness = df_user['answered_correctly'].values\n",
    "#     answer = df_user['user_answer'].values\n",
    "    \n",
    "#     elapsed_time = df_user['prior_question_elapsed_time'].values[1:] ## Already Padded\n",
    "#     prior_question_had_explanation = df_user['prior_question_had_explanation'].values[1:]*1 ## Already Padded\n",
    "    \n",
    "#     lag_time = timestamp[1:] - timestamp[:1] + elapsed_time\n",
    "    \n",
    "#     dico = {\n",
    "#         'exercise_id' : exercise_id,\n",
    "#         'container_id' : container_id,\n",
    "#         'timestamp' : timestamp,\n",
    "#         'correctness' : correctness,\n",
    "#         'answer' : answer, \n",
    "#         'elapsed_time' : elapsed_time,\n",
    "#         'prior_question_had_explanation' : prior_question_had_explanation,\n",
    "#         'lag_time' : lag_time\n",
    "#     }\n",
    "#     return dico\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 2000\n",
    "# count = 0\n",
    "# vect = []\n",
    "# count = 0\n",
    "# p = Pool(12)\n",
    "\n",
    "# for elt in tqdm(train.groupby('user_id'), total = train['user_id'].nunique()):\n",
    "#     vect.append(elt)\n",
    "#     if len(vect) == batch_size:\n",
    "#         vect = np.array(vect)\n",
    "#         vect_user = vect[:,0]\n",
    "#         vect_data = vect[:,1]\n",
    "#         vect = []\n",
    "        \n",
    "#         processed_dico = p.map(build_user_sequence, vect_data)\n",
    "        \n",
    "#         dico_user = {}\n",
    "#         for i, elt in enumerate(vect_user):\n",
    "#             dico_user[elt] = processed_dico[i]\n",
    "#         save(dico_user, 'batch_'+str(count), 'user_batch_saint')\n",
    "#         count += 1\n",
    "        \n",
    "# p.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## timestamp encoder\n",
    "train = load('train_train')\n",
    "t = train['timestamp'].values\n",
    "timestamp_enc = Discretiser(300)\n",
    "timestamp_enc.fit(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Elapsed time encoder\n",
    "dico_user = load('batch_'+str(0), 'user_batch_saint_2000')\n",
    "el = []\n",
    "for elt in dico_user:\n",
    "    ela = dico_user[elt]['elapsed_time']\n",
    "    ela[np.isnan(ela)] = 0\n",
    "    el += list(ela)\n",
    "elapsed_enc = Discretiser(300)\n",
    "elapsed_enc.fit(el)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question mean encoder\n",
    "dico_question = load('dico_questions_mean')\n",
    "val = list(dico_question.values())\n",
    "qmean_enc = Discretiser(300)\n",
    "qmean_enc.fit(val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving\n",
    "save((timestamp_enc, elapsed_enc, qmean_enc), 'discrete_encoders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building tokenizer\n",
    "lectures = pd.read_csv('lectures.csv')\n",
    "questions = pd.read_csv('questions.csv')\n",
    "user_answer = np.array([-1,0,1,2,3])\n",
    "answered_correctly = np.array([-1,0,1])\n",
    "\n",
    "lectures_id = lectures['lecture_id'].unique()\n",
    "question_id = questions['question_id'].unique()\n",
    "\n",
    "lectures_id = ['l_' +  elt for elt in  lectures_id.astype(str)]\n",
    "question_id = ['q_' +  elt for elt in  question_id.astype(str)]\n",
    "\n",
    "all_tokens = np.array(['[PAD]', '[CLS]', '[SEP]', '[MASK]'] + lectures_id + question_id)\n",
    "\n",
    "tokenizer = Tokenizer(filters = '')\n",
    "\n",
    "tokenizer.fit_on_texts(\n",
    "    all_tokens\n",
    ")\n",
    "\n",
    "save(tokenizer, 'tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionnaries():\n",
    "    df = pd.read_csv('questions.csv')\n",
    "    df1 = pd.read_csv('lectures.csv')\n",
    "\n",
    "    def apply(x):\n",
    "        return 'q_'+str(x)\n",
    "\n",
    "    def apply1(x):\n",
    "        return 'l_'+str(x)\n",
    "\n",
    "    def to_tab(x):\n",
    "        if str(x)!='nan':\n",
    "            x = np.array(str(x).split(' ')).astype(int)\n",
    "        else:\n",
    "            x = []\n",
    "        x.sort()\n",
    "        return x\n",
    "\n",
    "    df['tag'] = df['tags'].apply(to_tab)\n",
    "    df['qu'] = df['question_id'].apply(apply)\n",
    "    df1['l'] = df1['lecture_id'].apply(apply1)\n",
    "\n",
    "    ## unique tags part\n",
    "    tags_to_utags = {}\n",
    "    count = 0\n",
    "    for elt in df1['tag']:\n",
    "        if elt in tags_to_utags:\n",
    "            1\n",
    "        else:\n",
    "            tags_to_utags[str(elt)] = count\n",
    "            count+=1\n",
    "\n",
    "    for elt in df['tags']:\n",
    "        if elt in tags_to_utags:\n",
    "            1\n",
    "        else:\n",
    "            tags_to_utags[elt] = count\n",
    "            count+=1\n",
    "    df['utags'] = df['tags'].astype(str).replace(tags_to_utags)\n",
    "    df1['utags'] = df1['tag'].astype(str).replace(tags_to_utags)\n",
    "\n",
    "    ## Graph tags part\n",
    "    dico_l = {}\n",
    "    for t, data in df1.groupby('tag'):\n",
    "        dico_l[t] = data['l'].unique()\n",
    "\n",
    "    import networkx as nx\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(df['qu'])\n",
    "    G.add_nodes_from(df1['l'])\n",
    "\n",
    "    for i, elt in enumerate(tqdm(df['tag'])):\n",
    "        for j in elt:\n",
    "            try:\n",
    "                lec = dico_l[j]\n",
    "            except:\n",
    "                lec = []\n",
    "            for k in lec:\n",
    "                G.add_edge(df['qu'].iloc[i], k)\n",
    "\n",
    "    co = list(nx.connected_components(G))\n",
    "\n",
    "    tags_to_gtags = {}\n",
    "    count = 0\n",
    "    for i, elt in enumerate(tqdm(co)):\n",
    "        for j in elt:\n",
    "            tags_to_gtags[j] = i\n",
    "\n",
    "    df['gtags'] = df['qu'].replace(tags_to_gtags)\n",
    "    df1['gtags'] = df1['l'].replace(tags_to_gtags)\n",
    "\n",
    "    dico_utags = {}\n",
    "    dico_gtags = {}\n",
    "    dico_parts = {}\n",
    "    for pair in zip(df['qu'], df['utags'], df['gtags'], df['part']):\n",
    "        dico_utags[pair[0]] = pair[1]\n",
    "        dico_gtags[pair[0]] = pair[2]\n",
    "        dico_parts[pair[0]] = pair[3]\n",
    "        \n",
    "    for pair in zip(df1['l'], df1['utags'], df1['gtags'], df1['part']):\n",
    "        dico_utags[pair[0]] = pair[1]\n",
    "        dico_gtags[pair[0]] = pair[2]\n",
    "        dico_parts[pair[0]] = pair[3]\n",
    "            \n",
    "    return dico_utags, dico_gtags, dico_parts\n",
    "\n",
    "dico_utags, dico_gtags, dico_parts = create_dictionnaries()\n",
    "\n",
    "save((dico_utags, dico_gtags, dico_parts), 'dico_tags')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self,batch_size=32, max_len = 128, folder = 'user_batch_saint_100', strategy = 'begin'):\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = load('tokenizer')\n",
    "        self.max_len = max_len\n",
    "        self.folder = folder\n",
    "        self.dico_question = load('dico_questions_mean')\n",
    "        self.dico_utags, self.dico_gtags, self.dico_parts = load('dico_tags')\n",
    "        self.timestamp_enc, self.elapsed_enc, self.qmean_enc = load('discrete_encoders')\n",
    "        self.strategy = strategy\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 1000000\n",
    "    \n",
    "    def initiate_dico(self):\n",
    "        list_encoder = ['exercise', 'part', 'utag', 'gtag', 'timestamp', 'question_mean']\n",
    "        list_decoder = ['correct', 'answer', 'elapsed_time', 'lag_time', 'was_explained']\n",
    "        list_output = ['exercise', 'answer', 'correct']\n",
    "        \n",
    "        dico_input = {}\n",
    "        for elt in list_encoder + list_decoder:\n",
    "            if elt == 'exercise':\n",
    "                dico_input[elt] = np.zeros((self.batch_size, self.max_len)).astype(str)\n",
    "            else:\n",
    "                dico_input[elt] = np.zeros((self.batch_size, self.max_len)).astype('int32')\n",
    "        \n",
    "        dico_output = {}\n",
    "        for elt in list_output:\n",
    "            if elt == 'exercise':\n",
    "                dico_output[elt] = np.zeros((self.batch_size, self.max_len)).astype(str)\n",
    "            else:\n",
    "                dico_output[elt] = np.zeros((self.batch_size, self.max_len)).astype('int32')\n",
    "        return dico_input, dico_output\n",
    "\n",
    "    def map_part(self, ids):\n",
    "        def replace_dico_part(x):\n",
    "            try:\n",
    "                return self.dico_parts[x]\n",
    "            except:\n",
    "                return 0\n",
    "        return np.array(list(map(replace_dico_part,ids)))\n",
    "    \n",
    "    def map_utags(self, ids):\n",
    "        def replace_dico_utags(x):\n",
    "            try:\n",
    "                if str(self.dico_utags[x]) != 'nan':\n",
    "                    return str(self.dico_utags[x])\n",
    "                else:\n",
    "                    return 0\n",
    "            except:\n",
    "                return 0\n",
    "        return np.array(list(map(replace_dico_utags,ids)))\n",
    "    \n",
    "    def map_gtags(self, ids):\n",
    "        def replace_dico_gtags(x):\n",
    "            try:\n",
    "                if str(self.dico_gtags[x]) != 'nan':\n",
    "                    return str(self.dico_gtags[x])\n",
    "                else:\n",
    "                    return 0\n",
    "            except:\n",
    "                return 0\n",
    "        return np.array(list(map(replace_dico_gtags,ids)))\n",
    "    \n",
    "    def map_mean(self, ids):\n",
    "        def replace_dico_question(x):\n",
    "            try:\n",
    "                return self.dico_question[x]\n",
    "            except:\n",
    "                return 0.5\n",
    "        return np.array(list(map(replace_dico_question,ids)))\n",
    "    \n",
    "    def update_dico(self, dico_input, dico_output, input_vals, output_vals, i):\n",
    "        list_encoder = ['exercise', 'part', 'utag', 'gtag', 'timestamp', 'question_mean']\n",
    "        list_decoder = ['correct', 'answer', 'elapsed_time', 'lag_time', 'was_explained']\n",
    "        list_output = ['exercise', 'answer', 'correct']\n",
    "        \n",
    "        for j, elt in enumerate(list_encoder + list_decoder):\n",
    "            dico_input[elt][i] = input_vals[j]\n",
    "        \n",
    "        for j, elt in enumerate(list_output):\n",
    "            dico_output[elt][i] = output_vals[j]\n",
    "        return dico_input, dico_output\n",
    "\n",
    "    def remove_na(self, x):\n",
    "        x = np.array(list(x))\n",
    "        x[np.isnan(x)] = 0\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def build_sequence(self, user_history):\n",
    "        dico_sequence = deepcopy(user_history)        \n",
    "        dico_sequence['elapsed_time'] = self.remove_na(dico_sequence['elapsed_time'])\n",
    "        dico_sequence['lag_time'] = self.remove_na(dico_sequence['lag_time'])\n",
    "        dico_sequence['prior_question_had_explanation'] = self.remove_na(dico_sequence['prior_question_had_explanation'])\n",
    "        \n",
    "        ## Cut sequence\n",
    "        if self.strategy == 'begin':\n",
    "            for elt in dico_sequence:\n",
    "                dico_sequence[elt] = dico_sequence[elt][:self.max_len]\n",
    "        else:\n",
    "            for elt in dico_sequence:\n",
    "                dico_sequence[elt] = dico_sequence[elt][-self.max_len:]\n",
    "        \n",
    "        ## Pad sequence\n",
    "        pad_tokens = ['[PAD]', 0, 0, -1, -1, 0, 0, 0]\n",
    "        for j, elt in enumerate(dico_sequence):\n",
    "            size = len(dico_sequence[elt])\n",
    "            if size <= self.max_len:\n",
    "                adding = self.max_len - size\n",
    "                tok = pad_tokens[j]\n",
    "                if type(tok) == str:\n",
    "                    add = np.array([tok for elt in range(adding)])\n",
    "                else:\n",
    "                    add = np.zeros(adding) + tok\n",
    "                dico_sequence[elt] = np.concatenate([dico_sequence[elt], add], axis = 0)\n",
    "#                 print(dico_sequence[elt].shape)\n",
    "        \n",
    "        input_vals = [\n",
    "            dico_sequence['exercise_id'],\n",
    "            self.map_part(dico_sequence['exercise_id']),\n",
    "            self.map_utags(dico_sequence['exercise_id']),\n",
    "            self.map_gtags(dico_sequence['exercise_id']),\n",
    "            self.timestamp_enc.transform(dico_sequence['timestamp']),\n",
    "            self.qmean_enc.transform(self.map_mean(dico_sequence['exercise_id'])),\n",
    "            \n",
    "            np.concatenate([np.array([0]), (dico_sequence['correctness'] + 1)[:-1]]),\n",
    "            np.concatenate([np.array([0]), (dico_sequence['answer'] + 1)[:-1]]),\n",
    "            np.concatenate([np.array([0]), self.elapsed_enc.transform(dico_sequence['elapsed_time'])[:-1]]),\n",
    "            np.concatenate([np.array([0]), self.elapsed_enc.transform(dico_sequence['lag_time'])[:-1]]),\n",
    "            np.concatenate([np.array([0]), dico_sequence['prior_question_had_explanation'][:-1]]),\n",
    "        ]\n",
    "        \n",
    "        output_vals = [\n",
    "            np.concatenate([dico_sequence['exercise_id'][1:], np.array(['[PAD]'])]),\n",
    "            dico_sequence['answer'] + 1,\n",
    "            dico_sequence['correctness'] + 1,\n",
    "        ]\n",
    "        \n",
    "        \n",
    "#         x = np.zeros((11,self.max_len))\n",
    "#         y = np.zeros((3, self.max_len))\n",
    "        return input_vals,output_vals\n",
    "    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ## Load random batch\n",
    "        file_name = random.choice(os.listdir('./'+self.folder))\n",
    "        dico_user = load(file_name.split('.')[0], self.folder)\n",
    "        \n",
    "        list_user = np.random.choice(list(dico_user.keys()), size = self.batch_size)\n",
    "        \n",
    "        dico_input, dico_output = self.initiate_dico()\n",
    "        \n",
    "        \n",
    "        for i, elt in enumerate(list_user):\n",
    "            user_history = dico_user[elt]\n",
    "            input_vals, output_vals = self.build_sequence(user_history)\n",
    "            dico_input, dico_output = self.update_dico(dico_input, dico_output, input_vals, output_vals, i)\n",
    "        \n",
    "        x = deepcopy(dico_input['exercise'])\n",
    "        dico_input['exercise'] = np.array(self.tokenizer.texts_to_sequences([\" \".join(list(x)[elt]) for elt in range(len(x))]))\n",
    "        \n",
    "        x = deepcopy(dico_output['exercise'])\n",
    "        dico_output['exercise'] = np.array(self.tokenizer.texts_to_sequences([\" \".join(list(x)[elt]) for elt in range(len(x))]))\n",
    "        \n",
    "        X = list(np.array(list(dico_input.values())).astype('int32'))\n",
    "        y = list(np.array(list(dico_output.values())).astype('int32')) \n",
    "        \n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "\n",
    "    def __get_data(self, batch):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = DataGenerator(batch_size=64, max_len = 128, folder = 'user_batch_saint_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x, y = gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elt in x:\n",
    "    print(elt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elt in y:\n",
    "    print(elt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_transformers2 import *\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, TimeDistributed, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaintEncoder(tf.keras.layers.Layer):    \n",
    "    def __init__(self, num_layers = 2, d_model = 512, num_heads = 8, \n",
    "                 dff = 1024, input_vocab_size = 15000, maximum_position_encoding = 512, \n",
    "                 rate=0.1, bidirectional_encoder = True):\n",
    "        super(SaintEncoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.part_embedding = tf.keras.layers.Embedding(8, d_model)\n",
    "        self.utag_embedding = tf.keras.layers.Embedding(2000, d_model)\n",
    "        self.gtag_embedding = tf.keras.layers.Embedding(100, d_model)\n",
    "        self.timestamp_embedding = tf.keras.layers.Embedding(301, d_model)\n",
    "        self.question_mean_embedding = tf.keras.layers.Embedding(301, d_model)\n",
    "        \n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                self.d_model)\n",
    "\n",
    " \n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "        self.bidirectional_encoder = bidirectional_encoder\n",
    "        \n",
    "    def call(self, x, training,\n",
    "            part_id = None,\n",
    "            utag_id = None,\n",
    "            gtag_id = None,\n",
    "            timestamp_id = None,\n",
    "            question_mean_id = None,\n",
    "            use = []\n",
    "            ):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        \n",
    "        if self.bidirectional_encoder == False:\n",
    "            look_ahead_mask = create_look_ahead_mask(tf.shape(x)[1])\n",
    "            dec_target_padding_mask = create_padding_mask(x, pad_token = 1)\n",
    "            mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "        else:\n",
    "            mask = create_padding_mask(x, pad_token = 1)\n",
    "        \n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        \n",
    "        ## Adding all the embeddings\n",
    "        part_emb = self.part_embedding(part_id)\n",
    "        utag_emb = self.utag_embedding(utag_id)\n",
    "        gtag_emb = self.gtag_embedding(gtag_id)\n",
    "        timestamp_emb = self.timestamp_embedding(timestamp_id)\n",
    "        question_mean_emb = self.question_mean_embedding(part_id)\n",
    "        \n",
    "        if 'part' in use:\n",
    "            x += part_emb\n",
    "            \n",
    "        if 'utag' in use:\n",
    "            x += utag_emb\n",
    "            \n",
    "        if 'gtag' in use:\n",
    "            x += gtag_emb\n",
    "            \n",
    "        if 'timestamp' in use:\n",
    "            x += timestamp_emb\n",
    "            \n",
    "        if 'question_mean' in use:\n",
    "            x += question_mean_emb\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "    \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x, mask  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaintDecoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1, bidirectional_decoder = False):\n",
    "        super(SaintDecoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.answer_embedding = tf.keras.layers.Embedding(5, d_model)\n",
    "        self.elapsed_time_embedding = tf.keras.layers.Embedding(301, d_model)\n",
    "        self.lag_time_embedding = tf.keras.layers.Embedding(301, d_model)\n",
    "        self.was_explained_embedding = tf.keras.layers.Embedding(2, d_model)\n",
    "        \n",
    "        \n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "        self.bidirectional_decoder = bidirectional_decoder\n",
    "    \n",
    "    def call(self, x, enc_output, training = True, padding_mask = None, \n",
    "            answer_id = None,\n",
    "            elapsed_time_id = None,\n",
    "            lag_time_id = None,\n",
    "            was_explained_id = None,\n",
    "            calls = []\n",
    "            ):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "        \n",
    "        if self.bidirectional_decoder == False:\n",
    "            look_ahead_mask = create_look_ahead_mask(tf.shape(x)[1])\n",
    "            dec_target_padding_mask = create_padding_mask(x, pad_token = 0)\n",
    "            mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "        else:\n",
    "            mask = create_padding_mask(x, pad_token = 0)\n",
    "        \n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        \n",
    "        \n",
    "        ## Adding embeddings\n",
    "        answer_emb = self.answer_embedding(answer_id)\n",
    "        elapsed_time_emb = self.elapsed_time_embedding(elapsed_time_id)\n",
    "        lag_time_emb = self.lag_time_embedding(lag_time_id)\n",
    "        was_explained_emb = self.was_explained_embedding(was_explained_id)\n",
    "        \n",
    "        if 'answer' in calls:\n",
    "            x += answer_emb\n",
    "        \n",
    "        if 'elapsed_time' in calls:\n",
    "            x += elapsed_time_emb\n",
    "        \n",
    "        if 'lag_time' in calls:\n",
    "            x += lag_time_emb\n",
    "            \n",
    "        if 'was_explained' in calls:\n",
    "            x += was_explained_emb\n",
    "            \n",
    "        x = self.dropout(x, training=training)\n",
    "                \n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 128\n",
    "\n",
    "list_encoder = ['exercise', 'part', 'utag', 'gtag', 'timestamp', 'question_mean']\n",
    "list_decoder = ['correct', 'answer', 'elapsed_time', 'lag_time', 'was_explained']\n",
    "list_output = ['exercise', 'answer', 'correct']\n",
    "\n",
    "inputs_exercise = tf.keras.Input(shape = (max_len,))\n",
    "inputs_part = tf.keras.Input(shape = (max_len,))\n",
    "inputs_utag = tf.keras.Input(shape = (max_len,))\n",
    "inputs_gtag = tf.keras.Input(shape = (max_len,))\n",
    "inputs_timestamp = tf.keras.Input(shape = (max_len,))\n",
    "inputs_question_mean = tf.keras.Input(shape = (max_len,))\n",
    "\n",
    "inputs_correct = tf.keras.Input(shape = (max_len,))\n",
    "inputs_answer = tf.keras.Input(shape = (max_len,))\n",
    "inputs_elapsed_time = tf.keras.Input(shape = (max_len,))\n",
    "inputs_lag_time = tf.keras.Input(shape = (max_len,))\n",
    "inputs_lag_was_explained = tf.keras.Input(shape = (max_len,))\n",
    "\n",
    "inputs = [\n",
    "    inputs_exercise,\n",
    "    inputs_part,\n",
    "    inputs_utag,\n",
    "    inputs_gtag,\n",
    "    inputs_timestamp,\n",
    "    inputs_question_mean,\n",
    "    \n",
    "    inputs_correct,\n",
    "    inputs_answer,\n",
    "    inputs_elapsed_time,\n",
    "    inputs_lag_time,\n",
    "    inputs_lag_was_explained\n",
    "]\n",
    "\n",
    "encoder = SaintEncoder(num_layers = 4, d_model = 512, num_heads = 8, \n",
    "                 dff = 1024, input_vocab_size = 15000, maximum_position_encoding = 512, \n",
    "                 rate=0, bidirectional_encoder = False)\n",
    "\n",
    "decoder = SaintDecoder(num_layers = 4, d_model = 512, num_heads = 8, \n",
    "                       dff = 1024, target_vocab_size = 3, maximum_position_encoding = 512, \n",
    "                       rate=0, bidirectional_decoder = False)\n",
    "\n",
    "calls_encoder = [\n",
    "    'part', \n",
    "#     'utag', \n",
    "#     'gtag', \n",
    "    'timestamp', \n",
    "    'question_mean',\n",
    "]\n",
    "\n",
    "encoded, padding_mask = encoder(inputs_exercise, training = True,\n",
    "            part_id = inputs_part,\n",
    "            utag_id = inputs_utag,\n",
    "            gtag_id = inputs_gtag,\n",
    "            timestamp_id = inputs_timestamp,\n",
    "            question_mean_id = inputs_question_mean,\n",
    "            use = calls_encoder)\n",
    "\n",
    "calls_decoder = [\n",
    "    'answer', \n",
    "    'elapsed_time', \n",
    "    'lag_time', \n",
    "#     'was_explained',\n",
    "]\n",
    "\n",
    "decoded = decoder(inputs_correct, encoded, training = True, padding_mask = padding_mask, \n",
    "            answer_id = inputs_answer,\n",
    "            elapsed_time_id = inputs_elapsed_time,\n",
    "            lag_time_id = inputs_lag_time,\n",
    "            was_explained_id = inputs_lag_was_explained,\n",
    "            calls = calls_decoder\n",
    "                 )\n",
    "\n",
    "mix = encoded + decoded\n",
    "mix = tf.keras.layers.Dense(512, activation = 'relu')(mix)\n",
    "\n",
    "question_head = tf.keras.layers.Dense(15000, activation = 'softmax', name = 'question_head')(mix)\n",
    "answer_head = tf.keras.layers.Dense(5, activation = 'softmax', name = 'answer_head')(mix)\n",
    "correct_head = tf.keras.layers.Dense(3, activation = 'softmax', name = 'correct_head')(mix)\n",
    "\n",
    "outputs = [question_head, answer_head, correct_head]\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./weights/saint+++_base_question_.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## losses and metrics\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_qu(real_qu, pred_qu):\n",
    "    mask_qu = tf.math.logical_not(tf.math.equal(real_qu, 1))\n",
    "    loss_qu_ = loss_object(real_qu, pred_qu)\n",
    "    mask_qu = tf.cast(mask_qu , dtype=loss_qu_.dtype)\n",
    "    loss_qu_ *= mask_qu\n",
    "    loss_qu_ = tf.reduce_mean(loss_qu_)\n",
    "    return loss_qu_\n",
    "\n",
    "def loss_co(real_co, pred_co):\n",
    "    mask_co = tf.math.logical_not(tf.math.equal(real_co, 0))\n",
    "    loss_co_ = loss_object(real_co, pred_co)\n",
    "    mask_co = tf.cast(mask_co , dtype=loss_co_.dtype)\n",
    "    loss_co_ *= mask_co\n",
    "    loss_co_ = tf.reduce_mean(loss_co_)\n",
    "    return loss_co_*10\n",
    "\n",
    "def loss_an(real_an, pred_an):\n",
    "    mask_an = tf.math.logical_not(tf.math.equal(real_an, 0))\n",
    "    loss_an_ = loss_object(real_an, pred_an)\n",
    "    mask_an = tf.cast(mask_an , dtype=loss_an_.dtype)\n",
    "    loss_an_ *= mask_an\n",
    "    loss_an_ = tf.reduce_mean(loss_an_)\n",
    "    return loss_an_*10\n",
    "\n",
    "def acc_qu(true, pred):\n",
    "    mask = tf.cast(tf.math.logical_not(tf.math.equal(true, 1)),dtype = true.dtype)\n",
    "#     pred = pred[:,:,:3]\n",
    "    pred = tf.math.argmax(pred, axis=-1, output_type=tf.dtypes.int64, name=None)\n",
    "    pred = tf.cast(pred, dtype = true.dtype)\n",
    "    pred = pred*mask\n",
    "    true = true*mask\n",
    "    equal = tf.cast(tf.math.equal(pred, true), dtype = true.dtype)\n",
    "    n_equal = tf.math.reduce_sum(equal)\n",
    "    n_mask = tf.math.reduce_sum(mask)\n",
    "    n_tot = tf.math.reduce_sum(tf.cast(tf.math.greater(true, -1), dtype = true.dtype))\n",
    "    n_masked = n_tot - n_mask\n",
    "    return (n_equal - n_masked) / ((n_tot - n_masked))\n",
    "\n",
    "def acc_co(true, pred):\n",
    "    mask = tf.cast(tf.math.logical_not(tf.math.equal(true, 0)),dtype = true.dtype)\n",
    "#     pred = pred[:,:,:3]\n",
    "    pred = tf.math.argmax(pred, axis=-1, output_type=tf.dtypes.int64, name=None)\n",
    "    pred = tf.cast(pred, dtype = true.dtype)\n",
    "    pred = pred*mask\n",
    "    true = true*mask\n",
    "    equal = tf.cast(tf.math.equal(pred, true), dtype = true.dtype)\n",
    "    n_equal = tf.math.reduce_sum(equal)\n",
    "    n_mask = tf.math.reduce_sum(mask)\n",
    "    n_tot = tf.math.reduce_sum(tf.cast(tf.math.greater(true, -1), dtype = true.dtype))\n",
    "    n_masked = n_tot - n_mask\n",
    "    return (n_equal - n_masked) / (n_tot - n_masked)\n",
    "\n",
    "def acc_an(true, pred):\n",
    "    mask = tf.cast(tf.math.logical_not(tf.math.equal(true, 0)),dtype = true.dtype)\n",
    "#     pred = pred[:,:,:3]\n",
    "    pred = tf.math.argmax(pred, axis=-1, output_type=tf.dtypes.int64, name=None)\n",
    "    pred = tf.cast(pred, dtype = true.dtype)\n",
    "    pred = pred*mask\n",
    "    true = true*mask\n",
    "    equal = tf.cast(tf.math.equal(pred, true), dtype = true.dtype)\n",
    "    n_equal = tf.math.reduce_sum(equal)\n",
    "    n_mask = tf.math.reduce_sum(mask)\n",
    "    n_tot = tf.math.reduce_sum(tf.cast(tf.math.greater(true, -1), dtype = true.dtype))\n",
    "    n_masked = n_tot - n_mask\n",
    "    return (n_equal - n_masked) / (n_tot - n_masked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import warnings\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, validation=None, logs = {}, dico_params = {}, from_path = None):\n",
    "        super(CustomCallback, self).__init__()\n",
    "#         self.train = train\n",
    "        self.validation = validation\n",
    "        self.epoch = []\n",
    "        \n",
    "        self.loss = []\n",
    "        self.val_loss = []\n",
    "        self.roc_auc = []\n",
    "        self.val_roc_auc = []\n",
    "        \n",
    "        self.question_head_loss = []\n",
    "        self.val_question_head_loss = []\n",
    "        self.question_head_acc_qu = []\n",
    "        self.val_question_head_acc_qu = []\n",
    "        \n",
    "        self.correct_head_loss = []\n",
    "        self.val_correct_head_loss = []\n",
    "        self.correct_head_acc_co = []\n",
    "        self.val_correct_head_acc_co = []\n",
    "        \n",
    "        self.answer_head_loss = []\n",
    "        self.val_answer_head_loss = []\n",
    "        self.answer_head_acc_an = []\n",
    "        self.val_answer_head_acc_an = []\n",
    "        \n",
    "        self.lr = []\n",
    "#         self.clshare = []\n",
    "        self.qushare = []\n",
    "        self.coshare = []\n",
    "        self.anshare = []\n",
    "        \n",
    "        self.dico_params = dico_params\n",
    "        \n",
    "        if from_path is not None:\n",
    "            (self.epoch,\n",
    "            self.loss, self.val_loss, self.roc_auc, self.val_roc_auc,\n",
    "            self.question_head_loss, self.val_question_head_loss, self.question_head_acc_qu, self.val_question_head_acc_qu,\n",
    "            self.correct_head_loss, self.val_correct_head_loss, self.correct_head_acc_co, self.val_correct_head_acc_co,\n",
    "            self.answer_head_loss, self.val_answer_head_loss, self.answer_head_acc_an, self.val_answer_head_acc_an,\n",
    "            self.lr, self.qushare, self.coshare, self.anshare\n",
    "            ) = load(from_path)\n",
    "        \n",
    "#     def on_epoch_begin(self, epoch, logs={}):\n",
    "#         keys = list(logs.keys())\n",
    "#         print(\"Start epoch {} of training; got log keys: {}\".format(epoch, keys))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        keys = list(logs.keys())\n",
    "        values = list(logs.values())\n",
    "        \n",
    "#         print(keys)\n",
    "        \n",
    "        curr_epoch = len(self.loss)\n",
    "        self.epoch.append(curr_epoch)\n",
    "        \n",
    "        self.loss.append(logs['loss'])\n",
    "        self.val_loss.append(logs['val_loss'])\n",
    "        \n",
    "        \n",
    "        self.question_head_loss.append(logs['question_head_loss'])\n",
    "        self.val_question_head_loss.append(logs['val_question_head_loss'])\n",
    "        self.question_head_acc_qu.append(logs['question_head_acc_qu'])\n",
    "        self.val_question_head_acc_qu.append(logs['val_question_head_acc_qu'])\n",
    "        \n",
    "        self.correct_head_loss.append(logs['correct_head_loss'])\n",
    "        self.val_correct_head_loss.append(logs['val_correct_head_loss'])\n",
    "        self.correct_head_acc_co.append(logs['correct_head_acc_co'])\n",
    "        self.val_correct_head_acc_co.append(logs['val_correct_head_acc_co'])\n",
    "        \n",
    "        self.answer_head_loss.append(logs['answer_head_loss'])\n",
    "        self.val_answer_head_loss.append(logs['val_answer_head_loss'])\n",
    "        self.answer_head_acc_an.append(logs['answer_head_acc_an'])\n",
    "        self.val_answer_head_acc_an.append(logs['val_answer_head_acc_an'])\n",
    "        \n",
    "        ## Roc auc calculation on test set\n",
    "        x_val, y_val = self.validation[0], self.validation[1]\n",
    "        pred = self.model.predict(x_val, verbose = 0)\n",
    "        y_pred = pred[2][:,:,2]\n",
    "        y_true = y_val[2]\n",
    "        \n",
    "        y_true = y_true.reshape(y_true.shape[0]*y_true.shape[1])\n",
    "        y_pred = y_pred.reshape(y_pred.shape[0]*y_pred.shape[1])\n",
    "        \n",
    "        y_pred = y_pred[y_true != 0]\n",
    "        y_true = y_true[y_true != 0] - 1\n",
    "        \n",
    "        roc_auc = roc_auc_score(y_true, y_pred)\n",
    "        self.roc_auc.append(roc_auc)\n",
    "        self.val_roc_auc.append(roc_auc)\n",
    "        print(roc_auc)\n",
    "        \n",
    "        logs['roc_auc'] = roc_auc\n",
    "            \n",
    "        self.lr.append(self.dico_params['lr'])\n",
    "#         self.clshare.append(self.dico_params['cl'])\n",
    "        self.qushare.append(self.dico_params['qu'])\n",
    "        self.coshare.append(self.dico_params['co'])\n",
    "        self.anshare.append(self.dico_params['an'])        \n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        print(logs)\n",
    "        n_rows = 5\n",
    "        n_cols = 2\n",
    "        fig, ax = plt.subplots(n_rows, n_cols, \n",
    "                        gridspec_kw={'hspace': 0.3, 'wspace': 0.2}, figsize = (20,n_rows*7))\n",
    "        \n",
    "        #General\n",
    "        ax[0,0].plot(self.epoch, self.loss, label = 'loss')\n",
    "        ax[0,0].plot(self.epoch, self.val_loss, label = 'val_loss')\n",
    "        ax[0,0].set_title('losses')\n",
    "        ax[0,0].legend()\n",
    "        \n",
    "        ax[0,1].plot(self.epoch, self.val_roc_auc, label = 'roc_auc_val')\n",
    "        ax[0,1].set_title('roc_auc')\n",
    "        ax[0,1].legend()\n",
    "        \n",
    "        \n",
    "        ## Question target\n",
    "        ax[1,0].plot(self.epoch, self.question_head_loss, label = 'question_loss')\n",
    "        ax[1,0].plot(self.epoch, self.val_question_head_loss, label = 'val_question_loss')\n",
    "        ax[1,0].set_title('question_loss')\n",
    "        ax[1,0].legend()\n",
    "        \n",
    "        ax[1,1].plot(self.epoch, self.question_head_acc_qu, label = 'question_accuracy')\n",
    "        ax[1,1].plot(self.epoch, self.val_question_head_acc_qu, label = 'val_question_accuracy')\n",
    "        ax[1,1].set_title('question_accuracy')\n",
    "        ax[1,1].legend()\n",
    "        \n",
    "        ## Correct classif target\n",
    "        ax[2,0].plot(self.epoch, self.correct_head_loss, label = 'correct_loss')\n",
    "        ax[2,0].plot(self.epoch, self.val_correct_head_loss, label = 'val_correct_loss')\n",
    "        ax[2,0].set_title('correct_loss')\n",
    "        ax[2,0].legend()\n",
    "        \n",
    "        ax[2,1].plot(self.epoch, self.correct_head_acc_co, label = 'correct_accuracy')\n",
    "        ax[2,1].plot(self.epoch, self.val_correct_head_acc_co, label = 'val_correct_accuracy')\n",
    "        ax[2,1].set_title('correct_accuracy')\n",
    "        ax[2,1].legend()\n",
    "        \n",
    "        ## Answer target\n",
    "        ax[3,0].plot(self.epoch, self.answer_head_loss, label = 'answer_loss')\n",
    "        ax[3,0].plot(self.epoch, self.val_answer_head_loss, label = 'val_answer_loss')\n",
    "        ax[3,0].set_title('answer_loss')\n",
    "        ax[3,0].legend()\n",
    "        \n",
    "        ax[3,1].plot(self.epoch, self.answer_head_acc_an, label = 'answer_accuracy')\n",
    "        ax[3,1].plot(self.epoch, self.val_answer_head_acc_an, label = 'val_answer_accuracy')\n",
    "        ax[3,1].set_title('answer_accuracy')\n",
    "        ax[3,1].legend()\n",
    "        \n",
    "        ## Lr et objective split\n",
    "        ax[4,0].plot(self.epoch, self.lr, label = 'learning_rate')\n",
    "        ax[4,0].set_title('learning_rate')\n",
    "        ax[4,0].legend()\n",
    "        \n",
    "#         ax[4,1].plot(self.epoch, self.clshare, label = 'classification ratio')\n",
    "        ax[4,1].plot(self.epoch, self.qushare, label = 'question ratio')\n",
    "        ax[4,1].plot(self.epoch, self.coshare, label = 'correct ratio')\n",
    "        ax[4,1].plot(self.epoch, self.anshare, label = 'answer ratio')\n",
    "        ax[4,1].set_title('ratio of training objective')\n",
    "        ax[4,1].legend()\n",
    " \n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        params = (self.epoch,\n",
    "        self.loss, self.val_loss, self.roc_auc, self.val_roc_auc,\n",
    "            self.question_head_loss, self.val_question_head_loss, self.question_head_acc_qu, self.val_question_head_acc_qu,\n",
    "            self.correct_head_loss, self.val_correct_head_loss, self.correct_head_acc_co, self.val_correct_head_acc_co,\n",
    "            self.answer_head_loss, self.val_answer_head_loss, self.answer_head_acc_an, self.val_answer_head_acc_an,\n",
    "            self.lr, self.qushare, self.coshare, self.anshare\n",
    "        )\n",
    "        save(params, 'history_epoch_'+str(curr_epoch), 'historysaint+++')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "# losses = [loss_cl, loss_qu, loss_co, loss_an]\n",
    "lr = 3e-6\n",
    "qu = 0.1\n",
    "an = 0.1\n",
    "co = 0.9\n",
    "\n",
    "dico_params = {\n",
    "    'lr':lr,\n",
    "    'qu': qu,\n",
    "    'an':an,\n",
    "    'co':co\n",
    "}\n",
    "\n",
    "\n",
    "losses = {\"question_head\": loss_qu, 'answer_head': loss_an, 'correct_head': loss_co}\n",
    "\n",
    "lossWeights = { \"question_head\": qu, 'answer_head': an, 'correct_head': co}\n",
    "\n",
    "metrics = {\"question_head\": acc_qu, 'answer_head': acc_an, 'correct_head': acc_co}\n",
    "\n",
    "loss_classif     =  losses # find the right loss for multi-class classification\n",
    "optimizer        =  Adam(lr, 1e-8) # find the right optimizer\n",
    "metrics_classif  =  []\n",
    "\n",
    "model.compile(loss=loss_classif,\n",
    "              optimizer=optimizer,\n",
    "              metrics=metrics,\n",
    "             loss_weights=lossWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(batch_size=64, max_len = max_len, folder = 'user_batch_saint_100', strategy = 'end')\n",
    "test_gen = DataGenerator(batch_size=512, max_len = max_len, folder = 'user_batch_saint_test', strategy = 'end')\n",
    "x_test, y_test = test_gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "history = CustomCallback(validation = (x_test,  y_test), dico_params = dico_params, from_path = './historysaint+++/history_epoch_46')\n",
    "\n",
    "callbacks = [history]\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "n_epochs = 500\n",
    "steps_per_epoch = 200\n",
    "\n",
    "model.fit(train_gen, epochs=n_epochs,\n",
    "                    steps_per_epoch = steps_per_epoch, \n",
    "                    validation_data=(x_test,  y_test), \n",
    "                    max_queue_size=20,\n",
    "#                     workers=6,\n",
    "                    callbacks = callbacks,\n",
    "                    verbose = 1\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./weights/saint+++_base_question_.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(model.save_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = test_gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = model.predict(x_test, verbose = 1)[2]\n",
    "true1 = y_test[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 25\n",
    "M = 26\n",
    "bs = 512\n",
    "pred = pred1[:,m:M,2]\n",
    "true = true1[:,m:M]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred.reshape(bs*(M-m))\n",
    "true = true.reshape(bs*(M-m))\n",
    "\n",
    "qm = x_test[5][:,m:M].reshape(bs*(M-m))\n",
    "qm = qm[true != 0]\n",
    "\n",
    "y_pred = y_pred[true != 0]\n",
    "true = true[true != 0]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(true, (y_pred >= 0.5)*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_encoder = ['exercise', 'part', 'utag', 'gtag', 'timestamp', 'question_mean']\n",
    "list_decoder = ['correct', 'answer', 'elapsed_time', 'lag_time', 'was_explained']\n",
    "list_output = ['exercise', 'answer', 'correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def acc(true, pred):\n",
    "    true1 = np.array(true)\n",
    "    pred1 = np.array(pred)\n",
    "    \n",
    "    pred1 = pred1[true1 < 2]\n",
    "    true1 = true1[true1 < 2]\n",
    "    \n",
    "    \n",
    "    if true1.sum() == 0 or true1.sum() == len(true1):\n",
    "        true1 = np.concatenate([true1, np.array([0,1])])\n",
    "        pred1 = np.concatenate([pred1, np.array([0,1])])\n",
    "    \n",
    "    return roc_auc_score(true1, pred1)\n",
    "\n",
    "def test(true, pred):\n",
    "    p = []\n",
    "    \n",
    "    pred2 = pred.reshape(true.shape[0] * true.shape[1])\n",
    "    true2 = true.reshape(true.shape[0] * true.shape[1])\n",
    "    pred2 = pred2[true2 < 2]\n",
    "    true2 = true2[true2 < 2]\n",
    "    \n",
    "    print(roc_auc_score(true2, pred2))\n",
    "    \n",
    "    for i, elt in enumerate(tqdm(true)):\n",
    "#         print(pred[i])\n",
    "        p.append(acc(elt, pred[i]))\n",
    "    \n",
    "    plt.figure(figsize = (25,15))\n",
    "    plt.hist(p, bins = 50)\n",
    "    \n",
    "    print(np.mean(p))\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred[:,:,:2]\n",
    "\n",
    "def softmax(tab):\n",
    "    e = np.exp(tab)\n",
    "    s = np.sum(e, axis = -1)\n",
    "        \n",
    "    return e[:,:,1] / s\n",
    "\n",
    "pred = softmax(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[5][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = [[] for i in range(11)]\n",
    "y_val = []\n",
    "ind = 115\n",
    "for i, elt in enumerate(x_test[0][ind]):\n",
    "    if elt != 1:\n",
    "        s = i\n",
    "        x = [\n",
    "            np.concatenate([x_test[0][ind, i:], np.zeros(s) + 1]),\n",
    "            np.concatenate([x_test[1][ind, i:], np.zeros(s)]),\n",
    "            np.concatenate([x_test[2][ind, i:], np.zeros(s)]),\n",
    "            np.concatenate([x_test[3][ind, i:], np.zeros(s)]),\n",
    "            np.concatenate([x_test[4][ind, i:], np.zeros(s)]),\n",
    "            np.concatenate([x_test[5][ind, i:], np.zeros(s)]),\n",
    "            \n",
    "            x_test[6][ind, :],\n",
    "            x_test[7][ind, :],\n",
    "            x_test[8][ind, :],\n",
    "            x_test[9][ind, :],\n",
    "            x_test[10][ind, :],\n",
    "        ]\n",
    "        \n",
    "        for j, elt in enumerate(x):\n",
    "            x_val[j].append(elt)\n",
    "        \n",
    "        y_val.append(y_test[2][ind,i])\n",
    "        \n",
    "x_val = [np.array(elt).astype('int32') for elt in x_val]\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.predict(x_val, verbose = True)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a[:,0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_val, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elt in x_val[0]:\n",
    "    print(elt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = test(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ameliorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[5][:,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add context on lecture and tasks\n",
    "\n",
    "cluster lecture and tasks\n",
    "\n",
    "give average score of a given task\n",
    "\n",
    "enhance test set with train set (optimization constraint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./weights/lstmgpt_auc_0.757.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
