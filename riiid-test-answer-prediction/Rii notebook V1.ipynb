{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import _pickle as pickle\n",
    "import gc\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "def save(file,name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'wb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'wb')\n",
    "    pickle.dump(file, outfile, protocol=4)\n",
    "    outfile.close\n",
    "    \n",
    "def load(name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'rb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'rb')\n",
    "    file = pickle.load(outfile)\n",
    "    outfile.close\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv('train.csv')\n",
    "train = load('train')\n",
    "\n",
    "# train[train['content_id'] == 0] = 13433\n",
    "\n",
    "lectures = pd.read_csv('lectures.csv')\n",
    "questions = pd.read_csv('questions.csv')\n",
    "\n",
    "test = pd.read_csv('example_test.csv')\n",
    "sample = pd.read_csv('example_sample_submission.csv')\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['content_type_id'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_questions = {}\n",
    "\n",
    "for q, data in tqdm(train.groupby('content_id'), total = train['content_id'].nunique()):\n",
    "    dico_questions['q_'+str(q)] = data['answered_correctly'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(dico_questions, 'dico_questions_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeDataGenerator:\n",
    "    \n",
    "    def __init__(self):\n",
    "        '''\n",
    "        self.data will be a dictionnary to iterate over the stored data\n",
    "        self.all_rows will be the rows of the train set that are used by the generato\n",
    "        self.data_index will be all the data available in the dataset        \n",
    "        '''\n",
    "        self.data = None\n",
    "        self.all_rows = None\n",
    "        self.data_index = None\n",
    "        return None\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        sub = sample[['row_id', 'group_num']].copy()\n",
    "        sub['answered_correctly'] = np.zeros(sub.shape[0])+0.5\n",
    "        return (sample, sub)\n",
    "    \n",
    "    \n",
    "    def load(self, save_name):\n",
    "        self.data,self.all_rows = load(save_name)\n",
    "        self.data_index = np.array(list(self.data.keys()))\n",
    "    \n",
    "    def build_from_train(self, train, n_users, beginner_rate = 0.3, save_name = 'fake_train_generator'):\n",
    "        \"\"\"\n",
    "        train will be the training set you loaded\n",
    "        n_users is a number of user from whom you will sample the data\n",
    "        beginner_rate is the rate of these users who will begin their journey during test\n",
    "        save_name : the name under which the item will be saved\n",
    "        \"\"\"\n",
    "        \n",
    "        ## Sampling a restricted list of users\n",
    "        user_list = train['user_id'].unique()\n",
    "        test_user_list = np.random.choice(user_list, size = n_users)\n",
    "        train.index = train['user_id']\n",
    "        test_data_non_filter = train.loc[test_user_list]\n",
    "        test_data_non_filter.index = list(range(test_data_non_filter.shape[0]))\n",
    "        \n",
    "        ## building a dictionnary with all the rows and container id from a user\n",
    "        dico_user = {}\n",
    "        def agg(x):\n",
    "            return [elt for elt in x]\n",
    "        \n",
    "        print(\"Generating user dictionnary\")\n",
    "        for user, frame in tqdm(test_data_non_filter.groupby('user_id'), total =test_data_non_filter['user_id'].nunique()):\n",
    "            if frame.shape[0] > 0:\n",
    "                dico_user[user] = {}\n",
    "\n",
    "                dico_user[user]['min_indice'] = frame['task_container_id'].min()\n",
    "                dico_user[user]['max_indice'] = frame['task_container_id'].max()\n",
    "\n",
    "                r = random.uniform(0,1)\n",
    "                if r < beginner_rate:\n",
    "                    dico_user[user]['current_indice'] = dico_user[user]['min_indice']\n",
    "                else:\n",
    "                    dico_user[user]['current_indice'] = random.randint(dico_user[user]['min_indice'],dico_user[user]['max_indice']-2)\n",
    "\n",
    "                row_ids = frame[['task_container_id','row_id']].groupby('task_container_id').agg(agg)\n",
    "                row_ids = row_ids.to_dict()['row_id']\n",
    "                dico_user[user]['row_ids'] = row_ids\n",
    "\n",
    "        work_dico = deepcopy(dico_user)\n",
    "        \n",
    "        ## Choosing batch_data to generate\n",
    "        work_dico = deepcopy(dico_user)\n",
    "        batches = {}\n",
    "\n",
    "        all_rows = []\n",
    "        batch_number = 0\n",
    "        \n",
    "        print('Creating batches')\n",
    "        while len(work_dico)> 1:\n",
    "\n",
    "            size = random.randint(20,500)\n",
    "            size = min(size, len(work_dico))\n",
    "\n",
    "\n",
    "            batch = []\n",
    "\n",
    "            users = np.random.choice(np.array(list(work_dico.keys())),replace = False,  size = size)\n",
    "\n",
    "            for u in users:\n",
    "                try:\n",
    "                    batch.extend(work_dico[u]['row_ids'][work_dico[u]['current_indice']])\n",
    "                    all_rows.extend(work_dico[u]['row_ids'][work_dico[u]['current_indice']])\n",
    "                    work_dico[u]['current_indice'] += 1\n",
    "                    if work_dico[u]['current_indice'] == work_dico[u]['max_indice']:\n",
    "                        work_dico.pop(u)\n",
    "                except:\n",
    "                    work_dico.pop(u)\n",
    "\n",
    "            batches[batch_number] = batch\n",
    "            batch_number += 1\n",
    "        \n",
    "        ## building data\n",
    "\n",
    "        data = {}\n",
    "        \n",
    "        print(\"Building dataset\")\n",
    "        test_data_non_filter.index = test_data_non_filter['row_id']\n",
    "        for i in tqdm(batches):\n",
    "            current_data = test_data_non_filter.loc[np.array(batches[i])]\n",
    "            current_data['group_num'] = i\n",
    "\n",
    "            current_data['prior_group_answers_correct'] = [np.nan for elt in range(current_data.shape[0])]\n",
    "            current_data['prior_group_responses'] = [np.nan for elt in range(current_data.shape[0])]\n",
    "\n",
    "            if i != 0:\n",
    "                current_data['prior_group_answers_correct'].iloc[0] = saved_correct_answer\n",
    "                current_data['prior_group_responses'].iloc[0] = saved_answer\n",
    "\n",
    "            saved_answer = str(list(current_data[current_data['content_type_id'] == 0]['user_answer'].values))\n",
    "            saved_correct_answer = str(list(current_data[current_data['content_type_id'] == 0]['answered_correctly'].values))\n",
    "            current_data = current_data.drop(columns = ['user_answer', 'answered_correctly'])\n",
    "\n",
    "            data[i] = current_data\n",
    "\n",
    "        save((data,np.array(all_rows)) , save_name)\n",
    "        \n",
    "        self.data = data\n",
    "        self.all_rows = np.array(all_rows)\n",
    "        self.data_index = np.array(list(data.keys()))\n",
    "        print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = FakeDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.build_from_train(train, 15000, beginner_rate = 0.3, save_name = 'fake_train_generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(env.all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.load('fake_train_generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.all_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.index = train['row_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(index = env.all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(train, 'train_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "393656/5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dico = {}\n",
    "count = 0\n",
    "for userid, data in tqdm(train.groupby('user_id'), total = train['user_id'].nunique()):\n",
    "    dico[userid] = data\n",
    "    if len(dico.keys()) == 10000:\n",
    "        save(dico, 'userbatch_'+str(count), 'user_batch')\n",
    "        count+=1\n",
    "        dico = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elt in train.columns:\n",
    "    print(elt + '       '+ str(train[elt].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u115.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "timestamp : relative time since first interaction\n",
    "\n",
    "user_id : identifier of the user\n",
    "\n",
    "content_id : identifier of the content\n",
    "\n",
    "content_type_id : 0 = question, 1 = lecture\n",
    "\n",
    "task_container_id : identifier of a sequence of question (ie correction a la fin de la sequence)\n",
    "\n",
    "user_answer : user answer\n",
    "\n",
    "answered correctly : the user answered correctly to the question\n",
    "\n",
    "prior_quesiton_elapsed_time : avg time the user spend on the last container\n",
    "\n",
    "prior_question_had_explanatione : in a same bundle if the user have seen the answer of the last question or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elt in questions.columns:\n",
    "    print(elt + '       '+ str(questions[elt].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions['bundle_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parts\n",
    "Section 1 listening\n",
    "1 : 6 questions, four oral statement about photo choose right one\n",
    "2 : 25 questions, 3 reponse for one question oraly\n",
    "3 : 39 questions, conversation between people, question written, select best answer\n",
    "4 : 30 questions, talks or narrations ...\n",
    "    \n",
    "Section 2 reading\n",
    "5 : 30 questions, incomplete sentence completion\n",
    "6 : 16 questions, text completion\n",
    "7 : 29 + 25 questions, text understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lectures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lectures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lectures['type_of'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elt in lectures.columns:\n",
    "    print(elt + '       '+ str(lectures[elt].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\n",
    "    'content_id',\n",
    "    'content_type_id',\n",
    "    'task_container_id',\n",
    "    'user_answer_last',\n",
    "    'answered_correctly_last',\n",
    "    'prior_question_had_explanation',\n",
    "]\n",
    "\n",
    "num_cols = [\n",
    "    \"timestamp\",\n",
    "    \"prior_question_elapsed_time\",\n",
    "]\n",
    "\n",
    "pred_col = 'answered_correctly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence1 : ['content_id' + 'type_id','time_spent_discretised', 'answer', 'answer_correctly']\n",
    "sequence2 (embedding) : ['timestamp']\n",
    "sequence3 (embedding): ['number of event before']\n",
    "mask1 :  'padding_mask'\n",
    "mask2 :  'answer_correctly_mask'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load('train_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_sequence(df_user):\n",
    "    \n",
    "    df_user =  df_user.sort_values(by = 'timestamp')\n",
    "    df_user.index = list(range(df_user.shape[0]))\n",
    "    \n",
    "    df_user['content_type'] =  df_user['content_type_id'].apply(lambda x : 'q' if x == 0 else 'l')\n",
    "    df_user['content_seq'] = df_user['content_type'].astype(str) + '_' + df_user['content_id'].astype(str)\n",
    "    df_user['user_answer_seq'] = 'a_' + df_user['user_answer'].astype(str)\n",
    "    df_user['user_answer_corr_seq'] = 'r_' + df_user['answered_correctly'].astype(str)\n",
    "    \n",
    "    seq_to_encode = df_user[['content_seq', 'user_answer_seq', 'user_answer_corr_seq']].values\n",
    "    \n",
    "    reduced_seq = list(map(lambda x : ' '.join(x), seq_to_encode))\n",
    "    \n",
    "    seq = \" \".join(reduced_seq).split(' ')\n",
    "    \n",
    "    timestamps = df_user['timestamp'].values\n",
    "    timestamps = np.repeat(timestamps, 3)\n",
    "    \n",
    "    position = df_user.index\n",
    "    position = np.repeat(position, 3)\n",
    "    \n",
    "    ## Build masks and outups\n",
    "    y = []\n",
    "    for elt in seq[2:]:\n",
    "        if elt == 'r_0':\n",
    "            y.append(0)\n",
    "        elif elt == 'r_1':\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(2)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return seq, timestamps, position, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_test = train[train['user_id'] == 115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq, timestamps, position, y = build_user_sequence(user_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_user = {}\n",
    "count = 0\n",
    "for user, data_user in tqdm(train.groupby('user_id'), total = train['user_id'].nunique()):\n",
    "    seq, timestamps, position, y = build_user_sequence(data_user)\n",
    "    dico_user[user] = {\n",
    "                        \"sequence\" : seq,\n",
    "                        \"timestamps\" : timestamps,\n",
    "                        \"position\" : position,\n",
    "                        \"output\" : y\n",
    "                    }\n",
    "    \n",
    "    if len(dico_user) == 1000:\n",
    "        save(dico_user, 'batch_'+str(count), 'user_batch')\n",
    "        dico_user = {}\n",
    "        count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(dico_user, 'batch_'+str(count), 'user_batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_user = load('batch_'+str(0), 'user_batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building tokenizer\n",
    "lectures = pd.read_csv('lectures.csv')\n",
    "questions = pd.read_csv('questions.csv')\n",
    "user_answer = np.array([-1,0,1,2,3])\n",
    "answered_correctly = np.array([-1,0,1])\n",
    "\n",
    "\n",
    "lectures_id = lectures['lecture_id'].unique()\n",
    "question_id = questions['question_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_answer = ['a_'+ elt for elt in user_answer.astype(str)]\n",
    "answered_correctly = ['r_' + elt for elt in answered_correctly.astype(str)]\n",
    "lectures_id = ['l_' +  elt for elt in  lectures_id.astype(str)]\n",
    "question_id = ['q_' +  elt for elt in  question_id.astype(str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = np.array(['[PAD]','[CLS]','[RES]'] + answered_correctly + user_answer + lectures_id + question_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters = '')\n",
    "\n",
    "tokenizer.fit_on_texts(\n",
    "    all_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(tokenizer, 'tokenizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self,batch_size=32, max_len = 128, folder = 'user_batch'):\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = load('tokenizer')\n",
    "        self.max_len = max_len\n",
    "        self.folder = folder\n",
    "        self.dico_question = load('dico_questions_mean')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 1000000\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        ## Load random batch\n",
    "        file_name = random.choice(os.listdir('./'+self.folder))\n",
    "        dico_user = load(file_name.split('.')[0], self.folder)\n",
    "        \n",
    "        list_user = np.random.choice(list(dico_user.keys()), size = self.batch_size)\n",
    "        \n",
    "        \n",
    "        sequence = []\n",
    "        timestamp = []\n",
    "        positions = []\n",
    "        questions_mean = []\n",
    "        user_average = []\n",
    "        y = []\n",
    "        \n",
    "        for user in list_user:\n",
    "            s = dico_user[user]['sequence']\n",
    "            t = list(dico_user[user]['timestamps'])\n",
    "            p = list(range(int(len(t)/3)))\n",
    "            p = list(np.repeat(p, 3))\n",
    "            y_temp = list(dico_user[user]['output'])\n",
    "            \n",
    "            ## Choose if we start from start or not\n",
    "            a = random.uniform(0,1)\n",
    "            \n",
    "            if a < 0.5:\n",
    "                start = 0\n",
    "                s =  ['[CLS]'] + s\n",
    "            else:\n",
    "                start = random.choice(list(range(len(s))))\n",
    "                s = ['[RES]'] + s[start:]\n",
    "                t = t[start:]\n",
    "                p = p[start:]\n",
    "                y_temp = y_temp[start:]\n",
    "            \n",
    "            t = [0] + t\n",
    "            p = [0] + p\n",
    "            y_temp = [2] + y_temp +[2,2]\n",
    "            \n",
    "            ## Padding\n",
    "            while len(s) <= self.max_len:\n",
    "                s += ['[PAD]']\n",
    "                t += [0]\n",
    "                p += [0]\n",
    "                y_temp += [2]\n",
    "                \n",
    "            s = s[:self.max_len]\n",
    "            t = t[:self.max_len]\n",
    "            p = p[:self.max_len]\n",
    "            y_temp = y_temp[:self.max_len]\n",
    "            \n",
    "            ## Mean of questions\n",
    "            qm = []\n",
    "            for elt in s:\n",
    "                try:\n",
    "                    qm.append(self.dico_question[elt])\n",
    "                except:\n",
    "                    qm.append(0.5)\n",
    "            \n",
    "            ## Avg user grade\n",
    "            um = []\n",
    "            m  =[]\n",
    "            for elt in s:\n",
    "                if elt == 'r_0':\n",
    "                    m.append(0)\n",
    "                if elt == 'r_1':\n",
    "                    m.append(1)\n",
    "                \n",
    "                if len(m) == 0:\n",
    "                    um.append(0.5)\n",
    "                else:\n",
    "                    um.append(np.mean(m))           \n",
    "            \n",
    "            \n",
    "            \n",
    "            sequence.append(s)\n",
    "            timestamp.append(t)\n",
    "            positions.append(p)\n",
    "            questions_mean.append(qm)\n",
    "            user_average.append(um)\n",
    "            y.append(y_temp)\n",
    "            \n",
    "        sequence = self.tokenizer.texts_to_sequences(sequence)\n",
    "        sequence = np.array(sequence)\n",
    "        timestamp = np.array(timestamp)\n",
    "        positions = np.array(positions)\n",
    "        questions_mean = np.array(questions_mean).astype(\"float32\")\n",
    "        user_average = np.array(user_average).astype(\"float32\")\n",
    "        y = np.array(y)\n",
    "        \n",
    "        timestamp = timestamp.reshape((timestamp.shape[0],timestamp.shape[1], 1))\n",
    "        timestamp = np.log(timestamp+1)/10\n",
    "        \n",
    "#         print(sequence.shape)\n",
    "#         print(questions_mean)\n",
    "#         print(user_average)\n",
    "        \n",
    "        questions_mean = questions_mean.reshape((self.batch_size, self.max_len, 1))\n",
    "        user_average = user_average.reshape((self.batch_size, self.max_len, 1))\n",
    "        \n",
    "        numericals = np.concatenate([timestamp, questions_mean, user_average], axis = -1)\n",
    "        \n",
    "        \n",
    "        X = [sequence, numericals, positions]\n",
    "#         X = sequence\n",
    "#         y = tf.keras.utils.to_categorical(y)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "\n",
    "    def __get_data(self, batch):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = DataGenerator(batch_size=32, max_len = 128, folder = 'user_batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_transformers2 import *\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, TimeDistributed, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMGPTDecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(LSTMGPTDecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.lstm = tf.keras.layers.LSTM(\n",
    "                        d_model, activation='tanh', recurrent_activation='sigmoid', use_bias=True,\n",
    "                         recurrent_dropout=0.0, implementation=2, return_sequences=True\n",
    "                        )\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "    def call(self, x, training, look_ahead_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        x = self.lstm(x)\n",
    "#         print(x.shape)\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "#        attn2, attn_weights_block2 = self.mha2(out1, out1, out1, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "#        attn2 = self.dropout2(attn2, training=training)\n",
    "#        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDecoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff,\n",
    "               maximum_position_encoding, rate=0.1, bidirectional_decoder = False):\n",
    "        super(GPTDecoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(14000, d_model)\n",
    "        \n",
    "#         self.token_types_embedding = tf.keras.layers.Embedding(num_types, d_model)\n",
    "        \n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "        \n",
    "        self.numericals_encoding = Dense(d_model, activation = 'relu')\n",
    "        \n",
    "        self.question_mean_encoding = Dense(d_model, activation = 'relu')\n",
    "        \n",
    "        self.position_bis_encoding = tf.keras.layers.Embedding(20000, d_model)\n",
    "        \n",
    "        \n",
    "        self.dec_layers = [LSTMGPTDecoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "        self.bidirectional_decoder = bidirectional_decoder\n",
    "    \n",
    "    def call(self, x, training = True, numericals = None, positions = None):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "        \n",
    "        if self.bidirectional_decoder == False:\n",
    "            look_ahead_mask = create_look_ahead_mask(tf.shape(x)[1])\n",
    "            dec_target_padding_mask = create_padding_mask(x)\n",
    "            mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "        else:\n",
    "            mask = create_padding_mask(x)\n",
    "        \n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        \n",
    "        if numericals is not None:\n",
    "            numericals_emb = self.numericals_encoding(numericals)\n",
    "            x += numericals_emb\n",
    "        \n",
    "        if positions is not None:\n",
    "            positions_emb = self.position_bis_encoding(positions)\n",
    "            x += positions_emb\n",
    "            \n",
    "#         if question_mean is not None:\n",
    "#             question_mean_emb = self.question_mean_encoding(question_mean)\n",
    "#             x += question_mean_emb\n",
    "        \n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1 = self.dec_layers[i](x, training, look_ahead_mask = mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 3*128\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "inputs_ids = tf.keras.Input(shape = (max_len,))\n",
    "inputs_numericals = tf.keras.Input(shape = (max_len,3,))\n",
    "inputs_positions = tf.keras.Input(shape = (max_len,))\n",
    "\n",
    "inputs =[inputs_ids, inputs_numericals, inputs_positions]\n",
    "\n",
    "decoder = GPTDecoder(num_layers = 4, d_model = 512, \n",
    "                     num_heads = 8, dff = 512,\n",
    "                    maximum_position_encoding = 3*128, \n",
    "                     rate=0.1, bidirectional_decoder = False)\n",
    "\n",
    "decoded = decoder(inputs_ids, numericals = inputs_numericals, positions = inputs_positions)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(3, activation = 'softmax')(decoded)\n",
    "\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                    from_logits=True, reduction='none')\n",
    "\n",
    "\n",
    "# pred batch_size, seq_lenght, 3\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask1 = tf.math.logical_not(tf.math.equal(real, 2))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask1 = tf.cast(mask1, dtype=loss_.dtype)\n",
    "    loss_ *= mask1\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "def acc(true, pred):\n",
    "    mask = tf.cast(tf.math.logical_not(tf.math.equal(true, 2)),dtype = true.dtype)\n",
    "    \n",
    "    pred = pred[:,:,:2]\n",
    "    pred = tf.math.argmax(pred, axis=-1, output_type=tf.dtypes.int64, name=None)\n",
    "    pred = tf.cast(pred, dtype = true.dtype)\n",
    "    \n",
    "    pred = pred*mask\n",
    "    true = true*mask\n",
    "    \n",
    "    equal = tf.cast(tf.math.equal(pred, true), dtype = true.dtype)\n",
    "    \n",
    "    n_equal = tf.math.reduce_sum(equal)\n",
    "    n_mask = tf.math.reduce_sum(mask)\n",
    "    n_tot = tf.math.reduce_sum(tf.cast(tf.math.greater(true, -1), dtype = true.dtype))\n",
    "    n_masked = n_tot - n_mask\n",
    "    \n",
    "    return (n_equal - n_masked) / (n_tot - n_masked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "loss_classif     =  loss_function # find the right loss for multi-class classification\n",
    "optimizer        =  Adam(3e-5, 1e-8) # find the right optimizer\n",
    "metrics_classif  =  [acc]\n",
    "\n",
    "model.compile(loss=loss_classif,\n",
    "              optimizer=optimizer,\n",
    "              metrics=metrics_classif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(batch_size=32, max_len = 3*128, folder = 'user_batch')\n",
    "test_gen = DataGenerator(batch_size=1024, max_len = 3*128, folder = 'user_batch_test')\n",
    "x_test, y_test = test_gen[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Roc_Auc(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, train = None, validation=None):\n",
    "        super(Roc_Auc, self).__init__()\n",
    "        self.train = train\n",
    "        self.validation = validation\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        x_val, y_val = self.validation[0], self.validation[1]\n",
    "        \n",
    "        pred = self.model.predict(x_test, verbose = 0)\n",
    "        \n",
    "        pred = pred[:,:,1]\n",
    "        y_pred = pred.reshape(1024*384)\n",
    "        true = y_test.reshape(1024*384)\n",
    "\n",
    "        y_pred = y_pred[true != 2]\n",
    "        true = true[true != 2]\n",
    "        \n",
    "        metric = roc_auc_score(true, y_pred)\n",
    "        logs['roc_auc_val'] = metric\n",
    "        print(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=7, verbose=1, \n",
    "                                                mode='auto', restore_best_weights=True)\n",
    "reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, \n",
    "                                                 mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "roc = Roc_Auc(validation = (x_test,  y_test))\n",
    "\n",
    "bs = 32\n",
    "n_epochs = 50\n",
    "steps_per_epoch = 1250\n",
    "# steps_per_epoch = 10\n",
    "#, batch_size=bs\n",
    "history = model.fit(train_gen, epochs=n_epochs,steps_per_epoch = steps_per_epoch, validation_data=(x_test,  y_test), callbacks = [early, reduce, roc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred[:,:,1]\n",
    "y_pred = pred.reshape(1024*384)\n",
    "true = y_test.reshape(1024*384)\n",
    "\n",
    "y_pred = y_pred[true != 2]\n",
    "true = true[true != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(true, (y_pred >= 0.5)*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./weights/lstmgpt_auc_0.757.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def acc(true, pred):\n",
    "    true1 = np.array(true)\n",
    "    pred1 = np.array(pred)\n",
    "    \n",
    "    pred1 = pred1[true1 < 2]\n",
    "    true1 = true1[true1 < 2]\n",
    "    \n",
    "    \n",
    "    if true1.sum() == 0 or true1.sum() == len(true1):\n",
    "        true1 = np.concatenate([true1, np.array([0,1])])\n",
    "        pred1 = np.concatenate([pred1, np.array([0,1])])\n",
    "    \n",
    "    return roc_auc_score(true1, pred1)\n",
    "\n",
    "def test(true, pred):\n",
    "    p = []\n",
    "    \n",
    "    pred2 = pred.reshape(true.shape[0] * true.shape[1])\n",
    "    true2 = true.reshape(true.shape[0] * true.shape[1])\n",
    "    pred2 = pred2[true2 < 2]\n",
    "    true2 = true2[true2 < 2]\n",
    "    \n",
    "    print(roc_auc_score(true2, pred2))\n",
    "    \n",
    "    for i, elt in enumerate(tqdm(true)):\n",
    "#         print(pred[i])\n",
    "        p.append(acc(elt, pred[i]))\n",
    "    \n",
    "    plt.figure(figsize = (25,15))\n",
    "    plt.hist(p, bins = 50)\n",
    "    \n",
    "    print(np.mean(p))\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred[:,:,:2]\n",
    "\n",
    "def softmax(tab):\n",
    "    e = np.exp(tab)\n",
    "    s = np.sum(e, axis = -1)\n",
    "        \n",
    "    return e[:,:,1] / s\n",
    "\n",
    "pred = softmax(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = test(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ameliorations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add context on lecture and tasks\n",
    "\n",
    "cluster lecture and tasks\n",
    "\n",
    "give average score of a given task\n",
    "\n",
    "enhance test set with train set (optimization constraint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
