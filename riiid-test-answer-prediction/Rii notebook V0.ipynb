{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import _pickle as pickle\n",
    "\n",
    "def save(file,name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'wb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'wb')\n",
    "    pickle.dump(file, outfile, protocol=4)\n",
    "    outfile.close\n",
    "    \n",
    "def load(name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'rb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'rb')\n",
    "    file = pickle.load(outfile)\n",
    "    outfile.close\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'example_sample_submission.csv',\n",
       " 'example_test.csv',\n",
       " 'lectures.csv',\n",
       " 'processed_batch',\n",
       " 'questions.csv',\n",
       " 'riiideducation',\n",
       " 'test_batch.pickle',\n",
       " 'tf_transformers2.py',\n",
       " 'train.csv',\n",
       " 'train.pickle',\n",
       " 'Untitled.ipynb',\n",
       " 'user_batch',\n",
       " 'weak_or_strong_lre-6.h5',\n",
       " 'weak_or_strong_lre-7.h5',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7247"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train = pd.read_csv('train.csv')\n",
    "train = load('train')\n",
    "\n",
    "# train[train['content_id'] == 0] = 13433\n",
    "\n",
    "lectures = pd.read_csv('lectures.csv')\n",
    "questions = pd.read_csv('questions.csv')\n",
    "\n",
    "test = pd.read_csv('example_test.csv')\n",
    "sample = pd.read_csv('example_sample_submission.csv')\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>user_answer</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>5692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>56943</td>\n",
       "      <td>115</td>\n",
       "      <td>5716</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>118363</td>\n",
       "      <td>115</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>131167</td>\n",
       "      <td>115</td>\n",
       "      <td>7860</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>137965</td>\n",
       "      <td>115</td>\n",
       "      <td>7922</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  timestamp  user_id  content_id  content_type_id  task_container_id  \\\n",
       "0       0          0      115        5692                0                  1   \n",
       "1       1      56943      115        5716                0                  2   \n",
       "2       2     118363      115         128                0                  0   \n",
       "3       3     131167      115        7860                0                  3   \n",
       "4       4     137965      115        7922                0                  4   \n",
       "\n",
       "   user_answer  answered_correctly  prior_question_elapsed_time  \\\n",
       "0            3                   1                          NaN   \n",
       "1            2                   1                      37000.0   \n",
       "2            0                   1                      55000.0   \n",
       "3            0                   1                      19000.0   \n",
       "4            1                   1                      11000.0   \n",
       "\n",
       "  prior_question_had_explanation  \n",
       "0                            NaN  \n",
       "1                          False  \n",
       "2                          False  \n",
       "3                          False  \n",
       "4                          False  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da4d0c05dd845c9a1f3dbb1135d6bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeDataGenerator:\n",
    "    \n",
    "    def __init__(self):\n",
    "        '''\n",
    "        self.data will be a dictionnary to iterate over the stored data\n",
    "        self.all_rows will be the rows of the train set that are used by the generato\n",
    "        self.data_index will be all the data available in the dataset        \n",
    "        '''\n",
    "        self.data = None\n",
    "        self.all_rows = None\n",
    "        self.data_index = None\n",
    "        return None\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        sub = sample[['row_id', 'group_num']].copy()\n",
    "        sub['answered_correctly'] = np.zeros(sub.shape[0])+0.5\n",
    "        return (sample, sub)\n",
    "    \n",
    "    \n",
    "    def load(self, save_name):\n",
    "        self.data,self.all_rows = load(save_name)\n",
    "        self.data_index = np.array(list(self.data.keys()))\n",
    "    \n",
    "    def build_from_train(self, train, n_users, beginner_rate = 0.3, save_name = 'fake_train_generator'):\n",
    "        \"\"\"\n",
    "        train will be the training set you loaded\n",
    "        n_users is a number of user from whom you will sample the data\n",
    "        beginner_rate is the rate of these users who will begin their journey during test\n",
    "        save_name : the name under which the item will be saved\n",
    "        \"\"\"\n",
    "        \n",
    "        ## Sampling a restricted list of users\n",
    "        user_list = train['user_id'].unique()\n",
    "        test_user_list = np.random.choice(user_list, size = n_users)\n",
    "        train.index = train['user_id']\n",
    "        test_data_non_filter = train.loc[test_user_list]\n",
    "        test_data_non_filter.index = list(range(test_data_non_filter.shape[0]))\n",
    "        \n",
    "        ## building a dictionnary with all the rows and container id from a user\n",
    "        dico_user = {}\n",
    "        def agg(x):\n",
    "            return [elt for elt in x]\n",
    "        \n",
    "        print(\"Generating user dictionnary\")\n",
    "        for user, frame in tqdm(test_data_non_filter.groupby('user_id'), total =test_data_non_filter['user_id'].nunique()):\n",
    "            if frame.shape[0] > 0:\n",
    "                dico_user[user] = {}\n",
    "\n",
    "                dico_user[user]['min_indice'] = frame['task_container_id'].min()\n",
    "                dico_user[user]['max_indice'] = frame['task_container_id'].max()\n",
    "\n",
    "                r = random.uniform(0,1)\n",
    "                if r < beginner_rate:\n",
    "                    dico_user[user]['current_indice'] = dico_user[user]['min_indice']\n",
    "                else:\n",
    "                    dico_user[user]['current_indice'] = random.randint(dico_user[user]['min_indice'],dico_user[user]['max_indice']-2)\n",
    "\n",
    "                row_ids = frame[['task_container_id','row_id']].groupby('task_container_id').agg(agg)\n",
    "                row_ids = row_ids.to_dict()['row_id']\n",
    "                dico_user[user]['row_ids'] = row_ids\n",
    "\n",
    "        work_dico = deepcopy(dico_user)\n",
    "        \n",
    "        ## Choosing batch_data to generate\n",
    "        work_dico = deepcopy(dico_user)\n",
    "        batches = {}\n",
    "\n",
    "        all_rows = []\n",
    "        batch_number = 0\n",
    "        \n",
    "        print('Creating batches')\n",
    "        while len(work_dico)> 1:\n",
    "\n",
    "            size = random.randint(20,500)\n",
    "            size = min(size, len(work_dico))\n",
    "\n",
    "\n",
    "            batch = []\n",
    "\n",
    "            users = np.random.choice(np.array(list(work_dico.keys())),replace = False,  size = size)\n",
    "\n",
    "            for u in users:\n",
    "                try:\n",
    "                    batch.extend(work_dico[u]['row_ids'][work_dico[u]['current_indice']])\n",
    "                    all_rows.extend(work_dico[u]['row_ids'][work_dico[u]['current_indice']])\n",
    "                    work_dico[u]['current_indice'] += 1\n",
    "                    if work_dico[u]['current_indice'] == work_dico[u]['max_indice']:\n",
    "                        work_dico.pop(u)\n",
    "                except:\n",
    "                    work_dico.pop(u)\n",
    "\n",
    "            batches[batch_number] = batch\n",
    "            batch_number += 1\n",
    "        \n",
    "        ## building data\n",
    "\n",
    "        data = {}\n",
    "        \n",
    "        print(\"Building dataset\")\n",
    "        test_data_non_filter.index = test_data_non_filter['row_id']\n",
    "        for i in tqdm(batches):\n",
    "            current_data = test_data_non_filter.loc[np.array(batches[i])]\n",
    "            current_data['group_num'] = i\n",
    "\n",
    "            current_data['prior_group_answers_correct'] = [np.nan for elt in range(current_data.shape[0])]\n",
    "            current_data['prior_group_responses'] = [np.nan for elt in range(current_data.shape[0])]\n",
    "\n",
    "            if i != 0:\n",
    "                current_data['prior_group_answers_correct'].iloc[0] = saved_correct_answer\n",
    "                current_data['prior_group_responses'].iloc[0] = saved_answer\n",
    "\n",
    "            saved_answer = str(list(current_data[current_data['content_type_id'] == 0]['user_answer'].values))\n",
    "            saved_correct_answer = str(list(current_data[current_data['content_type_id'] == 0]['answered_correctly'].values))\n",
    "            current_data = current_data.drop(columns = ['user_answer', 'answered_correctly'])\n",
    "\n",
    "            data[i] = current_data\n",
    "\n",
    "        save((data,np.array(all_rows)) , save_name)\n",
    "        \n",
    "        self.data = data\n",
    "        self.all_rows = np.array(all_rows)\n",
    "        self.data_index = np.array(list(data.keys()))\n",
    "        print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = FakeDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating user dictionnary\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12127ce57c6e4690acefab1debcea68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14708.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating batches\n",
      "Building dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2479d5ab934670b291fbeac30976aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12757.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "env.build_from_train(train, 15000, beginner_rate = 0.3, save_name = 'fake_train_generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2381282"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(env.all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.load('fake_train_generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "963 µs ± 2.98 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df, sub = env[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2381282"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(env.all_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "393656/5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dico = {}\n",
    "count = 0\n",
    "for userid, data in tqdm(train.groupby('user_id'), total = train['user_id'].nunique()):\n",
    "    dico[userid] = data\n",
    "    if len(dico.keys()) == 10000:\n",
    "        save(dico, 'userbatch_'+str(count), 'user_batch')\n",
    "        count+=1\n",
    "        dico = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elt in train.columns:\n",
    "    print(elt + '       '+ str(train[elt].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u115 = train[train['user_id'] == 115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u115.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "timestamp : relative time since first interaction\n",
    "\n",
    "user_id : identifier of the user\n",
    "\n",
    "content_id : identifier of the content\n",
    "\n",
    "content_type_id : 0 = question, 1 = lecture\n",
    "\n",
    "task_container_id : identifier of a sequence of question (ie correction a la fin de la sequence)\n",
    "\n",
    "user_answer : user answer\n",
    "\n",
    "answered correctly : the user answered correctly to the question\n",
    "\n",
    "prior_quesiton_elapsed_time : avg time the user spend on the last container\n",
    "\n",
    "prior_question_had_explanatione : in a same bundle if the user have seen the answer of the last question or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elt in questions.columns:\n",
    "    print(elt + '       '+ str(questions[elt].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions['bundle_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parts\n",
    "Section 1 listening\n",
    "1 : 6 questions, four oral statement about photo choose right one\n",
    "2 : 25 questions, 3 reponse for one question oraly\n",
    "3 : 39 questions, conversation between people, question written, select best answer\n",
    "4 : 30 questions, talks or narrations ...\n",
    "    \n",
    "Section 2 reading\n",
    "5 : 30 questions, incomplete sentence completion\n",
    "6 : 16 questions, text completion\n",
    "7 : 29 + 25 questions, text understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lectures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lectures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lectures['type_of'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elt in lectures.columns:\n",
    "    print(elt + '       '+ str(lectures[elt].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = load('userbatch_'+str(1), 'user_batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elt in dico:\n",
    "    if dico[elt].shape[0] >= 50:\n",
    "        df = dico[elt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by = 'timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sequence : content_id warning, id0 = padding 1-32736\n",
    "\n",
    "sequence\n",
    "    task_container_id cat 0 - 9999\n",
    "    timestamp num\n",
    "    \n",
    "content\n",
    "    content_type_id cat 0-1\n",
    "    part cat 1-7  TBD\n",
    "    type of lecture cat 4  TBD\n",
    "    \n",
    "user_performance\n",
    "    user_answer_last cat 0-3 + -1\n",
    "    answered_correctly_last cat 0-1 + -1\n",
    "    \n",
    "features\n",
    "    prior_question_elapsed_time num\n",
    "    prior_question_had_explanation cat 0-1\n",
    "\n",
    "\n",
    "prediction\n",
    "    answerd_correctlu binary 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\n",
    "    'content_id',\n",
    "    'content_type_id',\n",
    "    'task_container_id',\n",
    "    'user_answer_last',\n",
    "    'answered_correctly_last',\n",
    "    'prior_question_had_explanation',\n",
    "]\n",
    "\n",
    "num_cols = [\n",
    "    \"timestamp\",\n",
    "    \"prior_question_elapsed_time\",\n",
    "]\n",
    "\n",
    "pred_col = 'answered_correctly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "def build_full_sequence(df, max_seq_lengh = 100, pad_token = 0):\n",
    "    \n",
    "    df =  df.sort_values(by = 'timestamp')\n",
    "    df = df[df['content_id'] < 15000]\n",
    "    \n",
    "    cats = df[['content_id', 'content_type_id','task_container_id', 'user_answer', 'answered_correctly', 'prior_question_had_explanation']].copy()\n",
    "    num = df[['timestamp', 'prior_question_elapsed_time']].copy()\n",
    "    preds = df['answered_correctly'].replace({-1:2, 1:1,0:0}).values.astype('int32')\n",
    "#     preds = np_utils.to_categorical(preds, num_classes = 4)\n",
    "    \n",
    "    cats['content_id'] = cats['content_id']\n",
    "    cats['user_answer'] = np.array([-1] + [elt for elt in cats['user_answer'].values[:-1]]) + 1\n",
    "    cats['answered_correctly'] = np.array([-1] + [elt for elt in cats['answered_correctly'].values[:-1]]) + 1\n",
    "    \n",
    "    cats['prior_question_had_explanation'] = cats['prior_question_had_explanation'].fillna(-1).values.astype(str)\n",
    "    cats['prior_question_had_explanation'] = cats['prior_question_had_explanation'].replace({'True' : 0, 'False' : 1, '-1' : 2})\n",
    "    \n",
    "    num['prior_question_elapsed_time'] = num['prior_question_elapsed_time'].fillna(-1)\n",
    "    num['timestamp']= num['timestamp'] / 1e9\n",
    "    num['prior_question_elapsed_time']= num['prior_question_elapsed_time'] / 5e3\n",
    "    \n",
    "    cats = cats.values.astype('int32')\n",
    "    num = num.values.astype('float32')\n",
    "    \n",
    "    if cats.shape[0] > 100:\n",
    "        cats = cats[:100]\n",
    "        num = num[:100]\n",
    "        preds = preds[:100]\n",
    "        \n",
    "    elif cats.shape[0] < 100:\n",
    "        cats = np.concatenate([cats, np.zeros((100 - cats.shape[0], 6)).astype('int32')])\n",
    "        num = np.concatenate([num, np.zeros((100 - num.shape[0], 2)).astype('float32')])\n",
    "        preds = np.concatenate([preds, np.zeros(100 - preds.shape[0]).astype('int32')+3])\n",
    "    else:\n",
    "        1\n",
    "    return cats, num, preds\n",
    "\n",
    "\n",
    "\n",
    "## function that take into account a full user journey and return a sequence that can be fitted into a model\n",
    "def build_full_sequence(df, max_seq_lengh = 100, pad_token = 0):\n",
    "    df =  df.sort_values(by = 'content_id')\n",
    "    df =  df.sort_values(by = 'timestamp')\n",
    "    df = df[df['content_id'] < 15000]\n",
    "    \n",
    "    df['answered_correctly'] = df['answered_correctly'].fillna(-1)\n",
    "    df['user_answer'] = df['user_answer'].fillna(-1)\n",
    "    \n",
    "    cats = df[['content_id', 'content_type_id','task_container_id', 'user_answer', 'answered_correctly', 'prior_question_had_explanation']].copy()\n",
    "    num = df[['timestamp', 'prior_question_elapsed_time']].copy()\n",
    "    preds = df['answered_correctly'].replace({-1:2, 1:1,0:0}).values.astype('int32')\n",
    "#     preds = np_utils.to_categorical(preds, num_classes = 4)\n",
    "    \n",
    "    cats['content_id'] = cats['content_id']\n",
    "    cats['user_answer'] = np.array([-1] + [elt for elt in cats['user_answer'].values[:-1]]) + 1\n",
    "    cats['answered_correctly'] = np.array([-1] + [elt for elt in cats['answered_correctly'].values[:-1]])\n",
    "    cats['answered_correctly']\n",
    "    \n",
    "    cats['prior_question_had_explanation'] = cats['prior_question_had_explanation'].values.astype(str)\n",
    "    cats['prior_question_had_explanation'] = cats['prior_question_had_explanation'].replace({'True' : 0, 'False' : 1, '-1' : 2, '<NA>' : 2, 'nan' : 2})\n",
    "    \n",
    "    num['prior_question_elapsed_time'] = num['prior_question_elapsed_time'].fillna(-1)\n",
    "    num['timestamp']= num['timestamp'] / 1e9\n",
    "    num['prior_question_elapsed_time']= num['prior_question_elapsed_time'] / 5e3\n",
    "    \n",
    "    cats = cats.values.astype('int32')\n",
    "    num = num.values.astype('float32')\n",
    "    \n",
    "    if cats.shape[0] > 100:\n",
    "        cats = cats[-100:]\n",
    "        num = num[-100:]\n",
    "        preds = preds[-100:]\n",
    "        \n",
    "    elif cats.shape[0] < 100:\n",
    "        cats = np.concatenate([cats, np.zeros((100 - cats.shape[0], 6)).astype('int32')])\n",
    "        num = np.concatenate([num, np.zeros((100 - num.shape[0], 2)).astype('float32')])\n",
    "        preds = np.concatenate([preds, np.zeros(100 - preds.shape[0]).astype('int32')+3])\n",
    "    else:\n",
    "        1\n",
    "        \n",
    "    return cats, num, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-66c27eb8e5d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_full_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_seq_lengh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad_token\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "cats, num, preds = build_full_sequence(df.iloc[:80], max_seq_lengh = 100, pad_token = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ace5d08c0c3465ba6552463cd970656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userbatch_0.pickle\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './test/userbatch_0.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-462b31b1b969>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-64-64deb169005a>\u001b[0m in \u001b[0;36msave\u001b[1;34m(file, name, folder)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0moutfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.pickle'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0moutfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.pickle'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './test/userbatch_0.pickle'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for file in tqdm(os.listdir('user_batch')):\n",
    "#     if not(file in os.listdir('processed_batch')):\n",
    "        print(file)\n",
    "        dico = load(file.split('.')[0], 'user_batch')\n",
    "\n",
    "\n",
    "        ids = np.zeros(len(dico)).astype(str)\n",
    "        cat = np.zeros((len(dico), 100, 6)).astype(int)\n",
    "        num = np.zeros((len(dico), 100, 2)).astype(float)\n",
    "        preds = np.zeros((len(dico), 100)).astype(int)\n",
    "\n",
    "        for i, elt in enumerate(tqdm(dico, leave = False)):\n",
    "            c, n, p = build_full_sequence(dico[elt], max_seq_lengh = 100, pad_token = 0)\n",
    "            preds[i, :] = p\n",
    "            cat[i, : ,:] = c\n",
    "            num[i,:,:] = n\n",
    "            ids[i] = elt\n",
    "\n",
    "\n",
    "        save((ids, cat, num, preds), file.split('.')[0], 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ids, cat, num, preds) = load('userbatch_0', 'processed_batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e45fb633fc249bab0d242150bb27ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ids, cat, num, preds = [], [], [], []\n",
    "\n",
    "for elt in tqdm(os.listdir('processed_batch')):\n",
    "    i, c, n, p = load(elt.split('.')[0], 'processed_batch')\n",
    "    ids.append(i)\n",
    "    cat.append(c)\n",
    "    num.append(n)\n",
    "    preds.append(p)\n",
    "    \n",
    "ids = np.concatenate(ids, axis = 0)\n",
    "cat = np.concatenate(cat, axis = 0)\n",
    "num = np.concatenate(num, axis = 0)\n",
    "preds = np.concatenate(preds, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(390000, 100, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['115', '124', '2746', ..., '547587124', '547588483', '547594902'],\n",
       "      dtype='<U32')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_transformers2 import *\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, TimeDistributed, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\n",
    "    'content_id',\n",
    "    'content_type_id',\n",
    "    'task_container_id',\n",
    "    'user_answer_last',\n",
    "    'answered_correctly_last',\n",
    "    'prior_question_had_explanation',\n",
    "]\n",
    "\n",
    "num_cols = [\n",
    "    \"timestamp\",\n",
    "    \"prior_question_elapsed_time\",\n",
    "]\n",
    "\n",
    "pred_col = 'answered_correctly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence : content_id warning, id0 = padding 1-32736\n",
    "\n",
    "sequence\n",
    "    task_container_id cat 0 - 9999\n",
    "    timestamp num\n",
    "    \n",
    "content\n",
    "    content_type_id cat 0-1\n",
    "    part cat 1-7  TBD\n",
    "    type of lecture cat 4  TBD\n",
    "    \n",
    "user_performance\n",
    "    user_answer_last cat 0-3 + -1\n",
    "    answered_correctly_last cat 0-1 + -1\n",
    "    \n",
    "features\n",
    "    prior_question_elapsed_time num\n",
    "    prior_question_had_explanation cat 0-1\n",
    "\n",
    "\n",
    "prediction\n",
    "    answerd_correctlu binary 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDecoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, num_types = 2, rate=0.1, bidirectional_decoder = False):\n",
    "        super(GPTDecoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        \n",
    "        ## cats enbedding\n",
    "        self.content_type_id_embedding = tf.keras.layers.Embedding(2, d_model)\n",
    "        self.task_container_id_embedding = tf.keras.layers.Embedding(10000, d_model)\n",
    "        self.user_answer_last_embedding = tf.keras.layers.Embedding(6, d_model)\n",
    "        self.answered_correctly_last_embedding = tf.keras.layers.Embedding(4, d_model)\n",
    "        self.prior_question_had_explanation_embedding = tf.keras.layers.Embedding(5, d_model)\n",
    "        self.num_embedding = tf.keras.layers.Dense(d_model, activation = 'relu')\n",
    "        \n",
    "        self.conc = tf.keras.layers.Concatenate(axis = -1)\n",
    "        \n",
    "        self.agg = tf.keras.layers.Dense(d_model, activation = 'relu')\n",
    "        \n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [GPTDecoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "        self.bidirectional_decoder = bidirectional_decoder\n",
    "    \n",
    "    def call(self, x, \n",
    "             content_type_id = None,\n",
    "             task_container_id = None, \n",
    "             user_answer_last = None, \n",
    "             answered_correctly_last = None, \n",
    "             prior_question_had_explanation = None, \n",
    "             nums = None,\n",
    "             training = True):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "#         print(x.shape)\n",
    "        if self.bidirectional_decoder == False:\n",
    "            look_ahead_mask = create_look_ahead_mask(tf.shape(x)[1])\n",
    "            dec_target_padding_mask = create_padding_mask(x)\n",
    "            mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "        else:\n",
    "            mask = create_padding_mask(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        content_type_id_emb = self.content_type_id_embedding(content_type_id)\n",
    "        task_container_id_emb = self.task_container_id_embedding(task_container_id)\n",
    "        user_answer_last_emb = self.user_answer_last_embedding(user_answer_last)\n",
    "        answered_correctly_last_emb = self.answered_correctly_last_embedding(answered_correctly_last)\n",
    "        prior_question_had_explanation_emb = self.prior_question_had_explanation_embedding(prior_question_had_explanation)\n",
    "        num_emb = self.num_embedding(nums)\n",
    "        \n",
    "        x = self.conc([x, content_type_id_emb, task_container_id_emb, user_answer_last_emb,\n",
    "                                        answered_correctly_last_emb,\n",
    "                                        prior_question_had_explanation_emb,\n",
    "                                        num_emb])\n",
    "        x = self.agg(x)\n",
    "        \n",
    "        \n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        \n",
    "#         if token_types_ids is not None:\n",
    "#             token_types_ids_emb = self.token_types_embedding(token_types_ids)\n",
    "#             x += token_types_ids_emb\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "#         print(x.shape)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x, block1 = self.dec_layers[i](x, training, look_ahead_mask = mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "#            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDecoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, num_types = 2, rate=0.1, bidirectional_decoder = False):\n",
    "        super(GPTDecoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        \n",
    "        ## cats enbedding\n",
    "        self.content_type_id_embedding = tf.keras.layers.Embedding(2, d_model)\n",
    "        self.task_container_id_embedding = tf.keras.layers.Embedding(10000, d_model)\n",
    "        self.user_answer_last_embedding = tf.keras.layers.Embedding(6, d_model)\n",
    "        \n",
    "        self.answered_correctly_last_embedding = tf.keras.layers.Embedding(4, d_model)\n",
    "        \n",
    "        self.prior_question_had_explanation_embedding = tf.keras.layers.Embedding(5, d_model)\n",
    "        self.num_embedding = tf.keras.layers.Dense(d_model, activation = 'relu')\n",
    "        \n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [GPTDecoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "        self.bidirectional_decoder = bidirectional_decoder\n",
    "    \n",
    "    def call(self, x, \n",
    "             content_type_id = None,\n",
    "             task_container_id = None, \n",
    "             user_answer_last = None, \n",
    "             answered_correctly_last = None, \n",
    "             prior_question_had_explanation = None, \n",
    "             nums = None,\n",
    "             training = True):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "#         print(x.shape)\n",
    "        if self.bidirectional_decoder == False:\n",
    "            look_ahead_mask = create_look_ahead_mask(tf.shape(x)[1])\n",
    "            dec_target_padding_mask = create_padding_mask(x)\n",
    "            mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "        else:\n",
    "            mask = create_padding_mask(x)\n",
    "        \n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "#         x = self.answered_correctly_last_embedding(answered_correctly_last)\n",
    "        \n",
    "        \n",
    "        content_type_id_emb = self.content_type_id_embedding(content_type_id)\n",
    "        x += content_type_id_emb\n",
    "        \n",
    "        task_container_id_emb = self.task_container_id_embedding(task_container_id)\n",
    "        x += task_container_id_emb\n",
    "        \n",
    "        user_answer_last_emb = self.user_answer_last_embedding(user_answer_last)\n",
    "        x += user_answer_last_emb\n",
    "        \n",
    "        answered_correctly_last_emb = self.answered_correctly_last_embedding(answered_correctly_last)\n",
    "        x += answered_correctly_last_emb\n",
    "        \n",
    "        prior_question_had_explanation_emb = self.prior_question_had_explanation_embedding(prior_question_had_explanation)\n",
    "        x += prior_question_had_explanation_emb\n",
    "        \n",
    "        num_emb = self.num_embedding(nums)\n",
    "        x += num_emb\n",
    "        \n",
    "        \n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        \n",
    "        \n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "#         print(x.shape)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x, block1 = self.dec_layers[i](x, training, look_ahead_mask = mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "#            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_inputs = Input(shape = ( 100, 2))\n",
    "cat_inputs = Input(shape = ( 100, 6))\n",
    "\n",
    "inputs = [cat_inputs, num_inputs]\n",
    "\n",
    "decoder = GPTDecoder(4, 768, 8, 512, 15001,\n",
    "               100, num_types = 2, rate=0.1, bidirectional_decoder = False)\n",
    "\n",
    "\n",
    "encoded = decoder(\n",
    "    cat_inputs[:,:,0],\n",
    "    content_type_id=cat_inputs[:,:,1],\n",
    "    task_container_id=cat_inputs[:,:,2], \n",
    "    user_answer_last=cat_inputs[:,:,3], \n",
    "    answered_correctly_last=cat_inputs[:,:,4], \n",
    "    prior_question_had_explanation=cat_inputs[:,:,5], \n",
    "    nums=num_inputs,\n",
    "        )[0]\n",
    "\n",
    "outputs = tf.keras.layers.Dense(4)(encoded)\n",
    "\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 100, 6)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 100)]        0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(None, 100)]        0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(None, 100)]        0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 100, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_5 (Te [(None, 100)]        0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, 100)]        0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [(None, 100)]        0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gpt_decoder (GPTDecoder)        ((None, 100, 768), { 35958272    tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 100, 4)       3076        gpt_decoder[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 35,961,348\n",
      "Trainable params: 35,961,348\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15001, 768)\n",
      "gpt_decoder/embedding/embeddings:0      11520768\n",
      "(2, 768)\n",
      "gpt_decoder/embedding_1/embeddings:0      1536\n",
      "(10000, 768)\n",
      "gpt_decoder/embedding_2/embeddings:0      7680000\n",
      "(6, 768)\n",
      "gpt_decoder/embedding_3/embeddings:0      4608\n",
      "(4, 768)\n",
      "gpt_decoder/embedding_4/embeddings:0      3072\n",
      "(5, 768)\n",
      "gpt_decoder/embedding_5/embeddings:0      3840\n",
      "(2, 768)\n",
      "gpt_decoder/dense/kernel:0      1536\n",
      "(768,)\n",
      "gpt_decoder/dense/bias:0      768\n",
      "(5376, 768)\n",
      "gpt_decoder/dense_1/kernel:0      4128768\n",
      "(768,)\n",
      "gpt_decoder/dense_1/bias:0      768\n",
      "(768, 768)\n",
      "gpt_decoder/gpt_decoder_layer/multi_head_attention/dense_2/kernel:0      589824\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer/multi_head_attention/dense_2/bias:0      768\n",
      "(768, 768)\n",
      "gpt_decoder/gpt_decoder_layer/multi_head_attention/dense_3/kernel:0      589824\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer/multi_head_attention/dense_3/bias:0      768\n",
      "(768, 768)\n",
      "gpt_decoder/gpt_decoder_layer/multi_head_attention/dense_4/kernel:0      589824\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer/multi_head_attention/dense_4/bias:0      768\n",
      "(768, 768)\n",
      "gpt_decoder/gpt_decoder_layer/multi_head_attention/dense_5/kernel:0      589824\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer/multi_head_attention/dense_5/bias:0      768\n",
      "(768, 512)\n",
      "gpt_decoder/gpt_decoder_layer/sequential/dense_10/kernel:0      393216\n",
      "(512,)\n",
      "gpt_decoder/gpt_decoder_layer/sequential/dense_10/bias:0      512\n",
      "(512, 768)\n",
      "gpt_decoder/gpt_decoder_layer/sequential/dense_11/kernel:0      393216\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer/sequential/dense_11/bias:0      768\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer/layer_normalization/gamma:0      768\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer/layer_normalization/beta:0      768\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer/layer_normalization_2/gamma:0      768\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer/layer_normalization_2/beta:0      768\n",
      "(768, 768)\n",
      "gpt_decoder/gpt_decoder_layer_1/multi_head_attention_2/dense_12/kernel:0      589824\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_1/multi_head_attention_2/dense_12/bias:0      768\n",
      "(768, 768)\n",
      "gpt_decoder/gpt_decoder_layer_1/multi_head_attention_2/dense_13/kernel:0      589824\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_1/multi_head_attention_2/dense_13/bias:0      768\n",
      "(768, 768)\n",
      "gpt_decoder/gpt_decoder_layer_1/multi_head_attention_2/dense_14/kernel:0      589824\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_1/multi_head_attention_2/dense_14/bias:0      768\n",
      "(768, 768)\n",
      "gpt_decoder/gpt_decoder_layer_1/multi_head_attention_2/dense_15/kernel:0      589824\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_1/multi_head_attention_2/dense_15/bias:0      768\n",
      "(768, 512)\n",
      "gpt_decoder/gpt_decoder_layer_1/sequential_1/dense_20/kernel:0      393216\n",
      "(512,)\n",
      "gpt_decoder/gpt_decoder_layer_1/sequential_1/dense_20/bias:0      512\n",
      "(512, 768)\n",
      "gpt_decoder/gpt_decoder_layer_1/sequential_1/dense_21/kernel:0      393216\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_1/sequential_1/dense_21/bias:0      768\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_1/layer_normalization_3/gamma:0      768\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_1/layer_normalization_3/beta:0      768\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_1/layer_normalization_5/gamma:0      768\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_1/layer_normalization_5/beta:0      768\n",
      "(768, 768)\n",
      "gpt_decoder/gpt_decoder_layer_2/multi_head_attention_4/dense_22/kernel:0      589824\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_2/multi_head_attention_4/dense_22/bias:0      768\n",
      "(768, 768)\n",
      "gpt_decoder/gpt_decoder_layer_2/multi_head_attention_4/dense_23/kernel:0      589824\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_2/multi_head_attention_4/dense_23/bias:0      768\n",
      "(768, 768)\n",
      "gpt_decoder/gpt_decoder_layer_2/multi_head_attention_4/dense_24/kernel:0      589824\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_2/multi_head_attention_4/dense_24/bias:0      768\n",
      "(768, 768)\n",
      "gpt_decoder/gpt_decoder_layer_2/multi_head_attention_4/dense_25/kernel:0      589824\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_2/multi_head_attention_4/dense_25/bias:0      768\n",
      "(768, 512)\n",
      "gpt_decoder/gpt_decoder_layer_2/sequential_2/dense_30/kernel:0      393216\n",
      "(512,)\n",
      "gpt_decoder/gpt_decoder_layer_2/sequential_2/dense_30/bias:0      512\n",
      "(512, 768)\n",
      "gpt_decoder/gpt_decoder_layer_2/sequential_2/dense_31/kernel:0      393216\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_2/sequential_2/dense_31/bias:0      768\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_2/layer_normalization_6/gamma:0      768\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_2/layer_normalization_6/beta:0      768\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_2/layer_normalization_8/gamma:0      768\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_2/layer_normalization_8/beta:0      768\n",
      "(768, 768)\n",
      "gpt_decoder/gpt_decoder_layer_3/multi_head_attention_6/dense_32/kernel:0      589824\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_3/multi_head_attention_6/dense_32/bias:0      768\n",
      "(768, 768)\n",
      "gpt_decoder/gpt_decoder_layer_3/multi_head_attention_6/dense_33/kernel:0      589824\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_3/multi_head_attention_6/dense_33/bias:0      768\n",
      "(768, 768)\n",
      "gpt_decoder/gpt_decoder_layer_3/multi_head_attention_6/dense_34/kernel:0      589824\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_3/multi_head_attention_6/dense_34/bias:0      768\n",
      "(768, 768)\n",
      "gpt_decoder/gpt_decoder_layer_3/multi_head_attention_6/dense_35/kernel:0      589824\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_3/multi_head_attention_6/dense_35/bias:0      768\n",
      "(768, 512)\n",
      "gpt_decoder/gpt_decoder_layer_3/sequential_3/dense_40/kernel:0      393216\n",
      "(512,)\n",
      "gpt_decoder/gpt_decoder_layer_3/sequential_3/dense_40/bias:0      512\n",
      "(512, 768)\n",
      "gpt_decoder/gpt_decoder_layer_3/sequential_3/dense_41/kernel:0      393216\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_3/sequential_3/dense_41/bias:0      768\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_3/layer_normalization_9/gamma:0      768\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_3/layer_normalization_9/beta:0      768\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_3/layer_normalization_11/gamma:0      768\n",
      "(768,)\n",
      "gpt_decoder/gpt_decoder_layer_3/layer_normalization_11/beta:0      768\n"
     ]
    }
   ],
   "source": [
    "for layer in decoder.trainable_weights:\n",
    "    j = 1\n",
    "    print(layer.shape)\n",
    "    for elt in np.array(layer.shape):\n",
    "        j = elt * j\n",
    "    j\n",
    "    print(layer.name + \"      \" + str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 100, 6)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 100)]        0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(None, 100)]        0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(None, 100)]        0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 100, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_5 (Te [(None, 100)]        0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, 100)]        0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [(None, 100)]        0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gpt_decoder (GPTDecoder)        ((None, 100, 768), { 35958272    tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 100, 4)       3076        gpt_decoder[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 35,961,348\n",
      "Trainable params: 35,961,348\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train, cat_test, y_train, y_test = train_test_split(cat, preds, random_state=42, test_size=0.1)\n",
    "num_train, num_test, _, _ = train_test_split(num, preds, random_state=42, test_size=0.1)\n",
    "\n",
    "X_train  =[cat_train, num_train]\n",
    "X_test = [cat_test, num_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask1 = tf.math.logical_not(tf.math.equal(real, 3))\n",
    "    mask2 = tf.math.logical_not(tf.math.equal(real, 2))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask1 = tf.cast(mask1, dtype=loss_.dtype)\n",
    "    mask2 = tf.cast(mask2, dtype=loss_.dtype)\n",
    "    loss_ *= mask1\n",
    "    loss_ *= mask2\n",
    "  \n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "\n",
    "\n",
    "def acc_end(true, pred):\n",
    "    true = tf.cast(true, dtype = pred.dtype)\n",
    "#     en_true = true[:, 1]\n",
    "#     en_pred = pred[:, 1]\n",
    "    \n",
    "    mask1 = tf.math.logical_not(tf.math.equal(true, 2))\n",
    "    mask1 = tf.cast(mask1, dtype = true.dtype)\n",
    "    \n",
    "    mask2 = tf.math.logical_not(tf.math.equal(true, 3))\n",
    "    mask2 = tf.cast(mask2, dtype = true.dtype)\n",
    "    \n",
    "    mask = mask1 * mask2\n",
    "    \n",
    "    n_mask = tf.math.equal(mask, 0)\n",
    "    n_mask = tf.cast(mask, dtype = true.dtype)\n",
    "    n_mask = tf.math.reduce_sum(n_mask)\n",
    "    \n",
    "    en_true = true * mask\n",
    "    \n",
    "#     r= tf.math.argmax(en_true)\n",
    "    p = tf.math.argmax(pred, axis = -1)\n",
    "    p = tf.cast(p, dtype = true.dtype)\n",
    "    en_pred = p * mask  \n",
    "    \n",
    "    equal = tf.reduce_sum(tf.cast(tf.math.equal(en_true,en_pred), true.dtype))\n",
    "    \n",
    "    total = tf.reduce_sum(tf.cast(tf.math.logical_not(tf.math.equal(true, 151)),dtype= true.dtype))\n",
    "    \n",
    "    sum_equal = equal - n_mask\n",
    "    total = total - n_mask\n",
    "    \n",
    "    return sum_equal / total\n",
    "\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "                    name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "loss_classif     =  'sparsecategoricalcrossentropy'# find the right loss for multi-class classification\n",
    "optimizer        =  Adam(3e-7, 1e-8) # find the right optimizer\n",
    "metrics_classif  =  [train_accuracy,acc_end]\n",
    "\n",
    "model.compile(loss=loss_classif,\n",
    "              optimizer=optimizer,\n",
    "              metrics=metrics_classif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 351000 samples, validate on 39000 samples\n",
      "Epoch 1/50\n",
      "351000/351000 [==============================] - 1597s 5ms/sample - loss: 0.3173 - train_accuracy: 0.3918 - acc_end: 0.6202 - val_loss: 0.3184 - val_train_accuracy: 0.3939 - val_acc_end: 0.6182\n",
      "Epoch 2/50\n",
      "  2048/351000 [..............................] - ETA: 24:52 - loss: 0.3228 - train_accuracy: 0.3940 - acc_end: 0.6094WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,train_accuracy,acc_end\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,train_accuracy,acc_end,lr\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-d19643c3f407>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#, batch_size=bs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mearly\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=4, verbose=1, \n",
    "                                                mode='auto', restore_best_weights=True)\n",
    "reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, \n",
    "                                                     mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "bs = 128\n",
    "n_epochs = 50\n",
    "#, batch_size=bs\n",
    "history = model.fit(X_train, y_train, batch_size=bs, epochs=n_epochs, validation_data=(X_test,  y_test), callbacks = [early, reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('weak_or_strong_lre-7.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def acc(true, pred):\n",
    "    true1 = np.array(true)\n",
    "    pred1 = np.array(pred)\n",
    "    \n",
    "    pred1 = pred1[true1 < 2]\n",
    "    true1 = true1[true1 < 2]\n",
    "    \n",
    "    \n",
    "    if true1.sum() == 0 or true1.sum() == len(true1):\n",
    "        true1 = np.concatenate([true1, np.array([0,1])])\n",
    "        pred1 = np.concatenate([pred1, np.array([0,1])])\n",
    "    \n",
    "    return roc_auc_score(true1, pred1)\n",
    "\n",
    "def test(true, pred):\n",
    "    p = []\n",
    "    \n",
    "    pred2 = pred.reshape(true.shape[0] * true.shape[1])\n",
    "    true2 = true.reshape(true.shape[0] * true.shape[1])\n",
    "    pred2 = pred2[true2 < 2]\n",
    "    true2 = true2[true2 < 2]\n",
    "    \n",
    "    print(roc_auc_score(true2, pred2))\n",
    "    \n",
    "    for i, elt in enumerate(tqdm(true)):\n",
    "#         print(pred[i])\n",
    "        p.append(acc(elt, pred[i]))\n",
    "    \n",
    "    plt.figure(figsize = (25,15))\n",
    "    plt.hist(p, bins = 50)\n",
    "    \n",
    "    print(np.mean(p))\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39000, 100, 4)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred[:,:,:2]\n",
    "\n",
    "def softmax(tab):\n",
    "    e = np.exp(tab)\n",
    "    s = np.sum(e, axis = -1)\n",
    "        \n",
    "    return e[:,:,1] / s\n",
    "\n",
    "pred = softmax(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39000, 100)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28751293, 0.63696694, 0.7239663 , 0.6437963 , 0.37826955,\n",
       "       0.16724584, 0.10550317, 0.11095072, 0.31691468, 0.6318078 ,\n",
       "       0.528592  , 0.20078447, 0.3849859 , 0.43025756, 0.40213463,\n",
       "       0.63918686, 0.70503014, 0.6399605 , 0.6735235 , 0.6762784 ,\n",
       "       0.7469161 , 0.42706996, 0.9223325 , 0.27291033, 0.7955996 ,\n",
       "       0.6657556 , 0.84566814, 0.42095813, 0.61018324, 0.67308456,\n",
       "       0.9431221 , 0.9402809 , 0.93755746, 0.93694913, 0.93691295,\n",
       "       0.93732804, 0.93768734, 0.938239  , 0.9383419 , 0.9376271 ,\n",
       "       0.93704027, 0.9368739 , 0.9370214 , 0.93852496, 0.94083965,\n",
       "       0.94218254, 0.9427476 , 0.94256103, 0.94122726, 0.9401764 ,\n",
       "       0.9395297 , 0.93872225, 0.938603  , 0.9393531 , 0.9409249 ,\n",
       "       0.9422062 , 0.94346666, 0.9432472 , 0.9425835 , 0.9413383 ,\n",
       "       0.940561  , 0.940646  , 0.9410207 , 0.9422387 , 0.94266135,\n",
       "       0.94179696, 0.93962556, 0.93675154, 0.93590194, 0.9375956 ,\n",
       "       0.9396144 , 0.93988115, 0.93866247, 0.93655515, 0.9352478 ,\n",
       "       0.9358188 , 0.93661046, 0.9372911 , 0.93782264, 0.9386999 ,\n",
       "       0.9399636 , 0.9405483 , 0.9415347 , 0.9422023 , 0.9424503 ,\n",
       "       0.94174767, 0.9397709 , 0.9377293 , 0.9363273 , 0.9360544 ,\n",
       "       0.9373074 , 0.93918747, 0.9405129 , 0.94041497, 0.9400522 ,\n",
       "       0.94086426, 0.9431384 , 0.9453437 , 0.9467643 , 0.9452776 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7656962865118073\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b400c77f73144ed9f1110cea40cc781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.7179201381516703\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "perf = test(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ameliorations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add context on lecture and tasks\n",
    "\n",
    "cluster lecture and tasks\n",
    "\n",
    "give average score of a given task\n",
    "\n",
    "enhance test set with train set (optimization constraint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
