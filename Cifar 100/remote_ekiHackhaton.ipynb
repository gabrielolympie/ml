{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ScVmE2VcrcBn"
   },
   "source": [
    "#Introduction\n",
    "Welcome to the first remote Eki hackaton. The aim of the hackaton is to build your first neural network and a learning scheme in a efficient way.The task is image classification on CIFAR10\n",
    "\n",
    "**************\n",
    "The code contains :\n",
    "\n",
    "1. Load and normalizing the CIFAR10 training and test datasets using\n",
    "   ``torchvision``\n",
    "2. Define a Convolutional Neural Network\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data\n",
    "\n",
    "**************\n",
    "Some **questions** too keep in mind :\n",
    "\n",
    "    - which kind of data transformation and augmentation?\n",
    "    - How building my neural network?\n",
    "    - which kind of optimization?\n",
    "\n",
    "Some tips here :) : [ML Lunch](https://bizoffice61.sharepoint.com/:p:/r/sites/Ekimetrics51/_layouts/15/Doc.aspx?sourcedoc=%7BA44BD8EB-39E2-4113-9861-A817680A7F55%7D&file=20200304%20-%20ML%20Lunch%20-%20Understanding%20Deep%20Learning.pptx&action=edit&mobileredirect=true)\n",
    "\n",
    "**************\n",
    "How to win?\n",
    "\n",
    "The winner will propose a script which:\n",
    "\n",
    "reachs at least 60% of accuracy on the dataset\n",
    "builds a network with a minimum number of parameters.\n",
    "Example :\n",
    "\n",
    "People 1 : Accuracy : 58%, number of parameter : 10K\n",
    "\n",
    "People 2 : Accuracy : 61%, number of parameters : 15K\n",
    "\n",
    "People 3: Accuracy : 67%, number of paremeters : 16K\n",
    "\n",
    "People 2 wins !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nzpZHfSepk12"
   },
   "source": [
    "#Import all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yyKYHGjTrBec"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import requests\n",
    "\n",
    "# Put the token you received in a mail here ! \n",
    "token = '5e9ed8b402f6580017600bca'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wuxlxnRsqedU"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jw1NDFrosjX6"
   },
   "source": [
    "# Load and normalizing the CIFAR10 training and test datasets using ``torchvision``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nm4gnJAurikT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973dac668c434ea5b1f81505d8b9ad75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# We transform them to Tensors of normalized range [-1, 1].\n",
    "\n",
    "transform = transforms.Compose(\n",
    "     [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on CIFAR10 in module torchvision.datasets.cifar object:\n",
      "\n",
      "class CIFAR10(torchvision.datasets.vision.VisionDataset)\n",
      " |  CIFAR10(root, train=True, transform=None, target_transform=None, download=False)\n",
      " |  \n",
      " |  `CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
      " |  \n",
      " |  Args:\n",
      " |      root (string): Root directory of dataset where directory\n",
      " |          ``cifar-10-batches-py`` exists or will be saved to if download is set to True.\n",
      " |      train (bool, optional): If True, creates dataset from training set, otherwise\n",
      " |          creates from test set.\n",
      " |      transform (callable, optional): A function/transform that takes in an PIL image\n",
      " |          and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
      " |      target_transform (callable, optional): A function/transform that takes in the\n",
      " |          target and transforms it.\n",
      " |      download (bool, optional): If true, downloads the dataset from the internet and\n",
      " |          puts it in root directory. If dataset is already downloaded, it is not\n",
      " |          downloaded again.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      CIFAR10\n",
      " |      torchvision.datasets.vision.VisionDataset\n",
      " |      torch.utils.data.dataset.Dataset\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Args:\n",
      " |          index (int): Index\n",
      " |      \n",
      " |      Returns:\n",
      " |          tuple: (image, target) where target is index of the target class.\n",
      " |  \n",
      " |  __init__(self, root, train=True, transform=None, target_transform=None, download=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  download(self)\n",
      " |  \n",
      " |  extra_repr(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  base_folder = 'cifar-10-batches-py'\n",
      " |  \n",
      " |  filename = 'cifar-10-python.tar.gz'\n",
      " |  \n",
      " |  meta = {'filename': 'batches.meta', 'key': 'label_names', 'md5': '5ff9...\n",
      " |  \n",
      " |  test_list = [['test_batch', '40351d587109b95175f43aff81a1287e']]\n",
      " |  \n",
      " |  tgz_md5 = 'c58f30108f718f92721af3b95e74349a'\n",
      " |  \n",
      " |  train_list = [['data_batch_1', 'c99cafc152244af753f735de768cd75f'], ['...\n",
      " |  \n",
      " |  url = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torchvision.datasets.vision.VisionDataset:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __add__(self, other)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.utils.data.dataset.Dataset:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tvOKSCLssj51"
   },
   "source": [
    "#Define a Convolutional Neural Network \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fw_c1dJ-q6PT"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "      \"\"\"\n",
    "      This is your network. Here you will define all the layers of the network.\n",
    "      In this example : conv1: first convolutional layer.\n",
    "                        pool : the pooling function you want to use (you can use several pooling functions)\n",
    "                        fc1 : the first fully connected layer.\n",
    "      \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(1176, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "      '''\n",
    "      make the forward computation \n",
    "      x : the normalised data (this is a batch of images, ie a 4D tensor)\n",
    "      '''\n",
    "        # first layer : convolution then relu then pooling function\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # flatten the matrix before passing into the first fc layer\n",
    "        x = x.view(-1, 6 * 14 * 14)\n",
    "        # second layer : fc then relu\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "\n",
    "def count_parameters(model):\n",
    "  '''\n",
    "  counts the number of parameters in yout model. Please do not touch to this function\n",
    "  '''\n",
    "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fz0jFpkSrKfN"
   },
   "source": [
    "# Define a Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QLYbIlngsAQb"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lzBhJMqRsEmT"
   },
   "source": [
    "#Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2lCz447zsKgS"
   },
   "outputs": [],
   "source": [
    "nepochs = 1\n",
    "\n",
    "for epoch in range(nepochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L3m7OkcesNUj"
   },
   "source": [
    "#Test the network on the test data : DO NOT TOUCH THIS PART\n",
    "\n",
    "---\n",
    "\n",
    "Your trained network is tested and the result is sent to the eki platform : \n",
    "http://eki-hackathon.herokuapp.com/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NT1bFBFesQz7"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "trainable_parameters = count_parameters(net)\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    accuracy))\n",
    "\n",
    "print(\"number of trainable parameters : %d\"%trainable_parameters)\n",
    "\n",
    "score = accuracy if accuracy <= 60. else 60. + 40 * np.tanh(10000/trainable_parameters)\n",
    "print(score)\n",
    "\n",
    "requests.put(\n",
    "  'http://eki-hackathon.herokuapp.com/submitScoreAndMetrics', \n",
    "  json={\n",
    "    'id': token,\n",
    "    'score': score,\n",
    "    'metrics': {\"trainable parameters\": trainable_parameters,\n",
    "                \"accuracy\" : accuracy}\n",
    "  })\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "remote_ekiHackhaton.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
