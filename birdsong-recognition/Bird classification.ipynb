{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import _pickle as pickle\n",
    "def save(file,name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'wb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'wb')\n",
    "    pickle.dump(file, outfile)\n",
    "    outfile.close\n",
    "    \n",
    "def load(name, folder = \"\"):\n",
    "    if folder != \"\":\n",
    "        outfile = open('./'+folder+'/'+name+'.pickle', 'rb')\n",
    "    else:\n",
    "        outfile = open(name+'.pickle', 'rb')\n",
    "    file = pickle.load(outfile)\n",
    "    outfile.close\n",
    "    return file\n",
    "\n",
    "import noisereduce as nr\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from multiprocess import Pool\n",
    "import gc\n",
    "import librosa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "\n",
    "import simpleaudio as sa\n",
    "\n",
    "from scipy.signal import resample\n",
    "\n",
    "(dico_bird_label, dico_label_bird) = load('dico_labels')\n",
    "\n",
    "def bird_to_label(labels):\n",
    "    y = np.zeros((len(labels), len(dico_label_bird.keys())))\n",
    "    \n",
    "    for i,elt in enumerate(labels):\n",
    "        list_bird = elt.split(' ')\n",
    "        for bird in list_bird:\n",
    "            try:\n",
    "                y[i, dico_bird_label[bird]] = 1\n",
    "            except:\n",
    "                1\n",
    "    return y\n",
    "\n",
    "def label_to_bird(y, tres):\n",
    "    labels = list(np.zeros(len(y)))\n",
    "    \n",
    "    for i, elt in enumerate(y):\n",
    "        text = []\n",
    "        for j, elt1 in enumerate(elt):\n",
    "            if elt1 >= tres:\n",
    "                text.append(dico_label_bird[j])\n",
    "        text = \" \".join(text)\n",
    "        if text == \"\":\n",
    "            text = 'nocall'\n",
    "        labels[i] = text\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydub \n",
    "import numpy as np\n",
    "\n",
    "def read(f, normalized=False):\n",
    "    \"\"\"MP3 to numpy array\"\"\"\n",
    "    a = pydub.AudioSegment.from_mp3(f)\n",
    "    y = np.array(a.get_array_of_samples())\n",
    "    if a.channels == 2:\n",
    "        y = y.reshape((-1, 2))\n",
    "        \n",
    "        if y[:,1].max() > y[:,0].max():\n",
    "            y = y[:,1]\n",
    "        else:\n",
    "            y = y[:,0]\n",
    "        \n",
    "    if normalized:\n",
    "        return a.frame_rate, np.float32(y) / 2**15\n",
    "    else:\n",
    "        return a.frame_rate, y\n",
    "\n",
    "def write(f, sr, x, normalized=False):\n",
    "    \"\"\"numpy array to MP3\"\"\"\n",
    "    channels = 2 if (x.ndim == 2 and x.shape[1] == 2) else 1\n",
    "    if normalized:  # normalized array - each item should be a float in [-1, 1)\n",
    "        y = np.int16(x * 2 ** 15)\n",
    "    else:\n",
    "        y = np.int16(x)\n",
    "    song = pydub.AudioSegment(y.tobytes(), frame_rate=sr, sample_width=2, channels=channels)\n",
    "    song.export(f, format=\"mp3\", bitrate=\"320k\")\n",
    "    \n",
    "# audio_file = 'XC2628.mp3'\n",
    "# sr, x = read(audio_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning to load and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr1, x1 = read('adfly_XC2628.mp3')\n",
    "sr2, x2 = read('amebit_XC127371.mp3')\n",
    "sr3, x3 = read('Bullori.mp3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_creneau(x):\n",
    "    cr = np.zeros(len(x))\n",
    "    \n",
    "    windows = 0.5\n",
    "    period = int(44100*windows)\n",
    "    seconds = int(len(x)/(44100*windows))\n",
    "    for elt in range(seconds):\n",
    "        if x[elt*period:(elt+1)*period].max()>2500:\n",
    "            cr[elt*period:(elt+1)*period] = 1\n",
    "    return cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = x2.astype('float')\n",
    "sr = sr1\n",
    "reduced_noise = nr.reduce_noise(audio_clip=clip, noise_clip=clip, verbose=False)\n",
    "creneau = build_creneau(reduced_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(range(len(clip)))/sr, clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(range(len(reduced_noise)))/sr\n",
    "plt.plot(a, reduced_noise)\n",
    "# plt.plot(a, np.ones(len(a))*2500)\n",
    "plt.plot(a, creneau*5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting individual bird samples on 0.5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(element):\n",
    "    import pydub \n",
    "    import numpy as np\n",
    "\n",
    "    def read(f, normalized=False):\n",
    "        \"\"\"MP3 to numpy array\"\"\"\n",
    "        a = pydub.AudioSegment.from_mp3(f)\n",
    "        y = np.array(a.get_array_of_samples())\n",
    "        if a.channels == 2:\n",
    "            y = y.reshape((-1, 2))\n",
    "\n",
    "            if y[:,1].max() > y[:,0].max():\n",
    "                y = y[:,1]\n",
    "            else:\n",
    "                y = y[:,0]\n",
    "\n",
    "        if normalized:\n",
    "            return a.frame_rate, np.float32(y) / 2**15\n",
    "        else:\n",
    "            return a.frame_rate, y\n",
    "\n",
    "    def write(f, sr, x, normalized=False):\n",
    "        \"\"\"numpy array to MP3\"\"\"\n",
    "        channels = 2 if (x.ndim == 2 and x.shape[1] == 2) else 1\n",
    "        if normalized:  # normalized array - each item should be a float in [-1, 1)\n",
    "            y = np.int16(x * 2 ** 15)\n",
    "        else:\n",
    "            y = np.int16(x)\n",
    "        song = pydub.AudioSegment(y.tobytes(), frame_rate=sr, sample_width=2, channels=channels)\n",
    "        song.export(f, format=\"mp3\", bitrate=\"320k\")\n",
    "    \n",
    "    import noisereduce as nr\n",
    "    import time\n",
    "    from copy import deepcopy\n",
    "    try:\n",
    "        label = []\n",
    "        X = []\n",
    "        bird = element[0]\n",
    "        file = element[1]\n",
    "        title  = bird\n",
    "        sr1, x1 = read('./train_audio/'+str(bird)+'/'+str(file))\n",
    "        clip = x1.astype('float')\n",
    "        reduced_noise = nr.reduce_noise(audio_clip=clip, noise_clip=clip, verbose=False)\n",
    "\n",
    "        x1 = deepcopy(reduced_noise)\n",
    "\n",
    "        treshold = 2500\n",
    "\n",
    "        windows = 0.5\n",
    "        period = int(44100*windows)\n",
    "        seconds = int(len(x1)/(44100*windows))\n",
    "        for elt in range(seconds):\n",
    "\n",
    "            if x1[elt*period:(elt+1)*period].max() < treshold/4:\n",
    "                label.append('noise')\n",
    "                X.append(x1[elt*period:(elt+1)*period])\n",
    "\n",
    "        cond = True\n",
    "        count = 0\n",
    "        passe = 100\n",
    "        for i in range(1,int(len(x1)/passe-period/passe)):\n",
    "            if cond == True:\n",
    "                if x1[passe*i-100:passe*i].max() >= treshold:\n",
    "                    X.append(x1[passe*i - 5000:passe*i - 5000 + period])\n",
    "                    label.append(title)\n",
    "                    cond = False\n",
    "                    count = 0\n",
    "            count += passe\n",
    "            if count >= period:\n",
    "                cond = True\n",
    "    except:\n",
    "        label = []\n",
    "        X = []\n",
    "            \n",
    "        \n",
    "    return (label, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building a dataset of noises:\n",
    "import gc\n",
    "for bird in tqdm(os.listdir('./train_audio')[54:]):\n",
    "    title = bird\n",
    "    \n",
    "    print(bird)\n",
    "    \n",
    "    p = Pool(6)\n",
    "#     bird = 'aldfly'\n",
    "    \n",
    "    listing = [(bird, elt) for elt in os.listdir('./train_audio/'+str(bird))]\n",
    "    \n",
    "    results = p.map(f, listing)\n",
    "    p.close()\n",
    "    X = []\n",
    "    label = []\n",
    "\n",
    "    for elt in results:\n",
    "        for elt1 in elt[0]:\n",
    "            label.append(elt1)\n",
    "        for elt2 in elt[1]:\n",
    "            X.append(elt2)\n",
    "    \n",
    "    df = pd.DataFrame({'label' : label, 'audio' : X})\n",
    "    save(df, title, 'raw_data')\n",
    "    \n",
    "    del X\n",
    "    del label\n",
    "    del df\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('./train_audio')[54:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer(x):\n",
    "    return x.astype('int32')\n",
    "\n",
    "def shape(x):\n",
    "    return x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load('aldfly', 'raw_data')\n",
    "print(df.shape)\n",
    "df['shape'] = df['audio'].apply(shape)\n",
    "# df['audio'] = df['audio'].apply(integer)\n",
    "df = df[df['shape'] != 0]\n",
    "df = df[df['label'] == 'aldfly']\n",
    "print(df.shape)\n",
    "save(df, 'aldfly')\n",
    "\n",
    "# del df\n",
    "# import gc\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birdname = 'aldfly'\n",
    "\n",
    "def f(birdname):\n",
    "    import pandas as pd\n",
    "    import _pickle as pickle\n",
    "    def save(file,name, folder = \"\"):\n",
    "        if folder != \"\":\n",
    "            outfile = open('./'+folder+'/'+name+'.pickle', 'wb')\n",
    "        else:\n",
    "            outfile = open(name+'.pickle', 'wb')\n",
    "        pickle.dump(file, outfile)\n",
    "        outfile.close\n",
    "\n",
    "    def load(name, folder = \"\"):\n",
    "        if folder != \"\":\n",
    "            outfile = open('./'+folder+'/'+name+'.pickle', 'rb')\n",
    "        else:\n",
    "            outfile = open(name+'.pickle', 'rb')\n",
    "        file = pickle.load(outfile)\n",
    "        outfile.close\n",
    "        return file\n",
    "    \n",
    "    def shape(x):\n",
    "        return x.shape[0]\n",
    "    \n",
    "    birdname = birdname.replace('.pickle', '')\n",
    "    df = load(birdname, 'raw_data1')\n",
    "    df['shape'] = df['audio'].apply(shape)\n",
    "    df = df[df['shape'] != 0]\n",
    "    df_noise = df[df['label'] == 'noise'].sample(n = 150)\n",
    "    df_bird = df[df['label'] == birdname]\n",
    "    df_bird = df_bird.sample(n = min(600, df_bird.shape[0]))\n",
    "\n",
    "    save(df_bird, birdname, 'raw_data')\n",
    "    save(df_noise, 'noise_'+str(birdname), 'noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Pool(6)\n",
    "p.map(f, os.listdir('./raw_data1'))\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a first dataset made of individual sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "\n",
    "\n",
    "for elt in tqdm(os.listdir('noise')):\n",
    "    df1 = load(elt.replace('.pickle', ''), 'noise')\n",
    "    df1 = df1.sample(n=100)\n",
    "    df.append(df1)\n",
    "    \n",
    "df = pd.concat(df)\n",
    "\n",
    "save(df, 'noise_100', 'datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "\n",
    "\n",
    "for elt in tqdm(os.listdir('raw_data')):\n",
    "    df1 = load(elt.replace('.pickle', ''), 'raw_data')\n",
    "    df1 = df1.sample(n=250, replace = True)\n",
    "    df.append(df1)\n",
    "    \n",
    "df = pd.concat(df)\n",
    "\n",
    "save(df, 'birds_250', 'datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = load('noise_100', 'datasets')\n",
    "df1['criterion'] = df1['audio'].apply(lambda x: x.max()/abs(x).mean())\n",
    "df1['audio'] = df1['audio'].apply(lambda x : x*random.randint(1,30))\n",
    "df1['label'] = 'nocall'\n",
    "df1  =df1.sample(n = 1500)\n",
    "print(df1['label'].unique())\n",
    "# df = pd.concat([load('noise_100', 'datasets'), load('birds_100', 'datasets')])\n",
    "df = load('birds_250', 'datasets')\n",
    "df['audio'] = df['audio'].apply(lambda x : x*random.uniform(0.3,2))\n",
    "\n",
    "df = pd.concat([df, df1])\n",
    "\n",
    "df = df.sample(n = df.shape[0])\n",
    "df = df[['label', 'audio']]\n",
    "\n",
    "del df1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([np.array(x) for x in df['audio'].values])\n",
    "Y = df['label'].values\n",
    "\n",
    "y = np_utils.to_categorical(Y)\n",
    "y = bird_to_label(Y)\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = []\n",
    "for elt in tqdm(X):\n",
    "    mfccs = librosa.feature.mfcc(y=elt, sr=44100, n_mfcc=64)\n",
    "    \n",
    "    melspec = librosa.feature.melspectrogram(elt, sr=44100, n_mels = 64)\n",
    "    melspec = librosa.power_to_db(melspec)\n",
    "    \n",
    "    chroma = librosa.feature.chroma_stft(y = elt, n_chroma = 64)\n",
    "    \n",
    "    temp = np.zeros((mfccs.shape[0], mfccs.shape[1], 3))\n",
    "    temp[:,:,0] = mfccs\n",
    "    temp[:,:,1] = melspec\n",
    "    temp[:,:,2] = chroma\n",
    "    \n",
    "    X1.append(temp)\n",
    "X = np.array(X1)\n",
    "\n",
    "del X1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(X[:33000], 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = load('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:33000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(X[:33000], 'dataset_with_features1')\n",
    "save(X[33000:], 'dataset_with_features2')\n",
    "save((Y, y), 'dataset_with_features_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([load('dataset_with_features1'), load('dataset_with_features2')], axis = 0)\n",
    "Y, y =load('dataset_with_features_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class audio_file_generator:\n",
    "    def __init__(self, \n",
    "                noise_min = 0.001,\n",
    "                noise_max = 0.015,\n",
    "                noise_p = 0.5,\n",
    "                stretch_min_rate = 0.8,\n",
    "                stretch_max_rate = 1.25,\n",
    "                stretch_p = 0.5,\n",
    "                pitch_min_semitones = -4,\n",
    "                pitch_max_semitones = 4,\n",
    "                pitch_p = 0.5,\n",
    "                shift_min_fraction = -0.5,\n",
    "                shift_max_fraction = 0.5,\n",
    "                shift_p = 0.5,\n",
    "                SAMPLE_RATE = 44100\n",
    "                ):\n",
    "        from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\n",
    "        import librosa\n",
    "        self.augmenter = Compose([\n",
    "                AddGaussianNoise(min_amplitude=noise_min, max_amplitude=noise_max, p=noise_p),\n",
    "                TimeStretch(min_rate=stretch_min_rate, max_rate=stretch_max_rate, p=stretch_p),\n",
    "                PitchShift(min_semitones=pitch_min_semitones, max_semitones=pitch_max_semitones, p=pitch_p),\n",
    "                Shift(min_fraction=shift_min_fraction, max_fraction=shift_max_fraction, p=shift_p),\n",
    "            ])\n",
    "        self.sample_rate = SAMPLE_RATE\n",
    "        \n",
    "    def get_batch(self, file, label, batch_size):\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        \n",
    "        batch_paths  = np.random.choice(a    = range(len(file)), \n",
    "                                          size = batch_size)\n",
    "        \n",
    "        for elt in batch_paths:\n",
    "            sound = np.array(file[elt])\n",
    "            sound_aug = self.augmenter(samples=sound, sample_rate=self.sample_rate)\n",
    "            mfccs = librosa.feature.mfcc(y=sound_aug, sr=44100, n_mfcc=44)\n",
    "            mfccs = mfccs.reshape(mfccs.shape[0], mfccs.shape[1], 1)\n",
    "            batch_x.append(mfccs)\n",
    "            batch_y.append(label[elt])\n",
    "        batch_x = np.array(batch_x)\n",
    "        batch_y = np.array(batch_y)\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    def flow(self, file, label, batch_size):\n",
    "        while True:\n",
    "            batch_x = []\n",
    "            batch_y = []\n",
    "\n",
    "            batch_paths  = np.random.choice(a    = range(len(file)), \n",
    "                                              size = batch_size)\n",
    "\n",
    "            for elt in batch_paths:\n",
    "                sound = np.array(file[elt])\n",
    "                sound_aug = self.augmenter(samples=sound, sample_rate=self.sample_rate)\n",
    "                mfccs = librosa.feature.mfcc(y=sound_aug, sr=44100, n_mfcc=44)\n",
    "                mfccs = mfccs.reshape(mfccs.shape[0], mfccs.shape[1], 1)\n",
    "                batch_x.append(mfccs)\n",
    "                batch_y.append(label[elt])\n",
    "            batch_x = np.array(batch_x)\n",
    "            batch_y = np.array(batch_y)\n",
    "\n",
    "            yield( batch_x, batch_y )\n",
    "        \n",
    "    def valid_generator(self, file, label):\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        batch_size = len(file)\n",
    "        batch_paths  = range(len(file))\n",
    "        \n",
    "        for elt in batch_paths:\n",
    "            sound = np.array(file[elt])\n",
    "#             sound_aug = augmenter(samples=sound, sample_rate=self.sample_rate)\n",
    "            mfccs = librosa.feature.mfcc(y=sound, sr=44100, n_mfcc=44)\n",
    "            mfccs = mfccs.reshape(mfccs.shape[0], mfccs.shape[1], 1)\n",
    "            batch_x.append(mfccs)\n",
    "            batch_y.append(label[elt])\n",
    "        batch_x = np.array(batch_x)\n",
    "        batch_y = np.array(batch_y)\n",
    "        \n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = audio_file_generator()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = aug.valid_generator(file = X_test, label = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X\n",
    "del y\n",
    "del Y\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resnet\n",
    "build = resnet.ResnetBuilder()\n",
    "model = build.build_resnet_12((64,44,3),265)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "optimizer = SGD(0.0001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "stop = tensorflow.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0.001, patience=6, verbose=1, mode='auto',\n",
    "    baseline=None, restore_best_weights=True\n",
    ")\n",
    "reduce = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, \n",
    "                                                     mode='auto', min_delta=0.0001, cooldown=0, min_lr=0.0001)\n",
    "\n",
    "import time\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "t0 = time.time()\n",
    "# history = model.fit_generator(aug.flow(X_train, y_train, batch_size=batch_size),\n",
    "#     validation_data=(X_test, y_test), steps_per_epoch=len(X_train) // batch_size,\n",
    "#     epochs=epochs, callbacks = [stop, reduce])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test),  epochs=epochs, callbacks = [stop, reduce])\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(t1-t0)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_5_accuracy(true, pred):\n",
    "    pred = np.argsort(pred, axis = 1)[:,-5:]\n",
    "    n1 = 0\n",
    "    n2 = 0\n",
    "    \n",
    "    for i, elt in enumerate(true):\n",
    "        if elt in pred[i]:\n",
    "            n1 += 1\n",
    "        n2 += 1\n",
    "        \n",
    "    return n1/n2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints/resnet for label/check')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = np.argmax(y_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_accuracy(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(confusion_matrix(true, pred), cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(true, pred, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(true == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(true == 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(confusion_matrix(true, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create fake samples of 5 seconds with between 0 and 3 bird call and between 1 and call per bird type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_noise = load('noise_100', 'datasets')\n",
    "df_birds = load('birds_250', 'datasets')\n",
    "\n",
    "noises = np.array([x for x in df_noise['audio'].values]).astype('int32')\n",
    "\n",
    "del df_noise\n",
    "\n",
    "bird_list = df_birds['label'].unique()\n",
    "\n",
    "dico_bird = {}\n",
    "for elt in tqdm(bird_list):\n",
    "    dico_bird[elt] = np.array([x for x in df_birds[df_birds['label'] == elt]['audio'].values]).astype('int32')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_bird['aldfly'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save((noises, dico_bird, bird_list), 'samples_for_creation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(noises, dico_bird, bird_list) = load('samples_for_creation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "44100*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(0,5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.randint(0,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(bird_list, 3).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_sample():\n",
    "    ## create a first sample with noise\n",
    "    noise_size = len(noises)\n",
    "    ind = np.random.randint(0, noise_size - 1 , 10)\n",
    "    \n",
    "    sample = np.concatenate([noises[i] for i in ind])\n",
    "    \n",
    "    ## Chosing the number of birds to play\n",
    "    n_birds = random.randint(0,4)\n",
    "    \n",
    "    bird_names = np.random.choice(bird_list, n_birds).astype(str)\n",
    "    \n",
    "    label = ' '.join([bird for bird in bird_names])\n",
    "    if label == '':\n",
    "        label = 'nocall'\n",
    "        \n",
    "    for bird in bird_names:\n",
    "        ## define the number of calls of the given bird\n",
    "        n_calls = random.choice([1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,4])\n",
    "        \n",
    "        for calls in range(n_calls):\n",
    "            c = random.choice(dico_bird[bird])\n",
    "            \n",
    "            start = random.randint(0,len(sample) - len(c))\n",
    "            \n",
    "            sample[start:start+len(c)] = sample[start:start+len(c)] + c\n",
    "    \n",
    "    ## Building features of the sample\n",
    "    sample = sample.astype('float')\n",
    "    \n",
    "    mfccs = librosa.feature.mfcc(y=sample, sr=44100, n_mfcc=64)\n",
    "    melspec = librosa.feature.melspectrogram(sample, sr=44100, n_mels = 64)\n",
    "    melspec = librosa.power_to_db(melspec)    \n",
    "    chroma = librosa.feature.chroma_stft(y = sample, n_chroma = 64)\n",
    "    \n",
    "    feature = np.zeros((mfccs.shape[0], mfccs.shape[1], 3))\n",
    "    feature[:,:,0] = mfccs\n",
    "    feature[:,:,1] = melspec\n",
    "    feature[:,:,2] = chroma\n",
    "    \n",
    "    return sample.astype(int), label, feature\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resnet\n",
    "build = resnet.ResnetBuilder()\n",
    "model = build.build_resnet_12((64,44,3),265)\n",
    "model.load_weights('./checkpoints/resnet for label/check')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(audio):\n",
    "#     features = []\n",
    "#     windows = []\n",
    "#     for i in tqdm(range(19)):\n",
    "#         sample = audio[11025*i : 11025*i + 22050]\n",
    "#         if sample.max() >= 2500:\n",
    "#             sample = sample.astype('float')\n",
    "#             windows.append((11025*i, 11025*i + 22050))\n",
    "#             mfccs = librosa.feature.mfcc(y=sample, sr=44100, n_mfcc=64)\n",
    "#             melspec = librosa.feature.melspectrogram(sample, sr=44100, n_mels = 64)\n",
    "#             melspec = librosa.power_to_db(melspec)    \n",
    "#             chroma = librosa.feature.chroma_stft(y = sample, n_chroma = 64)\n",
    "\n",
    "#             feature = np.zeros((mfccs.shape[0], mfccs.shape[1], 3))\n",
    "#             feature[:,:,0] = mfccs\n",
    "#             feature[:,:,1] = melspec\n",
    "#             feature[:,:,2] = chroma\n",
    "#             features.append(feature)\n",
    "#     features = np.array(features)\n",
    "#     pred = model.predict(features)\n",
    "#     return pred, windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(audio):      \n",
    "    \n",
    "    features = []\n",
    "    windows1 = []\n",
    "    x1 = audio\n",
    "    treshold = 2000    \n",
    "    windows = 0.5\n",
    "    period = int(44100*windows)\n",
    "    seconds = int(len(x1)/(44100*windows))\n",
    "    offset = 5000\n",
    "\n",
    "    count = 0\n",
    "    passe = 100\n",
    "    cond = True\n",
    "    for i in tqdm(range(int(offset/passe)+1,int((len(audio) - period + 5000)/passe) )):\n",
    "        if cond == True:\n",
    "            if audio[passe*i-100:passe*i].max() >= treshold:\n",
    "                sample = audio[passe*i - offset:passe*i - offset + period].astype(float)\n",
    "                windows1.append((passe*i - offset,passe*i - offset + period))\n",
    "                mfccs = librosa.feature.mfcc(y=sample, sr=44100, n_mfcc=64)\n",
    "                melspec = librosa.feature.melspectrogram(sample, sr=44100, n_mels = 64)\n",
    "                melspec = librosa.power_to_db(melspec)    \n",
    "                chroma = librosa.feature.chroma_stft(y = sample, n_chroma = 64)\n",
    "\n",
    "                feature = np.zeros((mfccs.shape[0], mfccs.shape[1], 3))\n",
    "                feature[:,:,0] = mfccs\n",
    "                feature[:,:,1] = melspec\n",
    "                feature[:,:,2] = chroma\n",
    "                features.append(feature)\n",
    "                \n",
    "                cond = False\n",
    "                count = 0\n",
    "        count += passe\n",
    "        if count >= period:\n",
    "            cond = True\n",
    "    features = np.array(features)\n",
    "    pred = model.predict(features)\n",
    "    return pred, windows1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, label, feature1 = generate_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(row, label38, data, features38) = load('validation_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 36\n",
    "sample = data[ind]\n",
    "label = label38[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, windows = predict(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_windows(wind):\n",
    "    x = []\n",
    "    for elt in wind:\n",
    "        s = np.zeros(len(sample))\n",
    "        s[elt[0]:elt[1]] = 1\n",
    "        x.append(s)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind = add_windows(windows)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(sample)\n",
    "\n",
    "for elt in wind:\n",
    "    plt.plot(elt*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_bird_softmax(y):\n",
    "    labels = list(np.zeros(len(y)))\n",
    "    y1 = np.argmax(y,axis = -1)\n",
    "    for i, elt in enumerate(y1):\n",
    "        labels[i] = dico_label_bird[elt]\n",
    "    \n",
    "    return labels, y.max(axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label1, proba = label_to_bird_softmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, elt in enumerate(label1):\n",
    "    print(elt + '      '+str(proba[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(feature[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(feature[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(feature[:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import simpleaudio as sa\n",
    "fs = 44100\n",
    "play_obj = sa.play_buffer(sample, 1, 2, fs)\n",
    "play_obj.wait_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(10)):\n",
    "    sample, label, feature = generate_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "size = 1000\n",
    "t0 = time.time()\n",
    "X = list(np.zeros(size))\n",
    "y = list(np.zeros(size))\n",
    "\n",
    "for i in tqdm(range(size)):\n",
    "    sample, label, feature = generate_sample()\n",
    "    X[i] = feature\n",
    "    y[i] = label\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save((X, y), 'testing_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(4,17)):\n",
    "    size = 6000\n",
    "    X = list(np.zeros(size))\n",
    "    y = list(np.zeros(size))\n",
    "    for j in tqdm(range(size)):\n",
    "        sample, label, feature = generate_sample()\n",
    "        X[j] = feature\n",
    "        y[j] = label\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    save((X, y), 'D:/bird_recognition/dataset/batch_'+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation du set de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(f, normalized=False):\n",
    "    \"\"\"MP3 to numpy array\"\"\"\n",
    "    a = pydub.AudioSegment.from_mp3(f)\n",
    "    y = np.array(a.get_array_of_samples())\n",
    "    if a.channels == 2:\n",
    "        y = y.reshape((-1, 2))\n",
    "        \n",
    "        if y[:,1].max() > y[:,0].max():\n",
    "            y = y[:,1]\n",
    "        else:\n",
    "            y = y[:,0]\n",
    "        \n",
    "    if normalized:\n",
    "        return a.frame_rate, np.float32(y) / 2**15\n",
    "    else:\n",
    "        return a.frame_rate, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = './example_test_audio/BLKFR-10-CPL_20190611_093000.pt540.mp3'\n",
    "audio1 = './example_test_audio/ORANGE-7-CAP_20190606_093000.pt623.mp3'\n",
    "\n",
    "sr, sample = read(audio1, normalized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_set():\n",
    "    df = pd.read_csv('test_example.csv')\n",
    "    \n",
    "    row = []\n",
    "    label = []\n",
    "    data = []\n",
    "    features = []\n",
    "    \n",
    "    \n",
    "    for ids in df['audio_id'].unique():\n",
    "        \n",
    "        if ids == 'ORANGE-7-CAP_20190606_093000':\n",
    "            \n",
    "            df1 = df[df['audio_id'] == ids]\n",
    "            \n",
    "            sr, sample = read('./example_test_audio/'+ids+'.mp3')\n",
    "            sample = sample - sample.mean()\n",
    "            sample = sample*30000/sample.max()\n",
    "            \n",
    "            ## resample the data\n",
    "            duration = len(sample) / sr\n",
    "            new_duration = duration * 44100\n",
    "            \n",
    "            sample = resample(sample.astype(int), int(new_duration))\n",
    "            \n",
    "            sr = 44100\n",
    "            ## clean\n",
    "            clip = sample.astype(float)\n",
    "            reduced_noise = nr.reduce_noise(audio_clip=clip, noise_clip=clip, verbose=False)\n",
    "            \n",
    "            ## cut and build features\n",
    "            for i, line in df1.iterrows():\n",
    "                row.append(line['row_id'])\n",
    "                label.append(line['labels'])\n",
    "                \n",
    "                seconds = line['seconds']\n",
    "                \n",
    "                s = reduced_noise[(seconds-5)*sr:seconds*sr]\n",
    "                \n",
    "                if len(s) > 44100*5:\n",
    "                    s = s[-44100*5:]\n",
    "                if len(s) < 44100*5:\n",
    "                    s = np.concatenate([np.zeros(44100*5-len(s)), s])\n",
    "                \n",
    "                data.append(s)\n",
    "                ## build features\n",
    "                mfccs = librosa.feature.mfcc(y=s, sr=sr, n_mfcc=64)\n",
    "                melspec = librosa.feature.melspectrogram(s, sr=sr, n_mels = 64)\n",
    "                melspec = librosa.power_to_db(melspec)    \n",
    "                chroma = librosa.feature.chroma_stft(y = s,sr = sr, n_chroma = 64)\n",
    "\n",
    "                feature = np.zeros((mfccs.shape[0], mfccs.shape[1], 3))\n",
    "                feature[:,:,0] = mfccs\n",
    "                feature[:,:,1] = melspec\n",
    "                feature[:,:,2] = chroma\n",
    "                features.append(feature)\n",
    "    \n",
    "    df_data = pd.DataFrame({'row_id' : row, 'label' : label, 'signal':data, 'features' : features})\n",
    "    \n",
    "    return row, label, data, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row, label, data, features = prepare_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save((row, label, data, features), 'validation_set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the final classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dico_bird_label = {'nocall':0}\n",
    "# dico_label_bird = {0:'nocall'}\n",
    "\n",
    "# for i, elt in enumerate(bird_list):\n",
    "#     dico_bird_label[elt] = i+1\n",
    "#     dico_label_bird[i+1] = elt\n",
    "\n",
    "(dico_bird_label, dico_label_bird) = load('dico_labels')\n",
    "\n",
    "def bird_to_labels(labels):\n",
    "    y = np.zeros((len(labels), len(dico_label_bird.keys())))\n",
    "    \n",
    "    for i,elt in enumerate(labels):\n",
    "        list_bird = elt.split(' ')\n",
    "        for bird in list_bird:\n",
    "            try:\n",
    "                y[i, dico_bird_label[bird]] = 1\n",
    "            except:\n",
    "                1\n",
    "    return y\n",
    "\n",
    "def labels_to_birds(y, tres):\n",
    "    labels = list(np.zeros(len(y)))\n",
    "    \n",
    "    for i, elt in enumerate(y):\n",
    "        text = []\n",
    "        for j, elt1 in enumerate(elt):\n",
    "            if elt1 >= tres:\n",
    "                text.append(dico_label_bird[j])\n",
    "        text = \" \".join(text)\n",
    "        if text == \"\":\n",
    "            text = 'nocall'\n",
    "        labels[i] = text\n",
    "    return labels\n",
    "        \n",
    "save((dico_bird_label, dico_label_bird), 'dico_labels')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, Y) = load('./batch/batch_'+str(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = bird_to_labels(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "del X\n",
    "del y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resnet\n",
    "build = resnet.ResnetBuilder()\n",
    "model = build.build_resnet_12((64,431,3),265)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = SGD(0.1)\n",
    "import tensorflow as tf\n",
    "model.compile(loss='categorical_crossentropy',#tf.nn.sigmoid_cross_entropy_with_logits,\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "stop = tensorflow.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0.001, patience=6, verbose=1, mode='auto',\n",
    "    baseline=None, restore_best_weights=True\n",
    ")\n",
    "reduce = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, \n",
    "                                                     mode='auto', min_delta=0.0001, cooldown=0, min_lr=0.001)\n",
    "\n",
    "import time\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "t0 = time.time()\n",
    "# history = model.fit_generator(aug.flow(X_train, y_train, batch_size=batch_size),\n",
    "#     validation_data=(X_test, y_test), steps_per_epoch=len(X_train) // batch_size,\n",
    "#     epochs=epochs, callbacks = [stop, reduce])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size,\n",
    "    validation_data=(X_test, y_test),  epochs=epochs, callbacks = [stop, reduce])\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = labels_to_birds(y_test,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = labels_to_birds(pred,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, elt in enumerate(pred):\n",
    "    print(elt + '      '+true[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_wise_f1_score_micro(y_true, y_pred):\n",
    "    \"\"\" author @shonenkov \"\"\"\n",
    "    F1 = []\n",
    "    for preds, trues in zip(y_pred, y_true):\n",
    "        TP, FN, FP = 0, 0, 0\n",
    "        preds = preds.split()\n",
    "        trues = trues.split()\n",
    "        for true in trues:\n",
    "            if true in preds:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        for pred in preds:\n",
    "            if pred not in trues:\n",
    "                FP += 1\n",
    "        F1.append(2*TP / (2*TP + FN + FP))\n",
    "    return np.mean(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_wise_f1_score_micro(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(row, label, data, features) = load('validation_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = bird_to_labels(label)\n",
    "label = labels_to_birds(label, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = model.predict(np.array(features))\n",
    "pred_val = labels_to_birds(pred_val,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, elt in enumerate(pred_val):\n",
    "    print(elt + '      '+label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_wise_f1_score_micro(label, pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
